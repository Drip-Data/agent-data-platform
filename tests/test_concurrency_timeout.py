#!/usr/bin/env python3
"""
å¹¶å‘å’Œè¶…æ—¶æ§åˆ¶æµ‹è¯•
éªŒè¯è¯·æ±‚é™åˆ¶ã€è¶…æ—¶å¤„ç†å’Œç³»ç»Ÿå¥åº·ç›‘æ§åŠŸèƒ½
"""

import asyncio
import logging
import time
import unittest
from unittest.mock import AsyncMock, patch
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from mcp_servers.deepsearch_server.deepsearch_tool_unified import DeepSearchToolUnified
from mcp_servers.deepsearch_server.request_optimizer import RequestOptimizer, LLMRequest

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TestConcurrencyTimeout(unittest.TestCase):
    """å¹¶å‘å’Œè¶…æ—¶æ§åˆ¶æµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•è®¾ç½®"""
        self.config = {
            "cache_enabled": True,
            "max_concurrent_requests": 2,  # è®¾ç½®è¾ƒå°çš„å¹¶å‘é™åˆ¶ä¾¿äºæµ‹è¯•
            "default_timeout": 5.0,        # è®¾ç½®è¾ƒçŸ­çš„è¶…æ—¶ä¾¿äºæµ‹è¯•
            "batch_size": 2
        }
        
        # Mock LLMå®¢æˆ·ç«¯
        self.mock_llm_client = AsyncMock()
        self.mock_llm_client._call_api = AsyncMock()
    
    async def test_concurrent_request_limiting(self):
        """æµ‹è¯•å¹¶å‘è¯·æ±‚é™åˆ¶"""
        
        # åˆ›å»ºæ…¢å“åº”çš„mock
        async def slow_response(messages):
            await asyncio.sleep(2)  # æ¨¡æ‹Ÿæ…¢å“åº”
            return f"æ…¢å“åº”ç»“æœ: {time.time()}"
        
        with patch('mcp_servers.deepsearch_server.deepsearch_tool_unified.LLMClient') as MockLLMClient:
            mock_client = AsyncMock()
            mock_client._call_api = slow_response
            MockLLMClient.return_value = mock_client
            
            tool = DeepSearchToolUnified(self.config)
            optimizer = tool.request_optimizer
            
            # åˆ›å»ºå¤šä¸ªå¹¶å‘è¯·æ±‚
            requests = []
            for i in range(5):  # è¶…è¿‡å¹¶å‘é™åˆ¶çš„è¯·æ±‚æ•°
                request = LLMRequest(
                    task_type="test",
                    prompt=f"å¹¶å‘æµ‹è¯•è¯·æ±‚ {i}",
                    priority=1,
                    timeout=10.0
                )
                requests.append(request)
            
            # å¹¶å‘æ‰§è¡Œè¯·æ±‚
            start_time = time.time()
            tasks = [optimizer.execute_request(req) for req in requests]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            execution_time = time.time() - start_time
            
            # éªŒè¯ç»“æœ
            self.assertEqual(len(results), 5)
            
            # æ£€æŸ¥ç»Ÿè®¡ä¿¡æ¯
            stats = optimizer.get_stats()
            logger.info(f"âœ… å¹¶å‘é™åˆ¶æµ‹è¯•å®Œæˆ")
            logger.info(f"   - æ‰§è¡Œæ—¶é—´: {execution_time:.2f}s")
            logger.info(f"   - å¹¶å‘é™åˆ¶å‘½ä¸­æ¬¡æ•°: {stats['concurrent_limit_hits']}")
            logger.info(f"   - æœ€å¤§å¹¶å‘è¾¾åˆ°: {stats['max_concurrent_reached']}")
            
            # éªŒè¯å¹¶å‘é™åˆ¶ç”Ÿæ•ˆ
            self.assertLessEqual(stats['max_concurrent_reached'], self.config['max_concurrent_requests'])
    
    async def test_timeout_handling(self):
        """æµ‹è¯•è¶…æ—¶å¤„ç†"""
        
        # åˆ›å»ºè¶…æ—¶å“åº”çš„mock
        async def timeout_response(messages):
            await asyncio.sleep(10)  # è¶…è¿‡é…ç½®çš„è¶…æ—¶æ—¶é—´
            return "æ°¸è¿œä¸ä¼šè¿”å›çš„ç»“æœ"
        
        with patch('mcp_servers.deepsearch_server.deepsearch_tool_unified.LLMClient') as MockLLMClient:
            mock_client = AsyncMock()
            mock_client._call_api = timeout_response
            MockLLMClient.return_value = mock_client
            
            tool = DeepSearchToolUnified(self.config)
            optimizer = tool.request_optimizer
            
            # åˆ›å»ºä¼šè¶…æ—¶çš„è¯·æ±‚
            request = LLMRequest(
                task_type="timeout_test",
                prompt="è¿™ä¸ªè¯·æ±‚ä¼šè¶…æ—¶",
                priority=1,
                timeout=2.0  # çŸ­è¶…æ—¶æ—¶é—´
            )
            
            # æ‰§è¡Œè¯·æ±‚å¹¶æœŸå¾…è¶…æ—¶
            start_time = time.time()
            with self.assertRaises(TimeoutError):
                await optimizer.execute_request(request)
            
            execution_time = time.time() - start_time
            
            # éªŒè¯è¶…æ—¶æ—¶é—´åˆç†
            self.assertLess(execution_time, 5.0)  # åº”è¯¥åœ¨è¶…æ—¶æ—¶é—´å†…å¤±è´¥
            
            # æ£€æŸ¥è¶…æ—¶ç»Ÿè®¡
            stats = optimizer.get_stats()
            self.assertGreater(stats['timeout_errors'], 0)
            
            logger.info(f"âœ… è¶…æ—¶å¤„ç†æµ‹è¯•å®Œæˆ")
            logger.info(f"   - æ‰§è¡Œæ—¶é—´: {execution_time:.2f}s")
            logger.info(f"   - è¶…æ—¶é”™è¯¯æ¬¡æ•°: {stats['timeout_errors']}")
    
    async def test_health_monitoring(self):
        """æµ‹è¯•å¥åº·ç›‘æ§åŠŸèƒ½"""
        
        # åˆ›å»ºæ··åˆå“åº”çš„mockï¼ˆéƒ¨åˆ†æˆåŠŸï¼Œéƒ¨åˆ†è¶…æ—¶ï¼‰
        call_count = 0
        async def mixed_response(messages):
            nonlocal call_count
            call_count += 1
            
            if call_count % 3 == 0:  # æ¯ç¬¬3ä¸ªè¯·æ±‚è¶…æ—¶
                await asyncio.sleep(10)
                return "è¶…æ—¶å“åº”"
            else:
                await asyncio.sleep(0.1)
                return f"æ­£å¸¸å“åº” #{call_count}"
        
        with patch('mcp_servers.deepsearch_server.deepsearch_tool_unified.LLMClient') as MockLLMClient:
            mock_client = AsyncMock()
            mock_client._call_api = mixed_response
            MockLLMClient.return_value = mock_client
            
            tool = DeepSearchToolUnified(self.config)
            optimizer = tool.request_optimizer
            
            # æ‰§è¡Œå¤šä¸ªè¯·æ±‚ä»¥ç”Ÿæˆç»Ÿè®¡æ•°æ®
            requests = []
            for i in range(6):
                request = LLMRequest(
                    task_type="health_test",
                    prompt=f"å¥åº·ç›‘æ§æµ‹è¯• {i}",
                    priority=1,
                    timeout=2.0
                )
                requests.append(request)
            
            # æ‰§è¡Œè¯·æ±‚ï¼ˆæœŸå¾…éƒ¨åˆ†å¤±è´¥ï¼‰
            results = []
            for req in requests:
                try:
                    result = await optimizer.execute_request(req)
                    results.append(result)
                except TimeoutError:
                    results.append(None)  # è¶…æ—¶è¯·æ±‚
            
            # æ£€æŸ¥å¥åº·çŠ¶æ€
            health_status = optimizer.get_health_status()
            
            logger.info(f"âœ… å¥åº·ç›‘æ§æµ‹è¯•å®Œæˆ")
            logger.info(f"   - å¥åº·çŠ¶æ€: {health_status['status']}")
            logger.info(f"   - å¥åº·è¯„åˆ†: {health_status['health_score']}")
            logger.info(f"   - è¶…æ—¶ç‡: {health_status['timeout_rate_percent']}%")
            logger.info(f"   - æ´»è·ƒè¯·æ±‚: {health_status['active_requests']}")
            
            # éªŒè¯å¥åº·ç›‘æ§åŠŸèƒ½
            self.assertIn(health_status['status'], ['healthy', 'degraded', 'unhealthy'])
            self.assertIsInstance(health_status['health_score'], (int, float))
            self.assertGreaterEqual(health_status['health_score'], 0)
            self.assertLessEqual(health_status['health_score'], 100)
    
    async def test_graceful_completion_waiting(self):
        """æµ‹è¯•ä¼˜é›…çš„å®Œæˆç­‰å¾…"""
        
        # åˆ›å»ºæœ‰å»¶è¿Ÿçš„å“åº”
        async def delayed_response(messages):
            await asyncio.sleep(1)
            return f"å»¶è¿Ÿå“åº”: {time.time()}"
        
        with patch('mcp_servers.deepsearch_server.deepsearch_tool_unified.LLMClient') as MockLLMClient:
            mock_client = AsyncMock()
            mock_client._call_api = delayed_response
            MockLLMClient.return_value = mock_client
            
            tool = DeepSearchToolUnified(self.config)
            optimizer = tool.request_optimizer
            
            # å¯åŠ¨ä¸€äº›åå°è¯·æ±‚
            background_tasks = []
            for i in range(3):
                request = LLMRequest(
                    task_type="background",
                    prompt=f"åå°è¯·æ±‚ {i}",
                    priority=1
                )
                task = asyncio.create_task(optimizer.execute_request(request))
                background_tasks.append(task)
            
            # ç¨ç­‰è®©è¯·æ±‚å¼€å§‹
            await asyncio.sleep(0.5)
            
            # ç­‰å¾…æ‰€æœ‰è¯·æ±‚å®Œæˆ
            start_time = time.time()
            
            # ç›´æ¥ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            await asyncio.gather(*background_tasks, return_exceptions=True)
            
            # ç„¶åç­‰å¾…ä¼˜åŒ–å™¨æ¸…ç†
            await optimizer.wait_for_completion(timeout=5.0)
            completion_time = time.time() - start_time
            
            # éªŒè¯æ‰€æœ‰ä»»åŠ¡éƒ½å®Œæˆäº†
            all_done = all(task.done() for task in background_tasks)
            
            logger.info(f"âœ… ä¼˜é›…å®Œæˆç­‰å¾…æµ‹è¯•")
            logger.info(f"   - ç­‰å¾…æ—¶é—´: {completion_time:.2f}s")
            logger.info(f"   - æ‰€æœ‰ä»»åŠ¡å®Œæˆ: {all_done}")
            logger.info(f"   - å‰©ä½™æ´»è·ƒè¯·æ±‚: {optimizer._active_requests}")
            
            # éªŒè¯å®ŒæˆçŠ¶æ€
            self.assertTrue(all_done)
            self.assertEqual(optimizer._active_requests, 0)
    
    async def test_integration_with_deepsearch_tool(self):
        """æµ‹è¯•ä¸DeepSearchå·¥å…·çš„é›†æˆ"""
        
        # å¿«é€Ÿå“åº”çš„mock
        def quick_response(messages):
            content = messages[0]["content"]
            if "æœç´¢æŸ¥è¯¢" in content:
                return '{"queries": ["é›†æˆæµ‹è¯•æŸ¥è¯¢"], "rationale": "integration test"}'
            else:
                return "å¿«é€Ÿé›†æˆæµ‹è¯•å“åº”"
        
        with patch('mcp_servers.deepsearch_server.deepsearch_tool_unified.LLMClient') as MockLLMClient:
            mock_client = AsyncMock()
            mock_client._call_api = AsyncMock(side_effect=quick_response)
            MockLLMClient.return_value = mock_client
            
            tool = DeepSearchToolUnified(self.config)
            
            # æ‰§è¡Œç ”ç©¶ä»»åŠ¡
            result = await tool.quick_research("é›†æˆæµ‹è¯•ï¼šå¹¶å‘å’Œè¶…æ—¶æ§åˆ¶")
            
            # éªŒè¯ç»“æœåŒ…å«æ€§èƒ½ç»Ÿè®¡
            self.assertTrue(result["success"])
            self.assertIn("performance_stats", result)
            
            performance_stats = result["performance_stats"]
            self.assertIn("optimization_stats", performance_stats)
            
            # è·å–å¥åº·çŠ¶æ€
            health_status = tool.get_health_status()
            optimization_stats = tool.get_optimization_stats()
            
            logger.info(f"âœ… DeepSearchå·¥å…·é›†æˆæµ‹è¯•å®Œæˆ")
            logger.info(f"   - ç ”ç©¶æˆåŠŸ: {result['success']}")
            logger.info(f"   - å¥åº·çŠ¶æ€: {health_status.get('status', 'unknown')}")
            logger.info(f"   - ä¼˜åŒ–ç»Ÿè®¡: {optimization_stats}")
            
            # éªŒè¯é›†æˆåŠŸèƒ½
            self.assertIsInstance(health_status, dict)
            self.assertIsInstance(optimization_stats, dict)

async def run_async_tests():
    """è¿è¡Œå¼‚æ­¥æµ‹è¯•"""
    test_instance = TestConcurrencyTimeout()
    test_instance.setUp()
    
    logger.info("ğŸš€ å¼€å§‹å¹¶å‘å’Œè¶…æ—¶æ§åˆ¶æµ‹è¯•")
    
    try:
        # è¿è¡Œå„é¡¹æµ‹è¯•
        await test_instance.test_concurrent_request_limiting()
        await test_instance.test_timeout_handling()
        await test_instance.test_health_monitoring()
        await test_instance.test_graceful_completion_waiting()
        await test_instance.test_integration_with_deepsearch_tool()
        
        logger.info("ğŸ‰ æ‰€æœ‰å¹¶å‘å’Œè¶…æ—¶æ§åˆ¶æµ‹è¯•é€šè¿‡")
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        raise

if __name__ == "__main__":
    # è¿è¡Œå¼‚æ­¥æµ‹è¯•
    asyncio.run(run_async_tests())
    
    print("\nğŸ“Š å¹¶å‘å’Œè¶…æ—¶æ§åˆ¶æµ‹è¯•å®Œæˆ")