#!/usr/bin/env python3
"""
æ€§èƒ½ä¼˜åŒ–é›†æˆæµ‹è¯•
éªŒè¯å¹¶è¡Œæœç´¢ã€æ™ºèƒ½ç¼“å­˜å’Œè¯·æ±‚ä¼˜åŒ–çš„é›†æˆæ•ˆæœ
"""

import asyncio
import logging
import time
import unittest
from unittest.mock import AsyncMock, patch, MagicMock
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from mcp_servers.deepsearch_server.deepsearch_tool_unified import DeepSearchToolUnified
from mcp_servers.deepsearch_server.intelligent_cache import IntelligentCache
from mcp_servers.deepsearch_server.request_optimizer import RequestOptimizer

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TestPerformanceOptimization(unittest.TestCase):
    """æ€§èƒ½ä¼˜åŒ–é›†æˆæµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•è®¾ç½®"""
        self.config = {
            "cache_enabled": True,
            "cache_similarity_threshold": 0.7
        }
        
        # Mock LLMå®¢æˆ·ç«¯
        self.mock_llm_client = AsyncMock()
        self.mock_llm_client._call_api = AsyncMock()
        
    def test_optimization_components_integration(self):
        """æµ‹è¯•ä¼˜åŒ–ç»„ä»¶é›†æˆ"""
        # åˆ›å»ºå·¥å…·å®ä¾‹
        with patch('mcp_servers.deepsearch_server.deepsearch_tool_unified.LLMClient') as MockLLMClient:
            MockLLMClient.return_value = self.mock_llm_client
            
            tool = DeepSearchToolUnified(self.config)
            
            # éªŒè¯ç»„ä»¶åˆå§‹åŒ–
            self.assertIsNotNone(tool.cache)
            self.assertTrue(hasattr(tool, 'request_optimizer'))
            self.assertIsInstance(tool.cache, IntelligentCache)
            
            logger.info("âœ… ä¼˜åŒ–ç»„ä»¶é›†æˆæ­£å¸¸")
    
    async def test_parallel_search_performance(self):
        """æµ‹è¯•å¹¶è¡Œæœç´¢æ€§èƒ½"""
        
        # Mock LLMå“åº”
        def mock_llm_response(messages):
            """æ¨¡æ‹ŸLLMå“åº”"""
            content = messages[0]["content"]
            if "æœç´¢æŸ¥è¯¢" in content:
                # æŸ¥è¯¢ç”Ÿæˆå“åº”
                return '{"queries": ["query1", "query2", "query3"], "rationale": "test"}'
            elif "æœç´¢æŸ¥è¯¢:" in content:
                # æœç´¢æ‰§è¡Œå“åº”
                return f"æœç´¢ç»“æœ: {time.time()}"
            elif "ç»¼åˆ" in content:
                # ç­”æ¡ˆç»¼åˆå“åº”
                return "ç»¼åˆåˆ†æç»“æœ"
            else:
                return "é»˜è®¤å“åº”"
        
        with patch('mcp_servers.deepsearch_server.deepsearch_tool_unified.LLMClient') as MockLLMClient:
            mock_client = AsyncMock()
            mock_client._call_api = AsyncMock(side_effect=mock_llm_response)
            MockLLMClient.return_value = mock_client
            
            tool = DeepSearchToolUnified(self.config)
            
            # æ‰§è¡Œç ”ç©¶
            start_time = time.time()
            result = await tool.research("æµ‹è¯•å¹¶è¡Œæœç´¢æ€§èƒ½", research_depth="standard")
            execution_time = time.time() - start_time
            
            # éªŒè¯ç»“æœ
            self.assertTrue(result["success"])
            self.assertIn("performance_stats", result)
            
            performance_stats = result["performance_stats"]
            self.assertIn("parallel_search_time", performance_stats)
            self.assertIn("total_research_time", performance_stats)
            
            logger.info(f"âœ… å¹¶è¡Œæœç´¢å®Œæˆï¼Œæ€»è€—æ—¶: {execution_time:.2f}s")
            logger.info(f"   - å¹¶è¡Œæœç´¢æ—¶é—´: {performance_stats['parallel_search_time']:.2f}s")
            logger.info(f"   - æ€»ç ”ç©¶æ—¶é—´: {performance_stats['total_research_time']:.2f}s")
    
    async def test_request_optimization_effectiveness(self):
        """æµ‹è¯•è¯·æ±‚ä¼˜åŒ–æ•ˆæœ"""
        
        call_count = 0
        def counting_mock_response(messages):
            nonlocal call_count
            call_count += 1
            
            content = messages[0]["content"]
            if "æœç´¢æŸ¥è¯¢" in content:
                return '{"queries": ["opt_query1", "opt_query2"], "rationale": "optimized"}'
            else:
                return f"ä¼˜åŒ–å“åº” #{call_count}"
        
        with patch('mcp_servers.deepsearch_server.deepsearch_tool_unified.LLMClient') as MockLLMClient:
            mock_client = AsyncMock()
            mock_client._call_api = AsyncMock(side_effect=counting_mock_response)
            MockLLMClient.return_value = mock_client
            
            tool = DeepSearchToolUnified(self.config)
            
            # æ‰§è¡Œç ”ç©¶
            result = await tool.research("æµ‹è¯•è¯·æ±‚ä¼˜åŒ–", research_depth="quick")
            
            # éªŒè¯ä¼˜åŒ–ç»Ÿè®¡
            self.assertTrue(result["success"])
            performance_stats = result["performance_stats"]
            
            if "optimization_stats" in performance_stats:
                opt_stats = performance_stats["optimization_stats"]
                logger.info(f"âœ… è¯·æ±‚ä¼˜åŒ–ç»Ÿè®¡: {opt_stats}")
            
            # éªŒè¯LLMè°ƒç”¨æ¬¡æ•°ï¼ˆåº”è¯¥è¢«ä¼˜åŒ–å‡å°‘ï¼‰
            logger.info(f"   - æ€»LLMè°ƒç”¨æ¬¡æ•°: {call_count}")
            
    async def test_cache_performance_impact(self):
        """æµ‹è¯•ç¼“å­˜å¯¹æ€§èƒ½çš„å½±å“"""
        
        with patch('mcp_servers.deepsearch_server.deepsearch_tool_unified.LLMClient') as MockLLMClient:
            mock_client = AsyncMock()
            mock_client._call_api = AsyncMock(return_value="ç¼“å­˜æµ‹è¯•å“åº”")
            MockLLMClient.return_value = mock_client
            
            tool = DeepSearchToolUnified(self.config)
            
            question = "æµ‹è¯•ç¼“å­˜æ€§èƒ½å½±å“"
            
            # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
            start_time = time.time()
            result1 = await tool.quick_research(question)
            first_call_time = time.time() - start_time
            
            # ç¬¬äºŒæ¬¡è°ƒç”¨ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
            start_time = time.time()
            result2 = await tool.quick_research(question)
            second_call_time = time.time() - start_time
            
            # éªŒè¯ç»“æœ
            self.assertTrue(result1["success"])
            self.assertTrue(result2["success"])
            
            # éªŒè¯ç¼“å­˜æ•ˆæœ
            if "_cache_info" in result2.get("output", {}):
                cache_info = result2["output"]["_cache_info"]
                logger.info(f"âœ… ç¼“å­˜å‘½ä¸­: {cache_info['hit_type']}")
            
            logger.info(f"   - ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶é—´: {first_call_time:.2f}s")
            logger.info(f"   - ç¬¬äºŒæ¬¡è°ƒç”¨æ—¶é—´: {second_call_time:.2f}s")
            logger.info(f"   - æ€§èƒ½æå‡: {((first_call_time - second_call_time) / first_call_time * 100):.1f}%")
    
    async def test_comprehensive_optimization_flow(self):
        """æµ‹è¯•å®Œæ•´ä¼˜åŒ–æµç¨‹"""
        
        optimization_log = []
        
        def logging_mock_response(messages):
            content = messages[0]["content"]
            optimization_log.append(f"LLMè°ƒç”¨: {content[:50]}...")
            
            if "æœç´¢æŸ¥è¯¢" in content:
                return '{"queries": ["comprehensive1", "comprehensive2", "comprehensive3"], "rationale": "full test"}'
            elif "æœç´¢æŸ¥è¯¢:" in content:
                return "è¯¦ç»†æœç´¢ç»“æœå†…å®¹"
            elif "åˆ†æ" in content:
                return '{"is_sufficient": true, "knowledge_gap": "", "follow_up_queries": []}'
            elif "ç»¼åˆ" in content:
                return "å®Œæ•´çš„ç»¼åˆåˆ†ææŠ¥å‘Š"
            else:
                return "é€šç”¨å“åº”"
        
        with patch('mcp_servers.deepsearch_server.deepsearch_tool_unified.LLMClient') as MockLLMClient:
            mock_client = AsyncMock()
            mock_client._call_api = AsyncMock(side_effect=logging_mock_response)
            MockLLMClient.return_value = mock_client
            
            tool = DeepSearchToolUnified(self.config)
            
            # æ‰§è¡Œå®Œæ•´ç ”ç©¶æµç¨‹
            start_time = time.time()
            result = await tool.research(
                "å®Œæ•´ä¼˜åŒ–æµç¨‹æµ‹è¯•", 
                research_depth="comprehensive", 
                max_iterations=2
            )
            total_time = time.time() - start_time
            
            # éªŒè¯ç»“æœ
            self.assertTrue(result["success"])
            self.assertIn("performance_stats", result)
            
            # åˆ†æä¼˜åŒ–æ•ˆæœ
            performance_stats = result["performance_stats"]
            
            logger.info(f"âœ… å®Œæ•´ä¼˜åŒ–æµç¨‹æµ‹è¯•å®Œæˆ")
            logger.info(f"   - æ€»æ‰§è¡Œæ—¶é—´: {total_time:.2f}s")
            logger.info(f"   - LLMè°ƒç”¨åºåˆ—: {len(optimization_log)}æ¬¡")
            logger.info(f"   - æ€§èƒ½ç»Ÿè®¡: {performance_stats}")
            
            # éªŒè¯ä¼˜åŒ–ç»„ä»¶å·¥ä½œçŠ¶æ€
            cache_stats = tool.cache.get_cache_stats()
            logger.info(f"   - ç¼“å­˜ç»Ÿè®¡: {cache_stats}")

async def run_async_tests():
    """è¿è¡Œå¼‚æ­¥æµ‹è¯•"""
    test_instance = TestPerformanceOptimization()
    test_instance.setUp()
    
    logger.info("ğŸš€ å¼€å§‹æ€§èƒ½ä¼˜åŒ–é›†æˆæµ‹è¯•")
    
    try:
        # è¿è¡Œå„é¡¹æµ‹è¯•
        await test_instance.test_parallel_search_performance()
        await test_instance.test_request_optimization_effectiveness()
        await test_instance.test_cache_performance_impact()
        await test_instance.test_comprehensive_optimization_flow()
        
        logger.info("ğŸ‰ æ‰€æœ‰æ€§èƒ½ä¼˜åŒ–æµ‹è¯•é€šè¿‡")
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        raise

if __name__ == "__main__":
    # è¿è¡ŒåŒæ­¥æµ‹è¯•
    suite = unittest.TestSuite()
    suite.addTest(TestPerformanceOptimization('test_optimization_components_integration'))
    runner = unittest.TextTestRunner(verbosity=2)
    sync_result = runner.run(suite)
    
    # è¿è¡Œå¼‚æ­¥æµ‹è¯•
    asyncio.run(run_async_tests())
    
    print("\nğŸ“Š æ€§èƒ½ä¼˜åŒ–é›†æˆæµ‹è¯•å®Œæˆ")