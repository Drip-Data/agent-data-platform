# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Quick Start for New Claude Code Instances

**Critical Dependencies:**
- MicroSandbox: `pip install microsandbox` (required for all code execution)
- Redis: Must be running for task queues and memory management
- Environment: `export GEMINI_API_KEY=your_key`

**Key Architecture Points:**
- All code execution MUST go through MicroSandbox server (port 8090)
- Anti-hallucination framework prevents fake tool results via XML streaming
- ToolScore system (port 8088/8089) manages all MCP server communications
- Enhanced Runtime (`runtimes/reasoning/enhanced_runtime.py`) is the main execution engine

**Most Important Files:**
- `main.py`: System entry point
- `core/interfaces.py`: Constants and data structures (avoid hardcoding)
- `runtimes/reasoning/enhanced_runtime.py`: Core execution logic
- `core/toolscore/`: Tool management system

## Essential Commands

### Start the platform
```bash
python3 main.py
```

### Run tests
```bash
# Run all tests
python3 -m pytest tests/ -v

# Run specific test suites  
python3 -m pytest tests/test_microsandbox_*.py -v
python3 -m pytest tests/test_system_validation.py -v

# Submit test tasks
python3 scripts/batch_test_tasks.py --tasks-file tasks.jsonl
python3 scripts/batch_test_tasks.py --tasks-file data/test_tasks.jsonl
```

### Health checks
```bash
curl http://localhost:8000/health
curl http://localhost:8088/health  # ToolScore service
```

### Dependency management
```bash
# Install core dependencies
pip install -r requirements.txt

# Install MicroSandbox (critical for code execution)
pip install microsandbox

# Verify MicroSandbox installation
python3 -c "from microsandbox import PythonSandbox; print('âœ… MicroSandbox ready')"
```

## Architecture Overview

Agent Data Platform is a multi-agent AI system combining LLM reasoning with real tool execution through an anti-hallucination framework. The system prevents LLMs from generating fake tool results by implementing a "stop-and-wait" mechanism.

### Core Components

**Enhanced Runtime** (`runtimes/reasoning/enhanced_runtime.py`)
- Main execution engine with XML streaming and anti-hallucination
- Handles memory management and trajectory enhancement
- Coordinates LLM interactions with real tool execution

**ToolScore System** (`core/toolscore/`)
- Unified tool management with MCP server integration
- Dynamic tool discovery and session management
- HTTP API on port 8088, WebSocket on port 8089

**Memory & Planning**
- `MemoryManager`: Redis-based persistent session memory
- `StepPlanner`: Multi-step reasoning with adaptive planning
- Supports up to 100 execution steps for complex tasks

### MCP Tool Servers

**MicroSandbox Server** (port 8090) - Critical for code execution
- Secure Python code execution environment
- Session management with state persistence
- Package installation and dependency management

**Browser Use Server** (port 8082) - Web automation
- AI-driven browser automation with 25+ tools
- Web scraping and intelligent form filling

**DeepSearch Server** (port 8086) - Research capabilities
- Advanced search and multi-source information aggregation
- Intelligent query optimization with caching

**Search Tool Server** (port 8080) - File operations
- File system search and content pattern matching

### Data Synthesis Learning

The platform implements a "data flywheel" for continuous learning:

**Trajectory Monitoring**
- Real-time monitoring of `output/trajectories/` directory
- Automatic triggering on trajectory file modifications
- Synthesis processing delay of 2-5 minutes

**Synthesis Process**
1. Extract successful execution patterns
2. Generate atomic seed tasks from trajectories
3. Apply depth/breadth expansion for task variants
4. Multi-dimensional quality validation
5. Store validated tasks in `output/seed_tasks.jsonl`

**Output Files**
- `output/trajectories/trajectories_collection.json`: Raw execution data
- `output/seed_tasks.jsonl`: Auto-generated learning tasks
- `output/task_essences.json`: Extracted task patterns

## Development Principles

### System Requirements
- **Python**: Use `python3` not `python`
- **Platform**: macOS 15.5 compatible
- **Redis**: Required for task queues and memory management
- **MicroSandbox**: Critical dependency for secure code execution

### Code Quality Standards
- **No hardcoded values**: Use constants from `core.interfaces.TaskExecutionConstants`
- **Modular design**: Prefer editing existing files over creating new ones
- **Clean architecture**: Maintain clear separation between components
- **Anti-hallucination**: All tool execution must go through MCP servers

### Key Development Patterns
```python
# âœ… Correct: Use constants
from core.interfaces import TaskExecutionConstants
answer_tag = TaskExecutionConstants.XML_TAGS['ANSWER']

# âŒ Wrong: Hardcoded strings
if "Final Answer:" in response:
    success = True
```

### Testing Requirements
- Always run pytest before committing changes
- Test MicroSandbox integration for code execution tasks
- Verify anti-hallucination framework integrity
- Check all MCP server connections

## ç³»ç»Ÿæ¦‚è¿°

Agent Data Platform æ˜¯ä¸€ä¸ªå¤æ‚çš„å¤šæ™ºèƒ½ä½“AIç³»ç»Ÿï¼Œå®ƒå°†å¤§è¯­è¨€æ¨¡å‹(LLM)æ¨ç†ä¸çœŸå®å·¥å…·æ‰§è¡Œç›¸ç»“åˆï¼Œé€šè¿‡åå¹»è§‰æ¡†æ¶å®ç°ã€‚è¯¥ç³»ç»Ÿé€šè¿‡å®æ–½"åœæ­¢å¹¶ç­‰å¾…"æœºåˆ¶æ¥é˜²æ­¢LLMç”Ÿæˆè™šå‡çš„å·¥å…·æ‰§è¡Œç»“æœï¼ŒLLMå¿…é¡»åœ¨æ¯æ¬¡å·¥å…·è°ƒç”¨åæš‚åœå¹¶ç­‰å¾…çœŸå®çš„æ‰§è¡Œç»“æœã€‚

## æ ¸å¿ƒå¼€å‘å‘½ä»¤

### ç³»ç»Ÿå¯åŠ¨å’Œç®¡ç†
```bash
# å¯åŠ¨æ•´ä¸ªå¹³å° (åŒ…å«ç«¯å£æ¸…ç†)
python3 main.py

# æ£€æŸ¥ç³»ç»Ÿå¥åº·çŠ¶æ€
curl http://localhost:8000/health

# æ‰‹åŠ¨æ¸…ç†ç«¯å£ (å¦‚éœ€è¦)
python3 utility/cleanup_ports.py
```

### æµ‹è¯•
```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python3 -m pytest tests/ -v

# è¿è¡Œç‰¹å®šæµ‹è¯•å¥—ä»¶
python3 -m pytest tests/test_microsandbox_*.py -v  # MicroSandbox æµ‹è¯•
python3 -m pytest tests/test_system_validation.py  # ç³»ç»ŸéªŒè¯æµ‹è¯•
python3 -m pytest tests/test_synthesis_focus.py    # åˆæˆç³»ç»Ÿæµ‹è¯•

# è¿è¡Œæ€§èƒ½æµ‹è¯•
python3 scripts/batch_test_tasks.py --tasks-file data/test_tasks.jsonl

# è¿è¡Œå•ä¸ªæµ‹è¯•ä»»åŠ¡
python3 scripts/batch_test_tasks.py --tasks-file tasks.jsonl
```

### å¼€å‘å·¥å…·
```bash
# éªŒè¯ç³»ç»Ÿé…ç½®
python3 scripts/validate_paths.py

# æ£€æŸ¥ç³»ç»Ÿå¥åº·
python3 scripts/check_system_health.py

# ç›‘æ§ç«¯å£ä½¿ç”¨
python3 scripts/port_manager.py

# éªŒè¯å·¥å…·æ˜ å°„
python3 scripts/verify_tool_id_mappings.py

# Tokenä¼˜åŒ–åŠŸèƒ½æµ‹è¯•
python3 tests/test_token_optimization.py
```

## æ¶æ„æ¦‚è§ˆ

### æ ¸å¿ƒç»„ä»¶

**å¢å¼ºè¿è¡Œæ—¶** (`runtimes/reasoning/enhanced_runtime.py`)
- å®ç°å¸¦XMLæµçš„åå¹»è§‰æ¡†æ¶
- å¤„ç†å†…å­˜ç®¡ç†å’Œè½¨è¿¹å¢å¼º
- åè°ƒLLMäº¤äº’ä¸çœŸå®å·¥å…·æ‰§è¡Œ

**ä»»åŠ¡å¤„ç†ç®¡é“**
- `TaskLoader`: ä»JSONLæ–‡ä»¶åŠ è½½å’ŒéªŒè¯ä»»åŠ¡
- `TaskEnhancer`: ç”¨ä¸Šä¸‹æ–‡å’Œå…ƒæ•°æ®ä¸°å¯Œä»»åŠ¡
- `TaskDistributor`: å°†ä»»åŠ¡è·¯ç”±åˆ°é€‚å½“çš„é˜Ÿåˆ—
- `TaskProcessingCoordinator`: ç¼–æ’æ•´ä¸ªç®¡é“

**ToolScoreç³»ç»Ÿ** (`core/toolscore/`)
- ä¸MCPæœåŠ¡å™¨é›†æˆçš„ç»Ÿä¸€å·¥å…·ç®¡ç†
- åŠ¨æ€å·¥å…·å‘ç°å’Œæ³¨å†Œ
- ä¼šè¯ç®¡ç†å’Œè¿æ¥æ± 

**å†…å­˜ä¸è§„åˆ’**
- `MemoryManager`: åŸºäºRediså­˜å‚¨çš„æŒä¹…ä¼šè¯å†…å­˜
- `StepPlanner`: å…·æœ‰è‡ªé€‚åº”è§„åˆ’çš„å¤šæ­¥æ¨ç†
- æ™ºèƒ½ä¸Šä¸‹æ–‡æ³¨å…¥ä»¥æé«˜LLMæ€§èƒ½

### MCPå·¥å…·æœåŠ¡å™¨

**MicroSandboxæœåŠ¡å™¨** (ç«¯å£ 8090)
- å®‰å…¨çš„Pythonä»£ç æ‰§è¡Œç¯å¢ƒ
- ä¼šè¯ç®¡ç†å’ŒçŠ¶æ€æŒä¹…æ€§
- åŒ…å®‰è£…å’Œä¾èµ–ç®¡ç†

**Browser UseæœåŠ¡å™¨** (ç«¯å£ 8082) 
- AIé©±åŠ¨çš„æµè§ˆå™¨è‡ªåŠ¨åŒ–
- ç½‘é¡µæŠ“å–å’Œäº¤äº’èƒ½åŠ›
- æ™ºèƒ½è¡¨å•å¡«å†™å’Œå¯¼èˆª

**DeepSearchæœåŠ¡å™¨** (ç«¯å£ 8086)
- é«˜çº§æœç´¢å’Œç ”ç©¶èƒ½åŠ›
- å¤šæºä¿¡æ¯èšåˆ
- æ™ºèƒ½æŸ¥è¯¢ä¼˜åŒ–

**Search ToolæœåŠ¡å™¨** (ç«¯å£ 8080)
- æ–‡ä»¶ç³»ç»Ÿæœç´¢å’Œç´¢å¼•
- å†…å®¹æ¨¡å¼åŒ¹é…å’Œåˆ†æ

### æ•°æ®æµæ¶æ„

1. **è¾“å…¥æ¥æ”¶**: é€šè¿‡REST APIæ¥æ”¶ä»»åŠ¡ (ç«¯å£ 8000)
2. **ä»»åŠ¡å¢å¼º**: ä¸Šä¸‹æ–‡ä¸°å¯Œå’ŒéªŒè¯
3. **é˜Ÿåˆ—åˆ†å‘**: åŸºäºRedisçš„ä»»åŠ¡è·¯ç”± (`tasks:reasoning`)
4. **è¿è¡Œæ—¶æ‰§è¡Œ**: å¸¦åå¹»è§‰çš„å¢å¼ºè¿è¡Œæ—¶
5. **å·¥å…·æ‰§è¡Œ**: é€šè¿‡MCPæœåŠ¡å™¨è¿›è¡ŒçœŸå®å·¥å…·è°ƒç”¨
6. **ç»“æœå­˜å‚¨**: è½¨è¿¹å­˜å‚¨å’Œåˆæˆå­¦ä¹ 

## Key Configuration Files

- `config/llm_config.yaml`: LLM provider settings (Gemini primary, OpenAI backup)
- `config/routing_config.yaml`: Task routing and queue configuration  
- `config/unified_tool_definitions.yaml`: Tool definitions and mappings
- `requirements.txt`: Python dependencies (MicroSandbox requires separate installation)

### Required Environment Variables
```bash
# Required
export GEMINI_API_KEY=your_gemini_api_key

# Optional
export OPENAI_API_KEY=your_openai_api_key
export REDIS_URL=redis://localhost:6379
export LOG_LEVEL=INFO
export MICROSANDBOX_TIMEOUT=30
```

### Port Configuration
- 8000: Task API Service
- 8088: ToolScore HTTP API
- 8089: ToolScore WebSocket
- 8090: MicroSandbox Server (critical)
- 8082: Browser Use Server
- 8086: DeepSearch Server
- 8080: Search Tool Server
- 6379: Redis

## å¼€å‘æŒ‡å—

### åå¹»è§‰å®ç°
- å§‹ç»ˆé€šè¿‡MCPæœåŠ¡å™¨å®ç°çœŸå®å·¥å…·æ‰§è¡Œ
- å¯¹å·¥å…·è°ƒç”¨ä½¿ç”¨å¸¦ç»“æœæ³¨å…¥çš„XMLæµ
- åœ¨LLMç»§ç»­ä¹‹å‰éªŒè¯æ‰€æœ‰å·¥å…·è¾“å‡º
- ç»ä¸å…è®¸LLMç”Ÿæˆè™šå‡çš„`<result>`æ ‡ç­¾

### åç¡¬ç¼–ç å®è·µ
```python
# âŒ é”™è¯¯çš„ç¡¬ç¼–ç æ–¹å¼
if "Final Answer:" in response:
    success = True
    final_result = "Task execution completed."

# âœ… æ­£ç¡®çš„å¸¸é‡åŒ–æ–¹å¼
from core.interfaces import TaskExecutionConstants

answer_tag = TaskExecutionConstants.XML_TAGS['ANSWER']
if f"</{answer_tag}>" in response:
    success = self._determine_task_success(response, trajectory)
    final_result = self._extract_final_result(response)
```

### Tokenä¼˜åŒ–ä¸æˆæœ¬æ§åˆ¶
```python
# ğŸ†• ä½¿ç”¨æ™ºèƒ½Tokenç®¡ç†å™¨è¿›è¡Œæˆæœ¬ä¼˜åŒ–
from core.intelligent_token_manager import IntelligentTokenManager
from core.context_cache_manager import CacheStrategy

# åˆå§‹åŒ–Tokenç®¡ç†å™¨
token_manager = IntelligentTokenManager(
    gemini_provider=gemini_provider,
    cache_strategy=CacheStrategy.BALANCED,
    token_budget_limit=1000000  # 100ä¸‡tokené¢„ç®—
)

# ç²¾ç¡®Tokenè®¡æ•°ï¼ˆä½¿ç”¨GeminiçœŸå®APIï¼‰
token_count = await token_manager.count_tokens_accurately(text, model="gemini-2.5-flash")

# æ™ºèƒ½æ¶ˆæ¯ä¼˜åŒ–ï¼ˆè‡ªåŠ¨ç¼“å­˜ä¸å¤ç”¨ï¼‰
optimized_messages, optimization_info = await token_manager.optimize_messages_with_cache(
    messages, model="gemini-2.5-flash", session_id="user_session"
)

# è¯¦ç»†æˆæœ¬åˆ†æ
cost_analysis = step_logger._calculate_cost_metrics(token_usage, duration)
print(f"æˆæœ¬: ${cost_analysis['estimated_cost_usd']:.6f}")
print(f"ç¼“å­˜èŠ‚çœ: ${cost_analysis['cache_analysis']['cache_savings_usd']:.6f}")
```

### çŠ¶æ€åˆ¤å®šæœ€ä½³å®è·µ
- ä½¿ç”¨`_determine_task_success()`è¿›è¡Œæ™ºèƒ½çŠ¶æ€åˆ¤å®š
- ä½¿ç”¨`_extract_final_result()`åŠ¨æ€æå–ç»“æœå†…å®¹
- é¿å…ç®€å•çš„å­—ç¬¦ä¸²åŒ¹é…ï¼Œé‡‡ç”¨å¤šç»´åº¦ç»¼åˆåˆ¤æ–­
- å‚è€ƒ: `runtimes/reasoning/enhanced_runtime.py` ä¸­çš„ä¿®å¤å®ä¾‹

### å·¥å…·é›†æˆ
```python
# æ·»åŠ æ–°çš„MCPæœåŠ¡å™¨
1. åœ¨ mcp_servers/{server_name}/ ä¸­åˆ›å»ºæœåŠ¡å™¨
2. å®ç° MCPServer åŸºç±»
3. æ·»åŠ åˆ° config/ports_config.yaml
4. åœ¨ service_manager ä¸­æ³¨å†Œ
```

### æœåŠ¡ç®¡ç†
- ä½¿ç”¨ç³»ç»Ÿçº§é‡å¯æ¥é‡å¯æœåŠ¡ï¼ˆé‡å¯main.pyï¼‰
- ç«¯å£æ¸…ç†æœºåˆ¶åœ¨å¯åŠ¨æ—¶è‡ªåŠ¨å¤„ç†å†²çªè¿›ç¨‹

### Task Types
- `code`: Code generation and execution tasks
- `reasoning`: Multi-step analysis tasks  
- `research`: Information gathering and analysis
- `web`: Browser-based interactions

### Memory Management
- Use `session_id` in task context for persistent memory
- MemoryManager automatically stores/retrieves context
- Context injected into LLM prompts for continuity

### Error Handling
- Structured error objects with recovery suggestions
- Automatic retry mechanisms for transient failures
- LLM reflection for complex error recovery
- Comprehensive error classification and severity levels

## æ•°æ®åˆæˆå­¦ä¹ 

å¹³å°å®ç°"æ•°æ®é£è½®"è¿›è¡ŒæŒç»­å­¦ä¹ ï¼š

**è½¨è¿¹ç›‘æ§**
- å®æ—¶ç›‘æ§`output/trajectories/`ç›®å½•
- è½¨è¿¹æ–‡ä»¶ä¿®æ”¹æ—¶è‡ªåŠ¨è§¦å‘
- åˆæˆå¤„ç†å»¶è¿Ÿ2-5åˆ†é’Ÿ

**åˆæˆè¿‡ç¨‹**
1. æå–æˆåŠŸçš„æ‰§è¡Œæ¨¡å¼
2. ä»è½¨è¿¹ç”ŸæˆåŸå­ç§å­ä»»åŠ¡
3. åº”ç”¨æ·±åº¦/å®½åº¦æ‰©å±•ä»¥è·å¾—ä»»åŠ¡å˜ä½“
4. å¤šç»´åº¦è´¨é‡éªŒè¯
5. å°†éªŒè¯çš„ä»»åŠ¡å­˜å‚¨åœ¨`output/seed_tasks.jsonl`ä¸­

**è¾“å‡ºæ–‡ä»¶**
- `output/trajectories/trajectories_collection.json`: åŸå§‹æ‰§è¡Œæ•°æ®
- `output/seed_tasks.jsonl`: è‡ªåŠ¨ç”Ÿæˆçš„å­¦ä¹ ä»»åŠ¡
- `output/task_essences.json`: æå–çš„ä»»åŠ¡æ¨¡å¼

## æµ‹è¯•å’ŒéªŒè¯

### é›†æˆæµ‹è¯•
```bash
# æäº¤æµ‹è¯•ä»»åŠ¡
curl -X POST "http://localhost:8000/api/v1/tasks" \
  -H "Content-Type: application/json" \
  -d '{"task_type": "code", "input": "æµ‹è¯• MicroSandbox: print(\"Hello!\")"}'

# æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
curl "http://localhost:8000/api/v1/tasks/{task_id}"
```

### æ€§èƒ½ç›‘æ§
- é€šè¿‡ToolScore HTTP APIçš„å®æ—¶æŒ‡æ ‡ (ç«¯å£ 8088)
- `logs/System.log`ä¸­çš„ç³»ç»Ÿæ—¥å¿— (ç»Ÿä¸€æ—¥å¿—è®°å½•)
- é€šè¿‡Redis CLIè¿›è¡Œé˜Ÿåˆ—ç›‘æ§
- æ‰§è¡Œæ¨¡å¼çš„è½¨è¿¹åˆ†æ

## Troubleshooting

### Quick Diagnostics
```bash
# Check all critical services
curl http://localhost:8000/health           # Task API
curl http://localhost:8088/health           # ToolScore
redis-cli ping                              # Redis
python3 -c "from microsandbox import PythonSandbox; print('âœ… MicroSandbox OK')"

# Port cleanup (if needed)
python3 utility/cleanup_ports.py

# Check task queue status
redis-cli XLEN tasks:reasoning

# Monitor system logs
tail -f logs/System.log
```

### Common Issues
- **Port conflicts**: `python3 utility/cleanup_ports.py` then restart
- **MicroSandbox missing**: `pip install microsandbox`
- **Redis down**: Start Redis service for your OS
- **Tasks stuck**: Check queue with `redis-cli XLEN tasks:reasoning`

## Security Considerations

- All code execution restricted to MicroSandbox containers
- API keys filtered from logs and error messages
- Input validation and sanitization throughout pipeline
- Resource limits and timeout enforcement
- Audit logging for all tool executions