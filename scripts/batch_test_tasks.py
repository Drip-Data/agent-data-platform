#!/usr/bin/env python3
"""
Agent Data Platform æ‰¹é‡ä»»åŠ¡æµ‹è¯•è„šæœ¬
æ”¯æŒä»tasks.jsonlæ–‡ä»¶è¯»å–ä»»åŠ¡å¹¶æ‰¹é‡æ‰§è¡Œæµ‹è¯•
"""

import asyncio
import aiohttp
import json
import time
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict
from datetime import datetime
import argparse

logger = logging.getLogger(__name__)

@dataclass
class TaskResult:
    """ä»»åŠ¡æ‰§è¡Œç»“æœ"""
    task_id: str
    original_task_id: Optional[str]
    description: str
    status: str
    success: bool
    final_result: Optional[str]
    error_message: Optional[str]
    total_duration: float
    submit_time: datetime
    complete_time: Optional[datetime]
    
    def to_dict(self) -> Dict[str, Any]:
        data = asdict(self)
        data['submit_time'] = self.submit_time.isoformat()
        if self.complete_time:
            data['complete_time'] = self.complete_time.isoformat()
        return data

class BatchTaskTester:
    """æ‰¹é‡ä»»åŠ¡æµ‹è¯•å™¨"""
    
    def __init__(self, 
                 task_api_url: str = "http://localhost:8000",
                 max_concurrent: int = 3,
                 timeout: int = 300):
        self.task_api_url = task_api_url
        self.max_concurrent = max_concurrent
        self.timeout = timeout
        self.results: List[TaskResult] = []
        
    def load_tasks_from_jsonl(self, file_path: str) -> List[Dict]:
        """ä»JSONLæ–‡ä»¶åŠ è½½ä»»åŠ¡"""
        tasks = []
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:
                        continue
                        
                    try:
                        task = json.loads(line)
                        # æ ‡å‡†åŒ–ä»»åŠ¡æ ¼å¼
                        standardized_task = self.standardize_task_format(task)
                        if standardized_task:
                            tasks.append(standardized_task)
                        else:
                            logger.warning(f"è·³è¿‡ç¬¬{line_num}è¡Œï¼šæ— æ•ˆçš„ä»»åŠ¡æ ¼å¼")
                    except json.JSONDecodeError as e:
                        logger.error(f"ç¬¬{line_num}è¡ŒJSONè§£æé”™è¯¯: {e}")
                        
        except FileNotFoundError:
            logger.error(f"ä»»åŠ¡æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            
        logger.info(f"ä» {file_path} åŠ è½½äº† {len(tasks)} ä¸ªä»»åŠ¡")
        return tasks
    
    def standardize_task_format(self, task: Dict) -> Optional[Dict]:
        """æ ‡å‡†åŒ–ä»»åŠ¡æ ¼å¼"""
        # æ”¯æŒå¤šç§ä»»åŠ¡æ ¼å¼
        standardized = {}
        
        # è·å–ä»»åŠ¡æè¿°
        description = (task.get("description") or 
                      task.get("input") or 
                      task.get("task_description"))
        if not description:
            return None
            
        standardized["input"] = description
        standardized["description"] = f"æ‰¹é‡æµ‹è¯•: {description[:50]}..."
        
        # ä¿ç•™åŸå§‹task_idç”¨äºè¿½è¸ª
        if "task_id" in task:
            standardized["original_task_id"] = task["task_id"]
            
        # å…¶ä»–å¯é€‰å­—æ®µ
        if "priority" in task:
            standardized["priority"] = task["priority"]
            
        return standardized
    
    async def submit_task(self, session: aiohttp.ClientSession, 
                         task: Dict) -> Optional[str]:
        """æäº¤å•ä¸ªä»»åŠ¡"""
        try:
            async with session.post(
                f"{self.task_api_url}/api/v1/tasks",
                json=task,
                timeout=10
            ) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    return data.get("task_id")
                else:
                    logger.error(f"ä»»åŠ¡æäº¤å¤±è´¥ (HTTP {resp.status}): {task.get('description', '')}")
                    
        except Exception as e:
            logger.error(f"ä»»åŠ¡æäº¤å¼‚å¸¸: {e}")
            
        return None
    
    async def wait_for_task_completion(self, session: aiohttp.ClientSession,
                                     task_id: str, 
                                     original_task_id: Optional[str],
                                     description: str,
                                     submit_time: datetime) -> TaskResult:
        """ç­‰å¾…ä»»åŠ¡å®Œæˆ"""
        start_time = time.time()
        
        while time.time() - start_time < self.timeout:
            try:
                async with session.get(
                    f"{self.task_api_url}/api/v1/tasks/{task_id}",
                    timeout=5
                ) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        status = data.get("status")
                        
                        if status in ["completed", "failed"]:
                            result_data = data.get("result", {})
                            
                            return TaskResult(
                                task_id=task_id,
                                original_task_id=original_task_id,
                                description=description,
                                status=status,
                                success=result_data.get("success", False),
                                final_result=result_data.get("final_result"),
                                error_message=result_data.get("error_message"),
                                total_duration=result_data.get("total_duration", 0),
                                submit_time=submit_time,
                                complete_time=datetime.now()
                            )
                            
            except Exception as e:
                logger.debug(f"æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å¼‚å¸¸: {e}")
                
            # ç­‰å¾…åé‡è¯•
            await asyncio.sleep(2)
        
        # è¶…æ—¶æƒ…å†µ
        return TaskResult(
            task_id=task_id,
            original_task_id=original_task_id,
            description=description,
            status="timeout",
            success=False,
            final_result=None,
            error_message=f"ä»»åŠ¡è¶…æ—¶ ({self.timeout}ç§’)",
            total_duration=self.timeout,
            submit_time=submit_time,
            complete_time=datetime.now()
        )
    
    async def process_single_task(self, session: aiohttp.ClientSession,
                                 task: Dict) -> TaskResult:
        """å¤„ç†å•ä¸ªä»»åŠ¡çš„å®Œæ•´æµç¨‹"""
        submit_time = datetime.now()
        description = task.get("input", "")
        original_task_id = task.get("original_task_id")
        
        logger.info(f"ğŸš€ æäº¤ä»»åŠ¡: {description[:50]}...")
        
        # æäº¤ä»»åŠ¡
        task_id = await self.submit_task(session, task)
        if not task_id:
            return TaskResult(
                task_id="",
                original_task_id=original_task_id,
                description=description,
                status="submit_failed",
                success=False,
                final_result=None,
                error_message="ä»»åŠ¡æäº¤å¤±è´¥",
                total_duration=0,
                submit_time=submit_time,
                complete_time=datetime.now()
            )
        
        logger.info(f"âœ… ä»»åŠ¡å·²æäº¤: {task_id}")
        
        # ç­‰å¾…å®Œæˆ
        result = await self.wait_for_task_completion(
            session, task_id, original_task_id, description, submit_time
        )
        
        status_emoji = "âœ…" if result.success else "âŒ"
        logger.info(f"{status_emoji} ä»»åŠ¡å®Œæˆ: {task_id} (è€—æ—¶: {result.total_duration:.1f}s)")
        
        return result
    
    async def run_batch_test(self, tasks: List[Dict]) -> List[TaskResult]:
        """è¿è¡Œæ‰¹é‡æµ‹è¯•"""
        logger.info(f"ğŸ¯ å¼€å§‹æ‰¹é‡æµ‹è¯• {len(tasks)} ä¸ªä»»åŠ¡ (æœ€å¤§å¹¶å‘: {self.max_concurrent})")
        
        async with aiohttp.ClientSession() as session:
            # åˆ›å»ºä¿¡å·é‡æ§åˆ¶å¹¶å‘
            semaphore = asyncio.Semaphore(self.max_concurrent)
            
            async def process_with_semaphore(task):
                async with semaphore:
                    return await self.process_single_task(session, task)
            
            # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
            self.results = await asyncio.gather(
                *[process_with_semaphore(task) for task in tasks],
                return_exceptions=True
            )
            
            # å¤„ç†å¼‚å¸¸ç»“æœ
            processed_results = []
            for i, result in enumerate(self.results):
                if isinstance(result, Exception):
                    logger.error(f"ä»»åŠ¡å¤„ç†å¼‚å¸¸: {result}")
                    # åˆ›å»ºé”™è¯¯ç»“æœ
                    error_result = TaskResult(
                        task_id="",
                        original_task_id=tasks[i].get("original_task_id"),
                        description=tasks[i].get("input", ""),
                        status="error",
                        success=False,
                        final_result=None,
                        error_message=str(result),
                        total_duration=0,
                        submit_time=datetime.now(),
                        complete_time=datetime.now()
                    )
                    processed_results.append(error_result)
                else:
                    processed_results.append(result)
            
            self.results = processed_results
            
        return self.results
    
    def generate_test_report(self) -> str:
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        if not self.results:
            return "æ— æµ‹è¯•ç»“æœ"
            
        total = len(self.results)
        successful = sum(1 for r in self.results if r.success)
        failed = total - successful
        
        avg_duration = sum(r.total_duration for r in self.results) / total
        
        report = []
        report.append("ğŸ“Š Agent Data Platform æ‰¹é‡æµ‹è¯•æŠ¥å‘Š")
        report.append("=" * 60)
        report.append(f"ğŸ“‹ æ€»ä»»åŠ¡æ•°: {total}")
        report.append(f"âœ… æˆåŠŸ: {successful} ({successful/total*100:.1f}%)")
        report.append(f"âŒ å¤±è´¥: {failed} ({failed/total*100:.1f}%)")
        report.append(f"â±ï¸ å¹³å‡è€—æ—¶: {avg_duration:.1f}ç§’")
        report.append("")
        
        # è¯¦ç»†ç»“æœ
        report.append("ğŸ“ è¯¦ç»†ç»“æœ:")
        for i, result in enumerate(self.results, 1):
            status_emoji = "âœ…" if result.success else "âŒ"
            original_id = f" (åŸID: {result.original_task_id})" if result.original_task_id else ""
            report.append(
                f"{i:2d}. {status_emoji} {result.description[:50]}... "
                f"[{result.status}] {result.total_duration:.1f}s{original_id}"
            )
            
        # å¤±è´¥ä»»åŠ¡è¯¦æƒ…
        failed_tasks = [r for r in self.results if not r.success]
        if failed_tasks:
            report.append("")
            report.append("ğŸ” å¤±è´¥ä»»åŠ¡è¯¦æƒ…:")
            for result in failed_tasks:
                report.append(f"  - {result.description[:50]}...")
                report.append(f"    é”™è¯¯: {result.error_message}")
                
        return "\n".join(report)
    
    def save_results(self, output_file: str):
        """ä¿å­˜æµ‹è¯•ç»“æœåˆ°æ–‡ä»¶"""
        results_data = {
            "test_time": datetime.now().isoformat(),
            "total_tasks": len(self.results),
            "successful_tasks": sum(1 for r in self.results if r.success),
            "failed_tasks": sum(1 for r in self.results if not r.success),
            "results": [result.to_dict() for result in self.results]
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results_data, f, ensure_ascii=False, indent=2)
            
        logger.info(f"ğŸ“ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Agent Data Platform æ‰¹é‡ä»»åŠ¡æµ‹è¯•")
    parser.add_argument("--tasks-file", default="tasks.jsonl", 
                       help="ä»»åŠ¡æ–‡ä»¶è·¯å¾„ (JSONLæ ¼å¼)")
    parser.add_argument("--api-url", default="http://localhost:8000",
                       help="Task API URL")
    parser.add_argument("--concurrent", type=int, default=3,
                       help="æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°")
    parser.add_argument("--timeout", type=int, default=300,
                       help="å•ä¸ªä»»åŠ¡è¶…æ—¶æ—¶é—´(ç§’)")
    parser.add_argument("--output", default="output/batch_test_results.json",
                       help="ç»“æœè¾“å‡ºæ–‡ä»¶")
    parser.add_argument("--verbose", action="store_true",
                       help="è¯¦ç»†æ—¥å¿—è¾“å‡º")
    
    args = parser.parse_args()
    
    # é…ç½®æ—¥å¿—
    log_level = logging.DEBUG if args.verbose else logging.INFO
    logging.basicConfig(
        level=log_level,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    # åˆ›å»ºæ‰¹é‡æµ‹è¯•å™¨
    tester = BatchTaskTester(
        task_api_url=args.api_url,
        max_concurrent=args.concurrent,
        timeout=args.timeout
    )
    
    # åŠ è½½ä»»åŠ¡
    tasks = tester.load_tasks_from_jsonl(args.tasks_file)
    if not tasks:
        logger.error("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ä»»åŠ¡ï¼Œé€€å‡º")
        return
        
    # æ‰§è¡Œæ‰¹é‡æµ‹è¯•
    logger.info("ğŸš€ å¼€å§‹æ‰¹é‡æµ‹è¯•...")
    start_time = time.time()
    
    results = await tester.run_batch_test(tasks)
    
    end_time = time.time()
    logger.info(f"ğŸ‰ æ‰¹é‡æµ‹è¯•å®Œæˆï¼Œæ€»è€—æ—¶: {end_time - start_time:.1f}ç§’")
    
    # ç”ŸæˆæŠ¥å‘Š
    report = tester.generate_test_report()
    print("\n" + report)
    
    # ä¿å­˜ç»“æœ
    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    tester.save_results(str(output_path))

if __name__ == "__main__":
    asyncio.run(main()) 