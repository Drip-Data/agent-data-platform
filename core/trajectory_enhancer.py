"""
è½¨è¿¹å¢å¼ºå™¨ - æ”¶é›†å’Œè®¡ç®—è¯¦ç»†çš„æ‰§è¡Œå…ƒæ•°æ®
å®ç°OpenHandsé£æ ¼çš„ç»†ç²’åº¦è¿½è¸ª
"""

import time
import uuid
import logging
import psutil
import platform
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, field
from core.interfaces import TrajectoryResult, ExecutionStep, LLMInteraction

logger = logging.getLogger(__name__)

@dataclass
class ResourceMetrics:
    """èµ„æºä½¿ç”¨æŒ‡æ ‡"""
    cpu_percent: float = 0.0
    memory_mb: float = 0.0
    network_bytes_sent: int = 0
    network_bytes_received: int = 0
    start_timestamp: float = field(default_factory=time.time)
    end_timestamp: Optional[float] = None
    
    def calculate_duration(self) -> float:
        """è®¡ç®—æŒç»­æ—¶é—´"""
        end_time = self.end_timestamp or time.time()
        return end_time - self.start_timestamp

class TrajectoryEnhancer:
    """è½¨è¿¹å¢å¼ºå™¨ - æ”¶é›†è¯¦ç»†çš„æ‰§è¡Œå…ƒæ•°æ®"""
    
    def __init__(self):
        self.session_start_time = time.time()
        self.task_resource_start = {}  # è®°å½•æ¯ä¸ªä»»åŠ¡çš„èµ„æºå¼€å§‹çŠ¶æ€
        
    def start_task_tracking(self, task_id: str) -> Dict[str, Any]:
        """å¼€å§‹è·Ÿè¸ªä»»åŠ¡çš„èµ„æºä½¿ç”¨"""
        try:
            process = psutil.Process()
            net_io = psutil.net_io_counters()
            
            start_metrics = ResourceMetrics(
                cpu_percent=process.cpu_percent(),
                memory_mb=process.memory_info().rss / 1024 / 1024,
                network_bytes_sent=net_io.bytes_sent if net_io else 0,
                network_bytes_received=net_io.bytes_recv if net_io else 0
            )
            
            self.task_resource_start[task_id] = start_metrics
            
            return {
                "tracking_started": True,
                "start_time": start_metrics.start_timestamp,
                "process_id": process.pid
            }
        except Exception as e:
            logger.warning(f"æ— æ³•å¯åŠ¨èµ„æºè·Ÿè¸ª: {e}")
            return {"tracking_started": False, "error": str(e)}
    
    def calculate_step_resource_usage(self, step_start_time: float, step_end_time: float) -> Dict[str, Any]:
        """è®¡ç®—æ­¥éª¤çš„èµ„æºä½¿ç”¨æƒ…å†µ"""
        try:
            process = psutil.Process()
            
            return {
                "cpu_usage_percent": process.cpu_percent(),
                "memory_usage_mb": round(process.memory_info().rss / 1024 / 1024, 2),
                "execution_time_ms": round((step_end_time - step_start_time) * 1000, 2),
                "timestamp": step_end_time
            }
        except Exception as e:
            logger.warning(f"æ— æ³•è®¡ç®—èµ„æºä½¿ç”¨: {e}")
            return {"error": str(e)}
    
    def create_sub_event(self, event_type: str, description: str, metadata: Dict[str, Any] = None) -> Dict[str, Any]:
        """åˆ›å»ºå­äº‹ä»¶è®°å½•"""
        return {
            "event_id": str(uuid.uuid4()),
            "timestamp": time.time(),
            "event_type": event_type,
            "description": description,
            "metadata": metadata or {}
        }
    
    def calculate_llm_metrics(self, trajectory: TrajectoryResult) -> Dict[str, Any]:
        """è®¡ç®—ç´¯ç§¯çš„LLMä½¿ç”¨æŒ‡æ ‡"""
        total_interactions = 0
        total_prompt_tokens = 0
        total_completion_tokens = 0
        total_cost = 0.0
        total_response_time = 0.0
        
        providers_used = set()
        models_used = set()
        
        for step in trajectory.steps:
            for interaction in step.llm_interactions:
                total_interactions += 1
                
                # æå–ä»¤ç‰Œä½¿ç”¨ä¿¡æ¯
                if interaction.token_usage:
                    total_prompt_tokens += interaction.token_usage.get('prompt_tokens', 0)
                    total_completion_tokens += interaction.token_usage.get('completion_tokens', 0)
                
                # æå–æˆæœ¬ä¿¡æ¯
                if interaction.cost_info:
                    total_cost += interaction.cost_info.get('total_cost', 0.0)
                
                total_response_time += interaction.response_time
                
                if interaction.provider:
                    providers_used.add(interaction.provider)
                if interaction.model:
                    models_used.add(interaction.model)
        
        return {
            "total_interactions": total_interactions,
            "accumulated_cost": round(total_cost, 6),
            "accumulated_token_usage": {
                "total_tokens": total_prompt_tokens + total_completion_tokens,
                "prompt_tokens": total_prompt_tokens,
                "completion_tokens": total_completion_tokens
            },
            "average_response_time": round(total_response_time / max(total_interactions, 1), 3),
            "total_response_time": round(total_response_time, 3),
            "providers_used": list(providers_used),
            "models_used": list(models_used)
        }
    
    def calculate_error_handling_stats(self, trajectory: TrajectoryResult) -> Dict[str, Any]:
        """è®¡ç®—é”™è¯¯å¤„ç†ç»Ÿè®¡"""
        errors_encountered = 0
        retry_attempts = 0
        error_types = []
        recovery_successful = trajectory.success
        
        for step in trajectory.steps:
            if step.error_type or step.error_message:
                errors_encountered += 1
                if step.error_type:
                    error_types.append(step.error_type.value if hasattr(step.error_type, 'value') else str(step.error_type))
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é‡è¯•å°è¯•ï¼ˆåŸºäºç›¸ä¼¼çš„action_paramsï¼‰
            # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„å®ç°ï¼Œå®é™…ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„é€»è¾‘
            if not step.success and step.step_id > 1:
                retry_attempts += 1
        
        return {
            "errors_encountered": errors_encountered,
            "retry_attempts": retry_attempts,
            "error_types": list(set(error_types)),
            "recovery_successful": recovery_successful,
            "error_rate": round(errors_encountered / max(len(trajectory.steps), 1), 3)
        }
    
    def get_execution_environment(self) -> Dict[str, Any]:
        """è·å–æ‰§è¡Œç¯å¢ƒä¿¡æ¯"""
        try:
            return {
                "platform": platform.system(),
                "platform_version": platform.version(),
                "python_version": platform.python_version(),
                "cpu_count": psutil.cpu_count(),
                "total_memory_gb": round(psutil.virtual_memory().total / 1024 / 1024 / 1024, 2),
                "session_start_time": self.session_start_time,
                "environment_id": str(uuid.uuid4())
            }
        except Exception as e:
            logger.warning(f"æ— æ³•è·å–ç¯å¢ƒä¿¡æ¯: {e}")
            return {"error": str(e)}
    
    def enhance_trajectory(self, trajectory: TrajectoryResult) -> TrajectoryResult:
        """å¢å¼ºè½¨è¿¹ï¼Œæ·»åŠ è¯¦ç»†å…ƒæ•°æ®å’Œæˆæœ¬ä¿¡æ¯"""
        try:
            # è®¡ç®—LLMæŒ‡æ ‡
            trajectory.llm_metrics = self.calculate_llm_metrics(trajectory)
            
            # ğŸ†• æ³¨å…¥æˆæœ¬åˆ†æä¿¡æ¯
            from core.cost_analyzer import get_cost_analyzer
            cost_analyzer = get_cost_analyzer()
            
            # æ„å»ºæ­¥éª¤æ—¥å¿—ç”¨äºæˆæœ¬åˆ†æ
            step_logs = []
            for step in trajectory.steps:
                step_log = {
                    'step_id': step.step_id,
                    'token_usage': {},
                    'cost_info': {},
                    'tools_used': [step.action_params.get('tool', 'unknown')] if step.action_params else []
                }
                
                # ä»LLMäº¤äº’ä¸­æ”¶é›†tokenå’Œæˆæœ¬ä¿¡æ¯
                for interaction in step.llm_interactions:
                    if interaction.token_usage:
                        step_log['token_usage'] = interaction.token_usage
                    if interaction.cost_info:
                        step_log['cost_info'] = interaction.cost_info
                
                step_logs.append(step_log)
            
            # å°†è½¨è¿¹æ•°æ®è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ç”¨äºæˆæœ¬åˆ†æ
            trajectory_dict = {
                'task_id': trajectory.task_id,
                'task_type': getattr(trajectory, 'task_type', 'unknown'),
                'success': trajectory.success,
                'execution_time': trajectory.total_duration,
                'step_logs': step_logs
            }
            
            # åˆ†æå¹¶è®¾ç½®æˆæœ¬ä¿¡æ¯
            cost_analysis = cost_analyzer.analyze_trajectory_cost(trajectory_dict, step_logs)
            trajectory.cost_analysis = cost_analysis
            
            # æ·»åŠ æ‰§è¡Œç¯å¢ƒä¿¡æ¯
            trajectory.execution_environment = self.get_execution_environment()
            
            # è®¡ç®—é”™è¯¯å¤„ç†ç»Ÿè®¡
            trajectory.error_handling = self.calculate_error_handling_stats(trajectory)
            
            # æ·»åŠ ä¼šè¯çº§åˆ«çš„å…ƒæ•°æ®
            if 'session_id' not in trajectory.metadata:
                trajectory.metadata['session_id'] = f"session_{trajectory.task_id}_{int(trajectory.created_at)}"
            
            trajectory.metadata['enhanced_at'] = time.time()
            trajectory.metadata['enhancer_version'] = "1.1.0"  # ç‰ˆæœ¬å·æ›´æ–°ï¼Œè¡¨ç¤ºåŠ å…¥äº†æˆæœ¬åˆ†æ
            
            logger.info(f"è½¨è¿¹å¢å¼ºå®Œæˆ (å«æˆæœ¬åˆ†æ): {trajectory.task_id}, æˆæœ¬: ${cost_analysis.total_cost_usd:.4f}")
            return trajectory
            
        except Exception as e:
            logger.error(f"è½¨è¿¹å¢å¼ºå¤±è´¥: {e}")
            return trajectory
    
    def enhance_step_with_causality(self, step: ExecutionStep, 
                                  previous_step: Optional[ExecutionStep] = None,
                                  triggering_event: str = None) -> ExecutionStep:
        """ä¸ºæ­¥éª¤æ·»åŠ å› æœå…³ç³»ä¿¡æ¯"""
        if previous_step:
            step.caused_by_step = previous_step.step_id
        
        if triggering_event:
            step.triggering_event = triggering_event
        
        return step
    
    def add_sub_event_to_step(self, step: ExecutionStep, event_type: str, 
                            description: str, metadata: Dict[str, Any] = None) -> ExecutionStep:
        """ä¸ºæ­¥éª¤æ·»åŠ å­äº‹ä»¶"""
        sub_event = self.create_sub_event(event_type, description, metadata)
        step.sub_events.append(sub_event)
        return step
    
    def merge_related_steps(self, trajectory: TrajectoryResult) -> TrajectoryResult:
        """ğŸ”§ ä¼˜åŒ–ï¼šåˆå¹¶ç›¸å…³æ­¥éª¤ï¼Œå‡å°‘è½¨è¿¹å¤æ‚åº¦
        
        æ™ºèƒ½åˆå¹¶è¿ç»­çš„ç›¸å…³æ­¥éª¤ï¼Œä¿æŒè½¨è¿¹çš„é€»è¾‘æ¸…æ™°åº¦
        """
        if not trajectory.steps or len(trajectory.steps) <= 2:
            return trajectory
        
        logger.info(f"ğŸ”„ å¼€å§‹åˆå¹¶è½¨è¿¹æ­¥éª¤: åŸå§‹æ­¥éª¤æ•° {len(trajectory.steps)}")
        
        merged_steps = []
        i = 0
        
        while i < len(trajectory.steps):
            current_step = trajectory.steps[i]
            
            # æ£€æŸ¥æ˜¯å¦å¯ä»¥ä¸åç»­æ­¥éª¤åˆå¹¶
            merge_group = [current_step]
            j = i + 1
            
            while j < len(trajectory.steps):
                next_step = trajectory.steps[j]
                
                if self._should_merge_steps(current_step, next_step):
                    merge_group.append(next_step)
                    j += 1
                else:
                    break
            
            if len(merge_group) > 1:
                # åˆå¹¶å¤šä¸ªæ­¥éª¤
                merged_step = self._merge_step_group(merge_group)
                merged_steps.append(merged_step)
                logger.debug(f"ğŸ”— åˆå¹¶äº† {len(merge_group)} ä¸ªæ­¥éª¤åˆ°æ­¥éª¤ {merged_step.step_id}")
            else:
                # å•ä¸ªæ­¥éª¤ï¼Œä¸éœ€è¦åˆå¹¶
                merged_steps.append(current_step)
            
            i = j if j > i + 1 else i + 1
        
        # é‡æ–°ç¼–å·æ­¥éª¤
        for idx, step in enumerate(merged_steps):
            step.step_id = idx + 1
        
        trajectory.steps = merged_steps
        logger.info(f"âœ… æ­¥éª¤åˆå¹¶å®Œæˆ: {len(merged_steps)} ä¸ªåˆå¹¶åæ­¥éª¤ (å‹ç¼©ç‡: {len(merged_steps)/len(trajectory.steps)*100:.1f}%)")
        
        return trajectory
    
    def _should_merge_steps(self, step1: ExecutionStep, step2: ExecutionStep) -> bool:
        """åˆ¤æ–­ä¸¤ä¸ªæ­¥éª¤æ˜¯å¦åº”è¯¥åˆå¹¶"""
        # ä¸åˆå¹¶å¤±è´¥æ­¥éª¤ï¼Œä¿æŒé”™è¯¯çš„å¯è§æ€§
        if not step1.success or not step2.success:
            return False
        
        # ä¸åˆå¹¶ä¸åŒå·¥å…·çš„æ“ä½œ
        params1 = step1.action_params or {}
        params2 = step2.action_params or {}
        tool1 = params1.get('tool_id', '')
        tool2 = params2.get('tool_id', '')
        
        if tool1 != tool2:
            return False
        
        # ä¸åˆå¹¶åŠ¨ä½œç±»å‹å·®å¼‚å¾ˆå¤§çš„æ­¥éª¤
        if step1.action_type != step2.action_type:
            # é™¤éæ˜¯ç›¸å…³çš„åŠ¨ä½œç±»å‹
            related_action_types = [
                {'CODE_GENERATION', 'CODE_EXECUTION'},
                {'RESEARCH_QUERY', 'KNOWLEDGE_EXTRACTION'},
                {'DATA_RETRIEVAL', 'ANALYSIS_PROCESSING'},
            ]
            
            action1_name = step1.action_type.value if hasattr(step1.action_type, 'value') else str(step1.action_type)
            action2_name = step2.action_type.value if hasattr(step2.action_type, 'value') else str(step2.action_type)
            
            is_related = any(
                action1_name in group and action2_name in group 
                for group in related_action_types
            )
            
            if not is_related:
                return False
        
        # æ£€æŸ¥æ—¶é—´é—´éš”ï¼Œå¦‚æœå¤ªä¹…è¿œåˆ™ä¸åˆå¹¶
        time_diff = abs(step2.timestamp - step1.timestamp)
        if time_diff > 30:  # è¶…è¿‡30ç§’ä¸åˆå¹¶
            return False
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯è¿ç»­çš„é‡è¯•æ­¥éª¤
        action1 = params1.get('action', '')
        action2 = params2.get('action', '')
        if action1 == action2 and 'retry' in step2.observation.lower():
            return True
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç›¸åŒå·¥å…·çš„è¿ç»­æ“ä½œ
        if tool1 == tool2 and action1 == action2:
            return True
        
        return False
    
    def _merge_step_group(self, steps: List[ExecutionStep]) -> ExecutionStep:
        """åˆå¹¶ä¸€ç»„ç›¸å…³æ­¥éª¤"""
        if not steps:
            raise ValueError("Cannot merge empty step group")
        
        if len(steps) == 1:
            return steps[0]
        
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ­¥éª¤ä½œä¸ºåŸºç¡€
        merged_step = steps[0]
        
        # åˆå¹¶è§‚å¯Ÿç»“æœ
        observations = []
        for i, step in enumerate(steps):
            if step.observation:
                prefix = f"[æ­¥éª¤{i+1}] " if len(steps) > 1 else ""
                observations.append(f"{prefix}{step.observation}")
        
        merged_step.observation = "\n".join(observations)
        
        # åˆå¹¶æ‰§è¡Œæ—¶é—´
        total_duration = sum(step.duration for step in steps)
        merged_step.duration = total_duration
        
        # åˆå¹¶LLMäº¤äº’
        all_interactions = []
        for step in steps:
            all_interactions.extend(step.llm_interactions)
        merged_step.llm_interactions = all_interactions
        
        # åˆå¹¶å­äº‹ä»¶
        all_sub_events = []
        for step in steps:
            all_sub_events.extend(step.sub_events)
        merged_step.sub_events = all_sub_events
        
        # æ›´æ–°å…ƒæ•°æ®
        merged_step.sub_events.append({
            "event_type": "step_merge",
            "description": f"åˆå¹¶äº† {len(steps)} ä¸ªç›¸å…³æ­¥éª¤",
            "timestamp": time.time(),
            "metadata": {
                "original_step_count": len(steps),
                "merged_step_ids": [step.step_id for step in steps],
                "total_duration": total_duration
            }
        })
        
        return merged_step
    
    def generate_execution_summary(self, trajectory: TrajectoryResult) -> Dict[str, Any]:
        """ğŸ”§ ä¼˜åŒ–ï¼šç”Ÿæˆæ‰§è¡Œæ‘˜è¦å’Œæ¨èä¿¡æ¯
        
        åˆ†æè½¨è¿¹å¹¶ç”Ÿæˆè¯¦ç»†çš„æ‰§è¡Œæ‘˜è¦ï¼ŒåŒ…å«æ€§èƒ½æŒ‡æ ‡å’Œæ”¹è¿›å»ºè®®
        """
        summary = {
            "overview": {},
            "performance_metrics": {},
            "tool_usage_analysis": {},
            "error_analysis": {},
            "recommendations": [],
            "success_factors": [],
            "improvement_areas": []
        }
        
        steps = trajectory.steps
        if not steps:
            return summary
        
        # åŸºç¡€æ¦‚è§ˆ
        summary["overview"] = {
            "total_steps": len(steps),
            "successful_steps": sum(1 for step in steps if step.success),
            "failed_steps": sum(1 for step in steps if not step.success),
            "execution_time": trajectory.total_duration,
            "success_rate": sum(1 for step in steps if step.success) / len(steps) if steps else 0,
            "task_complexity": self._assess_task_complexity(trajectory)
        }
        
        # æ€§èƒ½æŒ‡æ ‡
        summary["performance_metrics"] = {
            "average_step_duration": trajectory.total_duration / len(steps) if steps else 0,
            "longest_step_duration": max((step.duration for step in steps), default=0),
            "total_llm_interactions": sum(len(step.llm_interactions) for step in steps),
            "retry_attempts": sum(1 for step in steps if 'retry' in step.observation.lower() or not step.success),
            "efficiency_score": self._calculate_efficiency_score(trajectory)
        }
        
        # å·¥å…·ä½¿ç”¨åˆ†æ
        summary["tool_usage_analysis"] = self._analyze_tool_usage(trajectory)
        
        # é”™è¯¯åˆ†æ
        summary["error_analysis"] = self._analyze_errors(trajectory)
        
        # ç”Ÿæˆæ¨è
        summary["recommendations"] = self._generate_recommendations(trajectory, summary)
        
        # æˆåŠŸå› ç´ 
        summary["success_factors"] = self._identify_success_factors(trajectory)
        
        # æ”¹è¿›é¢†åŸŸ
        summary["improvement_areas"] = self._identify_improvement_areas(trajectory, summary)
        
        return summary
    
    def _assess_task_complexity(self, trajectory: TrajectoryResult) -> str:
        """è¯„ä¼°ä»»åŠ¡å¤æ‚åº¦"""
        steps = trajectory.steps
        tool_count = len(trajectory.used_tools) if trajectory.used_tools else 0
        error_count = sum(1 for step in steps if not step.success)
        
        if len(steps) > 15 or tool_count > 5 or error_count > 5:
            return "high"
        elif len(steps) > 8 or tool_count > 3 or error_count > 2:
            return "medium"
        else:
            return "low"
    
    def _calculate_efficiency_score(self, trajectory: TrajectoryResult) -> float:
        """è®¡ç®—æ‰§è¡Œæ•ˆç‡åˆ†æ•° (0-1)"""
        if not trajectory.steps:
            return 0.0
        
        success_rate = sum(1 for step in trajectory.steps if step.success) / len(trajectory.steps)
        
        # é‡è¯•æƒ©ç½š
        retry_penalty = sum(1 for step in trajectory.steps if 'retry' in step.observation.lower()) * 0.1
        retry_penalty = min(retry_penalty, 0.3)  # æœ€å¤§æƒ©ç½š30%
        
        # æ—¶é—´æ•ˆç‡ï¼ˆåŸºäºå¹³å‡æ­¥éª¤æ—¶é—´ï¼‰
        avg_duration = trajectory.total_duration / len(trajectory.steps)
        time_efficiency = 1.0 if avg_duration < 5 else max(0.5, 1.0 - (avg_duration - 5) * 0.05)
        
        efficiency = (success_rate * 0.6 + time_efficiency * 0.4) - retry_penalty
        return max(0.0, min(1.0, efficiency))
    
    def _analyze_tool_usage(self, trajectory: TrajectoryResult) -> Dict[str, Any]:
        """åˆ†æå·¥å…·ä½¿ç”¨æƒ…å†µ"""
        tool_usage = {}
        action_types = {}
        
        for step in trajectory.steps:
            if hasattr(step, 'action_params') and step.action_params:
                # ä¼˜å…ˆä»stepæœ¬èº«è·å–tool_idï¼Œå¢å¼ºè½¨è¿¹åˆ†æçš„å‡†ç¡®æ€§
                tool_id = getattr(step, 'tool_id', None) or step.action_params.get('tool_id', 'unknown')
                tool_usage[tool_id] = tool_usage.get(tool_id, 0) + 1
            
            action_type = step.action_type.value if hasattr(step.action_type, 'value') else str(step.action_type)
            action_types[action_type] = action_types.get(action_type, 0) + 1
        
        most_used_tool = max(tool_usage, key=tool_usage.get) if tool_usage else None
        dominant_action_type = max(action_types, key=action_types.get) if action_types else None
        
        return {
            "tools_used": list(tool_usage.keys()),
            "tool_usage_frequency": tool_usage,
            "most_used_tool": most_used_tool,
            "action_type_distribution": action_types,
            "dominant_action_type": dominant_action_type,
            "tool_switching_frequency": self._calculate_tool_switching(trajectory.steps)
        }
    
    def _calculate_tool_switching(self, steps: List[ExecutionStep]) -> int:
        """è®¡ç®—å·¥å…·åˆ‡æ¢é¢‘ç‡"""
        switches = 0
        prev_tool = None
        
        for step in steps:
            if hasattr(step, 'action_params') and step.action_params:
                current_tool = step.action_params.get('tool_id')
                if prev_tool and prev_tool != current_tool:
                    switches += 1
                prev_tool = current_tool
        
        return switches
    
    def _analyze_errors(self, trajectory: TrajectoryResult) -> Dict[str, Any]:
        """åˆ†æé”™è¯¯æ¨¡å¼"""
        failed_steps = [step for step in trajectory.steps if not step.success]
        
        error_types = {}
        error_tools = {}
        error_patterns = []
        
        for step in failed_steps:
            if step.error_type:
                error_type = step.error_type.value if hasattr(step.error_type, 'value') else str(step.error_type)
                error_types[error_type] = error_types.get(error_type, 0) + 1
            
            if hasattr(step, 'action_params') and step.action_params:
                tool_id = step.action_params.get('tool_id', 'unknown')
                error_tools[tool_id] = error_tools.get(tool_id, 0) + 1
            
            # æ£€æµ‹é”™è¯¯æ¨¡å¼
            if step.error_message:
                if 'timeout' in step.error_message.lower():
                    error_patterns.append("timeout_issues")
                elif 'parameter' in step.error_message.lower():
                    error_patterns.append("parameter_errors")
                elif 'network' in step.error_message.lower():
                    error_patterns.append("network_issues")
        
        return {
            "total_errors": len(failed_steps),
            "error_rate": len(failed_steps) / len(trajectory.steps) if trajectory.steps else 0,
            "error_types": error_types,
            "problematic_tools": error_tools,
            "error_patterns": list(set(error_patterns)),
            "recovery_success": self._calculate_recovery_success(trajectory.steps)
        }
    
    def _calculate_recovery_success(self, steps: List[ExecutionStep]) -> float:
        """è®¡ç®—é”™è¯¯æ¢å¤æˆåŠŸç‡"""
        recovery_attempts = 0
        successful_recoveries = 0
        
        for i, step in enumerate(steps[:-1]):
            if not step.success:
                recovery_attempts += 1
                # æ£€æŸ¥ä¸‹ä¸€ä¸ªæ­¥éª¤æ˜¯å¦æˆåŠŸï¼ˆå¯èƒ½æ˜¯æ¢å¤ï¼‰
                if i + 1 < len(steps) and steps[i + 1].success:
                    successful_recoveries += 1
        
        return successful_recoveries / recovery_attempts if recovery_attempts > 0 else 0.0
    
    def _generate_recommendations(self, trajectory: TrajectoryResult, summary: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›æ¨è"""
        recommendations = []
        
        # åŸºäºæˆåŠŸç‡çš„æ¨è
        if summary["overview"]["success_rate"] < 0.7:
            recommendations.append("å»ºè®®ä¼˜åŒ–é”™è¯¯å¤„ç†æœºåˆ¶ï¼Œæé«˜ä»»åŠ¡æ‰§è¡ŒæˆåŠŸç‡")
        
        # åŸºäºæ•ˆç‡çš„æ¨è
        if summary["performance_metrics"]["efficiency_score"] < 0.6:
            recommendations.append("å»ºè®®ä¼˜åŒ–æ‰§è¡Œæµç¨‹ï¼Œå‡å°‘ä¸å¿…è¦çš„é‡è¯•å’Œç­‰å¾…æ—¶é—´")
        
        # åŸºäºå·¥å…·ä½¿ç”¨çš„æ¨è
        tool_switching = summary["tool_usage_analysis"]["tool_switching_frequency"]
        if tool_switching > len(trajectory.steps) * 0.5:
            recommendations.append("é¢‘ç¹çš„å·¥å…·åˆ‡æ¢å¯èƒ½å½±å“æ•ˆç‡ï¼Œå»ºè®®ä¼˜åŒ–å·¥å…·é€‰æ‹©ç­–ç•¥")
        
        # åŸºäºé”™è¯¯åˆ†æçš„æ¨è
        error_rate = summary["error_analysis"]["error_rate"]
        if error_rate > 0.3:
            recommendations.append("é”™è¯¯ç‡è¾ƒé«˜ï¼Œå»ºè®®åŠ å¼ºå‚æ•°éªŒè¯å’Œé”™è¯¯é¢„é˜²")
        
        # åŸºäºå¤æ‚åº¦çš„æ¨è
        if summary["overview"]["task_complexity"] == "high":
            recommendations.append("ä»»åŠ¡å¤æ‚åº¦è¾ƒé«˜ï¼Œå»ºè®®è€ƒè™‘å°†ä»»åŠ¡åˆ†è§£ä¸ºæ›´å°çš„å­ä»»åŠ¡")
        
        return recommendations
    
    def _identify_success_factors(self, trajectory: TrajectoryResult) -> List[str]:
        """è¯†åˆ«æˆåŠŸå› ç´ """
        factors = []
        
        if trajectory.success:
            factors.append("ä»»åŠ¡æˆåŠŸå®Œæˆ")
            
            # åˆ†ææˆåŠŸæ­¥éª¤çš„æ¨¡å¼
            successful_tools = set()
            for step in trajectory.steps:
                if step.success and hasattr(step, 'action_params') and step.action_params:
                    tool_id = step.action_params.get('tool_id')
                    if tool_id:
                        successful_tools.add(tool_id)
            
            if successful_tools:
                factors.append(f"æœ‰æ•ˆä½¿ç”¨äº†ä»¥ä¸‹å·¥å…·: {', '.join(list(successful_tools)[:3])}")
        
        # è¯†åˆ«é«˜æ•ˆæ‰§è¡Œæ¨¡å¼
        quick_successes = [step for step in trajectory.steps if step.success and step.duration < 2]
        if len(quick_successes) > len(trajectory.steps) * 0.5:
            factors.append("å¤§éƒ¨åˆ†æ­¥éª¤æ‰§è¡Œè¿…é€Ÿï¼Œæ˜¾ç¤ºäº†è‰¯å¥½çš„æ‰§è¡Œæ•ˆç‡")
        
        return factors
    
    def _identify_improvement_areas(self, trajectory: TrajectoryResult, summary: Dict[str, Any]) -> List[str]:
        """è¯†åˆ«æ”¹è¿›é¢†åŸŸ"""
        areas = []
        
        # åŸºäºæ€§èƒ½æŒ‡æ ‡
        if summary["performance_metrics"]["retry_attempts"] > 3:
            areas.append("å‡å°‘é‡è¯•æ¬¡æ•°å’Œé”™è¯¯æ¢å¤æ—¶é—´")
        
        if summary["performance_metrics"]["average_step_duration"] > 10:
            areas.append("ä¼˜åŒ–æ­¥éª¤æ‰§è¡Œæ—¶é—´ï¼Œæé«˜æ•´ä½“æ•ˆç‡")
        
        # åŸºäºé”™è¯¯åˆ†æ
        if summary["error_analysis"]["error_rate"] > 0.2:
            areas.append("æ”¹è¿›é”™è¯¯é¢„é˜²å’Œå¤„ç†æœºåˆ¶")
        
        # åŸºäºå·¥å…·ä½¿ç”¨
        if len(summary["tool_usage_analysis"]["tools_used"]) > 5:
            areas.append("ç®€åŒ–å·¥å…·ä½¿ç”¨ç­–ç•¥ï¼Œå‡å°‘å·¥å…·åˆ‡æ¢å¼€é”€")
        
        return areas