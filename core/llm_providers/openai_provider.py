import os
import logging
from typing import Any, Dict, List, Optional
import httpx
import tiktoken

from .interfaces import ILLMProvider

logger = logging.getLogger(__name__)

class OpenAIProvider(ILLMProvider):
    """
    OpenAI LLM æä¾›å•†çš„å®ç°ã€‚
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.api_key = self.config.get('openai_api_key') or os.getenv('OPENAI_API_KEY')
        self.api_base = self.config.get('openai_api_base') or os.getenv('OPENAI_API_BASE', 'https://api.openai.com/v1')
        self.client = httpx.AsyncClient(timeout=60.0)
        self._supported_models = self.config.get('openai_supported_models', ["gpt-3.5-turbo", "gpt-4", "gpt-4o"])
        self._default_model = self.config.get('openai_default_model', "gpt-3.5-turbo")
        
        if not self.api_key:
            logger.warning("OPENAI_API_KEY æˆ–é…ç½®ä¸­æœªè®¾ç½®ã€‚OpenAIProvider å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œã€‚")

    async def generate_response(
        self,
        messages: List[Dict[str, Any]],
        model: str,
        temperature: float = 0.7,
        max_tokens: int = 1024,
        stream: bool = False,
        tools: Optional[List[Dict[str, Any]]] = None,
        tool_choice: Optional[str] = None,
        **kwargs
    ) -> Any:
        """
        æ ¹æ®ç»™å®šçš„æ¶ˆæ¯ç”Ÿæˆ OpenAI LLM å“åº”ã€‚
        """
        # å¤„ç†stop_sequenceså‚æ•° - OpenAI APIä½¿ç”¨'stop'è€Œä¸æ˜¯'stop_sequences'
        if 'stop_sequences' in kwargs:
            stop_sequences = kwargs.pop('stop_sequences')
            kwargs['stop'] = stop_sequences
            logger.debug(f"ğŸ”§ è½¬æ¢stop_sequencesä¸ºOpenAIçš„stopå‚æ•°: {stop_sequences}")
        if model not in self._supported_models:
            logger.warning(f"æ¨¡å‹ {model} ä¸å— OpenAIProvider æ”¯æŒï¼Œå°†ä½¿ç”¨é»˜è®¤æ¨¡å‹ {self._default_model}ã€‚")
            model = self._default_model

        payload = {
            "model": model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature,
            "stream": stream,
            **kwargs
        }
        
        if tools:
            payload["tools"] = tools
        if tool_choice:
            payload["tool_choice"] = tool_choice

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        try:
            response = await self.client.post(
                f"{self.api_base}/chat/completions",
                json=payload,
                headers=headers
            )
            response.raise_for_status()
            
            if stream:
                # å¯¹äºæµå¼å“åº”ï¼Œè¿”å› httpx.Response å¯¹è±¡ï¼Œç”±è°ƒç”¨è€…å¤„ç†
                return response
            else:
                result = response.json()
                # æå–æ–‡æœ¬å†…å®¹ï¼Œå¦‚æœå­˜åœ¨ tool_callsï¼Œåˆ™è¿”å› tool_calls
                if result["choices"] and result["choices"][0]["message"].get("tool_calls"):
                    return result["choices"][0]["message"]["tool_calls"]
                elif result["choices"] and result["choices"][0]["message"].get("content"):
                    return result["choices"][0]["message"]["content"]
                else:
                    return "" # æˆ–è€…æŠ›å‡ºé”™è¯¯ï¼Œå–å†³äºæœŸæœ›è¡Œä¸º
        except httpx.HTTPStatusError as e:
            logger.error(f"OpenAI API HTTP é”™è¯¯: {e.response.status_code} - {e.response.text}")
            raise
        except httpx.RequestError as e:
            logger.error(f"OpenAI API è¯·æ±‚é”™è¯¯: {e}")
            raise
        except Exception as e:
            logger.error(f"è°ƒç”¨ OpenAI API å¤±è´¥: {e}")
            raise

    async def count_tokens(self, text: str, model: str) -> int:
        """
        è®¡ç®—ç»™å®šæ–‡æœ¬åœ¨ç‰¹å®š OpenAI æ¨¡å‹ä¸­çš„ä»¤ç‰Œæ•°ã€‚
        """
        try:
            encoding = tiktoken.encoding_for_model(model)
            return len(encoding.encode(text))
        except KeyError:
            logger.warning(f"æœªæ‰¾åˆ°æ¨¡å‹ {model} çš„ tiktoken ç¼–ç ï¼Œå°†ä½¿ç”¨ cl100k_base ç¼–ç ã€‚")
            encoding = tiktoken.get_encoding("cl100k_base")
            return len(encoding.encode(text))
        except Exception as e:
            logger.error(f"è®¡ç®—ä»¤ç‰Œæ•°å¤±è´¥: {e}")
            return int(len(text) / 4) # ç²—ç•¥ä¼°è®¡ï¼Œå¹¶è½¬æ¢ä¸ºæ•´æ•°

    def get_supported_models(self) -> List[str]:
        """
        è·å–æ­¤æä¾›å•†æ”¯æŒçš„ OpenAI æ¨¡å‹åˆ—è¡¨ã€‚
        """
        return self._supported_models

    def get_default_model(self) -> str:
        """
        è·å–æ­¤æä¾›å•†çš„é»˜è®¤ OpenAI æ¨¡å‹ã€‚
        """
        return self._default_model