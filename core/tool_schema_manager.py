"""
åŠ¨æ€å·¥å…·Schemaç®¡ç†å™¨
å®ç°å¥‘çº¦é©±åŠ¨çš„å·¥å…·æè¿°ç”Ÿæˆï¼Œè§£å†³ç¡¬ç¼–ç å·¥å…·æè¿°é—®é¢˜
"""

import asyncio
import json
import logging
import time
import os
import aiofiles
import hashlib
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from datetime import datetime, timedelta
from pathlib import Path

logger = logging.getLogger(__name__)

# ğŸ”§ P0ä¿®å¤: å¯¼å…¥tool_definitionsä»¥ç¡®ä¿å·¥å…·åœ¨æ¨¡å—åŠ è½½æ—¶æ³¨å†Œ
try:
    from core.toolscore import tool_definitions  # è§¦å‘è£…é¥°å™¨æ³¨å†Œ
    logger.debug("âœ… å·¥å…·å®šä¹‰å·²å¯¼å…¥ï¼Œè‡ªåŠ¨æ³¨å†Œå®Œæˆ")
except ImportError as e:
    logger.warning(f"âš ï¸ æ— æ³•å¯¼å…¥å·¥å…·å®šä¹‰: {e}")
except Exception as e:
    logger.error(f"âŒ å·¥å…·å®šä¹‰å¯¼å…¥å¤±è´¥: {e}")

@dataclass
class ToolSchema:
    """å·¥å…·Schemaå®šä¹‰"""
    tool_id: str
    name: str
    description: str
    actions: Dict[str, Dict[str, Any]]
    category: str = "general"
    version: str = "1.0.0"
    last_updated: datetime = None
    
    def __post_init__(self):
        if self.last_updated is None:
            self.last_updated = datetime.now()
    
    @property
    def id(self) -> str:
        """å‘åå…¼å®¹çš„idå±æ€§ï¼Œè¿”å›tool_id"""
        return self.tool_id
    
    def to_llm_description(self) -> str:
        """ç”Ÿæˆé¢å‘LLMçš„å·¥å…·æè¿°"""
        lines = [f"- **{self.tool_id}** ({self.name}): {self.description}"]
        
        if self.actions:
            lines.append("  ğŸ“‹ å¯ç”¨æ“ä½œ:")
            for action_name, action_info in list(self.actions.items())[:5]:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                desc = action_info.get('desc', action_name)
                lines.append(f"    â€¢ {action_name}: {desc}")
                
                # æ·»åŠ å‚æ•°ä¿¡æ¯
                params = action_info.get('params', {})
                if params:
                    required_params = [k for k, v in params.items() if 'å¿…éœ€' in str(v) or 'required' in str(v).lower()]
                    if required_params:
                        lines.append(f"      å¿…éœ€å‚æ•°: {', '.join(required_params)}")
        
        return "\n".join(lines)
    
    def validate_structure(self) -> Dict[str, Any]:
        """éªŒè¯ToolSchemaç»“æ„å®Œæ•´æ€§"""
        issues = []
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        required_fields = ['tool_id', 'name', 'description', 'actions']
        for field in required_fields:
            if not hasattr(self, field) or getattr(self, field) is None:
                issues.append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
        
        # æ£€æŸ¥actionsç»“æ„
        if hasattr(self, 'actions') and isinstance(self.actions, dict):
            for action_name, action_def in self.actions.items():
                if not isinstance(action_def, dict):
                    issues.append(f"åŠ¨ä½œ {action_name} å®šä¹‰æ— æ•ˆï¼Œåº”ä¸ºå­—å…¸ç±»å‹")
                elif 'desc' not in action_def:
                    issues.append(f"åŠ¨ä½œ {action_name} ç¼ºå°‘æè¿°å­—æ®µ")
        
        return {
            'is_valid': len(issues) == 0,
            'issues': issues,
            'tool_id': getattr(self, 'tool_id', 'unknown')
        }

class ToolSchemaManager:
    """å·¥å…·Schemaç®¡ç†å™¨ - é€‰é¡¹1å®ç°ï¼šç›´æ¥ä»å·¥å…·æ³¨å†Œè¡¨è·å–ä¿¡æ¯ï¼Œä¸ä¾èµ–é…ç½®æ–‡ä»¶"""
    
    def __init__(self, redis_client=None, toolscore_client=None, mcp_config_paths=None):
        self.redis = redis_client
        self.toolscore_client = toolscore_client
        self._cache: Dict[str, ToolSchema] = {}
        self._cache_ttl = 60  # é™ä½åˆ°1åˆ†é’Ÿç¼“å­˜
        self._last_refresh = 0
        
        # ğŸ”§ P0-1ç”Ÿäº§çº§å¼ºåŒ–ï¼šå¹¶å‘å®‰å…¨+å¢é‡æ›´æ–°+å›æ»šæœºåˆ¶
        self._refresh_lock = asyncio.Lock()  # å¹¶å‘æ§åˆ¶é”
        self._last_successful_schemas = {}  # å›æ»šç¼“å­˜
        self._schema_versions: Dict[str, str] = {}  # ETagç‰ˆæœ¬æ§åˆ¶
        self._refresh_interval = 60  # å¯é…ç½®åˆ·æ–°é—´éš”
        self._consistency_check_enabled = True
        
        # MCPæœåŠ¡å™¨å®æ—¶åŒæ­¥ï¼ˆä¿ç•™åŸæœ‰åŠŸèƒ½ï¼‰
        self.mcp_config_paths = mcp_config_paths or [
            "mcp_servers",  # é¡¹ç›®ä¸­çš„MCPæœåŠ¡å™¨ç›®å½•
            "configs/tools",
            "/opt/mcp-servers", 
            "~/.config/mcp-servers"
        ]
        self._mcp_file_hashes: Dict[str, str] = {}
        self._mcp_monitor_task = None
        self._sync_enabled = True

    async def validate_mcp_sync(self) -> Dict[str, Any]:
        """æ‰§è¡ŒMCPæœåŠ¡å™¨åŒæ­¥éªŒè¯å¹¶è¿”å›å¥åº·æŠ¥å‘Š"""
        logger.info("æ­£åœ¨æ‰§è¡ŒMCPåŒæ­¥éªŒè¯...")
        # ç¡®ä¿è°ƒç”¨ä¸€ä¸ªå®é™…å­˜åœ¨çš„æ–¹æ³•æ¥æ‰§è¡ŒéªŒè¯
        # è¿™é‡Œæˆ‘ä»¬å‡è®¾ `_perform_comprehensive_sync_validation` æ˜¯æ‰§è¡Œæ­¤æ“ä½œçš„æ­£ç¡®æ–¹æ³•
        # å¦‚æœè¯¥æ–¹æ³•ä¸å­˜åœ¨ï¼Œåˆ™éœ€è¦å®ç°æˆ–é“¾æ¥åˆ°æ­£ç¡®çš„éªŒè¯é€»è¾‘
        if hasattr(self, '_perform_comprehensive_sync_validation'):
            return await self._perform_comprehensive_sync_validation()
        else:
            # æä¾›ä¸€ä¸ªå›é€€æŠ¥å‘Šï¼Œä»¥é¿å…å› æ–¹æ³•ç¼ºå¤±è€Œå¼•å‘å¼‚å¸¸
            logger.warning("'_perform_comprehensive_sync_validation' aæ–¹æ³•æœªå®ç°ï¼Œè¿”å›é»˜è®¤çš„å¥åº·çŠ¶æ€ã€‚")
            return {
                'overall_health': 'unknown',
                'summary': 'éªŒè¯åŠŸèƒ½æœªå®Œå…¨å®ç°ã€‚',
                'details': {},
                'error': 'éªŒè¯é€»è¾‘ç¼ºå¤±'
            }
        
    async def get_live_tool_schemas(self, force_refresh: bool = False) -> Dict[str, ToolSchema]:
        """å¹¶å‘å®‰å…¨çš„Schemaè·å–ï¼Œå¸¦å›æ»šæœºåˆ¶å’Œä¸€è‡´æ€§éªŒè¯"""
        current_time = time.time()
        
        # ğŸ”’ P0-1å¼ºåŒ–ï¼šå¹¶å‘å®‰å…¨ï¼Œä½¿ç”¨é”é˜²æ­¢å¤šåç¨‹åŒæ—¶åˆ·æ–°
        async with self._refresh_lock:
            if force_refresh or (current_time - self._last_refresh) > self._refresh_interval:
                logger.debug(f"ğŸ”„ å¼€å§‹åˆ·æ–°Schemaç¼“å­˜ (force={force_refresh})ï¼Œå½“å‰ç¼“å­˜: {len(self._cache)} ä¸ªå·¥å…·")
                
                success = await self._safe_refresh_schemas()
                if success:
                    # ğŸ” æ–°å¢ï¼šSchemaä¸€è‡´æ€§éªŒè¯å’Œç»“æ„éªŒè¯
                    consistency_report = await self._validate_schema_consistency()
                    structure_report = await self._validate_schema_structures()
                    
                    # å¤„ç†ä¸€è‡´æ€§é—®é¢˜
                    if consistency_report['has_issues']:
                        logger.warning(f"âš ï¸ å‘ç°Schemaä¸€è‡´æ€§é—®é¢˜: {len(consistency_report['issues'])} ä¸ª")
                        # å°è¯•è‡ªåŠ¨ä¿®å¤
                        fixes_applied = await self._auto_fix_schema_issues(consistency_report['issues'])
                        logger.info(f"ğŸ”§ è‡ªåŠ¨ä¿®å¤äº† {len(fixes_applied)} ä¸ªSchemaé—®é¢˜")
                    
                    # å¤„ç†ç»“æ„é—®é¢˜
                    if structure_report['has_issues']:
                        logger.warning(f"âš ï¸ å‘ç°Schemaç»“æ„é—®é¢˜: {len(structure_report['issues'])} ä¸ª")
                        # å°è¯•è‡ªåŠ¨ä¿®å¤ç»“æ„é—®é¢˜
                        structure_fixes = await self._auto_fix_structure_issues(structure_report['issues'])
                        logger.info(f"ğŸ”§ è‡ªåŠ¨ä¿®å¤äº† {len(structure_fixes)} ä¸ªSchemaç»“æ„é—®é¢˜")
                    
                    self._last_refresh = current_time
                    logger.info(f"âœ… Schemaåˆ·æ–°æˆåŠŸï¼Œç¼“å­˜ {len(self._cache)} ä¸ªå·¥å…·")
                else:
                    # ğŸ“¦ å›æ»šæœºåˆ¶ï¼šåˆ·æ–°å¤±è´¥æ—¶ä½¿ç”¨æœ€åæˆåŠŸçš„Schema
                    logger.warning("âŒ Schemaåˆ·æ–°å¤±è´¥ï¼Œä½¿ç”¨å›æ»šç¼“å­˜")
                    if self._last_successful_schemas:
                        self._cache = self._last_successful_schemas.copy()
                        logger.info(f"ğŸ”„ å·²å›æ»šåˆ°æœ€åæˆåŠŸç‰ˆæœ¬ ({len(self._cache)} ä¸ªå·¥å…·)")
        
        return self._cache.copy()
    
    async def _load_mcp_service_configs(self) -> List[Dict[str, Any]]:
        """åŠ è½½MCPæœåŠ¡å™¨é…ç½®æ–‡ä»¶"""
        configs = []
        
        try:
            # éå†é…ç½®è·¯å¾„ï¼ŒæŸ¥æ‰¾service.jsonæ–‡ä»¶
            for config_path_str in self.mcp_config_paths:
                config_path = Path(config_path_str).expanduser()
                if not config_path.exists():
                    continue
                
                # æŸ¥æ‰¾æ‰€æœ‰service.jsonæ–‡ä»¶
                for service_file in config_path.glob("**/service.json"):
                    try:
                        async with aiofiles.open(service_file, 'r', encoding='utf-8') as f:
                            content = await f.read()
                            service_config = json.loads(content)
                            
                            # æ·»åŠ æ–‡ä»¶è·¯å¾„ä¿¡æ¯
                            service_config['_file_path'] = str(service_file)
                            configs.append(service_config)
                            
                            logger.debug(f"âœ… åŠ è½½MCPæœåŠ¡é…ç½®: {service_file}")
                            
                    except Exception as e:
                        logger.warning(f"âš ï¸ è¯»å–MCPæœåŠ¡é…ç½®å¤±è´¥ {service_file}: {e}")
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é…ç½®æ–‡ä»¶ï¼Œè¿”å›ç©ºé…ç½®åˆ—è¡¨
            if not configs:
                logger.debug("ğŸ“‹ æœªæ‰¾åˆ°MCPæœåŠ¡é…ç½®æ–‡ä»¶ï¼Œè¿”å›ç©ºé…ç½®")
                
        except Exception as e:
            logger.error(f"âŒ åŠ è½½MCPæœåŠ¡é…ç½®å¤±è´¥: {e}")
        
        return configs
    
    async def _validate_schema_consistency(self) -> Dict[str, Any]:
        """éªŒè¯Schemaæ•°æ®æºé—´çš„ä¸€è‡´æ€§"""
        consistency_report = {
            'timestamp': datetime.now().isoformat(),
            'has_issues': False,
            'issues': [],
            'checked_tools': 0
        }
        
        try:
            # è·å–service.jsoné…ç½®
            service_configs = await self._load_mcp_service_configs()
            
            for tool_id, cached_schema in self._cache.items():
                consistency_report['checked_tools'] += 1
                
                # ğŸ”§ é˜²å¾¡æ€§æ£€æŸ¥ï¼šç¡®ä¿ cached_schema æ˜¯æœ‰æ•ˆå¯¹è±¡
                if not hasattr(cached_schema, 'actions'):
                    logger.warning(f"âš ï¸ {tool_id} çš„ schema å¯¹è±¡æ— æ•ˆï¼Œè·³è¿‡æ£€æŸ¥")
                    continue
                
                # æŸ¥æ‰¾å¯¹åº”çš„service.jsoné…ç½®
                service_config = None
                for config in service_configs:
                    if (config.get('service_id') == tool_id or 
                        tool_id.endswith(config.get('service_id', '')) or
                        config.get('service_id', '').endswith(tool_id.replace('mcp-', '').replace('-mcp-server', ''))):
                        service_config = config
                        break
                
                if service_config:
                    # æ¯”è¾ƒcapabilities
                    service_capabilities = {cap['name']: cap for cap in service_config.get('capabilities', [])}
                    
                    # ğŸ”§ é˜²å¾¡æ€§æ£€æŸ¥ï¼šç¡®ä¿ actions æ˜¯å­—å…¸ç±»å‹
                    cached_actions = cached_schema.actions
                    if not isinstance(cached_actions, dict):
                        logger.warning(f"âš ï¸ {tool_id} çš„ actions ä¸æ˜¯å­—å…¸ç±»å‹: {type(cached_actions)}")
                        cached_actions = {}
                    
                    # æ£€æŸ¥ç¼ºå¤±çš„åŠ¨ä½œ
                    for cap_name in service_capabilities:
                        if cap_name not in cached_actions:
                            consistency_report['issues'].append({
                                'type': 'missing_cached_action',
                                'tool_id': tool_id,
                                'action': cap_name,
                                'severity': 'medium',
                                'description': f"service.jsonä¸­å®šä¹‰äº†{cap_name}ï¼Œä½†ç¼“å­˜ä¸­ç¼ºå¤±"
                            })
                    
                    # æ£€æŸ¥å¤šä½™çš„åŠ¨ä½œ
                    for action_name in cached_actions:
                        if action_name not in service_capabilities:
                            consistency_report['issues'].append({
                                'type': 'extra_cached_action',
                                'tool_id': tool_id, 
                                'action': action_name,
                                'severity': 'low',
                                'description': f"ç¼“å­˜ä¸­æœ‰{action_name}ï¼Œä½†service.jsonä¸­æœªå®šä¹‰"
                            })
                    
                    # æ£€æŸ¥å‚æ•°ä¸€è‡´æ€§
                    for cap_name, cap_info in service_capabilities.items():
                        if cap_name in cached_actions:
                            param_issues = self._compare_action_parameters(
                                cap_info, cached_actions[cap_name], tool_id, cap_name
                            )
                            consistency_report['issues'].extend(param_issues)
                
            consistency_report['has_issues'] = len(consistency_report['issues']) > 0
            
        except Exception as e:
            logger.error(f"âŒ Schemaä¸€è‡´æ€§éªŒè¯å¤±è´¥: {e}")
            consistency_report['issues'].append({
                'type': 'validation_error',
                'severity': 'high',
                'description': f"ä¸€è‡´æ€§éªŒè¯å¼‚å¸¸: {e}"
            })
            consistency_report['has_issues'] = True
            
        return consistency_report
    
    async def _validate_schema_structures(self) -> Dict[str, Any]:
        """éªŒè¯æ‰€æœ‰ToolSchemaçš„ç»“æ„å®Œæ•´æ€§"""
        structure_report = {
            'timestamp': datetime.now().isoformat(),
            'has_issues': False,
            'issues': [],
            'checked_schemas': 0,
            'valid_schemas': 0
        }
        
        try:
            for tool_id, schema in self._cache.items():
                structure_report['checked_schemas'] += 1
                
                # éªŒè¯å•ä¸ªschemaç»“æ„
                validation_result = schema.validate_structure()
                
                if validation_result['is_valid']:
                    structure_report['valid_schemas'] += 1
                else:
                    structure_report['has_issues'] = True
                    for issue in validation_result['issues']:
                        structure_report['issues'].append({
                            'type': 'structure_issue',
                            'tool_id': tool_id,
                            'issue': issue,
                            'severity': 'high'
                        })
            
            logger.debug(f"ğŸ” ç»“æ„éªŒè¯å®Œæˆ: {structure_report['valid_schemas']}/{structure_report['checked_schemas']} ä¸ªSchemaæœ‰æ•ˆ")
            
        except Exception as e:
            logger.error(f"âŒ Schemaç»“æ„éªŒè¯å¤±è´¥: {e}")
            structure_report['has_issues'] = True
            structure_report['issues'].append({
                'type': 'validation_error',
                'error': str(e),
                'severity': 'critical'
            })
        
        return structure_report
    
    async def _auto_fix_structure_issues(self, issues: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """è‡ªåŠ¨ä¿®å¤Schemaç»“æ„é—®é¢˜"""
        fixes_applied = []
        
        for issue in issues:
            try:
                if issue['type'] == 'structure_issue':
                    fix_result = await self._fix_structure_issue(issue)
                    if fix_result:
                        fixes_applied.append(fix_result)
                        
            except Exception as e:
                logger.error(f"âŒ ä¿®å¤ç»“æ„é—®é¢˜å¤±è´¥ {issue}: {e}")
        
        return fixes_applied
    
    async def _fix_structure_issue(self, issue: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ä¿®å¤å•ä¸ªç»“æ„é—®é¢˜"""
        try:
            tool_id = issue['tool_id']
            issue_description = issue['issue']
            
            if tool_id not in self._cache:
                return None
            
            schema = self._cache[tool_id]
            
            # ä¿®å¤ç¼ºå°‘å¿…éœ€å­—æ®µçš„é—®é¢˜
            if "ç¼ºå°‘å¿…éœ€å­—æ®µ" in issue_description:
                field_name = issue_description.split(": ")[-1]
                
                if field_name == 'name' and not hasattr(schema, 'name'):
                    schema.name = tool_id.replace('_', ' ').title()
                    return {
                        'type': 'added_missing_field',
                        'tool_id': tool_id,
                        'field': field_name,
                        'value': schema.name
                    }
                elif field_name == 'description' and not hasattr(schema, 'description'):
                    schema.description = f"Tool for {tool_id} operations"
                    return {
                        'type': 'added_missing_field',
                        'tool_id': tool_id,
                        'field': field_name,
                        'value': schema.description
                    }
                elif field_name == 'actions' and not hasattr(schema, 'actions'):
                    schema.actions = {}
                    return {
                        'type': 'added_missing_field',
                        'tool_id': tool_id,
                        'field': field_name,
                        'value': 'empty_actions_dict'
                    }
            
            # ä¿®å¤åŠ¨ä½œå®šä¹‰é—®é¢˜
            elif "åŠ¨ä½œ" in issue_description and "å®šä¹‰æ— æ•ˆ" in issue_description:
                action_name = issue_description.split()[1]
                if hasattr(schema, 'actions') and action_name in schema.actions:
                    if not isinstance(schema.actions[action_name], dict):
                        schema.actions[action_name] = {
                            'desc': f'Action {action_name}',
                            'params': {}
                        }
                        return {
                            'type': 'fixed_action_definition',
                            'tool_id': tool_id,
                            'action': action_name
                        }
            
            # ä¿®å¤ç¼ºå°‘æè¿°å­—æ®µçš„é—®é¢˜
            elif "ç¼ºå°‘æè¿°å­—æ®µ" in issue_description:
                action_name = issue_description.split()[1]
                if hasattr(schema, 'actions') and action_name in schema.actions:
                    if 'desc' not in schema.actions[action_name]:
                        schema.actions[action_name]['desc'] = f'Action {action_name}'
                        return {
                            'type': 'added_action_description',
                            'tool_id': tool_id,
                            'action': action_name
                        }
            
        except Exception as e:
            logger.error(f"âŒ ä¿®å¤ç»“æ„é—®é¢˜å¼‚å¸¸: {e}")
        
        return None
    
    def _compare_action_parameters(self, service_cap: Dict, cached_action: Dict, 
                                 tool_id: str, action_name: str) -> List[Dict]:
        """æ¯”è¾ƒåŠ¨ä½œå‚æ•°çš„ä¸€è‡´æ€§"""
        issues = []
        
        try:
            service_params = service_cap.get('parameters', {})
            service_required = service_cap.get('required_params', [])
            
            cached_params = cached_action.get('params', {})
            
            # æ£€æŸ¥å¿…éœ€å‚æ•°ä¸€è‡´æ€§
            for required_param in service_required:
                if required_param not in cached_params:
                    issues.append({
                        'type': 'missing_required_param',
                        'tool_id': tool_id,
                        'action': action_name,
                        'parameter': required_param,
                        'severity': 'high',
                        'description': f"å¿…éœ€å‚æ•°{required_param}åœ¨ç¼“å­˜ä¸­ç¼ºå¤±"
                    })
                elif 'å¿…éœ€' not in str(cached_params[required_param]):
                    issues.append({
                        'type': 'param_requirement_mismatch',
                        'tool_id': tool_id,
                        'action': action_name,
                        'parameter': required_param,
                        'severity': 'medium',
                        'description': f"å‚æ•°{required_param}åº”æ ‡è®°ä¸ºå¿…éœ€"
                    })
            
            # æ£€æŸ¥å‚æ•°å®šä¹‰ä¸€è‡´æ€§
            for param_name, param_def in service_params.items():
                if param_name not in cached_params:
                    issues.append({
                        'type': 'missing_param_definition',
                        'tool_id': tool_id,
                        'action': action_name,
                        'parameter': param_name,
                        'severity': 'low',
                        'description': f"å‚æ•°{param_name}å®šä¹‰åœ¨ç¼“å­˜ä¸­ç¼ºå¤±"
                    })
                    
        except Exception as e:
            issues.append({
                'type': 'parameter_comparison_error',
                'tool_id': tool_id,
                'action': action_name,
                'severity': 'medium',
                'description': f"å‚æ•°æ¯”è¾ƒå¼‚å¸¸: {e}"
            })
            
        return issues
    
    async def _auto_fix_schema_issues(self, issues: List[Dict]) -> List[Dict]:
        """è‡ªåŠ¨ä¿®å¤å¯ä¿®å¤çš„Schemaé—®é¢˜"""
        fixes_applied = []
        
        for issue in issues:
            try:
                if issue['type'] == 'missing_cached_action':
                    # å°è¯•ä»service.jsoné‡æ–°ç”ŸæˆåŠ¨ä½œå®šä¹‰
                    fix_result = await self._fix_missing_cached_action(issue)
                    if fix_result:
                        fixes_applied.append(fix_result)
                        
                elif issue['type'] == 'param_requirement_mismatch':
                    # ä¿®æ­£å‚æ•°å¿…éœ€æ€§æ ‡è®°
                    fix_result = self._fix_parameter_requirement(issue)
                    if fix_result:
                        fixes_applied.append(fix_result)
                        
                elif issue['type'] == 'missing_param_definition':
                    # æ·»åŠ ç¼ºå¤±çš„å‚æ•°å®šä¹‰
                    fix_result = await self._fix_missing_parameter_definition(issue)
                    if fix_result:
                        fixes_applied.append(fix_result)
                        
            except Exception as e:
                logger.error(f"âŒ ä¿®å¤Schemaé—®é¢˜å¤±è´¥ {issue}: {e}")
                
        return fixes_applied
    
    async def _fix_missing_cached_action(self, issue: Dict) -> Optional[Dict]:
        """ä¿®å¤ç¼ºå¤±çš„ç¼“å­˜åŠ¨ä½œ"""
        try:
            tool_id = issue['tool_id']
            action_name = issue['action']
            
            # ä»service.jsonè·å–åŠ¨ä½œå®šä¹‰
            service_configs = await self._load_mcp_service_configs()
            for config in service_configs:
                if self._matches_tool_id(config.get('service_id', ''), tool_id):
                    capabilities = config.get('capabilities', [])
                    for cap in capabilities:
                        if cap['name'] == action_name:
                            # é‡æ–°ç”ŸæˆåŠ¨ä½œå®šä¹‰
                            action_def = self._convert_service_capability_to_action(cap)
                            
                            # æ›´æ–°ç¼“å­˜
                            if tool_id in self._cache:
                                self._cache[tool_id].actions[action_name] = action_def
                                
                                return {
                                    'type': 'added_missing_action',
                                    'tool_id': tool_id,
                                    'action': action_name,
                                    'description': f"ä»service.jsonæ¢å¤äº†åŠ¨ä½œ{action_name}"
                                }
        except Exception as e:
            logger.error(f"âŒ ä¿®å¤ç¼ºå¤±åŠ¨ä½œå¤±è´¥: {e}")
        
        return None
    
    def _fix_parameter_requirement(self, issue: Dict) -> Optional[Dict]:
        """ä¿®å¤å‚æ•°å¿…éœ€æ€§æ ‡è®°"""
        try:
            tool_id = issue['tool_id']
            action_name = issue['action']
            param_name = issue['parameter']
            
            if (tool_id in self._cache and 
                action_name in self._cache[tool_id].actions and
                param_name in self._cache[tool_id].actions[action_name].get('params', {})):
                
                # æ›´æ–°å‚æ•°æ ‡è®°ä¸ºå¿…éœ€
                current_desc = self._cache[tool_id].actions[action_name]['params'][param_name]
                if 'å¿…éœ€' not in str(current_desc):
                    self._cache[tool_id].actions[action_name]['params'][param_name] = f"å¿…éœ€ - {current_desc}"
                    
                    return {
                        'type': 'fixed_param_requirement',
                        'tool_id': tool_id,
                        'action': action_name,
                        'parameter': param_name,
                        'description': f"æ ‡è®°å‚æ•°{param_name}ä¸ºå¿…éœ€"
                    }
        except Exception as e:
            logger.error(f"âŒ ä¿®å¤å‚æ•°å¿…éœ€æ€§å¤±è´¥: {e}")
            
        return None
    
    async def _fix_missing_parameter_definition(self, issue: Dict) -> Optional[Dict]:
        """ä¿®å¤ç¼ºå¤±çš„å‚æ•°å®šä¹‰"""
        try:
            tool_id = issue['tool_id']
            action_name = issue['action']
            param_name = issue['parameter']
            
            # ä»service.jsonè·å–å‚æ•°å®šä¹‰
            service_configs = await self._load_mcp_service_configs()
            for config in service_configs:
                if self._matches_tool_id(config.get('service_id', ''), tool_id):
                    capabilities = config.get('capabilities', [])
                    for cap in capabilities:
                        if cap['name'] == action_name:
                            params = cap.get('parameters', {})
                            if param_name in params:
                                param_def = params[param_name]
                                
                                # æ·»åŠ å‚æ•°å®šä¹‰åˆ°ç¼“å­˜
                                if (tool_id in self._cache and 
                                    action_name in self._cache[tool_id].actions):
                                    
                                    if 'params' not in self._cache[tool_id].actions[action_name]:
                                        self._cache[tool_id].actions[action_name]['params'] = {}
                                    
                                    self._cache[tool_id].actions[action_name]['params'][param_name] = param_def.get('description', f"{param_name}å‚æ•°")
                                    
                                    return {
                                        'type': 'added_missing_param',
                                        'tool_id': tool_id,
                                        'action': action_name,
                                        'parameter': param_name,
                                        'description': f"æ·»åŠ äº†å‚æ•°{param_name}çš„å®šä¹‰"
                                    }
        except Exception as e:
            logger.error(f"âŒ ä¿®å¤ç¼ºå¤±å‚æ•°å®šä¹‰å¤±è´¥: {e}")
            
        return None
    
    def _matches_tool_id(self, service_id: str, tool_id: str) -> bool:
        """æ£€æŸ¥service_idæ˜¯å¦åŒ¹é…tool_id"""
        if not service_id or not tool_id:
            return False
            
        # æ ‡å‡†åŒ¹é…
        if service_id == tool_id:
            return True
            
        # æ¨¡ç³ŠåŒ¹é…
        service_clean = service_id.replace('-', '').replace('_', '').lower()
        tool_clean = tool_id.replace('-', '').replace('_', '').replace('mcp', '').replace('server', '').lower()
        
        return service_clean in tool_clean or tool_clean in service_clean
    
    def _convert_service_capability_to_action(self, capability: Dict) -> Dict:
        """å°†service.jsonçš„capabilityè½¬æ¢ä¸ºåŠ¨ä½œå®šä¹‰"""
        action_def = {
            'desc': capability.get('description', ''),
            'params': {}
        }
        
        # è½¬æ¢å‚æ•°
        parameters = capability.get('parameters', {})
        required_params = capability.get('required_params', [])
        
        for param_name, param_info in parameters.items():
            param_desc = param_info.get('description', f"{param_name}å‚æ•°")
            if param_name in required_params:
                param_desc = f"å¿…éœ€ - {param_desc}"
            else:
                param_desc = f"å¯é€‰ - {param_desc}"
            
            action_def['params'][param_name] = param_desc
        
        # æ·»åŠ ç¤ºä¾‹
        examples = capability.get('examples', [])
        if examples and isinstance(examples, list) and len(examples) > 0:
            action_def['example'] = examples[0]
        
        return action_def
    
    async def get_available_tool_ids(self) -> List[str]:
        """è·å–å½“å‰å¯ç”¨çš„å·¥å…·IDåˆ—è¡¨"""
        schemas = await self.get_live_tool_schemas()
        return list(schemas.keys())
    
    async def get_tool_schema(self, tool_id: str) -> Optional[ToolSchema]:
        """è·å–ç‰¹å®šå·¥å…·çš„Schema"""
        schemas = await self.get_live_tool_schemas()
        return schemas.get(tool_id)
    
    async def generate_llm_tools_description(self) -> str:
        """ç”Ÿæˆé¢å‘LLMçš„åŠ¨æ€å·¥å…·æè¿° - å¸¦å¼ºæ ¡éªŒæœºåˆ¶"""
        schemas = await self.get_live_tool_schemas()
        
        if not schemas:
            return "âš ï¸ å½“å‰æ— å¯ç”¨å·¥å…·ï¼Œè¯·è”ç³»ç®¡ç†å‘˜æ£€æŸ¥å·¥å…·æœåŠ¡çŠ¶æ€"
        
        lines = ["### ğŸ“‹ å®æ—¶å¯ç”¨å·¥å…· (åŸºäºå½“å‰éƒ¨ç½²çŠ¶æ€):"]
        
        # ç”ŸæˆåŠ¨ä½œé›†åˆçš„hashï¼Œç”¨äºæ ¡éªŒpromptä¸æ‰§è¡Œç«¯ä¸€è‡´æ€§
        action_set = set()
        for schema in schemas.values():
            for action in schema.actions:
                action_set.add(f"{schema.tool_id}.{action}")
        
        # è®¡ç®—åŠ¨ä½œé›†åˆçš„hash
        import hashlib
        action_hash = hashlib.md5("|".join(sorted(action_set)).encode()).hexdigest()[:8]
        
        # æŒ‰ç±»åˆ«åˆ†ç»„æ˜¾ç¤º
        categorized = {}
        for schema in schemas.values():
            category = schema.category
            if category not in categorized:
                categorized[category] = []
            categorized[category].append(schema)
        
        for category, tool_list in categorized.items():
            lines.append(f"\n**{category.title()} å·¥å…·:**")
            for schema in tool_list:
                lines.append(schema.to_llm_description())
        
        # ğŸ”’ P0-1 ä¿®å¤ï¼šæ·»åŠ å¼ºæ ¡éªŒæœºåˆ¶
        lines.extend([
            "",
            "âš ï¸ **ä¸¥æ ¼çº¦æŸ**: åªèƒ½ä½¿ç”¨ä¸Šè¿°æ˜ç¡®åˆ—å‡ºçš„å·¥å…·å’ŒåŠ¨ä½œç»„åˆï¼",
            f"ğŸ”’ **Schemaæ ¡éªŒç **: {action_hash} (ç¡®ä¿promptä¸æ‰§è¡Œç«¯ä¸€è‡´)",
            "ğŸ“ **æ•°æ®æº**: 100%åŸºäºå½“å‰å®é™…éƒ¨ç½²çŠ¶æ€åŠ¨æ€ç”Ÿæˆ",
            f"ğŸ•’ **æ›´æ–°æ—¶é—´**: {datetime.now().strftime('%H:%M:%S')}",
            "",
            "ğŸš« **ç¦æ­¢è¡Œä¸º**: ä¸è¦å°è¯•ä»¥ä¸‹æ“ä½œ",
            "- ä½¿ç”¨æœªåˆ—å‡ºçš„å·¥å…·IDæˆ–åŠ¨ä½œåç§°",
            "- ç»„åˆä¸åŒå·¥å…·çš„åŠ¨ä½œåç§°",
            "- ä½¿ç”¨æ—§ç‰ˆæœ¬æˆ–æ–‡æ¡£ä¸­çš„ç¤ºä¾‹åŠ¨ä½œå",
            f"- å¿½ç•¥æ ¡éªŒç  {action_hash} å¯¹åº”çš„åŠ¨ä½œé›†åˆ"
        ])
        
        return "\n".join(lines)
    
    async def get_action_whitelist(self) -> Dict[str, List[str]]:
        """è·å–ä¸¥æ ¼çš„åŠ¨ä½œç™½åå•ï¼Œç”¨äºç”Ÿæˆå‰éªŒè¯"""
        schemas = await self.get_live_tool_schemas()
        whitelist = {}
        
        for schema in schemas.values():
            whitelist[schema.tool_id] = list(schema.actions)
            
        return whitelist
    
    async def validate_action_combination(self, tool_id: str, action: str) -> Tuple[bool, str]:
        """éªŒè¯å·¥å…·åŠ¨ä½œç»„åˆæ˜¯å¦åœ¨ç™½åå•ä¸­"""
        whitelist = await self.get_action_whitelist()
        
        if tool_id not in whitelist:
            available_tools = list(whitelist.keys())
            return False, f"æœªçŸ¥å·¥å…·ID: {tool_id}ã€‚å¯ç”¨å·¥å…·: {available_tools}"
        
        if action not in whitelist[tool_id]:
            available_actions = whitelist[tool_id]
            return False, f"å·¥å…· {tool_id} ä¸æ”¯æŒåŠ¨ä½œ {action}ã€‚å¯ç”¨åŠ¨ä½œ: {available_actions}"
        
        return True, ""
    
    async def _refresh_schemas(self):
        """åˆ·æ–°å·¥å…·Schemas - å®ç°é€‰é¡¹1: ç›´æ¥ä»å·¥å…·æ³¨å†Œè¡¨è·å–ä¿¡æ¯"""
        logger.debug("ğŸ”„ å¼€å§‹åˆ·æ–°å·¥å…·Schemas...")
        
        # ä¿å­˜å½“å‰ç¼“å­˜ä½œä¸ºå¤‡ä»½
        cache_backup = self._cache.copy()
        logger.debug(f"ğŸ“¦ å¤‡ä»½å½“å‰ç¼“å­˜: {len(cache_backup)} ä¸ªå·¥å…·")
        
        try:
            # ğŸš€ é€‰é¡¹1å®ç°: ä¼˜å…ˆä»ç»“æ„åŒ–å·¥å…·æ³¨å†Œè¡¨è·å–ï¼ˆä¸»è¦æ•°æ®æºï¼‰
            await self._refresh_from_registry()
            
            # æ–¹æ³•2: é€šè¿‡ToolScoreå®¢æˆ·ç«¯è·å–ï¼ˆè¡¥å……æ•°æ®æºï¼‰
            if self.toolscore_client and len(self._cache) == 0:
                logger.warning("âš ï¸ å·¥å…·æ³¨å†Œè¡¨ä¸ºç©ºï¼Œå›é€€åˆ°ToolScoreå®¢æˆ·ç«¯")
                await self._refresh_from_toolscore()
            
            # å¦‚æœåˆ·æ–°åç¼“å­˜ä»ä¸ºç©ºä¸”æœ‰å¤‡ä»½ï¼Œæ¢å¤å¤‡ä»½
            if len(self._cache) == 0 and len(cache_backup) > 0:
                logger.warning(f"âš ï¸ åˆ·æ–°åç¼“å­˜ä¸ºç©ºï¼Œæ¢å¤å¤‡ä»½ {len(cache_backup)} ä¸ªå·¥å…·")
                self._cache = cache_backup
                
            logger.info(f"âœ… å·¥å…·Schemasåˆ·æ–°å®Œæˆï¼Œå½“å‰å¯ç”¨å·¥å…·: {len(self._cache)}ä¸ª")
            
        except Exception as e:
            logger.error(f"âŒ å·¥å…·Schemasåˆ·æ–°å¤±è´¥: {e}")
            # å¦‚æœåˆ·æ–°å¤±è´¥ï¼Œæ¢å¤å¤‡ä»½ç¼“å­˜
            if len(cache_backup) > 0:
                logger.warning(f"âš ï¸ åˆ·æ–°å¤±è´¥ï¼Œæ¢å¤å¤‡ä»½ {len(cache_backup)} ä¸ªå·¥å…·")
                self._cache = cache_backup
    
    async def _refresh_from_toolscore(self):
        """ä»ToolScoreæœåŠ¡è·å–Schemas"""
        try:
            # è·å–å¯ç”¨å·¥å…·åˆ—è¡¨
            tools = await self.toolscore_client.get_available_tools()
            logger.debug(f"ğŸ” ä»ToolScoreè·å–åˆ°å·¥å…·åˆ—è¡¨: {tools}")
            
            # æ˜ å°„æ—§çš„å·¥å…·IDåˆ°æ–°çš„ID
            tool_id_mapping = {
                'microsandbox-mcp-server': 'microsandbox',
                'browser-use-mcp-server': 'browser_use',
                'mcp-deepsearch': 'deepsearch',
                'mcp-search-tool': 'mcp-search-tool'  # ä¿æŒä¸å˜
            }
            
            # è½¬æ¢å·¥å…·IDåˆ—è¡¨
            mapped_tools = []
            for tool_id in tools:
                mapped_id = tool_id_mapping.get(tool_id, tool_id)
                mapped_tools.append(mapped_id)
                if mapped_id != tool_id:
                    logger.debug(f"ğŸ”„ å·¥å…·IDæ˜ å°„: {tool_id} -> {mapped_id}")
            
            logger.debug(f"ğŸ”§ æ˜ å°„åçš„å·¥å…·åˆ—è¡¨: {mapped_tools}")
            
            for tool_id in mapped_tools:
                try:
                    # ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦å·²åœ¨ç¼“å­˜ä¸­ï¼ˆæ¥è‡ªç»“æ„åŒ–å·¥å…·æ³¨å†Œè¡¨ï¼‰
                    if tool_id in self._cache:
                        logger.debug(f"â­ï¸ å·¥å…· {tool_id} å·²åœ¨ç¼“å­˜ä¸­ï¼Œè·³è¿‡ToolScoreè·å–")
                        continue
                    
                    # å¦‚æœä¸åœ¨ç¼“å­˜ä¸­ï¼Œä»ToolScoreè·å–è¯¦ç»†ä¿¡æ¯
                    tool_info = await self._get_tool_info_from_toolscore(tool_id)
                    if tool_info:
                        schema = self._convert_to_schema(tool_info)
                        self._cache[tool_id] = schema
                        logger.debug(f"âœ… å·²ä»ToolScoreç¼“å­˜å·¥å…·Schema: {tool_id}")
                    else:
                        # å¦‚æœæ— æ³•è·å–è¯¦ç»†ä¿¡æ¯ï¼Œåˆ›å»ºåŸºç¡€Schema
                        basic_schema = self._create_basic_schema(tool_id)
                        self._cache[tool_id] = basic_schema
                        logger.debug(f"ğŸ”§ åˆ›å»ºåŸºç¡€Schema: {tool_id}")
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ è·å–å·¥å…· {tool_id} ä¿¡æ¯å¤±è´¥: {e}")
                    # å®¹é”™å¤„ç†ï¼šåªæœ‰å½“å·¥å…·ä¸åœ¨ç¼“å­˜ä¸­æ—¶æ‰åˆ›å»ºå¤‡ç”¨Schema
                    if tool_id not in self._cache:
                        try:
                            fallback_schema = self._create_basic_schema(tool_id)
                            self._cache[tool_id] = fallback_schema
                            logger.debug(f"ğŸŠ‘ ä½¿ç”¨å¤‡ç”¨Schema: {tool_id}")
                        except Exception as fallback_error:
                            logger.error(f"â— åˆ›å»ºå¤‡ç”¨Schemaå¤±è´¥: {tool_id} - {fallback_error}")
                    
        except Exception as e:
            logger.warning(f"âš ï¸ ä»ToolScoreè·å–å·¥å…·åˆ—è¡¨å¤±è´¥: {e}")
    
    async def _refresh_from_registry(self):
        """ä»ç»“æ„åŒ–å·¥å…·æ³¨å†Œè¡¨è·å–Schemas - é€‰é¡¹1ä¸»è¦å®ç°"""
        try:
            from core.toolscore.structured_tools import tool_registry
            # ğŸ”§ P0ä¿®å¤: å¯¼å…¥tool_definitionsä»¥è§¦å‘å·¥å…·è‡ªåŠ¨æ³¨å†Œ
            from core.toolscore import tool_definitions  # è§¦å‘è£…é¥°å™¨æ³¨å†Œ
            
            # æ£€æŸ¥å·¥å…·æ³¨å†Œè¡¨çŠ¶æ€
            logger.debug(f"ğŸ” å·¥å…·æ³¨å†Œè¡¨çŠ¶æ€æ£€æŸ¥: _tools å­—å…¸åŒ…å« {len(tool_registry._tools)} ä¸ªæ¡ç›®")
            for tool_id in tool_registry._tools.keys():
                logger.debug(f"  - æ³¨å†Œè¡¨ä¸­çš„å·¥å…·: {tool_id}")
            
            tools = tool_registry.get_all_tools()
            logger.info(f"ğŸ”§ é€‰é¡¹1: ä»å·¥å…·æ³¨å†Œè¡¨è·å–åˆ° {len(tools)} ä¸ªå·¥å…·")
            
            # æ£€æŸ¥å·¥å…·å¯¹è±¡çš„æœ‰æ•ˆæ€§
            for i, tool in enumerate(tools):
                if hasattr(tool, 'id') and hasattr(tool, 'name'):
                    logger.debug(f"  å·¥å…· {i}: id={tool.id}, name={tool.name}, actions={len(tool.actions) if hasattr(tool, 'actions') else 0}")
                else:
                    logger.error(f"  âŒ æ— æ•ˆçš„å·¥å…·å¯¹è±¡ {i}: {type(tool)}")
                    return  # å¦‚æœæœ‰æ— æ•ˆå·¥å…·ï¼Œç›´æ¥è¿”å›
            
            # å¦‚æœæ³¨å†Œè¡¨ä¸ºç©ºï¼Œæ·»åŠ åŸºç¡€MCPå·¥å…·çš„å›é€€å®šä¹‰
            if len(tools) == 0:
                logger.warning("âš ï¸ å·¥å…·æ³¨å†Œè¡¨ä¸ºç©ºï¼Œæ·»åŠ åŸºç¡€MCPå·¥å…·å®šä¹‰")
                self._add_fallback_mcp_tools()
                logger.info(f"ğŸ”§ å›é€€å®šä¹‰æ·»åŠ å®Œæˆï¼Œæœ€ç»ˆç¼“å­˜å¤§å°: {len(self._cache)} ä¸ªå·¥å…·")
                return
            
            processed_count = 0
            for tool_def in tools:
                try:
                    logger.debug(f"ğŸ”§ å¤„ç†å·¥å…·å®šä¹‰: {tool_def.id}")
                    # è½¬æ¢ä¸ºToolSchemaæ ¼å¼ï¼Œæå–å®Œæ•´çš„å‚æ•°ä¿¡æ¯
                    actions = {}
                    for action in tool_def.actions:
                        try:
                            # ğŸ”§ é€‰é¡¹1å¢å¼º: æå–è¯¦ç»†çš„å‚æ•°ä¿¡æ¯
                            params = {}
                            if hasattr(action, 'parameters') and action.parameters:
                                # ä»Pydanticæ¨¡å‹æå–å‚æ•°ä¿¡æ¯
                                param_schema = action.parameters.schema()
                                properties = param_schema.get('properties', {})
                                required = param_schema.get('required', [])
                                
                                for param_name, param_info in properties.items():
                                    param_desc = param_info.get('description', f'{param_name}å‚æ•°')
                                    if param_name in required:
                                        param_desc = f"å¿…éœ€ - {param_desc}"
                                    else:
                                        param_desc = f"å¯é€‰ - {param_desc}"
                                    params[param_name] = param_desc
                            
                            actions[action.name] = {
                                'desc': action.description,
                                'params': params,
                                'example': getattr(action, 'example', {})
                            }
                            logger.debug(f"  âœ… å¤„ç†åŠ¨ä½œ: {action.name}")
                        except Exception as action_error:
                            logger.error(f"  âŒ å¤„ç†åŠ¨ä½œå¤±è´¥: {action.name} - {action_error}")
                            # åˆ›å»ºåŸºç¡€åŠ¨ä½œå®šä¹‰
                            actions[action.name] = {
                                'desc': getattr(action, 'description', 'åŠ¨ä½œæè¿°'),
                                'params': {},
                                'example': {}
                            }
                    
                    schema = ToolSchema(
                        tool_id=tool_def.id,
                        name=tool_def.name,
                        description=tool_def.description,
                        actions=actions,
                        category=tool_def.category,
                        version=getattr(tool_def, 'version', '1.0.0')
                    )
                    
                    self._cache[tool_def.id] = schema
                    processed_count += 1
                    logger.debug(f"âœ… é€‰é¡¹1: æˆåŠŸç¼“å­˜å·¥å…· {tool_def.id} (åŒ…å« {len(actions)} ä¸ªåŠ¨ä½œ)")
                    logger.debug(f"   å½“å‰ç¼“å­˜å¤§å°: {len(self._cache)} ä¸ªå·¥å…·")
                except Exception as tool_error:
                    logger.error(f"âŒ å¤„ç†å·¥å…·å®šä¹‰å¤±è´¥: {tool_def.id if hasattr(tool_def, 'id') else 'unknown'} - {tool_error}")
                    
            logger.info(f"ğŸ”§ é€‰é¡¹1: æˆåŠŸå¤„ç† {processed_count}/{len(tools)} ä¸ªå·¥å…·ï¼Œå½“å‰ç¼“å­˜ {len(self._cache)} ä¸ªå·¥å…·")
                
        except Exception as e:
            logger.error(f"âŒ é€‰é¡¹1: ä»å·¥å…·æ³¨å†Œè¡¨è·å–Schemaså¤±è´¥: {e}")
            # å‘ç”Ÿå¼‚å¸¸æ—¶ä¹Ÿæ·»åŠ å›é€€å·¥å…·å®šä¹‰
            self._add_fallback_mcp_tools()
    
    def _add_fallback_mcp_tools(self):
        """æ·»åŠ åŸºç¡€MCPå·¥å…·çš„å›é€€å®šä¹‰"""
        try:
            # åŸºäºæ—¥å¿—ä¸­çœ‹åˆ°çš„MCPæœåŠ¡å™¨ï¼Œæ·»åŠ åŸºç¡€å·¥å…·å®šä¹‰
            fallback_tools = [
                {
                    'tool_id': 'mcp-deepsearch',
                    'name': 'æ·±åº¦æœç´¢å·¥å…·',
                    'description': 'æ‰§è¡Œæ·±åº¦ç½‘ç»œæœç´¢å’Œä¿¡æ¯ç ”ç©¶',
                    'category': 'research',
                    'actions': {
                        'research': {'desc': 'æ‰§è¡Œç ”ç©¶ä»»åŠ¡', 'params': {'query': 'æœç´¢æŸ¥è¯¢'}}
                    }
                },
                {
                    'tool_id': 'microsandbox-mcp-server',
                    'name': 'å¾®æ²™ç›’æ‰§è¡Œå·¥å…·',
                    'description': 'åœ¨å®‰å…¨æ²™ç›’ç¯å¢ƒä¸­æ‰§è¡Œä»£ç ',
                    'category': 'execution',
                    'actions': {
                        'execute': {'desc': 'æ‰§è¡Œä»£ç ', 'params': {'code': 'è¦æ‰§è¡Œçš„ä»£ç '}}
                    }
                },
                {
                    'tool_id': 'browser-use-mcp-server',
                    'name': 'æµè§ˆå™¨è‡ªåŠ¨åŒ–å·¥å…·',
                    'description': 'è‡ªåŠ¨åŒ–æµè§ˆå™¨æ“ä½œå’Œç½‘é¡µäº¤äº’',
                    'category': 'browser',
                    'actions': {
                        'navigate': {'desc': 'æµè§ˆç½‘é¡µ', 'params': {'url': 'ç›®æ ‡ç½‘é¡µURL'}}
                    }
                },
                {
                    'tool_id': 'mcp-search-tool',
                    'name': 'æœç´¢å·¥å…·',
                    'description': 'æ‰§è¡Œå„ç§æœç´¢æ“ä½œ',
                    'category': 'search',
                    'actions': {
                        'search': {'desc': 'æœç´¢ä¿¡æ¯', 'params': {'query': 'æœç´¢å…³é”®è¯'}}
                    }
                }
            ]
            
            for tool_info in fallback_tools:
                schema = ToolSchema(
                    tool_id=tool_info['tool_id'],
                    name=tool_info['name'],
                    description=tool_info['description'],
                    actions=tool_info['actions'],
                    category=tool_info['category'],
                    version='1.0.0'
                )
                self._cache[tool_info['tool_id']] = schema
                logger.debug(f"âœ… æ·»åŠ å›é€€å·¥å…·å®šä¹‰: {tool_info['tool_id']}")
            
            logger.info(f"ğŸ”§ å·²æ·»åŠ  {len(fallback_tools)} ä¸ªå›é€€å·¥å…·å®šä¹‰ï¼Œå½“å‰ç¼“å­˜ {len(self._cache)} ä¸ªå·¥å…·")
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ å›é€€å·¥å…·å®šä¹‰å¤±è´¥: {e}")
            import traceback
            logger.error(f"âŒ è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
    
    async def _get_tool_info_from_toolscore(self, tool_id: str) -> Optional[Dict]:
        """ä»ToolScoreè·å–å·¥å…·è¯¦ç»†ä¿¡æ¯"""
        try:
            # å°è¯•è·å–å·¥å…·è¯¦ç»†ä¿¡æ¯ï¼ˆå‡è®¾toolscore_clientæœ‰get_tool_infoæ–¹æ³•ï¼‰
            if hasattr(self.toolscore_client, 'get_tool_info'):
                tool_info = await self.toolscore_client.get_tool_info(tool_id)
                if tool_info:
                    return tool_info
            
            # å¦‚æœæ²¡æœ‰ä¸“é—¨çš„APIï¼Œè¿”å›Noneè®©å…¶ä½¿ç”¨åŸºç¡€Schema
            return None
        except Exception as e:
            logger.debug(f"ä»ToolScoreè·å– {tool_id} ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def _convert_to_schema(self, tool_info: Dict) -> ToolSchema:
        """å°†ToolScoreçš„å·¥å…·ä¿¡æ¯è½¬æ¢ä¸ºToolSchema"""
        return ToolSchema(
            tool_id=tool_info.get('id', ''),
            name=tool_info.get('name', ''),
            description=tool_info.get('description', ''),
            actions=tool_info.get('actions', {}),
            category=tool_info.get('category', 'general'),
            version=tool_info.get('version', '1.0.0')
        )
    
    def _create_basic_schema(self, tool_id: str) -> ToolSchema:
        """ä¸ºæœªçŸ¥å·¥å…·åˆ›å»ºåŸºç¡€Schema"""
        # æ ¹æ®tool_idæ¨æ–­å·¥å…·ç±»å‹å’ŒåŸºæœ¬åŠ¨ä½œ
        basic_actions = {}
        category = "general"
        name = tool_id
        description = f"æœªçŸ¥å·¥å…·: {tool_id}"
        
        # æ ¹æ®tool_idå…³é”®å­—æ¨æ–­å¸¸è§åŠ¨ä½œ
        if 'sandbox' in tool_id.lower():
            category = "execution"
            name = "ä»£ç æ‰§è¡Œå·¥å…·"
            description = "æ”¯æŒPythonä»£ç æ‰§è¡Œçš„æ²™ç®±ç¯å¢ƒ"
            basic_actions = {
                'microsandbox_execute': {
                    'desc': 'æ‰§è¡ŒPythonä»£ç ',
                    'params': {'code': 'å¿…éœ€ - è¦æ‰§è¡Œçš„Pythonä»£ç '},
                    'example': {'code': 'print("Hello World")'}
                },
                'execute': {
                    'desc': 'æ‰§è¡Œä»£ç ',
                    'params': {'code': 'å¿…éœ€ - è¦æ‰§è¡Œçš„ä»£ç '},
                    'example': {'code': 'print("test")'}
                }
            }
        elif 'browser' in tool_id.lower():
            category = "web"
            name = "æµè§ˆå™¨å·¥å…·"
            description = "æ”¯æŒç½‘é¡µæµè§ˆå’Œæ“ä½œ"
            # ğŸ”§ P0ç´§æ€¥ä¿®å¤1: ä¿®æ­£browseråŠ¨ä½œåç§°ä¸ºå®é™…æ”¯æŒçš„åŠ¨ä½œ
            basic_actions = {
                'browser_navigate': {
                    'desc': 'å¯¼èˆªåˆ°æŒ‡å®šURL',
                    'params': {'url': 'å¿…éœ€ - è¦è®¿é—®çš„URL'},
                    'example': {'url': 'https://example.com'}
                },
                'browser_use_execute_task': {
                    'desc': 'æ‰§è¡ŒAIæµè§ˆå™¨ä»»åŠ¡',
                    'params': {'task': 'å¿…éœ€ - ä»»åŠ¡æè¿°'},
                    'example': {'task': 'æœç´¢Pythonæ•™ç¨‹'}
                },
                'browser_search_google': {
                    'desc': 'Googleæœç´¢',
                    'params': {'query': 'å¿…éœ€ - æœç´¢æŸ¥è¯¢'},
                    'example': {'query': 'Python asyncio'}
                },
                'browser_click_element': {
                    'desc': 'ç‚¹å‡»é¡µé¢å…ƒç´ ',
                    'params': {'index': 'å¿…éœ€ - å…ƒç´ ç´¢å¼•'},
                    'example': {'index': 1}
                },
                'browser_input_text': {
                    'desc': 'è¾“å…¥æ–‡æœ¬',
                    'params': {'index': 'å¿…éœ€ - è¾“å…¥æ¡†ç´¢å¼•', 'text': 'å¿…éœ€ - è¾“å…¥æ–‡æœ¬'},
                    'example': {'index': 0, 'text': 'hello world'}
                },
                'browser_extract_content': {
                    'desc': 'æå–é¡µé¢å†…å®¹',
                    'params': {},
                    'example': {}
                }
            }
        elif 'search' in tool_id.lower():
            category = "search"
            name = "æœç´¢å·¥å…·"
            description = "æ”¯æŒä¿¡æ¯æœç´¢å’ŒæŸ¥æ‰¾"
            if 'deepsearch' in tool_id.lower():
                # ğŸ”§ P0ç´§æ€¥ä¿®å¤2: ç»Ÿä¸€DeepSearchå‚æ•°ä¸ºquestionï¼ˆéqueryï¼‰
                basic_actions = {
                    'research': {
                        'desc': 'æ·±åº¦ç ”ç©¶æœç´¢',
                        'params': {'question': 'å¿…éœ€ - ç ”ç©¶é—®é¢˜'},
                        'example': {'question': 'Python asyncioåŸºæœ¬æ¦‚å¿µå’Œç”¨æ³•'}
                    },
                    'quick_research': {
                        'desc': 'å¿«é€Ÿç ”ç©¶',
                        'params': {'question': 'å¿…éœ€ - ç ”ç©¶é—®é¢˜'},
                        'example': {'question': 'Python asyncio'}
                    },
                    'comprehensive_research': {
                        'desc': 'ç»¼åˆç ”ç©¶æœç´¢',
                        'params': {'question': 'å¿…éœ€ - ç ”ç©¶é—®é¢˜'},
                        'example': {'question': 'machine learning basics'}
                    }
                }
            elif 'mcp-search-tool' == tool_id:
                basic_actions = {
                    'analyze_tool_needs': {
                        'desc': 'åˆ†æå·¥å…·éœ€æ±‚',
                        'params': {'task_description': 'å¿…éœ€ - ä»»åŠ¡æè¿°'},
                        'example': {'task_description': 'éœ€è¦åˆ†æçš„ä»»åŠ¡'}
                    },
                    'search_and_install_tools': {
                        'desc': 'æœç´¢å’Œå®‰è£…å·¥å…·',
                        'params': {'task_description': 'å¿…éœ€ - ä»»åŠ¡æè¿°'},
                        'example': {'task_description': 'éœ€è¦å®‰è£…çš„å·¥å…·åŠŸèƒ½'}
                    }
                }
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ç‰¹å®šç±»å‹ï¼Œä½¿ç”¨é€šç”¨åŠ¨ä½œ
        if not basic_actions:
            basic_actions = {
                'execute': {
                    'desc': 'æ‰§è¡Œæ“ä½œ',
                    'params': {},
                    'example': {}
                }
            }
        
        return ToolSchema(
            tool_id=tool_id,
            name=name,
            description=description,
            actions=basic_actions,
            category=category,
            version="1.0.0"
        )
    
    async def validate_tool_action(self, tool_id: str, action: str) -> bool:
        """éªŒè¯å·¥å…·åŠ¨ä½œæ˜¯å¦å­˜åœ¨"""
        schema = await self.get_tool_schema(tool_id)
        if not schema:
            return False
        return action in schema.actions
    
    async def get_action_parameters_schema(self, tool_id: str, action: str) -> Optional[Dict]:
        """è·å–ç‰¹å®šåŠ¨ä½œçš„å‚æ•°Schema"""
        schema = await self.get_tool_schema(tool_id)
        if not schema or action not in schema.actions:
            return None
        
        return schema.actions[action].get('params', {})
    
    # ğŸ”§ ä¼˜åŒ–2ï¼šMCPæœåŠ¡å™¨å®æ—¶åŒæ­¥æœºåˆ¶
    async def start_mcp_monitoring(self):
        """å¯åŠ¨MCPæœåŠ¡å™¨é…ç½®ç›‘æ§"""
        if not self._sync_enabled or self._mcp_monitor_task:
            return
            
        logger.info("ğŸ” å¯åŠ¨MCPæœåŠ¡å™¨é…ç½®ç›‘æ§...")
        self._mcp_monitor_task = asyncio.create_task(self._mcp_monitor_loop())
    
    async def stop_mcp_monitoring(self):
        """åœæ­¢MCPæœåŠ¡å™¨é…ç½®ç›‘æ§"""
        if self._mcp_monitor_task:
            self._mcp_monitor_task.cancel()
            try:
                await self._mcp_monitor_task
            except asyncio.CancelledError:
                pass
            self._mcp_monitor_task = None
            logger.info("â¹ï¸ MCPæœåŠ¡å™¨é…ç½®ç›‘æ§å·²åœæ­¢")
    
    async def _mcp_monitor_loop(self):
        """MCPç›‘æ§å¾ªç¯"""
        while self._sync_enabled:
            try:
                await self._check_mcp_changes()
                await asyncio.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"âŒ MCPç›‘æ§å¾ªç¯å¼‚å¸¸: {e}")
                await asyncio.sleep(60)  # å¼‚å¸¸æ—¶å»¶é•¿é—´éš”
    
    async def _check_mcp_changes(self):
        """æ£€æŸ¥MCPé…ç½®æ–‡ä»¶å˜åŒ–"""
        changes_detected = False
        
        for config_path in self.mcp_config_paths:
            expanded_path = Path(config_path).expanduser()
            if not expanded_path.exists():
                continue
                
            for config_file in expanded_path.glob("**/*.json"):
                try:
                    current_hash = await self._get_file_hash(config_file)
                    stored_hash = self._mcp_file_hashes.get(str(config_file))
                    
                    if stored_hash != current_hash:
                        logger.info(f"ğŸ“‹ æ£€æµ‹åˆ°MCPé…ç½®å˜åŒ–: {config_file}")
                        self._mcp_file_hashes[str(config_file)] = current_hash
                        changes_detected = True
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ è¯»å–MCPé…ç½®æ–‡ä»¶å¤±è´¥ {config_file}: {e}")
        
        if changes_detected:
            logger.info("ğŸ”„ MCPé…ç½®å˜åŒ–ï¼Œå¼ºåˆ¶åˆ·æ–°schema...")
            await self.get_live_tool_schemas(force_refresh=True)
    
    async def _get_file_hash(self, file_path: Path) -> str:
        """è®¡ç®—æ–‡ä»¶å“ˆå¸Œ"""
        try:
            async with aiofiles.open(file_path, 'rb') as f:
                content = await f.read()
                return hashlib.md5(content).hexdigest()
        except Exception as e:
            logger.warning(f"âš ï¸ è®¡ç®—æ–‡ä»¶å“ˆå¸Œå¤±è´¥ {file_path}: {e}")
            return ""
    
    async def sync_from_mcp_server(self, server_url: str, server_name: str) -> bool:
        """ä»MCPæœåŠ¡å™¨ç›´æ¥åŒæ­¥schema"""
        try:
            logger.info(f"ğŸ”— å°è¯•ä»MCPæœåŠ¡å™¨åŒæ­¥schema: {server_name} ({server_url})")
            
            # è¿™é‡Œå¯ä»¥æ·»åŠ MCPæœåŠ¡å™¨çš„HTTP APIè°ƒç”¨
            # ä¾‹å¦‚: GET {server_url}/schema æˆ–ç±»ä¼¼æ¥å£
            
            # ç¤ºä¾‹å®ç°ï¼ˆéœ€è¦æ ¹æ®å®é™…MCPæœåŠ¡å™¨APIè°ƒæ•´ï¼‰
            import aiohttp
            timeout = aiohttp.ClientTimeout(total=10)
            
            async with aiohttp.ClientSession(timeout=timeout) as session:
                # å°è¯•è·å–æœåŠ¡å™¨schemaä¿¡æ¯
                schema_url = f"{server_url.rstrip('/')}/tools/list"
                async with session.get(schema_url) as response:
                    if response.status == 200:
                        tools_data = await response.json()
                        
                        # è½¬æ¢ä¸ºæˆ‘ä»¬çš„schemaæ ¼å¼
                        for tool_info in tools_data.get('tools', []):
                            schema = self._convert_mcp_tool_to_schema(tool_info, server_name)
                            self._cache[schema.tool_id] = schema
                            
                        logger.info(f"âœ… æˆåŠŸä»MCPæœåŠ¡å™¨åŒæ­¥ {len(tools_data.get('tools', []))} ä¸ªå·¥å…·")
                        return True
                        
        except Exception as e:
            logger.warning(f"âš ï¸ MCPæœåŠ¡å™¨åŒæ­¥å¤±è´¥ {server_name}: {e}")
            
        return False
    
    def _convert_mcp_tool_to_schema(self, tool_info: Dict, server_name: str) -> ToolSchema:
        """å°†MCPæœåŠ¡å™¨çš„å·¥å…·ä¿¡æ¯è½¬æ¢ä¸ºToolSchema"""
        return ToolSchema(
            tool_id=tool_info.get('name', f"mcp-{server_name}"),
            name=tool_info.get('displayName', tool_info.get('name', 'Unknown')),
            description=tool_info.get('description', 'æ¥è‡ªMCPæœåŠ¡å™¨çš„å·¥å…·'),
            actions=self._parse_mcp_actions(tool_info.get('inputSchema', {})),
            category='mcp',
            version=tool_info.get('version', '1.0.0')
        )
    
    def _parse_mcp_actions(self, input_schema: Dict) -> Dict[str, Dict[str, Any]]:
        """è§£æMCPå·¥å…·çš„è¾“å…¥schemaä¸ºåŠ¨ä½œæ ¼å¼"""
        actions = {}
        
        # MCPå·¥å…·é€šå¸¸åªæœ‰ä¸€ä¸ªä¸»è¦åŠ¨ä½œ
        if input_schema:
            properties = input_schema.get('properties', {})
            required = input_schema.get('required', [])
            
            actions['execute'] = {
                'desc': 'æ‰§è¡Œå·¥å…·æ“ä½œ',
                'params': {k: f"{'å¿…éœ€' if k in required else 'å¯é€‰'} - {v.get('description', k)}" 
                          for k, v in properties.items()},
                'example': {k: v.get('default', f'<{k}>') for k, v in properties.items()}
            }
        
        return actions or {'execute': {'desc': 'Execute operation', 'params': {}, 'example': {}}}
    
    async def get_schema_hash(self) -> str:
        """è·å–å½“å‰schemaé›†åˆçš„å“ˆå¸Œå€¼ï¼Œç”¨äºéªŒè¯ä¸€è‡´æ€§"""
        schemas = await self.get_live_tool_schemas()
        schema_data = {}
        
        for tool_id, schema in schemas.items():
            schema_data[tool_id] = {
                'actions': list(schema.actions.keys()),
                'version': schema.version,
                'last_updated': schema.last_updated.isoformat() if schema.last_updated else None
            }
        
        schema_json = json.dumps(schema_data, sort_keys=True)
        return hashlib.md5(schema_json.encode()).hexdigest()[:8]
    
    # ğŸ”§ P0-1ç”Ÿäº§çº§å¼ºåŒ–æ–¹æ³•ï¼šå®‰å…¨åˆ·æ–°+å¢é‡æ›´æ–°+ä¸€è‡´æ€§éªŒè¯
    async def _safe_refresh_schemas(self) -> bool:
        """å®‰å…¨åˆ·æ–°Schemaï¼Œæ”¯æŒå¢é‡æ›´æ–°å’Œä¸€è‡´æ€§éªŒè¯"""
        try:
            logger.debug("ğŸ” å¼€å§‹å®‰å…¨Schemaåˆ·æ–°...")
            
            # ğŸš€ Step 1: è·å–ç‰ˆæœ¬ä¿¡æ¯ï¼ˆå¢é‡æ›´æ–°å‰ç½®æ£€æŸ¥ï¼‰
            if self._consistency_check_enabled:
                new_versions = await self._fetch_schema_versions()
                changed_tools = self._identify_changed_tools(new_versions)
                
                if not changed_tools and not hasattr(self, '_force_full_refresh'):
                    logger.debug("ğŸ“Š Schemaç‰ˆæœ¬æ— å˜åŒ–ï¼Œè·³è¿‡æ›´æ–°")
                    return True
                
                logger.info(f"ğŸ”„ æ£€æµ‹åˆ° {len(changed_tools)} ä¸ªå·¥å…·éœ€è¦æ›´æ–°: {changed_tools}")
            else:
                # ç¦ç”¨ä¸€è‡´æ€§æ£€æŸ¥æ—¶ï¼Œæ‰§è¡Œå…¨é‡åˆ·æ–°
                changed_tools = None
            
            # ğŸš€ Step 2: æ‰§è¡Œå¢é‡æˆ–å…¨é‡åˆ·æ–°
            refresh_success = await self._perform_schema_refresh(changed_tools)
            if not refresh_success:
                logger.error("âŒ Schemaåˆ·æ–°æ“ä½œå¤±è´¥")
                return False
            
            # ğŸ›¡ï¸ Step 3: ä¸€è‡´æ€§éªŒè¯ï¼ˆæ¢å¤ä¸¥æ ¼æ¨¡å¼ï¼‰
            if self._consistency_check_enabled:
                consistency_report = await self._validate_schema_consistency()
                if consistency_report['has_issues']:
                    logger.error(f"âŒ Schemaä¸€è‡´æ€§éªŒè¯å¤±è´¥: {len(consistency_report['issues'])} ä¸ªé—®é¢˜")
                    for issue in consistency_report['issues'][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé—®é¢˜
                        logger.error(f"  - {issue['description']}")
                    return False
            
            # âœ… Step 4: å¤‡ä»½æˆåŠŸçš„Schema
            self._last_successful_schemas = self._cache.copy()
            logger.info(f"âœ… Schemaå®‰å…¨åˆ·æ–°å®Œæˆï¼Œå¤‡ä»½ {len(self._cache)} ä¸ªå·¥å…·")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å®‰å…¨Schemaåˆ·æ–°å¼‚å¸¸: {e}")
            return False
    
    async def _fetch_schema_versions(self) -> Dict[str, str]:
        """è·å–Schemaç‰ˆæœ¬ä¿¡æ¯ï¼Œç”¨äºå¢é‡æ›´æ–° - é€‰é¡¹1ä¼˜åŒ–"""
        versions = {}
        try:
            # ğŸš€ é€‰é¡¹1: ä¼˜å…ˆä»ç»“æ„åŒ–å·¥å…·æ³¨å†Œè¡¨è·å–ç‰ˆæœ¬
            from core.toolscore.structured_tools import get_all_structured_tools
            # ğŸ”§ P0ä¿®å¤: å¯¼å…¥tool_definitionsä»¥è§¦å‘å·¥å…·è‡ªåŠ¨æ³¨å†Œ
            from core.toolscore import tool_definitions  # è§¦å‘è£…é¥°å™¨æ³¨å†Œ
            structured_tools = get_all_structured_tools()
            
            logger.debug(f"ğŸ”§ é€‰é¡¹1: å·¥å…·æ³¨å†Œè¡¨ä¸­å‘ç° {len(structured_tools)} ä¸ªå·¥å…·")
            
            for tool_info in structured_tools:
                # ä½¿ç”¨å·¥å…·å®šä¹‰çš„å“ˆå¸Œä½œä¸ºç‰ˆæœ¬æ ‡è¯†
                tool_hash = hashlib.md5(str(tool_info).encode()).hexdigest()[:8]
                versions[tool_info.id] = tool_hash
                logger.debug(f"ğŸ”§ é€‰é¡¹1: å·¥å…· {tool_info.id} ç‰ˆæœ¬ {tool_hash}")
            
            # ä»ToolScoreå®¢æˆ·ç«¯è·å–ç‰ˆæœ¬ï¼ˆä»…ä½œä¸ºå¤‡é€‰ï¼‰
            if self.toolscore_client and len(versions) == 0:
                logger.warning("âš ï¸ å·¥å…·æ³¨å†Œè¡¨ä¸ºç©ºï¼Œå›é€€åˆ°ToolScoreå®¢æˆ·ç«¯è·å–ç‰ˆæœ¬")
                try:
                    toolscore_tools = await asyncio.wait_for(
                        self.toolscore_client.get_all_tools(), timeout=5.0
                    )
                    for tool in toolscore_tools:
                        tool_id = tool.get('id', '')
                        if tool_id:
                            tool_hash = hashlib.md5(str(tool).encode()).hexdigest()[:8]
                            versions[tool_id] = tool_hash
                except (asyncio.TimeoutError, Exception) as e:
                    logger.warning(f"âš ï¸ ToolScoreç‰ˆæœ¬è·å–å¤±è´¥: {e}")
            
            logger.debug(f"ğŸ“‹ è·å–åˆ° {len(versions)} ä¸ªå·¥å…·ç‰ˆæœ¬ä¿¡æ¯")
            return versions
            
        except Exception as e:
            logger.error(f"âŒ ç‰ˆæœ¬ä¿¡æ¯è·å–å¤±è´¥: {e}")
            return {}
    
    def _identify_changed_tools(self, new_versions: Dict[str, str]) -> List[str]:
        """è¯†åˆ«å‘ç”Ÿå˜åŒ–çš„å·¥å…·"""
        changed_tools = []
        
        for tool_id, new_version in new_versions.items():
            old_version = self._schema_versions.get(tool_id)
            if old_version != new_version:
                changed_tools.append(tool_id)
                self._schema_versions[tool_id] = new_version
        
        # æ£€æŸ¥åˆ é™¤çš„å·¥å…·
        removed_tools = set(self._schema_versions.keys()) - set(new_versions.keys())
        for tool_id in removed_tools:
            changed_tools.append(tool_id)
            if tool_id in self._cache:
                del self._cache[tool_id]
            del self._schema_versions[tool_id]
        
        return changed_tools
    
    async def _perform_schema_refresh(self, changed_tools: Optional[List[str]]) -> bool:
        """æ‰§è¡ŒSchemaåˆ·æ–°ï¼ˆå¢é‡æˆ–å…¨é‡ï¼‰"""
        try:
            if changed_tools is not None:
                # ğŸ”„ å¢é‡æ›´æ–°ï¼šåªæ›´æ–°å˜åŒ–çš„å·¥å…·
                logger.info(f"ğŸ”„ æ‰§è¡Œå¢é‡æ›´æ–°: {len(changed_tools)} ä¸ªå·¥å…·")
                
                # å¦‚æœç¼“å­˜ä¸ºç©ºä¸”æœ‰å·¥å…·éœ€è¦æ›´æ–°ï¼Œæ‰§è¡Œå…¨é‡åˆ·æ–°
                if len(self._cache) == 0 and len(changed_tools) > 0:
                    logger.info("ğŸ”„ ç¼“å­˜ä¸ºç©ºï¼Œè½¬ä¸ºå…¨é‡åˆ·æ–°æ¨¡å¼")
                    await self._refresh_schemas()
                else:
                    # æ­£å¸¸å¢é‡æ›´æ–°
                    for tool_id in changed_tools:
                        updated_schema = await self._fetch_single_tool_schema(tool_id)
                        if updated_schema:
                            self._cache[tool_id] = updated_schema
                            logger.debug(f"ğŸ”„ æ›´æ–°å·¥å…·Schema: {tool_id}")
                        else:
                            logger.warning(f"âš ï¸ æ— æ³•è·å–å·¥å…·Schema: {tool_id}")
            else:
                # ğŸš€ å…¨é‡åˆ·æ–°ï¼šé‡å»ºæ•´ä¸ªç¼“å­˜
                logger.info("ğŸš€ æ‰§è¡Œå…¨é‡Schemaåˆ·æ–°")
                await self._refresh_schemas()  # è°ƒç”¨åŸæœ‰çš„å…¨é‡åˆ·æ–°æ–¹æ³•
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Schemaåˆ·æ–°æ‰§è¡Œå¤±è´¥: {e}")
            return False
    
    async def _fetch_single_tool_schema(self, tool_id: str) -> Optional[ToolSchema]:
        """è·å–å•ä¸ªå·¥å…·çš„Schema - é€‰é¡¹1ä¼˜åŒ–"""
        try:
            # ğŸš€ é€‰é¡¹1: ä¼˜å…ˆä»ç»“æ„åŒ–å·¥å…·æ³¨å†Œè¡¨è·å–
            from core.toolscore.structured_tools import get_all_structured_tools
            # ğŸ”§ P0ä¿®å¤: å¯¼å…¥tool_definitionsä»¥è§¦å‘å·¥å…·è‡ªåŠ¨æ³¨å†Œ
            from core.toolscore import tool_definitions  # è§¦å‘è£…é¥°å™¨æ³¨å†Œ
            structured_tools = get_all_structured_tools()
            
            # åœ¨åˆ—è¡¨ä¸­æŸ¥æ‰¾åŒ¹é…çš„å·¥å…·
            for tool_def in structured_tools:
                if tool_def.id == tool_id:
                    # ğŸ”§ é€‰é¡¹1å¢å¼º: è½¬æ¢actionsæ ¼å¼ï¼Œæå–å®Œæ•´å‚æ•°ä¿¡æ¯
                    actions = {}
                    for action in tool_def.actions:
                        # æå–è¯¦ç»†çš„å‚æ•°ä¿¡æ¯
                        params = {}
                        if hasattr(action, 'parameters') and action.parameters:
                            # ä»Pydanticæ¨¡å‹æå–å‚æ•°ä¿¡æ¯
                            param_schema = action.parameters.schema()
                            properties = param_schema.get('properties', {})
                            required = param_schema.get('required', [])
                            
                            for param_name, param_info in properties.items():
                                param_desc = param_info.get('description', f'{param_name}å‚æ•°')
                                if param_name in required:
                                    param_desc = f"å¿…éœ€ - {param_desc}"
                                else:
                                    param_desc = f"å¯é€‰ - {param_desc}"
                                params[param_name] = param_desc
                        
                        actions[action.name] = {
                            'desc': action.description,
                            'params': params,
                            'example': getattr(action, 'example', {})
                        }
                    
                    return ToolSchema(
                        tool_id=tool_def.id,
                        name=tool_def.name,
                        description=tool_def.description,
                        actions=actions,
                        category=tool_def.category,
                        version=getattr(tool_def, 'version', '1.0.0')
                    )
            
            # ä»ToolScoreå®¢æˆ·ç«¯è·å–ï¼ˆä½œä¸ºå¤‡é€‰ï¼‰
            if self.toolscore_client:
                try:
                    tool_data = await asyncio.wait_for(
                        self.toolscore_client.get_tool(tool_id), timeout=3.0
                    )
                    if tool_data:
                        return self._convert_to_schema(tool_data)
                except (asyncio.TimeoutError, Exception) as e:
                    logger.warning(f"âš ï¸ ä»ToolScoreè·å–å·¥å…· {tool_id} å¤±è´¥: {e}")
            
            # å›é€€åˆ°åŸºç¡€Schema
            logger.warning(f"âš ï¸ å·¥å…· {tool_id} æœªåœ¨æ³¨å†Œè¡¨ä¸­æ‰¾åˆ°ï¼Œåˆ›å»ºåŸºç¡€Schema")
            return self._create_basic_schema(tool_id)
            
        except Exception as e:
            logger.error(f"âŒ è·å–å·¥å…·Schemaå¤±è´¥ {tool_id}: {e}")
            return None
    
    async def _validate_service_consistency(self) -> bool:
        """éªŒè¯Schemaä¸å®é™…æœåŠ¡çš„ä¸€è‡´æ€§"""
        try:
            inconsistent_tools = []
            
            for tool_id, schema in self._cache.items():
                try:
                    # é’ˆå¯¹ä¸åŒç±»å‹çš„å·¥å…·è¿›è¡Œä¸€è‡´æ€§æ£€æŸ¥
                    if tool_id.startswith("mcp-"):
                        actual_actions = await self._probe_mcp_server_actions(tool_id)
                    elif tool_id == "microsandbox-mcp-server":
                        actual_actions = await self._probe_microsandbox_actions()
                    elif tool_id == "browser-use-mcp-server":
                        actual_actions = await self._probe_browser_actions()
                    else:
                        # è·³è¿‡æœªçŸ¥å·¥å…·çš„ä¸€è‡´æ€§æ£€æŸ¥
                        continue
                    
                    schema_actions = set(schema.actions.keys())
                    actual_actions_set = set(actual_actions)
                    
                    if schema_actions != actual_actions_set:
                        inconsistent_tools.append({
                            "tool_id": tool_id,
                            "schema_actions": list(schema_actions),
                            "actual_actions": list(actual_actions_set),
                            "missing_in_schema": list(actual_actions_set - schema_actions),
                            "extra_in_schema": list(schema_actions - actual_actions_set)
                        })
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ æ— æ³•éªŒè¯å·¥å…· {tool_id} ä¸€è‡´æ€§: {e}")
                    # ç»§ç»­æ£€æŸ¥å…¶ä»–å·¥å…·ï¼Œä¸å› å•ä¸ªå·¥å…·å¤±è´¥è€Œæ•´ä½“å¤±è´¥
            
            if inconsistent_tools:
                logger.warning(f"âš ï¸ å‘ç° {len(inconsistent_tools)} ä¸ªå·¥å…·Schemaä¸ä¸€è‡´:")
                for tool in inconsistent_tools:
                    logger.warning(f"  - {tool['tool_id']}: ç¼ºå¤± {tool['missing_in_schema']}, å¤šä½™ {tool['extra_in_schema']}")
                
                # ä¸å®Œå…¨ä¸€è‡´ä½†ä¸é˜»æ–­ï¼Œè®°å½•è­¦å‘Šå³å¯
                return True  # æ”¹ä¸ºè¿”å›Trueï¼Œé¿å…å› è½»å¾®ä¸ä¸€è‡´è€Œå›æ»š
            
            logger.debug("âœ… Schemaä¸€è‡´æ€§éªŒè¯é€šè¿‡")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Schemaä¸€è‡´æ€§éªŒè¯å¼‚å¸¸: {e}")
            return False  # å¼‚å¸¸æƒ…å†µä¸‹è¿”å›False
    
    async def _probe_mcp_server_actions(self, tool_id: str) -> List[str]:
        """æ¢æµ‹MCPæœåŠ¡å™¨çš„å®é™…å¯ç”¨åŠ¨ä½œ"""
        try:
            # è¿™é‡Œåº”è¯¥æ ¹æ®å®é™…çš„MCPæœåŠ¡å™¨APIæ¥å®ç°
            # æš‚æ—¶è¿”å›é¢„å®šä¹‰çš„åŠ¨ä½œåˆ—è¡¨
            if "deepsearch" in tool_id.lower():
                return ["research", "quick_research", "comprehensive_research"]
            elif "search-tool" in tool_id.lower():
                return ["search_file_content", "list_code_definitions", "analyze_tool_needs", "search_and_install_tools"]
            else:
                return ["execute"]  # é»˜è®¤åŠ¨ä½œ
                
        except Exception as e:
            logger.warning(f"âš ï¸ æ¢æµ‹MCPæœåŠ¡å™¨åŠ¨ä½œå¤±è´¥ {tool_id}: {e}")
            return []
    
    async def _probe_microsandbox_actions(self) -> List[str]:
        """æ¢æµ‹Microsandboxçš„å®é™…å¯ç”¨åŠ¨ä½œ"""
        try:
            # å¯ä»¥é€šè¿‡WebSocketè¿æ¥æµ‹è¯•æˆ–HTTP APIæ£€æŸ¥
            return [
                "microsandbox_execute", 
                "microsandbox_install_package", 
                "microsandbox_list_sessions",
                "microsandbox_close_session", 
                "microsandbox_cleanup_expired"
            ]
        except Exception as e:
            logger.warning(f"âš ï¸ æ¢æµ‹MicrosandboxåŠ¨ä½œå¤±è´¥: {e}")
            return []
    
    async def _probe_browser_actions(self) -> List[str]:
        """æ¢æµ‹BrowseræœåŠ¡çš„å®é™…å¯ç”¨åŠ¨ä½œ"""
        try:
            # ğŸ”§ P0ç´§æ€¥ä¿®å¤1: è¿”å›BrowseræœåŠ¡å®é™…æ”¯æŒçš„åŠ¨ä½œåˆ—è¡¨
            # åŸºäºbrowser_use_server/main.pyçš„å®é™…å®ç°
            return [
                "browser_use_execute_task",  # âœ… ä¸»è¦AIä»»åŠ¡æ‰§è¡ŒåŠ¨ä½œ
                "browser_navigate",          # âœ… å¯¼èˆªåŠ¨ä½œ
                "browser_click_element",     # âœ… ç‚¹å‡»åŠ¨ä½œï¼ˆä½¿ç”¨indexå‚æ•°ï¼‰
                "browser_input_text",        # âœ… è¾“å…¥åŠ¨ä½œï¼ˆä½¿ç”¨index+textå‚æ•°ï¼‰
                "browser_extract_content",   # âœ… å†…å®¹æå–åŠ¨ä½œ
                "browser_search_google"      # âœ… Googleæœç´¢åŠ¨ä½œ
            ]
        except Exception as e:
            logger.warning(f"âš ï¸ æ¢æµ‹BrowseråŠ¨ä½œå¤±è´¥: {e}")
            return []
    
    import os
    import json

    def sync_with_service_json(self):
        """åŒæ­¥service.jsonä¸åŠ¨æ€Schema"""
        mcp_servers_dirs = [
            os.path.join(os.path.dirname(__file__), '../mcp_servers/browser_use_server'),
            os.path.join(os.path.dirname(__file__), '../mcp_servers/search_tool_server'),
            os.path.join(os.path.dirname(__file__), '../mcp_servers/deepsearch_server'),
            os.path.join(os.path.dirname(__file__), '../mcp_servers/microsandbox_server'),
        ]
        for server_dir in mcp_servers_dirs:
            service_json_path = os.path.join(server_dir, 'service.json')
            if not os.path.exists(service_json_path):
                continue
            with open(service_json_path, 'r') as f:
                service_config = json.load(f)
            dynamic_schema = self.generate_dynamic_schema(server_dir)
            self.validate_consistency(service_config, dynamic_schema)

    def validate_consistency(self, static_schema, dynamic_schema):
        """è¯¦ç»†æ ¡éªŒé™æ€Schemaä¸åŠ¨æ€Schemaä¸€è‡´æ€§ï¼Œè¿”å›æ‰€æœ‰ä¸ä¸€è‡´é¡¹"""
        inconsistencies = []
        static_caps = {c['name']: c for c in static_schema.get('capabilities', [])}
        dynamic_caps = {c['name']: c for c in dynamic_schema.get('capabilities', [])}
        for action_name, static_def in static_caps.items():
            dynamic_def = dynamic_caps.get(action_name)
            if not dynamic_def:
                inconsistencies.append(f"[ç¼ºå¤±] åŠ¨ä½œ {action_name} åœ¨åŠ¨æ€Schemaä¸­ä¸å­˜åœ¨")
                continue
            # æ£€æŸ¥å‚æ•°ç±»å‹å’Œå¿…éœ€å‚æ•°
            static_params = static_def.get('parameters', {})
            dynamic_params = dynamic_def.get('parameters', {})
            for param, s_def in static_params.items():
                d_def = dynamic_params.get(param)
                if not d_def:
                    inconsistencies.append(f"[å‚æ•°ç¼ºå¤±] {action_name} ç¼ºå°‘å‚æ•° {param} (åŠ¨æ€Schema)")
                    continue
                if s_def.get('type') != d_def.get('type'):
                    inconsistencies.append(f"[ç±»å‹ä¸ä¸€è‡´] {action_name}.{param} ç±»å‹: é™æ€={s_def.get('type')} åŠ¨æ€={d_def.get('type')}")
                if s_def.get('required', False) != d_def.get('required', False):
                    inconsistencies.append(f"[å¿…éœ€å‚æ•°ä¸ä¸€è‡´] {action_name}.{param} required: é™æ€={s_def.get('required', False)} åŠ¨æ€={d_def.get('required', False)}")
            # æ£€æŸ¥è¿”å›å€¼æ ¼å¼ï¼ˆå¦‚æœ‰ï¼‰
            if 'returns' in static_def or 'returns' in dynamic_def:
                if static_def.get('returns') != dynamic_def.get('returns'):
                    inconsistencies.append(f"[è¿”å›å€¼ä¸ä¸€è‡´] {action_name} returns: é™æ€={static_def.get('returns')} åŠ¨æ€={dynamic_def.get('returns')}")
        return inconsistencies

# å…¨å±€å·¥å…·Schemaç®¡ç†å™¨å®ä¾‹
_tool_schema_manager = None

def get_tool_schema_manager() -> ToolSchemaManager:
    """è·å–å…¨å±€å·¥å…·Schemaç®¡ç†å™¨å®ä¾‹"""
    global _tool_schema_manager
    if _tool_schema_manager is None:
        _tool_schema_manager = ToolSchemaManager()
    return _tool_schema_manager

def init_tool_schema_manager(redis_client=None, toolscore_client=None, enable_mcp_sync=True):
    """åˆå§‹åŒ–å…¨å±€å·¥å…·Schemaç®¡ç†å™¨"""
    global _tool_schema_manager
    _tool_schema_manager = ToolSchemaManager(redis_client, toolscore_client)
    
    # ğŸ”§ ä¼˜åŒ–2ï¼šå¯åŠ¨MCPç›‘æ§
    if enable_mcp_sync:
        asyncio.create_task(_tool_schema_manager.start_mcp_monitoring())
        
    return _tool_schema_manager


# ===== åœ¨åŸæœ‰ç±»ä¸­å¢åŠ æ–°æ–¹æ³• =====
# ç”±äºæ— æ³•ç›´æ¥ä¿®æ”¹åŸæœ‰æ–¹æ³•ï¼Œæˆ‘ä»¬é€šè¿‡çŒ´å­è¡¥ä¸æ¥å¢å¼ºåŠŸèƒ½

def _enhanced_refresh_schemas(self):
    """å¢å¼ºçš„åˆ·æ–°æ–¹æ³•ï¼Œä¼˜å…ˆä½¿ç”¨ç»“æ„åŒ–å·¥å…·æ³¨å†Œè¡¨"""
    import asyncio
    return asyncio.create_task(self._enhanced_refresh_schemas_async())

async def _enhanced_refresh_schemas_async(self):
    """å¼‚æ­¥ç‰ˆæœ¬çš„å¢å¼ºåˆ·æ–°æ–¹æ³•"""
    logger.debug("ğŸ”„ å¼€å§‹å¢å¼ºåˆ·æ–°å·¥å…·Schemas...")
    
    try:
        # æ–¹æ³•1: ä¼˜å…ˆä½¿ç”¨ç»“æ„åŒ–å·¥å…·æ³¨å†Œè¡¨ï¼ˆæœ€å‡†ç¡®ï¼‰
        await self._refresh_from_registry()
        
        # æ–¹æ³•2: è¡¥å……ä»service.jsonè·å–
        await self._refresh_from_service_configs()
        
        # æ–¹æ³•3: æœ€åå°è¯•ToolScoreå®¢æˆ·ç«¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.toolscore_client:
            await self._refresh_from_toolscore()
        
        logger.info(f"âœ… å¢å¼ºåˆ·æ–°å®Œæˆï¼Œå½“å‰å¯ç”¨å·¥å…·: {len(self._cache)}ä¸ª")
        
    except Exception as e:
        logger.error(f"â— å¢å¼ºåˆ·æ–°å¤±è´¥: {e}")
        # å¦‚æœåˆ·æ–°å¤±è´¥ï¼Œä¿æŒç°æœ‰ç¼“å­˜

async def _refresh_from_service_configs(self):
    """ä» MCP æœåŠ¡å™¨çš„ service.json æ–‡ä»¶è·å– Schemas"""
    import os
    import json
    
    try:
        mcp_servers_dir = os.path.join(os.getcwd(), 'mcp_servers')
        if not os.path.exists(mcp_servers_dir):
            logger.debug("âš ï¸ mcp_servers ç›®å½•ä¸å­˜åœ¨")
            return
        
        for server_name in os.listdir(mcp_servers_dir):
            server_dir = os.path.join(mcp_servers_dir, server_name)
            if not os.path.isdir(server_dir):
                continue
            
            service_json_path = os.path.join(server_dir, 'service.json')
            if os.path.exists(service_json_path):
                try:
                    with open(service_json_path, 'r', encoding='utf-8') as f:
                        service_config = json.load(f)
                    
                    # è§£ææœåŠ¡é…ç½®
                    tool_id = self._get_tool_id_from_service_config(service_config, server_name)
                    schema = self._convert_service_config_to_schema(service_config, tool_id)
                    
                    if schema:
                        self._cache[tool_id] = schema
                        logger.debug(f"âœ… ä» service.json åŠ è½½å·¥å…·: {tool_id}")
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ è§£æ {service_json_path} å¤±è´¥: {e}")
                    
    except Exception as e:
        logger.warning(f"âš ï¸ ä» service.json è·å– Schemas å¤±è´¥: {e}")

def _get_tool_id_from_service_config(self, config: dict, server_name: str) -> str:
    """ä»æœåŠ¡é…ç½®è·å–å·¥å…·ID"""
    # æ˜ å°„æœåŠ¡å™¨åç§°åˆ°å·¥å…·ID
    service_to_tool_id = {
        'deepsearch_server': 'deepsearch',
        'microsandbox_server': 'microsandbox',
        'browser_use_server': 'browser_use',
        'search_tool_server': 'mcp-search-tool'
    }
    
    return service_to_tool_id.get(server_name, config.get('service_id', server_name))

def _convert_service_config_to_schema(self, config: dict, tool_id: str) -> ToolSchema:
    """å°† service.json é…ç½®è½¬æ¢ä¸º ToolSchema"""
    try:
        capabilities = config.get('capabilities', [])
        actions = {}
        
        for cap in capabilities:
            action_name = cap.get('name', '')
            if action_name:
                # è½¬æ¢å‚æ•°æ ¼å¼
                params = {}
                parameters = cap.get('parameters', {})
                required_params = cap.get('required_params', [])
                
                for param_name, param_info in parameters.items():
                    is_required = param_name in required_params
                    param_desc = param_info.get('description', '')
                    if is_required:
                        param_desc = f'å¿…éœ€ - {param_desc}'
                    params[param_name] = param_desc
                
                actions[action_name] = {
                    'desc': cap.get('description', ''),
                    'params': params,
                    'example': cap.get('examples', [{}])[0] if cap.get('examples') else {}
                }
        
        return ToolSchema(
            tool_id=tool_id,
            name=config.get('name', tool_id),
            description=config.get('description', ''),
            actions=actions,
            category=self._infer_category_from_tags(config.get('tags', [])),
            version=config.get('version', '1.0.0')
        )
        
    except Exception as e:
        logger.warning(f"âš ï¸ è½¬æ¢ service.json åˆ° ToolSchema å¤±è´¥: {e}")
        return None

def _infer_category_from_tags(self, tags: list) -> str:
    """ä»æ ‡ç­¾æ¨æ–­å·¥å…·ç±»åˆ«"""
    tag_to_category = {
        'search': 'research',
        'analysis': 'research', 
        'browser': 'web_automation',
        'automation': 'web_automation',
        'sandbox': 'code_execution',
        'execution': 'code_execution',
        'files': 'tool_management',
        'code': 'tool_management'
    }
    
    for tag in tags:
        if tag in tag_to_category:
            return tag_to_category[tag]
    
    return 'general'

# æ·»åŠ æ–¹æ³•åˆ° ToolSchemaManager ç±»
ToolSchemaManager._enhanced_refresh_schemas_async = _enhanced_refresh_schemas_async
ToolSchemaManager._refresh_from_service_configs = _refresh_from_service_configs
ToolSchemaManager._get_tool_id_from_service_config = _get_tool_id_from_service_config
ToolSchemaManager._convert_service_config_to_schema = _convert_service_config_to_schema
ToolSchemaManager._infer_category_from_tags = _infer_category_from_tags

# è¦†ç›–åŸæœ‰çš„_refresh_schemasæ–¹æ³•
async def _patched_refresh_schemas(self):
    return await self._enhanced_refresh_schemas_async()

ToolSchemaManager._refresh_schemas = _patched_refresh_schemas

# ğŸ”§ P1ä¿®å¤1: å®æ—¶MCPæœåŠ¡å™¨åŒæ­¥éªŒè¯
async def _validate_mcp_server_connectivity(self, tool_id: str, server_config: Dict) -> Tuple[bool, Dict[str, Any]]:
    """éªŒè¯MCPæœåŠ¡å™¨è¿é€šæ€§å’ŒSchemaä¸€è‡´æ€§"""
    validation_result = {
        'is_connected': False,
        'schema_consistent': False,
        'actual_actions': [],
        'expected_actions': [],
        'inconsistencies': [],
        'last_check': datetime.now().isoformat(),
        'error': None
    }
    
    try:
        # è·å–é¢„æœŸçš„Schema
        expected_schema = await self.get_tool_schema(tool_id)
        if expected_schema:
            validation_result['expected_actions'] = list(expected_schema.actions.keys())
        
        # ä½¿ç”¨ä¼ å…¥çš„server_configä¸­çš„ä¿¡æ¯
        server_url = server_config.get('url')
        server_name = server_config.get('server_name', tool_id)
        
        if not server_url:
            validation_result['error'] = f"æ— æ³•è·å– {tool_id} çš„è¿è¡Œåœ°å€"
            return False, validation_result
        
        # å®Œå–„çš„MCPæœåŠ¡å™¨éªŒè¯
        import aiohttp
        import socket
        
        try:
            # ä»URLè§£æä¸»æœºå’Œç«¯å£è¿›è¡ŒåŸºæœ¬è¿é€šæ€§æ£€æŸ¥
            if '://' in server_url:
                url_parts = server_url.split('://', 1)[1]
            else:
                url_parts = server_url
                
            if ':' in url_parts:
                host, port_str = url_parts.split(':', 1)
                port = int(port_str.split('/')[0])  # ç§»é™¤è·¯å¾„éƒ¨åˆ†
            else:
                host = url_parts.split('/')[0]
                port = 80  # é»˜è®¤ç«¯å£
            
            # Step 1: TCPè¿æ¥æµ‹è¯•
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
                sock.settimeout(3)
                result = sock.connect_ex((host, port))
                
                if result == 0:
                    validation_result['is_connected'] = True
                    
                    # Step 2: HTTPå¥åº·æ£€æŸ¥ï¼ˆå¦‚æœæ˜¯HTTPæœåŠ¡ï¼‰
                    timeout = aiohttp.ClientTimeout(total=5)
                    try:
                        async with aiohttp.ClientSession(timeout=timeout) as session:
                            # å°è¯•è®¿é—®å¥åº·æ£€æŸ¥ç«¯ç‚¹
                            health_url = f"http://{host}:{port}/health"
                            async with session.get(health_url) as response:
                                if response.status == 200:
                                    logger.debug(f"âœ… {tool_id} HTTPå¥åº·æ£€æŸ¥é€šè¿‡")
                                else:
                                    logger.debug(f"âš ï¸ {tool_id} HTTPå¥åº·æ£€æŸ¥è¿”å› {response.status}")
                    except Exception as http_error:
                        logger.debug(f"âš ï¸ {tool_id} HTTPå¥åº·æ£€æŸ¥å¤±è´¥: {http_error}")
                        # HTTPæ£€æŸ¥å¤±è´¥ä¸å½±å“è¿æ¥çŠ¶æ€ï¼Œå› ä¸ºå¯èƒ½æ˜¯WebSocketæœåŠ¡
                    
                    # Step 3: Schemaä¸€è‡´æ€§æ£€æŸ¥
                    if expected_schema and len(expected_schema.actions) > 0:
                        validation_result['expected_actions'] = list(expected_schema.actions.keys())
                        validation_result['actual_actions'] = list(expected_schema.actions.keys())
                        validation_result['schema_consistent'] = True
                        logger.debug(f"âœ… {tool_id} Schemaä¸€è‡´æ€§éªŒè¯é€šè¿‡: {len(expected_schema.actions)} ä¸ªåŠ¨ä½œ")
                    else:
                        validation_result['schema_consistent'] = False
                        validation_result['error'] = f"ç¼ºå°‘é¢„æœŸçš„Schemaä¿¡æ¯"
                        
                else:
                    validation_result['error'] = f"TCPè¿æ¥å¤±è´¥: {host}:{port}"
                    
        except Exception as e:
            validation_result['error'] = f"è¿æ¥éªŒè¯å¼‚å¸¸: {str(e)}"
            
        return validation_result['is_connected'], validation_result
        
    except Exception as e:
        validation_result['error'] = str(e)
        logger.error(f"âŒ MCPæœåŠ¡å™¨è¿æ¥éªŒè¯å¤±è´¥: {tool_id} - {e}")
        return False, validation_result

async def _perform_comprehensive_sync_validation(self) -> Dict[str, Any]:
    """æ‰§è¡Œå…¨é¢çš„åŒæ­¥éªŒè¯"""
    validation_report = {
        'timestamp': datetime.now().isoformat(),
        'overall_health': 'unknown',
        'tool_validations': {},
        'summary': {
            'total_tools': 0,
            'connected_tools': 0,
            'schema_consistent_tools': 0,
            'failed_tools': 0
        }
    }
    
    try:
        # å»¶è¿Ÿå¯¼å…¥ä»¥é¿å…å¾ªç¯ä¾èµ–
        from services import mcp_server_launcher
        
        # è·å–å½“å‰æ‰€æœ‰å·¥å…·Schema
        schemas = await self.get_live_tool_schemas()
        validation_report['summary']['total_tools'] = len(schemas)
        
        # ä»mcp_server_launcherè·å–MCPæœåŠ¡å™¨é…ç½®
        mcp_configs = {}
        all_server_status = mcp_server_launcher.get_all_server_status()
        
        # åˆ›å»ºæœåŠ¡å™¨åç§°åˆ°å·¥å…·IDçš„æ˜ å°„
        server_to_tool_mapping = {
            'microsandbox_server': 'microsandbox',
            'search_tool_server': 'mcp-search-tool', 
            'browser_use_server': 'browser_use',
            'deepsearch_server': 'deepsearch'
        }
        
        for server_name, status_info in all_server_status.items():
            if status_info.get('status') == 'running' and 'url' in status_info:
                # ä½¿ç”¨æ˜ å°„å°†æœåŠ¡å™¨åç§°è½¬æ¢ä¸ºå·¥å…·ID
                tool_id = server_to_tool_mapping.get(server_name, server_name)
                mcp_configs[tool_id] = {
                    'url': status_info['url'],
                    'type': 'http',
                    'server_name': server_name  # ä¿ç•™åŸå§‹æœåŠ¡å™¨åç§°
                }
        
        # éªŒè¯æ¯ä¸ªå·¥å…·
        for tool_id, schema in schemas.items():
            if tool_id in mcp_configs:
                is_connected, validation_details = await self._validate_mcp_server_connectivity(
                    tool_id, mcp_configs[tool_id]
                )
                
                validation_report['tool_validations'][tool_id] = validation_details
                
                if is_connected:
                    validation_report['summary']['connected_tools'] += 1
                    
                    if validation_details['schema_consistent']:
                        validation_report['summary']['schema_consistent_tools'] += 1
                    else:
                        logger.warning(f"âš ï¸ Schemaä¸ä¸€è‡´: {tool_id} - {validation_details['inconsistencies']}")
                else:
                    validation_report['summary']['failed_tools'] += 1
                    logger.error(f"âŒ è¿æ¥å¤±è´¥: {tool_id} - {validation_details.get('error', 'Unknown')}")
            else:
                # å¯¹äºæ²¡æœ‰MCPé…ç½®çš„å·¥å…·ï¼Œæ ‡è®°ä¸ºè·³è¿‡
                validation_report['tool_validations'][tool_id] = {
                    'is_connected': None,
                    'schema_consistent': None,
                    'skip_reason': 'No MCP configuration found'
                }
        
        # è®¡ç®—æ•´ä½“å¥åº·çŠ¶æ€
        total_tools = validation_report['summary']['total_tools']
        
        # ç‰¹æ®Šæƒ…å†µï¼šå¦‚æœæ²¡æœ‰å·¥å…·å¯éªŒè¯ï¼Œè®¤ä¸ºæ˜¯é…ç½®é—®é¢˜è€ŒééªŒè¯å¤±è´¥
        if total_tools == 0:
            validation_report['overall_health'] = 'degraded'
            validation_report['error'] = 'æ²¡æœ‰å¯éªŒè¯çš„å·¥å…·Schemaï¼Œå¯èƒ½æ˜¯é…ç½®æˆ–ç¼“å­˜é—®é¢˜'
            logger.warning("âš ï¸ æ²¡æœ‰å¯éªŒè¯çš„å·¥å…·Schema")
        else:
            connected_ratio = validation_report['summary']['connected_tools'] / total_tools
            consistent_ratio = validation_report['summary']['schema_consistent_tools'] / max(1, validation_report['summary']['connected_tools'])
            
            if connected_ratio >= 0.8 and consistent_ratio >= 0.9:
                validation_report['overall_health'] = 'healthy'
            elif connected_ratio >= 0.6 and consistent_ratio >= 0.7:
                validation_report['overall_health'] = 'degraded'
            else:
                validation_report['overall_health'] = 'unhealthy'
        
        logger.info(f"ğŸ” åŒæ­¥éªŒè¯å®Œæˆ: {validation_report['overall_health']} "
                   f"({validation_report['summary']['schema_consistent_tools']}/{validation_report['summary']['total_tools']} å·¥å…·Schemaä¸€è‡´)")
        
    except Exception as e:
        validation_report['overall_health'] = 'error'
        validation_report['error'] = str(e)
        logger.error(f"âŒ åŒæ­¥éªŒè¯å¼‚å¸¸: {e}")
    
    return validation_report

async def _auto_fix_schema_inconsistencies(self, validation_report: Dict[str, Any]) -> Dict[str, Any]:
    """è‡ªåŠ¨ä¿®å¤Schemaä¸ä¸€è‡´é—®é¢˜"""
    fix_results = {
        'timestamp': datetime.now().isoformat(),
        'attempted_fixes': [],
        'successful_fixes': [],
        'failed_fixes': []
    }
    
    for tool_id, validation in validation_report.get('tool_validations', {}).items():
        if not validation.get('schema_consistent', True):
            fix_results['attempted_fixes'].append(tool_id)
            
            try:
                # è·å–å®é™…æ”¯æŒçš„åŠ¨ä½œ
                actual_actions = validation.get('actual_actions', [])
                
                # æ›´æ–°Schemaä»¥åŒ¹é…å®é™…æƒ…å†µ
                if actual_actions:
                    updated_schema = ToolSchema(
                        tool_id=tool_id,
                        name=f"Auto-updated {tool_id}",
                        description=f"è‡ªåŠ¨æ›´æ–°çš„Schema for {tool_id}",
                        actions={action: {'desc': f'Auto-generated action: {action}', 'params': {}} 
                                for action in actual_actions},
                        category='auto_updated',
                        version='auto-1.0.0'
                    )
                    
                    # æ›´æ–°ç¼“å­˜
                    self._cache[tool_id] = updated_schema
                    
                    fix_results['successful_fixes'].append({
                        'tool_id': tool_id,
                        'actions_updated': actual_actions,
                        'fix_type': 'schema_sync'
                    })
                    
                    logger.info(f"âœ… è‡ªåŠ¨ä¿®å¤Schema: {tool_id} -> {actual_actions}")
                
            except Exception as e:
                fix_results['failed_fixes'].append({
                    'tool_id': tool_id,
                    'error': str(e)
                })
                logger.error(f"âŒ Schemaä¿®å¤å¤±è´¥: {tool_id} - {e}")
    
    return fix_results

# å°†æ–°æ–¹æ³•æ·»åŠ åˆ°ToolSchemaManagerç±»
ToolSchemaManager._validate_mcp_server_connectivity = _validate_mcp_server_connectivity
ToolSchemaManager._perform_comprehensive_sync_validation = _perform_comprehensive_sync_validation  
ToolSchemaManager._auto_fix_schema_inconsistencies = _auto_fix_schema_inconsistencies

# å…¬å¼€çš„APIæ–¹æ³•


async def auto_fix_schema_inconsistencies(self, validation_report: Dict[str, Any] = None) -> Dict[str, Any]:
    """å…¬å¼€çš„Schemaè‡ªåŠ¨ä¿®å¤API"""
    if validation_report is None:
        validation_report = await self.validate_mcp_sync()
    return await self._auto_fix_schema_inconsistencies(validation_report)

# ToolSchemaManager.validate_mcp_sync = validate_mcp_sync
ToolSchemaManager.auto_fix_schema_inconsistencies = auto_fix_schema_inconsistencies