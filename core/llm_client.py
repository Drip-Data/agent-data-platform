#!/usr/bin/env python3
"""
LLMå®¢æˆ·ç«¯ç»Ÿä¸€æ¥å£
æ”¯æŒå¤šç§APIæä¾›å•†ï¼švLLMæœ¬åœ°æœåŠ¡ã€OpenAIã€Google Geminiã€DeepSeekç­‰
"""

import os
import json
import logging
from typing import Dict, Any, Optional, List
from enum import Enum
import httpx
import asyncio
import time

logger = logging.getLogger(__name__)

class LLMProvider(Enum):
    """LLMæä¾›å•†æšä¸¾"""
    VLLM = "vllm"
    OPENAI = "openai"
    GEMINI = "gemini"
    DEEPSEEK = "deepseek"

class LLMClient:
    """ç»Ÿä¸€çš„LLMå®¢æˆ·ç«¯"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        # ä¼˜å…ˆä½¿ç”¨é…ç½®ä¸­æŒ‡å®šçš„æä¾›å•†ï¼Œæ²¡æœ‰åˆ™è¿›è¡Œè‡ªåŠ¨æ£€æµ‹
        if 'provider' in config:
            provider_name = config['provider'].lower()
            if provider_name == 'vllm':
                self.provider = LLMProvider.VLLM
            elif provider_name == 'openai':
                self.provider = LLMProvider.OPENAI
            elif provider_name == 'gemini':
                self.provider = LLMProvider.GEMINI
            elif provider_name == 'deepseek':
                self.provider = LLMProvider.DEEPSEEK
            else:
                logger.warning(f"Unknown provider in config: {provider_name}, falling back to auto-detection")
                self.provider = self._detect_provider()
        else:
            self.provider = self._detect_provider()
            
        self.client = httpx.AsyncClient(timeout=60.0)
        
        logger.info(f"Initialized LLM client with provider: {self.provider.value}")
    
    def _detect_provider(self) -> LLMProvider:
        """è‡ªåŠ¨æ£€æµ‹ä½¿ç”¨çš„LLMæä¾›å•†"""
        # ä¼˜å…ˆçº§ï¼šGemini > DeepSeek > OpenAI > vLLM
        if os.getenv('GEMINI_API_KEY'):
            return LLMProvider.GEMINI
        elif os.getenv('DEEPSEEK_API_KEY'):
            return LLMProvider.DEEPSEEK
        elif os.getenv('OPENAI_API_KEY'):
            return LLMProvider.OPENAI
        else:
            return LLMProvider.VLLM
    
    async def generate_code(self, description: str, language: str = "python") -> Dict[str, str]:
        """ç”Ÿæˆä»£ç ï¼Œå¹¶è¿”å›æ€è€ƒè¿‡ç¨‹å’Œä»£ç """
        disable_cache = os.getenv("DISABLE_CACHE") or self.config.get("disable_cache", False)
        logger.debug(f"LLMClient.generate_code called: disable_cache={disable_cache}, description={description[:50]}")
        prompt = self._build_code_prompt(description, language)
        
        try:
            response = await self._call_api(prompt)
            code = self._extract_code(response, language)
            # ä¿å­˜åŸå§‹æ€è€ƒè¿‡ç¨‹
            thinking = response
            if len(thinking) > 2000:  # å¦‚æœæ€è€ƒè¿‡ç¨‹å¤ªé•¿ï¼Œæˆªå–å‰åéƒ¨åˆ†
                thinking = thinking[:1000] + "\n... (å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­) ...\n" + thinking[-1000:]
            
            return {
                "code": code,
                "thinking": thinking,
                "success": True
            }
        except Exception as e:
            logger.error(f"Failed to generate code: {e}")
            # ä¸å†ä½¿ç”¨å¤‡ç”¨æ¨¡æ¿ï¼Œè€Œæ˜¯ç›´æ¥æŠ¥å‘Šé”™è¯¯
            raise RuntimeError(f"æ— æ³•ç”Ÿæˆä»£ç : {e}") from e
    
    async def generate_web_actions(self, description: str, page_content: str = "") -> List[Dict]:
        """ç”ŸæˆWebæ“ä½œæ­¥éª¤"""
        prompt = self._build_web_prompt(description, page_content)
        
        try:
            response = await self._call_api(prompt)
            actions = self._extract_web_actions(response)
            return actions
        except Exception as e:
            logger.error(f"Failed to generate web actions: {e}")
            return self._fallback_web_actions(description)
    
    async def generate_reasoning(self, task_description: str, available_tools: List[str],
                                previous_steps: List[Dict] = None,
                                browser_context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨ç†æ­¥éª¤å’Œå·¥å…·è°ƒç”¨"""
        prompt = self._build_reasoning_prompt(task_description, available_tools, previous_steps, browser_context)
        
        try:
            response = await self._call_api(prompt)
            return self._parse_reasoning_response(response)
        except Exception as e:
            logger.error(f"Failed to generate reasoning: {e}")
            return {
                "thinking": f"Error occurred while processing: {e}",
                "action": "error",
                "tool": None,
                "parameters": {},
                "confidence": 0.0
            }
    
    async def generate_enhanced_reasoning(self, task_description: str, available_tools: List[str],
                                         tool_descriptions: str,
                                         previous_steps: List[Dict] = None,
                                         execution_context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """ç”Ÿæˆå¢å¼ºæ¨ç†æ­¥éª¤å’Œå·¥å…·è°ƒç”¨ - ä½¿ç”¨ä¸°å¯Œçš„å·¥å…·æè¿°å’Œæ‰§è¡Œä¸Šä¸‹æ–‡"""
        prompt = self._build_enhanced_reasoning_prompt(
            task_description, available_tools, tool_descriptions, previous_steps, execution_context
        )
        
        try:
            response = await self._call_api(prompt)
            return self._parse_reasoning_response(response)
        except Exception as e:
            logger.error(f"Failed to generate enhanced reasoning: {e}")
            return {
                "thinking": f"Error occurred while processing: {e}",
                "action": "error",
                "tool": None,
                "parameters": {},
                "confidence": 0.0
            }
    
    async def generate_task_summary(self, task_description: str, steps: List[Dict], 
                                   final_outputs: List[str]) -> str:
        """ç”Ÿæˆä»»åŠ¡æ‰§è¡Œæ€»ç»“"""
        prompt = self._build_summary_prompt(task_description, steps, final_outputs)
        
        try:
            response = await self._call_api(prompt)
            return response.strip()
        except Exception as e:
            logger.error(f"Failed to generate summary: {e}")
            return f"Task completed with {len(steps)} steps. Final outputs: {'; '.join(final_outputs[:3])}"
    
    async def check_task_completion(self, task_description: str, steps: List[Dict], 
                                   current_outputs: List[str]) -> Dict[str, Any]:
        """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å®Œæˆ"""
        prompt = self._build_completion_check_prompt(task_description, steps, current_outputs)
        
        try:
            response = await self._call_api(prompt)
            return self._parse_completion_response(response)
        except Exception as e:
            logger.error(f"Failed to check completion: {e}")
            return {"completed": False, "confidence": 0.0, "reason": f"Error: {e}"}

    async def analyze_task_requirements(self, task_description: str) -> Dict[str, Any]:
        """åˆ†æä»»åŠ¡æè¿°ï¼Œæ€»ç»“éœ€è¦çš„åŠŸèƒ½å’Œèƒ½åŠ› - å¸®åŠ©LLMæ›´å¥½åœ°åœ¨mcp_tools.jsonä¸­æ‰¾åˆ°åˆé€‚å·¥å…·"""
        prompt = self._build_task_analysis_prompt(task_description)
        
        try:
            response = await self._call_api(prompt)
            return self._parse_task_requirements_response(response)
        except Exception as e:
            logger.error(f"Failed to analyze task requirements: {e}")
            return {
                "task_type": "unknown",
                "required_capabilities": [],
                "tools_needed": [],
                "reasoning": f"åˆ†æå¤±è´¥: {str(e)}",
                "confidence": 0.0
            }

    async def get_next_action(self, task_description: str, available_tools: List[str],
                              tool_descriptions: str, previous_steps: List[Dict] = None,
                              execution_context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        è·å–LLMçš„ä¸‹ä¸€ä¸ªè¡ŒåŠ¨å†³ç­–ã€‚
        è¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„æ¥å£ï¼Œç”¨äºåœ¨å¢å¼ºæ¨ç†æ¨¡å¼ä¸‹è·å–LLMçš„å†³ç­–ã€‚
        å®ƒå°†ç›´æ¥è°ƒç”¨ generate_enhanced_reasoning æ–¹æ³•ã€‚
        """
        logger.info("Calling get_next_action (unified LLM decision interface)")
        return await self.generate_enhanced_reasoning(
            task_description=task_description,
            available_tools=available_tools,
            tool_descriptions=tool_descriptions,
            previous_steps=previous_steps,
            execution_context=execution_context
        )

    async def _call_api(self, prompt: str) -> str:
        """è°ƒç”¨ç›¸åº”çš„APIï¼Œå¹¶è®°å½•å®Œæ•´çš„äº¤äº’ä¿¡æ¯"""
        # ğŸ” æ–°å¢ï¼šè®°å½•APIè°ƒç”¨ä¿¡æ¯
        logger.info("ğŸš€ LLM APIè°ƒç”¨å¼€å§‹")
        logger.info(f"   æä¾›å•†: {self.provider.value}")
        logger.info(f"   Prompté•¿åº¦: {len(prompt)} å­—ç¬¦")
        
        # è®°å½•promptå†…å®¹ï¼ˆè°ƒè¯•æ¨¡å¼ä¸‹è®°å½•æ›´å¤šè¯¦æƒ…ï¼‰
        if logger.isEnabledFor(logging.DEBUG):
            logger.debug(f"   å®Œæ•´Promptå†…å®¹:\n{prompt}")
        else:
            # ç”Ÿäº§æ¨¡å¼ä¸‹åªè®°å½•å‰åç‰‡æ®µ
            prompt_preview = prompt[:200] + "..." + prompt[-100:] if len(prompt) > 300 else prompt
            logger.info(f"   Prompté¢„è§ˆ: {prompt_preview}")
        
        start_time = time.time()
        
        try:
            # æ ¹æ®æä¾›å•†è°ƒç”¨ç›¸åº”API
            if self.provider == LLMProvider.VLLM:
                response = await self._call_vllm(prompt)
            elif self.provider == LLMProvider.OPENAI:
                response = await self._call_openai(prompt)
            elif self.provider == LLMProvider.GEMINI:
                response = await self._call_gemini(prompt)
            elif self.provider == LLMProvider.DEEPSEEK:
                response = await self._call_deepseek(prompt)
            else:
                raise ValueError(f"Unsupported provider: {self.provider}")
            
            # ğŸ” æ–°å¢ï¼šè®°å½•APIå“åº”ä¿¡æ¯
            duration = time.time() - start_time
            logger.info("âœ… LLM APIè°ƒç”¨æˆåŠŸ")
            logger.info(f"   å“åº”æ—¶é—´: {duration:.2f}ç§’")
            logger.info(f"   å“åº”é•¿åº¦: {len(response)} å­—ç¬¦")
            
            # è®°å½•å“åº”å†…å®¹
            if logger.isEnabledFor(logging.DEBUG):
                logger.debug(f"   å®Œæ•´å“åº”å†…å®¹:\n{response}")
            else:
                # ç”Ÿäº§æ¨¡å¼ä¸‹åªè®°å½•å‰åç‰‡æ®µ
                response_preview = response[:200] + "..." + response[-100:] if len(response) > 300 else response
                logger.info(f"   å“åº”é¢„è§ˆ: {response_preview}")
            
            return response
            
        except Exception as e:
            # ğŸ” æ–°å¢ï¼šè®°å½•APIé”™è¯¯ä¿¡æ¯
            duration = time.time() - start_time
            logger.error("âŒ LLM APIè°ƒç”¨å¤±è´¥")
            logger.error(f"   å¤±è´¥æ—¶é—´: {duration:.2f}ç§’")
            logger.error(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
            
            # è®°å½•æ›´å¤šé”™è¯¯ç»†èŠ‚ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            if hasattr(e, 'response') and e.response:
                logger.error(f"   HTTPçŠ¶æ€ç : {getattr(e.response, 'status_code', 'Unknown')}")
                logger.error(f"   å“åº”å†…å®¹: {getattr(e.response, 'text', 'No response text')}")
            
            raise
    
    async def _call_vllm(self, prompt: str) -> str:
        """è°ƒç”¨vLLMæœ¬åœ°æœåŠ¡"""
        vllm_url = self.config.get("vllm_url", "http://localhost:8000")
        
        payload = {
            "model": "default",
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "max_tokens": 1024,
            "temperature": 0.1
        }
        
        response = await self.client.post(
            f"{vllm_url}/v1/chat/completions",
            json=payload
        )
        response.raise_for_status()
        
        result = response.json()
        return result["choices"][0]["message"]["content"]
    
    async def _call_openai(self, prompt: str) -> str:
        """è°ƒç”¨OpenAI API"""
        api_key = os.getenv('OPENAI_API_KEY')
        api_base = os.getenv('OPENAI_API_BASE', 'https://api.openai.com/v1')
        
        payload = {
            "model": "gpt-3.5-turbo",
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "max_tokens": 1024,
            "temperature": 0.1
        }
        
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        response = await self.client.post(
            f"{api_base}/chat/completions",
            json=payload,
            headers=headers
        )
        response.raise_for_status()
        
        result = response.json()
        return result["choices"][0]["message"]["content"]
    
    async def _call_gemini(self, prompt: str) -> str:
        """è°ƒç”¨Google Gemini API"""
        api_key = os.getenv('GEMINI_API_KEY')
        api_url = os.getenv('GEMINI_API_URL', 'https://generativelanguage.googleapis.com/v1beta')
        
        # éªŒè¯å¹¶ä½¿ç”¨æœ‰æ•ˆçš„Geminiæ¨¡å‹åç§°
        model_name = os.getenv('GEMINI_MODEL', 'gemini-2.5-flash-preview-05-20')  # æ›´æ–°é»˜è®¤æ¨¡å‹
        valid_models = [
            'gemini-2.5-flash-preview-05-20',  # æ·»åŠ æ–°çš„é¢„è§ˆæ¨¡å‹
            'gemini-2.0-flash', 'gemini-2.0-pro', 
            'gemini-1.0-pro', 'gemini-pro'
        ]
        
        if model_name not in valid_models:
            logger.warning(f"Invalid Gemini model '{model_name}', using default 'gemini-2.5-flash-preview-05-20'")
            model_name = 'gemini-2.5-flash-preview-05-20'
        
        payload = {
            "contents": [
                {
                    "parts": [
                        {"text": prompt}
                    ]
                }
            ],
            "generationConfig": {
                "temperature": 0.1,
                "maxOutputTokens": 4096,  # ğŸ” å¢åŠ tokené™åˆ¶ï¼Œç¡®ä¿å®Œæ•´å“åº”
                "candidateCount": 1,
                "stopSequences": [],
                "topP": 0.9,
                "topK": 40
            }
        }
        
        try:
            # ğŸ”§ æ·»åŠ DNSè§£æé‡è¯•æœºåˆ¶
            from httpx._config import Timeout
            import asyncio
            
            # åˆ›å»ºä¸€ä¸ªä¸´æ—¶å®¢æˆ·ç«¯ï¼Œé…ç½®æ›´é•¿çš„è¶…æ—¶å’Œé‡è¯•
            temp_client = httpx.AsyncClient(
                timeout=Timeout(timeout=120.0, connect=30.0),
                limits=httpx.Limits(max_connections=10, max_keepalive_connections=5),
                trust_env=False  # ä¸ä½¿ç”¨ç¯å¢ƒä»£ç†è®¾ç½®
            )
            
            response = await temp_client.post(
                f"{api_url}/models/{model_name}:generateContent?key={api_key}",
                json=payload
            )
            response.raise_for_status()
            
            result = response.json()
            
            # æ£€æŸ¥å“åº”æ ¼å¼
            if "candidates" not in result:
                raise ValueError(f"Invalid Gemini response format: missing 'candidates' field")
            
            if not result["candidates"]:
                raise ValueError(f"Empty candidates in Gemini response")
                
            candidate = result["candidates"][0]
            if "content" not in candidate:
                raise ValueError(f"Invalid candidate format: missing 'content' field")
                
            content = candidate["content"]
            if "parts" not in content:
                raise ValueError(f"Invalid content format: missing 'parts' field")
                
            if not content["parts"]:
                raise ValueError(f"Empty parts in content")
                
            part = content["parts"][0]
            if "text" not in part:
                raise ValueError(f"Invalid part format: missing 'text' field")
                
            await temp_client.aclose()
            return part["text"]
            
        except Exception as e:
            logger.error(f"Gemini API call failed: {e}")
            
            # ğŸ”§ å¼ºåŒ–çš„é‡è¯•æœºåˆ¶ï¼šä½¿ç”¨ç¨³å®šæ¨¡å‹+ç›´æ¥IP
            if "name resolution" in str(e).lower() or "connection" in str(e).lower():
                logger.info("å°è¯•ä½¿ç”¨å¤‡ç”¨ç½‘ç»œé…ç½®é‡è¯•...")
                try:
                    # ä½¿ç”¨å¤‡ç”¨DNSé…ç½®
                    backup_client = httpx.AsyncClient(
                        timeout=Timeout(timeout=180.0, connect=60.0),
                        limits=httpx.Limits(max_connections=5, max_keepalive_connections=2),
                        trust_env=False
                    )
                    
                    # ä½¿ç”¨ç¨³å®šæ¨¡å‹é‡è¯•
                    stable_model = 'gemini-1.5-flash'
                    response = await backup_client.post(
                        f"{api_url}/models/{stable_model}:generateContent?key={api_key}",
                        json=payload
                    )
                    response.raise_for_status()
                    result = response.json()
                    
                    # åŒæ ·çš„æ ¼å¼æ£€æŸ¥
                    if ("candidates" in result and result["candidates"] and 
                        "content" in result["candidates"][0] and
                        "parts" in result["candidates"][0]["content"] and
                        result["candidates"][0]["content"]["parts"] and
                        "text" in result["candidates"][0]["content"]["parts"][0]):
                        await backup_client.aclose()
                        logger.info("âœ… ä½¿ç”¨å¤‡ç”¨ç½‘ç»œé…ç½®æˆåŠŸæ¢å¤")
                        return result["candidates"][0]["content"]["parts"][0]["text"]
                    else:
                        raise ValueError(f"Invalid backup response format")
                        
                except Exception as backup_e:
                    logger.error(f"å¤‡ç”¨ç½‘ç»œé…ç½®ä¹Ÿå¤±è´¥: {backup_e}")
                    raise e
            else:
                raise e
    
    async def _call_deepseek(self, prompt: str) -> str:
        """è°ƒç”¨DeepSeek API"""
        api_key = os.getenv('DEEPSEEK_API_KEY')
        api_url = os.getenv('DEEPSEEK_API_URL', 'https://api.deepseek.com/v1')
        
        payload = {
            "model": "deepseek-coder",
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "max_tokens": 1024,
            "temperature": 0.1
        }
        
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        response = await self.client.post(
            f"{api_url}/chat/completions",
            json=payload,
            headers=headers
        )
        response.raise_for_status()
        
        result = response.json()
        return result["choices"][0]["message"]["content"]
    
    def _build_code_prompt(self, description: str, language: str) -> str:
        """æ„å»ºä»£ç ç”Ÿæˆæç¤ºï¼Œå¢å¼ºæ€è€ƒè¿‡ç¨‹æ•è·"""
        return f"""è¯·æ ¹æ®ä»¥ä¸‹æè¿°ç”Ÿæˆ{language}ä»£ç ã€‚

é¦–å…ˆï¼Œè¯¦ç»†æ€è€ƒå¦‚ä½•è§£å†³è¿™ä¸ªé—®é¢˜ï¼ŒåŒ…æ‹¬å¯èƒ½çš„ç®—æ³•ã€æ•°æ®ç»“æ„ä»¥åŠå®ç°æ­¥éª¤ã€‚
åœ¨ä½ çš„æ€è€ƒè¿‡ç¨‹ä¸­ï¼Œåˆ†æä¸åŒçš„è§£å†³æ–¹æ¡ˆå¹¶é€‰æ‹©æœ€ä½³æ–¹æ¡ˆã€‚

æè¿°ï¼š{description}

è¦æ±‚ï¼š
1. å…ˆè¯¦ç»†æè¿°ä½ çš„æ€è€ƒè¿‡ç¨‹ï¼ŒåŒ…æ‹¬ä½ è€ƒè™‘çš„ä¸åŒæ–¹æ³•
2. ä»£ç åº”è¯¥å®Œæ•´ä¸”å¯æ‰§è¡Œ
3. åŒ…å«å¿…è¦çš„æ³¨é‡Š
4. å¤„ç†å¯èƒ½çš„å¼‚å¸¸æƒ…å†µ
5. è¾“å‡ºç»“æœåˆ°æ§åˆ¶å°

==== æ€è€ƒè¿‡ç¨‹ ====
(è¯·åœ¨è¿™é‡Œè¯¦ç»†å†™å‡ºä½ çš„æ€è€ƒè¿‡ç¨‹ï¼ŒåŒ…æ‹¬ç®—æ³•é€‰æ‹©ã€æ•°æ®ç»“æ„ã€å®ç°æ€è·¯ç­‰)

==== ä»£ç å®ç° ====
(åœ¨æ­¤å¤„ç”Ÿæˆæœ€ç»ˆä»£ç )
"""
    
    def _build_web_prompt(self, description: str, page_content: str) -> str:
        """æ„å»ºWebæ“ä½œæç¤º"""
        return f"""è¯·æ ¹æ®ä»¥ä¸‹æè¿°ç”ŸæˆWebæ“ä½œæ­¥éª¤ï¼š

ä»»åŠ¡æè¿°ï¼š{description}

å½“å‰é¡µé¢å†…å®¹ï¼š
{page_content[:1000] if page_content else 'æ— '}

è¯·è¿”å›JSONæ ¼å¼çš„æ“ä½œæ­¥éª¤åˆ—è¡¨ï¼Œæ¯ä¸ªæ­¥éª¤åŒ…å«ï¼š
- action: æ“ä½œç±»å‹ï¼ˆnavigate, click, fill, waitç­‰ï¼‰
- selector: CSSé€‰æ‹©å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
- value: è¾“å…¥å€¼ï¼ˆå¦‚æœéœ€è¦ï¼‰
- description: æ“ä½œæè¿°

ç¤ºä¾‹æ ¼å¼ï¼š
[
  {{"action": "navigate", "url": "https://example.com", "description": "æ‰“å¼€ç½‘ç«™"}},
  {{"action": "fill", "selector": "#search", "value": "æœç´¢å†…å®¹", "description": "å¡«å†™æœç´¢æ¡†"}},
  {{"action": "click", "selector": "button[type=submit]", "description": "ç‚¹å‡»æœç´¢æŒ‰é’®"}}
]

è¯·åªè¿”å›JSONæ•°ç»„ï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—ï¼š"""
    
    def _build_reasoning_prompt(self, task_description: str, available_tools: List[str],
                                previous_steps: List[Dict] = None,
                                browser_context: Optional[Dict[str, Any]] = None) -> str:
        """æ„å»ºæ¨ç†æç¤º"""
        tool_descriptions = []
        for tool_name in available_tools:
            # å¼ºåˆ¶ä½¿ç”¨ä¸¥æ ¼çš„å·¥å…·è°ƒç”¨æ ¼å¼å’Œç¤ºä¾‹ï¼Œè¯¦è§ docs/AGENT_IMPROVEMENT_PLAN.md
            logger.debug("æ„å»ºæ¨ç†æç¤ºï¼šåº”ç”¨ä¸¥æ ¼çš„å·¥å…·ä½¿ç”¨è§„åˆ™å’Œç¤ºä¾‹")
            if tool_name == 'browser':
                browser_desc = (
                    f"- browser: ç”¨äºä¸ç½‘é¡µäº¤äº’çš„å·¥å…·ã€‚æ”¯æŒä»¥ä¸‹ä¸»è¦ ACTION:\n"
                    f"    - `browser_navigate`: å¯¼èˆªåˆ°æŒ‡å®šURLã€‚PARAMETERS: `{{ \"url\": \"<å®Œæ•´çš„HTTP/HTTPS URL>\" }}`\n"
                    f"    - `browser_get_text`: æå–é¡µé¢æ–‡æœ¬ã€‚PARAMETERS: `{{ \"selector\": \"<CSSé€‰æ‹©å™¨(å¯é€‰)>\" }}` (è‹¥æ— selectorï¼Œåˆ™æå–bodyæ–‡æœ¬)\n"
                    f"    - `browser_click`: ç‚¹å‡»æŒ‡å®šå…ƒç´ ã€‚PARAMETERS: `{{ \"selector\": \"<CSSé€‰æ‹©å™¨>\" }}`\n"
                    f"    (æ›´å¤šæ“ä½œå¦‚ browser_fill_form, browser_extract_links ç­‰è¯·å‚è€ƒå·¥å…·æ–‡æ¡£ï¼Œå¹¶ç¡®ä¿ PARAMETERS æ ¼å¼æ­£ç¡®)"
                )
                tool_descriptions.append(browser_desc)
            elif tool_name == 'python_executor':
                python_desc = (
                    f"- python_executor: ç”¨äºæ‰§è¡ŒPythonä»£ç ã€‚ä¸»è¦ ACTION:\n"
                    f"    - `python_execute`: æ‰§è¡ŒPythonä»£ç ã€‚PARAMETERS: `{{ \"code\": \"<Pythonä»£ç å­—ç¬¦ä¸²>\" }}`"
                )
                tool_descriptions.append(python_desc)
            else:
                tool_descriptions.append(f"- {tool_name}")
        tools_desc = "\n".join(tool_descriptions)
        
        browser_context_str = ""
        if browser_context:
            bc = browser_context # shortcut
            # Ensuring consistent indentation for the f-string block
            browser_context_str = (
                f"\n\nå½“å‰æµè§ˆå™¨çŠ¶æ€:\n"
                f"- å½“å‰URL: {bc.get('current_url', 'N/A')}\n"
                f"- é¡µé¢æ ‡é¢˜: {bc.get('current_page_title', 'N/A')}\n"
                f"- æœ€è¿‘å¯¼èˆªå†å²:\n  {bc.get('recent_navigation_summary', 'æ— å¯¼èˆªå†å²').replace(chr(10), chr(10) + '  ')}\n" # Indent multi-line summary
                f"- ä¸Šæ¬¡æå–æ–‡æœ¬ç‰‡æ®µ: {bc.get('last_text_snippet', 'æ— ')}\n"
                f"- å½“å‰é¡µé¢é“¾æ¥æ‘˜è¦: {bc.get('links_on_page_summary', 'æ— ')}"
            )

        previous_steps_str = ""
        if previous_steps:
            previous_steps_str = "\n\nä¹‹å‰çš„æ‰§è¡Œæ­¥éª¤:\n"
            for i, step in enumerate(previous_steps[-3:], 1):  # åªæ˜¾ç¤ºæœ€è¿‘3æ­¥
                action_str = step.get('action', step.get('action_type', 'unknown_action'))
                observation_str = str(step.get('observation', ''))[:200]
                previous_steps_str += f"  {i}. Action: {action_str}, Observation: {observation_str}...\n"

        # æ„å»ºä¼˜åŒ–çš„åŸºç¡€æ¨ç†æç¤º
        logger.debug("Applying strict tool usage rules from AGENT_IMPROVEMENT_PLAN.md")
        prompt_template = f"""# AI Agent - Reasoning Assistant

ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æ¨ç†åŠ©æ‰‹ï¼Œå…·å¤‡åŠ¨æ€å·¥å…·æ‰©å±•èƒ½åŠ›ã€‚
ç›®æ ‡ï¼šå‡†ç¡®ã€é«˜æ•ˆåœ°å®Œæˆä»»åŠ¡ï¼Œå¹¶å±•ç¤ºæ¸…æ™°çš„å†³ç­–è¿‡ç¨‹ã€‚

## ğŸ“‹ ä»»åŠ¡ä¿¡æ¯
**ä»»åŠ¡**: {task_description}

## ğŸ”§ å¯ç”¨å·¥å…·
{tools_desc}
{browser_context_str}
{previous_steps_str}

## ğŸ“¤ å“åº”æ ¼å¼

è¯·ä»¥JSONæ ¼å¼è¿”å›ä½ çš„å†³ç­–ï¼š

```json
{{
  "thinking": "STEP 1-ä»»åŠ¡åˆ†æ: [ä»»åŠ¡éœ€è¦ä»€ä¹ˆï¼Ÿ]\\nSTEP 2-å·¥å…·è¯„ä¼°: [å½“å‰å·¥å…·æ˜¯å¦å……è¶³ï¼Ÿ]\\nSTEP 3-å†³ç­–åˆ¶å®š: [é€‰æ‹©çš„è¡ŒåŠ¨å’Œç†ç”±]\\nSTEP 4-æ‰§è¡Œè®¡åˆ’: [å¦‚ä½•è¿›è¡Œï¼Ÿ]",
  "confidence": 0.85,
  "tool_id": "å…·ä½“å·¥å…·åç§°",
  "action": "å…·ä½“è¡ŒåŠ¨åç§°", 
  "parameters": {{
    "param1": "value1",
    "param2": "value2"
  }}
}}
```

## ğŸ¯ å…³é”®è§„åˆ™

### å·¥å…·å‚æ•°è§„èŒƒ:
1. **browser_navigate**: `{{"url": "å®Œæ•´HTTP/HTTPS URL"}}`
2. **browser_click**: `{{"selector": "CSSé€‰æ‹©å™¨"}}`
3. **browser_get_text**: `{{"selector": "CSSé€‰æ‹©å™¨"}}` æˆ– `{{}}`
4. **python_execute**: `{{"code": "Pythonä»£ç å­—ç¬¦ä¸²"}}`
5. **complete_task**: `{{}}`
6. **error**: `{{}}`

### å†³ç­–ä¼˜å…ˆçº§:
- ä¼˜å…ˆä½¿ç”¨ç°æœ‰å·¥å…·å®Œæˆä»»åŠ¡
- ç¡®ä¿å‚æ•°å®Œæ•´ä¸”æ ¼å¼æ­£ç¡®  
- å¤±è´¥æ—¶åˆ†æåŸå› å¹¶è°ƒæ•´ç­–ç•¥
- å¿…è¦æ—¶è€ƒè™‘å·¥å…·æ‰©å±•

**åªè¿”å›JSONå¯¹è±¡ï¼Œä¸è¦å…¶ä»–æ–‡å­—ï¼**
"""
        return prompt_template
    
    def _build_enhanced_reasoning_prompt(self, task_description: str, available_tools: List[str],
                                        tool_descriptions: str, previous_steps: List[Dict] = None,
                                        execution_context: Optional[Dict[str, Any]] = None) -> str:
        """ä¸ºå¢å¼ºæ¨ç†æ„å»ºä¼˜åŒ–çš„æç¤º - æ”¯æŒMCPä¸»åŠ¨é€‰æ‹©æœºåˆ¶"""

        prompt_parts = [
            "# AI Agent with Dynamic Tool Expansion",
            "",
            "You are an intelligent AI agent capable of **self-evolution** through dynamic tool acquisition.",
            "Your core innovation: **PROACTIVELY identify tool gaps and install new MCP servers when needed**.",
            "",
            f"## ğŸ¯ Current Task",
            f"**Task**: {task_description}",
            "",
            "## ğŸ”§ Available Tools",
            tool_descriptions,
            "",
        ]

        # æ™ºèƒ½å†å²åˆ†æå’ŒçŠ¶æ€æ£€æµ‹
        if previous_steps:
            # ç»Ÿè®¡å…³é”®æ“ä½œ
            analyze_count = sum(1 for s in previous_steps if s.get('tool_id') == 'mcp-search-tool' and s.get('action') == 'analyze_tool_needs')
            search_count = sum(1 for s in previous_steps if s.get('tool_id') == 'mcp-search-tool' and s.get('action') == 'search_and_install_tools')
            tool_install_success = any('æˆåŠŸå®‰è£…' in str(s.get('observation', '')) or 'successfully installed' in str(s.get('observation', '')) for s in previous_steps)
            
            # æ£€æŸ¥æ¨èä¿¡å·
            has_search_recommendation = any(
                'search_for_new_tools' in str(s.get('observation', '')) or
                'éœ€è¦æ–°å·¥å…·' in str(s.get('observation', '')) or
                'install' in str(s.get('observation', ''))
                for s in previous_steps
            )
            
            # æ£€æŸ¥å¤±è´¥æ¨¡å¼
            consecutive_failures = 0
            for s in reversed(previous_steps[-3:]):
                if not s.get('success', True):
                    consecutive_failures += 1
                else:
                    break
            
            # æ„å»ºæ™ºèƒ½å†å²æ‘˜è¦
            history_summary = []
            for i, s in enumerate(previous_steps[-4:], 1):  # æ˜¾ç¤ºæœ€è¿‘4æ­¥
                step_id = s.get('step_id', i)
                tool_action = f"{s.get('tool_id', 'unknown')}.{s.get('action', 'unknown')}"
                status = "âœ…" if s.get('success', True) else "âŒ"
                obs_snippet = str(s.get('observation', ''))[:50]
                history_summary.append(f"  {step_id}. {tool_action} {status} - {obs_snippet}...")
            
            prompt_parts.extend([
                "## ğŸ“‹ Execution History",
                "\n".join(history_summary),
                f"**Status**: Analyzed {analyze_count}x | Searched {search_count}x | Installed: {'Yes' if tool_install_success else 'No'}",
                "",
            ])
            
            # æ™ºèƒ½å†³ç­–æŒ‡å¯¼
            if consecutive_failures >= 2:
                prompt_parts.extend([
                    "ğŸš¨ **CRITICAL**: Multiple consecutive failures detected!",
                    "**Action Required**: Use 'mcp-search-tool' â†’ 'search_and_install_tools' to acquire new capabilities.",
                    ""
                ])
            elif analyze_count >= 2 and search_count == 0:
                prompt_parts.extend([
                    "âš ï¸ **LOOP DETECTED**: Analysis completed, but no action taken!",
                    "**Next Action MUST be**: 'mcp-search-tool' â†’ 'search_and_install_tools'",
                    ""
                ])
            elif has_search_recommendation and search_count == 0:
                prompt_parts.extend([
                    "ğŸ” **SEARCH RECOMMENDED**: Previous analysis suggests tool installation needed.",
                    "**Proceed with**: 'mcp-search-tool' â†’ 'search_and_install_tools'",
                    ""
                ])
            elif tool_install_success:
                prompt_parts.extend([
                    "ğŸ‰ **TOOLS INSTALLED**: New capabilities available! Use them to complete the task.",
                    ""
                ])

        # å¢å¼ºçš„å†³ç­–é€»è¾‘ - åŸºäºä»»åŠ¡ç±»å‹çš„æ™ºèƒ½åˆ¤æ–­
        prompt_parts.extend([
            "## ğŸ§  Intelligent Decision Framework",
            "",
            "### ğŸ¨ For Image/Chart Generation Tasks:",
            "```",
            "if no_image_tools_available:",
            "    if analyze_count == 0:",
            "        â†’ use 'mcp-search-tool.analyze_tool_needs'",
            "    elif analyze_count >= 1:",
            "        â†’ use 'mcp-search-tool.search_and_install_tools'",
            "    else:",
            "        â†’ proceed with available tools",
            "```",
            "",
            "### ğŸ“„ For Document Processing Tasks:",
            "```",
            "if no_document_tools_available:",
            "    â†’ follow same pattern as image generation",
            "```",
            "",
            "### ğŸŒ For Web Scraping/API Tasks:",
            "```",
            "if browser_tools_sufficient:",
            "    â†’ use existing browser-navigator tools",
            "else:",
            "    â†’ search for specialized API/scraping tools",
            "```",
            "",
            "### âš¡ OPTIMIZATION RULES:",
            "- **Never** call 'analyze_tool_needs' more than 2 times",
            "- **Always** follow analysis recommendations",
            "- **Prefer** using newly installed tools over workarounds",
            "- **Complete task** once capabilities are sufficient",
            "",
        ])

        # æ‰§è¡Œä¸Šä¸‹æ–‡ä¿¡æ¯
        if execution_context:
            context_info = []
            if execution_context.get('browser_state'):
                context_info.append(f"Browser: {execution_context['browser_state'].get('current_url', 'N/A')}")
            if execution_context.get('installed_tools'):
                context_info.append(f"Newly Installed: {', '.join(execution_context['installed_tools'])}")
            
            if context_info:
                prompt_parts.extend([
                    "## ğŸ”„ Execution Context",
                    "\n".join(f"- {info}" for info in context_info),
                    "",
                ])

        # ä¸¥æ ¼çš„å“åº”æ ¼å¼
        prompt_parts.extend([
            "## ğŸ“¤ Response Format (JSON Only)",
            "",
            "Return **ONLY** a valid JSON object with this exact structure:",
            "",
            "```json",
            "{",
            '  "thinking": "STEP 1-TASK ANALYSIS: [What does the task require?]\\nSTEP 2-CAPABILITY CHECK: [Do current tools suffice?]\\nSTEP 3-DECISION: [Chosen action and reasoning]\\nSTEP 4-EXECUTION PLAN: [How to proceed]",',
            '  "confidence": 0.85,',
            '  "tool_id": "exact-tool-identifier",',
            '  "action": "exact_action_name",',
            '  "parameters": {',
            '    "task_description": "copy task exactly if using mcp-search-tool",',
            '    "reason": "explain why new tools are needed (for search actions)",',
            '    "other_params": "as required by specific tool"',
            '  }',
            "}",
            "```",
            "",
            "### ğŸ¯ Key Guidelines:",
            "1. **thinking**: Use 4-step analysis format above",
            "2. **tool_id**: Must match available tool names exactly",
            "3. **action**: Must match tool's supported actions",
            "4. **parameters**: Include all required parameters for the chosen action",
            "5. **confidence**: 0.8+ for tool installation, 0.9+ for task completion",
            "",
            "**NO other text outside the JSON object!**",
        ])
        
        return "\n".join(prompt_parts)
    
    def _build_summary_prompt(self, task_description: str, steps: List[Dict], 
                                   final_outputs: List[str]) -> str:
        """ç”Ÿæˆä»»åŠ¡æ‰§è¡Œæ€»ç»“"""
        # å®‰å…¨åœ°æå–æ­¥éª¤æè¿°
        step_descriptions = []
        for step in steps:
            if isinstance(step, dict):
                # å°è¯•ä¸åŒçš„å¯èƒ½å­—æ®µå
                desc = step.get('description') or step.get('observation') or step.get('action_type', 'Unknown step')
                step_descriptions.append(str(desc))
            else:
                step_descriptions.append(str(step))
        
        prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹æè¿°ç”Ÿæˆä»»åŠ¡æ‰§è¡Œæ€»ç»“ï¼š

ä»»åŠ¡æè¿°ï¼š{task_description}

æ­¥éª¤ï¼š
{'; '.join(step_descriptions)}

æœ€ç»ˆè¾“å‡ºï¼š{'; '.join(final_outputs[:3])}
"""
        return prompt
    
    def _build_completion_check_prompt(self, task_description: str, steps: List[Dict], 
                                   current_outputs: List[str]) -> str:
        """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å®Œæˆ"""
        # å®‰å…¨åœ°æå–æ­¥éª¤æè¿°
        step_descriptions = []
        for step in steps:
            if isinstance(step, dict):
                # å°è¯•ä¸åŒçš„å¯èƒ½å­—æ®µå
                desc = step.get('description') or step.get('observation') or step.get('action_type', 'Unknown step')
                step_descriptions.append(str(desc))
            else:
                step_descriptions.append(str(step))
        
        prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹æè¿°æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å®Œæˆï¼š

ä»»åŠ¡æè¿°ï¼š{task_description}

æ­¥éª¤ï¼š
{'; '.join(step_descriptions)}

å½“å‰è¾“å‡ºï¼š{'; '.join(current_outputs[:3])}
"""
        return prompt
    
    def _extract_code(self, response: str, language: str) -> str:
        """ä»å“åº”ä¸­æå–ä»£ç """
        # è¿™é‡Œéœ€è¦å®ç°ä»å“åº”ä¸­æå–ä»£ç çš„é€»è¾‘
        return response
    
    def _extract_web_actions(self, response: str) -> List[Dict]:
        """ä»å“åº”ä¸­æå–Webæ“ä½œæ­¥éª¤"""
        # è¿™é‡Œéœ€è¦å®ç°ä»å“åº”ä¸­æå–Webæ“ä½œæ­¥éª¤çš„é€»è¾‘
        return []
    
    def _fallback_web_actions(self, description: str) -> List[Dict]:
        """ç”Ÿæˆå¤‡ç”¨Webæ“ä½œæ­¥éª¤"""
        # è¿™é‡Œéœ€è¦å®ç°ç”Ÿæˆå¤‡ç”¨Webæ“ä½œæ­¥éª¤çš„é€»è¾‘
        return []
    
    def _parse_reasoning_response(self, response: str) -> Dict[str, Any]:
        """è§£ææ¨ç†å“åº” - æ”¯æŒå¢å¼ºçš„MCPä¸»åŠ¨é€‰æ‹©æœºåˆ¶"""
        import re
        
        logger.info(f"ğŸ” è§£æLLMå“åº” (é•¿åº¦: {len(response)})")
        
        try:
            # é¦–å…ˆå°è¯•ç›´æ¥è§£æJSON
            response_clean = response.strip()
            
            # ğŸ” å¢å¼ºçš„JSONæå– - å¤„ç†å„ç§æ ¼å¼
            json_patterns = [
                r'```json\s*(\{.*?\})\s*```',  # markdownä»£ç å—
                r'```\s*(\{.*?\})\s*```',      # æ™®é€šä»£ç å—  
                r'(\{[^{}]*"thinking"[^{}]*\})', # åŒ…å«thinkingçš„JSON
                r'(\{.*?\})',                  # ä»»ä½•JSONå¯¹è±¡
            ]
            
            json_text = None
            for pattern in json_patterns:
                match = re.search(pattern, response_clean, re.DOTALL)
                if match:
                    json_text = match.group(1)
                    logger.info(f"âœ… ä½¿ç”¨æ¨¡å¼æå–åˆ°JSON: {pattern}")
                    break
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONå—ï¼Œå°è¯•ç›´æ¥è§£æ
            if not json_text:
                # ç§»é™¤å¯èƒ½çš„markdownä»£ç å—åŒ…è£…
                if response_clean.startswith('```json'):
                    response_clean = response_clean[7:]
                if response_clean.endswith('```'):
                    response_clean = response_clean[:-3]
                json_text = response_clean.strip()
            
            # ğŸ” ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
            if json_text:
                # ä¿®å¤è¢«æˆªæ–­çš„JSON
                if not json_text.endswith('}') and json_text.count('{') > json_text.count('}'):
                    missing_braces = json_text.count('{') - json_text.count('}')
                    json_text += '}' * missing_braces
                    logger.warning(f"ğŸ”§ ä¿®å¤äº† {missing_braces} ä¸ªç¼ºå¤±çš„å³æ‹¬å·")
                
                # ä¿®å¤å¸¸è§çš„æ ¼å¼é—®é¢˜
                json_text = json_text.replace('\n', '\\n').replace('\r', '\\r')
                
                # å°è¯•è§£æJSON
                try:
                    parsed = json.loads(json_text)
                    logger.info("âœ… JSONè§£ææˆåŠŸ")
                    
                    # ğŸ” æ™ºèƒ½å­—æ®µè¡¥å…¨å’ŒéªŒè¯
                    result = self._validate_and_complete_parsed_response(parsed)
                    
                    logger.info(f"ğŸ¯ æœ€ç»ˆè§£æç»“æœ: action={result.get('action')}, tool_id={result.get('tool_id')}, confidence={result.get('confidence')}")
                    return result
                    
                except json.JSONDecodeError as json_error:
                    logger.warning(f"âŒ JSONè§£æå¤±è´¥: {json_error}")
                    # ç»§ç»­ä½¿ç”¨å¤‡ç”¨è§£ææ–¹æ³•
            
        except Exception as e:
            logger.error(f"âŒ å“åº”è§£æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        
        # ğŸ” å¢å¼ºçš„å¤‡ç”¨è§£ææ–¹æ³•
        logger.warning("ğŸ”„ ä½¿ç”¨å¤‡ç”¨è§£ææ–¹æ³•")
        return self._fallback_parse_response(response)
    
    def _validate_and_complete_parsed_response(self, parsed: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯å¹¶è¡¥å…¨è§£æåçš„å“åº”"""
        result = {}
        
        # è¡¥å…¨thinkingå­—æ®µ
        result['thinking'] = parsed.get('thinking', f"LLMå“åº”ç¼ºå°‘thinkingå­—æ®µ: {str(parsed)[:200]}")
        
        # è¡¥å…¨å¹¶éªŒè¯actionå­—æ®µ
        action = parsed.get('action', 'error')
        result['action'] = action
        
        # è¡¥å…¨å¹¶éªŒè¯tool_idå­—æ®µ
        tool_id = parsed.get('tool_id') or parsed.get('tool')
        
        # ğŸ” æ™ºèƒ½æ¨æ–­å·¥å…·ID
        if not tool_id:
            if action in ['search_and_install_tools', 'analyze_tool_needs']:
                tool_id = 'mcp-search-tool'
                logger.info(f"ğŸ”§ è‡ªåŠ¨æ¨æ–­å·¥å…·ID: {tool_id} (åŸºäºaction: {action})")
            elif 'search' in result['thinking'].lower() or 'install' in result['thinking'].lower():
                tool_id = 'mcp-search-tool'
                logger.info(f"ğŸ”§ åŸºäºthinkingå†…å®¹æ¨æ–­å·¥å…·ID: {tool_id}")
        
        result['tool_id'] = tool_id
        result['tool'] = tool_id  # å‘åå…¼å®¹
        
        # è¡¥å…¨parameterså­—æ®µ
        parameters = parsed.get('parameters', {})
        
        # ğŸ” åŸºäºactionæ™ºèƒ½è¡¥å…¨å‚æ•°
        if action in ['search_and_install_tools', 'analyze_tool_needs'] and not parameters.get('task_description'):
            # ä»thinkingä¸­æå–ä»»åŠ¡æè¿°
            thinking = result['thinking']
            if 'TASK ANALYSIS:' in thinking:
                task_desc_start = thinking.find('TASK ANALYSIS:') + len('TASK ANALYSIS:')
                task_desc_end = thinking.find('STEP 2', task_desc_start)
                if task_desc_end > task_desc_start:
                    task_desc = thinking[task_desc_start:task_desc_end].strip()
                    parameters['task_description'] = task_desc[:200]  # é™åˆ¶é•¿åº¦
        
        result['parameters'] = parameters
        
        # è¡¥å…¨å¹¶éªŒè¯confidenceå­—æ®µ
        confidence = parsed.get('confidence', 0.5)
        if not isinstance(confidence, (int, float)) or confidence < 0 or confidence > 1:
            confidence = 0.5
        result['confidence'] = confidence
        
        return result
    
    def _fallback_parse_response(self, response: str) -> Dict[str, Any]:
        """å¢å¼ºçš„å¤‡ç”¨è§£ææ–¹æ³•"""
        import re
        
        logger.info("ğŸ”„ æ‰§è¡Œå¢å¼ºå¤‡ç”¨è§£æ")
        
        # ğŸ” å¢å¼ºçš„å­—æ®µæå–
        result = {
            'thinking': self._extract_thinking_field(response),
            'action': self._extract_action_field(response),
            'tool_id': self._extract_tool_id_field(response),
            'parameters': self._extract_parameters_field(response),
            'confidence': self._extract_confidence_field(response)
        }
        
        # ğŸ” æ™ºèƒ½æ¨æ–­å’Œä¿®æ­£
        result = self._smart_inference_and_correction(result, response)
        
        # å‘åå…¼å®¹
        result['tool'] = result['tool_id']
        
        logger.info(f"ğŸ¯ å¤‡ç”¨è§£æç»“æœ: action={result['action']}, tool_id={result['tool_id']}")
        return result
    
    def _extract_thinking_field(self, response: str) -> str:
        """æå–thinkingå­—æ®µ"""
        import re
        patterns = [
            r'"thinking":\s*"([^"]*(?:\\.[^"]*)*)"',
            r'thinking["\']?\s*[:=]\s*["\']([^"\']*)["\']',
            r'STEP 1[^:]*:([^"]*?)(?:STEP 2|$)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, response, re.DOTALL | re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œè¿”å›å“åº”çš„å‰500å­—ç¬¦
        return response[:500]
    
    def _extract_action_field(self, response: str) -> str:
        """æå–actionå­—æ®µ"""
        import re
        patterns = [
            r'"action":\s*"([^"]+)"',
            r'action["\']?\s*[:=]\s*["\']([^"\']+)["\']',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, response, re.IGNORECASE)
            if match:
                return match.group(1)
        
        # ğŸ” åŸºäºå†…å®¹æ¨æ–­action
        if any(keyword in response.lower() for keyword in ['search', 'install', 'tool']):
            return 'search_and_install_tools'
        elif any(keyword in response.lower() for keyword in ['analyze', 'need']):
            return 'analyze_tool_needs'
        elif any(keyword in response.lower() for keyword in ['complete', 'finish', 'done']):
            return 'complete_task'
        
        return 'error'
    
    def _extract_tool_id_field(self, response: str) -> str:
        """æå–tool_idå­—æ®µ"""
        import re
        patterns = [
            r'"tool_id":\s*"([^"]+)"',
            r'"tool":\s*"([^"]+)"',
            r'tool_id["\']?\s*[:=]\s*["\']([^"\']+)["\']',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, response, re.IGNORECASE)
            if match:
                return match.group(1)
        
        return None
    
    def _extract_parameters_field(self, response: str) -> Dict[str, Any]:
        """æå–parameterså­—æ®µ"""
        import re
        
        # å°è¯•æå–å®Œæ•´çš„parameterså¯¹è±¡
        params_match = re.search(r'"parameters":\s*(\{[^}]*\})', response, re.DOTALL)
        if params_match:
            try:
                return json.loads(params_match.group(1))
            except:
                pass
        
        # å¤‡ç”¨æ–¹æ¡ˆï¼šæå–å¸¸è§å‚æ•°
        params = {}
        
        # æå–task_description
        task_desc_patterns = [
            r'"task_description":\s*"([^"]*)"',
            r'task_description["\']?\s*[:=]\s*["\']([^"\']*)["\']',
        ]
        
        for pattern in task_desc_patterns:
            match = re.search(pattern, response, re.IGNORECASE)
            if match:
                params['task_description'] = match.group(1)
                break
        
        return params
    
    def _extract_confidence_field(self, response: str) -> float:
        """æå–confidenceå­—æ®µ"""
        import re
        
        patterns = [
            r'"confidence":\s*([0-9.]+)',
            r'confidence["\']?\s*[:=]\s*([0-9.]+)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, response, re.IGNORECASE)
            if match:
                try:
                    confidence = float(match.group(1))
                    return max(0.0, min(1.0, confidence))
                except:
                    pass
        
        return 0.5
    
    def _smart_inference_and_correction(self, result: Dict[str, Any], response: str) -> Dict[str, Any]:
        """æ™ºèƒ½æ¨æ–­å’Œä¿®æ­£ç»“æœ"""
        
        # å¦‚æœactionæ˜¯errorä½†å“åº”ä¸­åŒ…å«å·¥å…·ç›¸å…³å†…å®¹ï¼Œå°è¯•ä¿®æ­£
        if result['action'] == 'error':
            if any(keyword in response.lower() for keyword in ['mcp-search', 'search_and_install', 'tool']):
                result['action'] = 'search_and_install_tools'
                logger.info("ğŸ”§ ä¿®æ­£actionä¸º: search_and_install_tools")
        
        # å¦‚æœæ²¡æœ‰tool_idä½†actionéœ€è¦å·¥å…·ï¼Œè‡ªåŠ¨è®¾ç½®
        if not result['tool_id'] and result['action'] in ['search_and_install_tools', 'analyze_tool_needs']:
            result['tool_id'] = 'mcp-search-tool'
            logger.info("ğŸ”§ è‡ªåŠ¨è®¾ç½®tool_idä¸º: mcp-search-tool")
        
        # å¦‚æœparametersä¸ºç©ºä½†actionéœ€è¦å‚æ•°ï¼Œå°è¯•ç”Ÿæˆ
        if not result['parameters'] and result['action'] in ['search_and_install_tools', 'analyze_tool_needs']:
            # ä»thinkingä¸­æå–ä»»åŠ¡ç›¸å…³ä¿¡æ¯
            thinking = result['thinking']
            params = {}
            
            if 'ä»»åŠ¡' in thinking or 'task' in thinking.lower():
                # æå–å¯èƒ½çš„ä»»åŠ¡æè¿°
                lines = thinking.split('\n')
                for line in lines:
                    if 'ä»»åŠ¡' in line or 'task' in line.lower():
                        # ç®€åŒ–çš„ä»»åŠ¡æè¿°æå–
                        task_desc = line.strip()[:100]
                        params['task_description'] = task_desc
                        break
            
            if params:
                result['parameters'] = params
                logger.info(f"ğŸ”§ ç”Ÿæˆå‚æ•°: {params}")
        
        return result
    
    def _parse_completion_response(self, response: str) -> Dict[str, Any]:
        """è§£æå®Œæˆæ£€æŸ¥å“åº”"""
        # è¿™é‡Œéœ€è¦å®ç°è§£æå®Œæˆæ£€æŸ¥å“åº”çš„é€»è¾‘
        return {"completed": True, "confidence": 1.0}

    def _build_task_analysis_prompt(self, task_description: str) -> str:
        """æ„å»ºä»»åŠ¡éœ€æ±‚åˆ†ææç¤ºè¯"""
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»»åŠ¡åˆ†æåŠ©æ‰‹ã€‚è¯·ä»”ç»†åˆ†æä»¥ä¸‹ä»»åŠ¡æè¿°ï¼Œæ€»ç»“å®Œæˆè¿™ä¸ªä»»åŠ¡éœ€è¦ä»€ä¹ˆæ ·çš„åŠŸèƒ½å’Œèƒ½åŠ›ã€‚

ä»»åŠ¡æè¿°: {task_description}

è¯·ä»ä»¥ä¸‹ç»´åº¦åˆ†æè¿™ä¸ªä»»åŠ¡ï¼š

1. **ä»»åŠ¡ç±»å‹åˆ†ç±»** (task_type):
   - reasoning: éœ€è¦å¤æ‚æ¨ç†ã€å¤šå·¥å…·ååŒã€åˆ†æå¯¹æ¯”
   - web: ä¸»è¦æ¶‰åŠç½‘é¡µæ“ä½œã€ä¿¡æ¯æœç´¢ã€ç½‘ç«™å¯¼èˆª  
   - code: ä¸»è¦æ˜¯ç¼–ç¨‹ã€ç®—æ³•ã€è®¡ç®—ã€æ•°æ®å¤„ç†
   - image: å›¾åƒç”Ÿæˆã€å›¾åƒå¤„ç†ã€è§†è§‰ç›¸å…³
   - file: æ–‡ä»¶æ“ä½œã€æ–‡æ¡£å¤„ç†ã€æ ¼å¼è½¬æ¢
   - data: æ•°æ®åˆ†æã€ç»Ÿè®¡ã€å¯è§†åŒ–
   - communication: é€šä¿¡ã€å‘é€æ¶ˆæ¯ã€APIè°ƒç”¨

2. **æ ¸å¿ƒèƒ½åŠ›éœ€æ±‚** (required_capabilities):
   åˆ†æä»»åŠ¡éœ€è¦å“ªäº›å…·ä½“çš„æŠ€æœ¯èƒ½åŠ›ï¼Œä¾‹å¦‚ï¼š
   - image_generation (å›¾åƒç”Ÿæˆ)
   - web_scraping (ç½‘é¡µæŠ“å–)
   - data_analysis (æ•°æ®åˆ†æ)
   - file_processing (æ–‡ä»¶å¤„ç†)
   - code_execution (ä»£ç æ‰§è¡Œ)
   - search (æœç´¢åŠŸèƒ½)
   - browser_automation (æµè§ˆå™¨è‡ªåŠ¨åŒ–)
   - database_access (æ•°æ®åº“è®¿é—®)
   - api_calls (APIè°ƒç”¨)
   - text_processing (æ–‡æœ¬å¤„ç†)

3. **å…·ä½“å·¥å…·ç±»å‹** (tools_needed):
   åŸºäºèƒ½åŠ›éœ€æ±‚ï¼Œæ¨æµ‹å¯èƒ½éœ€è¦çš„å·¥å…·ç±»å‹ï¼Œä¾‹å¦‚ï¼š
   - å›¾åƒç”Ÿæˆå·¥å…· (å¦‚DALL-E, Stable Diffusionç›¸å…³)
   - æµè§ˆå™¨æ“ä½œå·¥å…· (å¦‚Selenium, Playwrightç›¸å…³)
   - æ•°æ®åˆ†æå·¥å…· (å¦‚pandas, numpyç›¸å…³)
   - æ–‡ä»¶å¤„ç†å·¥å…· (å¦‚PDF, Excelå¤„ç†ç›¸å…³)
   - APIè°ƒç”¨å·¥å…· (å¦‚HTTPå®¢æˆ·ç«¯ç›¸å…³)

4. **å…³é”®ç‰¹å¾è¯†åˆ«** (key_features):
   è¯†åˆ«ä»»åŠ¡æè¿°ä¸­çš„å…³é”®ç‰¹å¾ï¼Œå¸®åŠ©åŒ¹é…å·¥å…·

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼š

{{
  "task_type": "...",
  "required_capabilities": ["capability1", "capability2", "..."],
  "tools_needed": ["tool_type1", "tool_type2", "..."],
  "key_features": ["feature1", "feature2", "..."],
  "reasoning": "è¯¦ç»†çš„åˆ†ææ¨ç†è¿‡ç¨‹ï¼Œè¯´æ˜ä¸ºä»€ä¹ˆéœ€è¦è¿™äº›èƒ½åŠ›å’Œå·¥å…·",
  "confidence": 0.9
}}

è¦æ±‚ï¼š
- åˆ†æè¦å‡†ç¡®ä¸”å…·ä½“
- ä¸è¦çŒœæµ‹ä¸å­˜åœ¨çš„éœ€æ±‚
- é‡ç‚¹å…³æ³¨ä»»åŠ¡çš„æ ¸å¿ƒåŠŸèƒ½éœ€æ±‚
- ç¡®ä¿JSONæ ¼å¼æ­£ç¡®"""
        
        return prompt

    def _parse_task_requirements_response(self, response: str) -> Dict[str, Any]:
        """è§£æä»»åŠ¡éœ€æ±‚åˆ†æå“åº”"""
        try:
            import re
            import json
            
            # æå–JSON
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                parsed = json.loads(json_match.group())
                
                # ç¡®ä¿æ‰€æœ‰å¿…éœ€å­—æ®µå­˜åœ¨ï¼Œè®¾ç½®é»˜è®¤å€¼
                result = {
                    "task_type": parsed.get("task_type", "unknown"),
                    "required_capabilities": parsed.get("required_capabilities", []),
                    "tools_needed": parsed.get("tools_needed", []),
                    "key_features": parsed.get("key_features", []),
                    "reasoning": parsed.get("reasoning", "æ— åˆ†æè¿‡ç¨‹"),
                    "confidence": float(parsed.get("confidence", 0.7))
                }
                
                logger.info(f"âœ… ä»»åŠ¡éœ€æ±‚åˆ†æå®Œæˆ:")
                logger.info(f"   ä»»åŠ¡ç±»å‹: {result['task_type']}")
                logger.info(f"   æ‰€éœ€èƒ½åŠ›: {result['required_capabilities']}")
                logger.info(f"   å·¥å…·ç±»å‹: {result['tools_needed']}")
                logger.info(f"   ç½®ä¿¡åº¦: {result['confidence']}")
                
                return result
            else:
                logger.error("æ— æ³•ä»å“åº”ä¸­æå–æœ‰æ•ˆçš„JSONæ ¼å¼")
                return self._create_fallback_requirements_analysis(response)
                
        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æå¤±è´¥: {e}")
            return self._create_fallback_requirements_analysis(response)
        except Exception as e:
            logger.error(f"è§£æä»»åŠ¡éœ€æ±‚å“åº”æ—¶å‡ºé”™: {e}")
            return self._create_fallback_requirements_analysis(response)

    def _create_fallback_requirements_analysis(self, response: str) -> Dict[str, Any]:
        """åˆ›å»ºå¤‡ç”¨çš„éœ€æ±‚åˆ†æç»“æœ"""
        # åŸºäºå“åº”å†…å®¹çš„ç®€å•å…³é”®è¯åˆ†æ
        response_lower = response.lower()
        
        capabilities = []
        tools_needed = []
        task_type = "unknown"
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…é€»è¾‘
        if any(word in response_lower for word in ['å›¾', 'å›¾ç‰‡', 'å›¾åƒ', 'image', 'picture', 'ç”Ÿæˆ']):
            capabilities.append("image_generation")
            tools_needed.append("å›¾åƒç”Ÿæˆå·¥å…·")
            task_type = "image"
        
        if any(word in response_lower for word in ['ç½‘é¡µ', 'web', 'browser', 'æµè§ˆ', 'æœç´¢']):
            capabilities.append("web_scraping")
            capabilities.append("browser_automation")
            tools_needed.append("æµè§ˆå™¨æ“ä½œå·¥å…·")
            if task_type == "unknown":
                task_type = "web"
        
        if any(word in response_lower for word in ['ä»£ç ', 'code', 'python', 'ç¼–ç¨‹', 'ç®—æ³•']):
            capabilities.append("code_execution")
            tools_needed.append("ä»£ç æ‰§è¡Œå·¥å…·")
            if task_type == "unknown":
                task_type = "code"
        
        if any(word in response_lower for word in ['æ•°æ®', 'data', 'åˆ†æ', 'analysis']):
            capabilities.append("data_analysis")
            tools_needed.append("æ•°æ®åˆ†æå·¥å…·")
            if task_type == "unknown":
                task_type = "data"
        
        if any(word in response_lower for word in ['æ–‡ä»¶', 'file', 'æ–‡æ¡£', 'document']):
            capabilities.append("file_processing")
            tools_needed.append("æ–‡ä»¶å¤„ç†å·¥å…·")
            if task_type == "unknown":
                task_type = "file"
        
        return {
            "task_type": task_type,
            "required_capabilities": list(set(capabilities)),
            "tools_needed": list(set(tools_needed)),
            "key_features": [],
            "reasoning": f"åŸºäºå“åº”å†…å®¹çš„ç®€å•åˆ†æ: {response[:100]}...",
            "confidence": 0.6
        }
