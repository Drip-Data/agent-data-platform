#!/usr/bin/env python3
"""
LLMå®¢æˆ·ç«¯ç»Ÿä¸€æ¥å£
æ”¯æŒå¤šç§APIæä¾›å•†ï¼švLLMæœ¬åœ°æœåŠ¡ã€OpenAIã€Google Geminiã€DeepSeekç­‰
"""

import os
import logging
import json
from typing import Dict, Any, Optional, List
from enum import Enum
import time
import httpx # é‡æ–°å¼•å…¥httpxï¼Œå› ä¸º_call_apiä¸­çš„å¼‚å¸¸å¤„ç†éœ€è¦å®ƒ

from core.llm_providers.interfaces import ILLMProvider
from core.llm_providers.openai_provider import OpenAIProvider
from core.llm_providers.gemini_provider import GeminiProvider
from core.llm_providers.deepseek_provider import DeepSeekProvider
from core.llm_providers.vllm_provider import VLLMProvider

# å¯¼å…¥æç¤ºæ„å»ºå™¨
from core.llm.prompt_builders.interfaces import IPromptBuilder
from core.llm.prompt_builders.code_prompt_builder import CodePromptBuilder
from core.llm.prompt_builders.web_prompt_builder import WebPromptBuilder
from core.llm.prompt_builders.reasoning_prompt_builder import ReasoningPromptBuilder
from core.llm.prompt_builders.summary_prompt_builder import SummaryPromptBuilder
from core.llm.prompt_builders.completion_check_prompt_builder import CompletionCheckPromptBuilder
from core.llm.prompt_builders.task_analysis_prompt_builder import TaskAnalysisPromptBuilder

# å¯¼å…¥å“åº”è§£æå™¨
from core.llm.response_parsers.interfaces import IResponseParser
from core.llm.response_parsers.reasoning_response_parser import ReasoningResponseParser
from core.llm.response_parsers.code_response_parser import CodeResponseParser
from core.llm.response_parsers.web_actions_response_parser import WebActionsResponseParser
from core.llm.response_parsers.completion_check_response_parser import CompletionCheckResponseParser
from core.llm.response_parsers.task_analysis_response_parser import TaskAnalysisResponseParser


logger = logging.getLogger(__name__)

class LLMProvider(Enum):
    """LLMæä¾›å•†æšä¸¾"""
    VLLM = "vllm"
    OPENAI = "openai"
    GEMINI = "gemini"
    DEEPSEEK = "deepseek"

from core.unified_tool_manager import UnifiedToolManager

class LLMClient:
    """ç»Ÿä¸€çš„LLMå®¢æˆ·ç«¯"""
    
    def __init__(self, config: Dict[str, Any], tool_manager: UnifiedToolManager):
        self.config = config
        self.provider_instance: Optional[ILLMProvider] = None # åˆå§‹åŒ–ä¸ºNone
        
        # ç¡®ä¿ç¯å¢ƒå˜é‡ä¼ é€’åˆ°é…ç½®ä¸­
        self._enrich_config_with_env_vars()
        
        # å®ä¾‹åŒ–æç¤ºæ„å»ºå™¨
        streaming_mode = config.get('streaming_mode', True)  # é»˜è®¤å¯ç”¨XMLæµå¼æ¨¡å¼
        self.code_prompt_builder: IPromptBuilder = CodePromptBuilder()
        self.web_prompt_builder: IPromptBuilder = WebPromptBuilder()
        self.reasoning_prompt_builder: IPromptBuilder = ReasoningPromptBuilder(tool_manager=tool_manager, streaming_mode=streaming_mode)
        self.summary_prompt_builder: IPromptBuilder = SummaryPromptBuilder()
        self.completion_check_prompt_builder: IPromptBuilder = CompletionCheckPromptBuilder()
        self.task_analysis_prompt_builder: IPromptBuilder = TaskAnalysisPromptBuilder()

        # å®ä¾‹åŒ–å“åº”è§£æå™¨
        self.reasoning_response_parser: IResponseParser = ReasoningResponseParser()
        self.code_response_parser: IResponseParser = CodeResponseParser()
        self.web_actions_response_parser: IResponseParser = WebActionsResponseParser()
        self.completion_check_response_parser: IResponseParser = CompletionCheckResponseParser()
        self.task_analysis_response_parser: IResponseParser = TaskAnalysisResponseParser()

        # ä¼˜å…ˆä½¿ç”¨é…ç½®ä¸­æŒ‡å®šçš„æä¾›å•†ï¼Œæ²¡æœ‰åˆ™è¿›è¡Œè‡ªåŠ¨æ£€æµ‹
        provider_name = config.get('provider') or config.get('default_provider')
        if provider_name:
            provider_name = provider_name.lower()
            if provider_name == 'vllm':
                self.provider = LLMProvider.VLLM
                self.provider_instance = VLLMProvider(config)
            elif provider_name == 'openai':
                self.provider = LLMProvider.OPENAI
                self.provider_instance = OpenAIProvider(config)
            elif provider_name == 'gemini':
                self.provider = LLMProvider.GEMINI
                # ä»åµŒå¥—é…ç½®ä¸­æå– Gemini ç‰¹å®šé…ç½®å¹¶åˆå¹¶åˆ°æ ¹çº§åˆ«
                gemini_config = config.copy()
                if 'providers' in config and 'gemini' in config['providers']:
                    gemini_provider_config = config['providers']['gemini']
                    gemini_config.update(gemini_provider_config)
                self.provider_instance = GeminiProvider(gemini_config)
            elif provider_name == 'deepseek':
                self.provider = LLMProvider.DEEPSEEK
                self.provider_instance = DeepSeekProvider(config)
            else:
                logger.warning(f"Unknown provider in config: {provider_name}, falling back to auto-detection")
                self.provider = self._detect_provider()
                self._initialize_provider_instance()
        else:
            self.provider = self._detect_provider()
            self._initialize_provider_instance()
            
        logger.info(f"Initialized LLM client with provider: {self.provider.value}")

    def _enrich_config_with_env_vars(self):
        """å°†ç¯å¢ƒå˜é‡æ·»åŠ åˆ°é…ç½®ä¸­ä»¥ç¡®ä¿providersèƒ½æ­£ç¡®è®¿é—®"""
        env_vars = {
            'gemini_api_key': os.getenv('GEMINI_API_KEY'),
            'gemini_api_url': os.getenv('GEMINI_API_URL'),
            'openai_api_key': os.getenv('OPENAI_API_KEY'),
            'openai_base_url': os.getenv('OPENAI_BASE_URL'),
            'deepseek_api_key': os.getenv('DEEPSEEK_API_KEY'),
            'deepseek_base_url': os.getenv('DEEPSEEK_BASE_URL'),
            'vllm_base_url': os.getenv('VLLM_BASE_URL')
        }
        
        # åªæ·»åŠ éç©ºçš„ç¯å¢ƒå˜é‡
        for key, value in env_vars.items():
            if value:
                self.config[key] = value
        
        logger.debug(f"Enriched config with environment variables: {list(self.config.keys())}")

    def _initialize_provider_instance(self):
        """æ ¹æ®æ£€æµ‹åˆ°çš„æä¾›å•†åˆå§‹åŒ–å…·ä½“çš„LLMæä¾›å•†å®ä¾‹"""
        try:
            if self.provider == LLMProvider.VLLM:
                self.provider_instance = VLLMProvider(self.config)
            elif self.provider == LLMProvider.OPENAI:
                self.provider_instance = OpenAIProvider(self.config)
            elif self.provider == LLMProvider.GEMINI:
                # ä»åµŒå¥—é…ç½®ä¸­æå– Gemini ç‰¹å®šé…ç½®å¹¶åˆå¹¶åˆ°æ ¹çº§åˆ«
                gemini_config = self.config.copy()
                if 'providers' in self.config and 'gemini' in self.config['providers']:
                    gemini_provider_config = self.config['providers']['gemini']
                    gemini_config.update(gemini_provider_config)
                self.provider_instance = GeminiProvider(gemini_config)
            elif self.provider == LLMProvider.DEEPSEEK:
                self.provider_instance = DeepSeekProvider(self.config)
            else:
                raise ValueError(f"Unsupported provider: {self.provider}")
            
            # ğŸ” éªŒè¯provider_instanceä¸æ˜¯Mockå¯¹è±¡
            if self.provider_instance and "Mock" in type(self.provider_instance).__name__:
                logger.error(f"âŒ Provideråˆå§‹åŒ–åå‘ç°Mockå¯¹è±¡: {type(self.provider_instance)}")
                raise ValueError(f"Provideråˆå§‹åŒ–å¤±è´¥ï¼šè¿”å›äº†Mockå¯¹è±¡ {type(self.provider_instance)}")
            
            logger.debug(f"âœ… Providerå®ä¾‹åˆå§‹åŒ–æˆåŠŸ: {type(self.provider_instance).__name__}")
            
        except Exception as e:
            logger.error(f"âŒ Provideråˆå§‹åŒ–å¤±è´¥: {e}")
            self.provider_instance = None
            raise
    
    def get_llm_config(self) -> Dict[str, Any]:
        """è·å–å½“å‰LLMé…ç½®"""
        return {
            "provider": self.provider.value,
            "config": self.config,
            "provider_instance": str(type(self.provider_instance).__name__) if self.provider_instance else None
        }
    
    def _detect_provider(self) -> LLMProvider:
        """è‡ªåŠ¨æ£€æµ‹ä½¿ç”¨çš„LLMæä¾›å•†"""
        # ä¼˜å…ˆçº§ï¼šGemini > DeepSeek > OpenAI > vLLM
        if os.getenv('GEMINI_API_KEY'):
            return LLMProvider.GEMINI
        elif os.getenv('DEEPSEEK_API_KEY'):
            return LLMProvider.DEEPSEEK
        elif os.getenv('OPENAI_API_KEY'):
            return LLMProvider.OPENAI
        else:
            return LLMProvider.VLLM
    
    async def generate_code(self, description: str, language: str = "python") -> Dict[str, Any]:
        """ç”Ÿæˆä»£ç ï¼Œå¹¶è¿”å›æ€è€ƒè¿‡ç¨‹å’Œä»£ç """
        disable_cache = os.getenv("DISABLE_CACHE") or self.config.get("disable_cache", False)
        logger.debug(f"LLMClient.generate_code called: disable_cache={disable_cache}, description={description[:50]}")
        messages = self.code_prompt_builder.build_prompt(description=description, language=language)
        
        try:
            response = await self._call_api(messages)
            return self.code_response_parser.parse_response(response, language=language)
        except Exception as e:
            logger.error(f"Failed to generate code: {e}")
            raise RuntimeError(f"æ— æ³•ç”Ÿæˆä»£ç : {e}") from e
    
    async def generate_web_actions(self, description: str, page_content: str = "") -> Dict[str, Any]:
        """ç”ŸæˆWebæ“ä½œæ­¥éª¤"""
        messages = self.web_prompt_builder.build_prompt(description=description, page_content=page_content)
        
        try:
            response = await self._call_api(messages)
            return self.web_actions_response_parser.parse_response(response, description=description)
        except Exception as e:
            logger.error(f"Failed to generate web actions: {e}")
            # å¤‡ç”¨é€»è¾‘ç°åœ¨ç”±è§£æå™¨å†…éƒ¨å¤„ç†
            return self.web_actions_response_parser.parse_response("", description=description) # ä¼ å…¥ç©ºå­—ç¬¦ä¸²è§¦å‘å¤‡ç”¨
    
    async def generate_reasoning(self, task_description: str, available_tools: List[str],
                                previous_steps: Optional[List[Dict[str, Any]]] = None,
                                browser_context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨ç†æ­¥éª¤å’Œå·¥å…·è°ƒç”¨"""
        messages = self.reasoning_prompt_builder.build_prompt(
            task_description=task_description,
            available_tools=available_tools,
            previous_steps=previous_steps,
            browser_context=browser_context
        )
        
        try:
            response = await self._call_api(messages)
            return self.reasoning_response_parser.parse_response(response)
        except Exception as e:
            logger.error(f"Failed to generate reasoning: {e}")
            return {
                "thinking": f"Error occurred while processing: {e}",
                "action": "error",
                "tool": None,
                "parameters": {},
                "confidence": 0.0
            }
    
    async def generate_enhanced_reasoning(self, task_description: str, available_tools: List[str],
                                         tool_descriptions: str,
                                         previous_steps: Optional[List[Dict[str, Any]]] = None,
                                         execution_context: Optional[Dict[str, Any]] = None,
                                         streaming_mode: Optional[bool] = None) -> Dict[str, Any]:
        """ç”Ÿæˆå¢å¼ºæ¨ç†æ­¥éª¤å’Œå·¥å…·è°ƒç”¨ - ä½¿ç”¨ä¸°å¯Œçš„å·¥å…·æè¿°å’Œæ‰§è¡Œä¸Šä¸‹æ–‡ï¼Œæ”¯æŒXMLæµå¼æ¨¡å¼"""
        messages = self.reasoning_prompt_builder.build_prompt(
            task_description=task_description,
            available_tools=available_tools,
            tool_descriptions=tool_descriptions,
            previous_steps=previous_steps,
            execution_context=execution_context,
            streaming_mode=streaming_mode
        )
        
        try:
            response = await self._call_api(messages)
            return self.reasoning_response_parser.parse_response(response)
        except Exception as e:
            logger.error(f"Failed to generate enhanced reasoning: {e}")
            return {
                "thinking": f"Error occurred while processing: {e}",
                "action": "error",
                "tool": None,
                "parameters": {},
                "confidence": 0.0
            }
    
    async def generate_task_summary(self, task_description: str, steps: List[Dict],
                                   final_outputs: List[str]) -> str:
        """ç”Ÿæˆä»»åŠ¡æ‰§è¡Œæ€»ç»“"""
        messages = self.summary_prompt_builder.build_prompt(
            task_description=task_description,
            steps=steps,
            final_outputs=final_outputs
        )
        
        try:
            response = await self._call_api(messages)
            return response.strip() # æ€»ç»“é€šå¸¸æ˜¯çº¯æ–‡æœ¬ï¼Œç›´æ¥è¿”å›
        except Exception as e:
            logger.error(f"Failed to generate summary: {e}")
            return f"Task completed with {len(steps)} steps. Final outputs: {'; '.join(final_outputs[:3])}"
    
    async def check_task_completion(self, task_description: str, steps: List[Dict],
                                   current_outputs: List[str]) -> Dict[str, Any]:
        """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å®Œæˆ"""
        messages = self.completion_check_prompt_builder.build_prompt(
            task_description=task_description,
            steps=steps,
            current_outputs=current_outputs
        )
        
        try:
            response = await self._call_api(messages)
            return self.completion_check_response_parser.parse_response(response)
        except Exception as e:
            logger.error(f"Failed to check completion: {e}")
            return {"completed": False, "confidence": 0.0, "reason": f"Error: {e}"}

    async def analyze_task_requirements(self, task_description: str) -> Dict[str, Any]:
        """åˆ†æä»»åŠ¡æè¿°ï¼Œæ€»ç»“éœ€è¦çš„åŠŸèƒ½å’Œèƒ½åŠ› - å¸®åŠ©LLMæ›´å¥½åœ°åœ¨mcp_tools.jsonä¸­æ‰¾åˆ°åˆé€‚å·¥å…·"""
        messages = self.task_analysis_prompt_builder.build_prompt(task_description=task_description)
        
        try:
            response = await self._call_api(messages)
            return self.task_analysis_response_parser.parse_response(response)
        except Exception as e:
            logger.error(f"Failed to analyze task requirements: {e}")
            return {
                "task_type": "unknown",
                "required_capabilities": [],
                "tools_needed": [],
                "reasoning": f"åˆ†æå¤±è´¥: {str(e)}",
                "confidence": 0.0
            }

    async def get_next_action(self, task_description: str, available_tools: List[str],
                                tool_descriptions: str, previous_steps: Optional[List[Dict[str, Any]]] = None, # ä¿®æ”¹ç±»å‹æç¤º
                                execution_context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        è·å–LLMçš„ä¸‹ä¸€ä¸ªè¡ŒåŠ¨å†³ç­–ã€‚
        è¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„æ¥å£ï¼Œç”¨äºåœ¨å¢å¼ºæ¨ç†æ¨¡å¼ä¸‹è·å–LLMçš„å†³ç­–ã€‚
        å®ƒå°†ç›´æ¥è°ƒç”¨ generate_enhanced_reasoning æ–¹æ³•ã€‚
        """
        logger.info("Calling get_next_action (unified LLM decision interface)")
        return await self.generate_enhanced_reasoning(
            task_description=task_description,
            available_tools=available_tools,
            tool_descriptions=tool_descriptions,
            previous_steps=previous_steps,
            execution_context=execution_context
        )

    async def _call_api(self, messages: List[Dict[str, Any]], timeout: int = 120, stop_sequences: Optional[List[str]] = None) -> Dict[str, Any]:
        """è°ƒç”¨ç›¸åº”çš„APIï¼Œå¹¶è®°å½•å®Œæ•´çš„äº¤äº’ä¿¡æ¯"""
        # ğŸ”§ æ–°å¢ï¼šé¢„è°ƒç”¨æ•°æ®éªŒè¯ - é˜²æ­¢æ•°æ®ç±»å‹é”™è¯¯ä¼ æ’­
        try:
            validated_messages = self._validate_input_messages(messages)
        except Exception as validation_error:
            logger.error(f"è¾“å…¥æ¶ˆæ¯éªŒè¯å¤±è´¥: {validation_error}")
            raise ValueError(f"LLM APIè°ƒç”¨å‚æ•°æ— æ•ˆ: {validation_error}")
        
        # ğŸ” æ–°å¢ï¼šè®°å½•APIè°ƒç”¨ä¿¡æ¯
        logger.info("ğŸš€ LLM APIè°ƒç”¨å¼€å§‹")
        logger.info(f"   æä¾›å•†: {self.provider.value}")
        logger.info(f"   æ¶ˆæ¯æ•°é‡: {len(validated_messages)}")
        
        # è®°å½•promptå†…å®¹ï¼ˆè°ƒè¯•æ¨¡å¼ä¸‹è®°å½•æ›´å¤šè¯¦æƒ…ï¼‰
        if logger.isEnabledFor(logging.DEBUG):
            logger.debug(f"   å®Œæ•´Messageså†…å®¹:\n{json.dumps(validated_messages, ensure_ascii=False, indent=2)}")
        else:
            # ç”Ÿäº§æ¨¡å¼ä¸‹è®°å½•æ¶ˆæ¯æ¦‚è§ˆ
            msg_summary = []
            for i, msg in enumerate(validated_messages):
                role = msg.get("role", "unknown")
                content_len = len(str(msg.get("content", "")))
                msg_summary.append(f"{role}({content_len}å­—ç¬¦)")
            logger.info(f"   æ¶ˆæ¯æ¦‚è§ˆ: {' -> '.join(msg_summary)}")
        
        start_time = time.time()
        
        try:
            if self.provider_instance is None:
                raise ValueError("LLM provider instance is not initialized.")
            
            # ğŸ” æ–°å¢ï¼šæ£€æŸ¥provider_instanceç±»å‹ï¼Œé˜²æ­¢AsyncMockæ³„éœ²
            provider_type = type(self.provider_instance).__name__
            if "Mock" in provider_type:
                logger.error(f"âŒ æ£€æµ‹åˆ°Mockå¯¹è±¡è¢«ç”¨ä½œLLM provider: {provider_type}")
                logger.error(f"   é‡æ–°åˆå§‹åŒ–provider...")
                self._initialize_provider_instance()
                if "Mock" in type(self.provider_instance).__name__:
                    raise ValueError(f"LLM providerè¢«æ„å¤–è®¾ç½®ä¸ºMockå¯¹è±¡: {type(self.provider_instance)}")
            
            # è·å–é»˜è®¤æ¨¡å‹å¹¶ä¼ é€’ç»™ generate_response
            model_name = self.provider_instance.get_default_model()
            
            # å‡†å¤‡å‚æ•°ï¼ŒåŒ…å«stop_sequencesï¼ˆå¦‚æœæ”¯æŒï¼‰
            params = {
                "messages": validated_messages,
                "model": model_name,
                "timeout": timeout
            }
            
            # å¦‚æœæä¾›äº†stop_sequencesï¼Œæ·»åŠ åˆ°å‚æ•°ä¸­
            if stop_sequences:
                params["stop_sequences"] = stop_sequences
                logger.info(f"ğŸ”§ ä½¿ç”¨stop_sequences: {stop_sequences}")
            
            response = await self.provider_instance.generate_response(**params)
            
            # ğŸ” æ–°å¢ï¼šæ£€æŸ¥å“åº”ç±»å‹ï¼Œå¤„ç†ä¸åŒçš„è¿”å›æ ¼å¼
            duration = time.time() - start_time
            
            # å¦‚æœproviderè¿”å›å­—ç¬¦ä¸²ï¼ˆæ—§æ ¼å¼ï¼‰ï¼Œè½¬æ¢ä¸ºæ–°æ ¼å¼
            if isinstance(response, str):
                response_data = {
                    'content': response,
                    'usage': None,  # æ—§æ ¼å¼æ²¡æœ‰usageä¿¡æ¯
                    'metadata': {
                        'response_time': duration,
                        'provider': self.provider.value,
                        'model': model_name
                    }
                }
                logger.warning(f"âš ï¸ Providerè¿”å›æ—§æ ¼å¼(string)ï¼Œå·²è½¬æ¢ä¸ºæ–°æ ¼å¼")
            elif isinstance(response, dict):
                # æ–°æ ¼å¼ï¼šå­—å…¸åŒ…å«contentå’Œmetadata
                response_data = response
                response_data.setdefault('metadata', {})
                response_data['metadata'].update({
                    'response_time': duration,
                    'provider': self.provider.value,
                    'model': model_name
                })
            elif hasattr(response, '_mock_name') or "Mock" in type(response).__name__:
                logger.error(f"âŒ LLM providerè¿”å›äº†Mockå¯¹è±¡: {type(response)}")
                raise ValueError(f"LLM providerè¿”å›äº†Mockå¯¹è±¡: {type(response)}")
            else:
                logger.error(f"âŒ LLM providerè¿”å›äº†æ„å¤–ç±»å‹: {type(response)}")
                raise ValueError(f"LLM providerè¿”å›äº†æ„å¤–ç±»å‹: {type(response)}")
            
            # éªŒè¯å“åº”å†…å®¹
            content = response_data.get('content', '')
            if not isinstance(content, str):
                logger.warning(f"âš ï¸ å“åº”å†…å®¹ç±»å‹å¼‚å¸¸: {type(content)}, å°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²")
                content = str(content) if content is not None else ""
                response_data['content'] = content
            
            # ğŸ” æ–°å¢ï¼šè®°å½•APIå“åº”ä¿¡æ¯å’Œæ•°æ®æµè¿½è¸ª
            logger.info("âœ… LLM APIè°ƒç”¨æˆåŠŸ")
            logger.info(f"   å“åº”æ—¶é—´: {duration:.2f}ç§’")
            logger.info(f"   å“åº”é•¿åº¦: {len(content)} å­—ç¬¦")
            logger.info(f"   åŒ…å«usageä¿¡æ¯: {response_data.get('usage') is not None}")
            
            # æ£€æŸ¥å“åº”æ˜¯å¦ä¸ºç©ºæˆ–å¼‚å¸¸
            if not content or content.strip() == "":
                logger.warning("âš ï¸ LLM APIè¿”å›ç©ºå“åº”")
            elif len(content) > 10000:
                logger.warning(f"âš ï¸ LLM APIè¿”å›å“åº”è¿‡é•¿: {len(content)} å­—ç¬¦")
            
            # è®°å½•å“åº”å†…å®¹
            if logger.isEnabledFor(logging.DEBUG):
                logger.debug(f"   å®Œæ•´å“åº”å†…å®¹:\n{content}")
            else:
                # ç”Ÿäº§æ¨¡å¼ä¸‹åªè®°å½•å‰åç‰‡æ®µ
                response_preview = content[:200] + "..." + content[-100:] if len(content) > 300 else content
                logger.info(f"   å“åº”é¢„è§ˆ: {response_preview}")
            
            return response_data
            
        except httpx.HTTPStatusError as e: # æ•è·æ›´å…·ä½“çš„HTTPé”™è¯¯
            # ğŸ” æ–°å¢ï¼šè®°å½•APIé”™è¯¯ä¿¡æ¯
            duration = time.time() - start_time
            logger.error("âŒ LLM APIè°ƒç”¨å¤±è´¥")
            logger.error(f"   å¤±è´¥æ—¶é—´: {duration:.2f}ç§’")
            logger.error(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
            logger.error(f"   HTTPçŠ¶æ€ç : {e.response.status_code}")
            logger.error(f"   å“åº”å†…å®¹: {e.response.text}")
            raise
        except Exception as e:
            # ğŸ” æ–°å¢ï¼šè®°å½•APIé”™è¯¯ä¿¡æ¯
            duration = time.time() - start_time
            logger.error("âŒ LLM APIè°ƒç”¨å¤±è´¥")
            logger.error(f"   å¤±è´¥æ—¶é—´: {duration:.2f}ç§’")
            logger.error(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
            # å¯¹äºéHTTPStatusErrorï¼Œå¯èƒ½æ²¡æœ‰responseå±æ€§
            raise

    def _validate_input_messages(self, messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """éªŒè¯å’Œæ¸…ç†è¾“å…¥æ¶ˆæ¯ï¼Œé˜²æ­¢æ•°æ®ç±»å‹é”™è¯¯ä¼ æ’­"""
        if not isinstance(messages, list):
            raise ValueError(f"messageså¿…é¡»æ˜¯åˆ—è¡¨ç±»å‹ï¼Œå®é™…ç±»å‹: {type(messages)}")
        
        validated_messages = []
        for i, msg in enumerate(messages):
            try:
                # ç¡®ä¿æ¯ä¸ªæ¶ˆæ¯éƒ½æ˜¯å­—å…¸
                if not isinstance(msg, dict):
                    logger.warning(f"æ¶ˆæ¯ {i} ä¸æ˜¯å­—å…¸ç±»å‹: {type(msg)}, å°è¯•è½¬æ¢")
                    if hasattr(msg, '__dict__'):
                        msg = msg.__dict__
                    else:
                        raise ValueError(f"æ¶ˆæ¯ {i} æ— æ³•è½¬æ¢ä¸ºå­—å…¸")
                
                # éªŒè¯å¿…éœ€å­—æ®µ
                if "role" not in msg:
                    raise ValueError(f"æ¶ˆæ¯ {i} ç¼ºå°‘'role'å­—æ®µ")
                if "content" not in msg:
                    raise ValueError(f"æ¶ˆæ¯ {i} ç¼ºå°‘'content'å­—æ®µ")
                
                # æ¸…ç†å’ŒéªŒè¯å­—æ®µå€¼
                validated_msg = {
                    "role": str(msg["role"]).strip(),
                    "content": self._validate_and_clean_content(msg["content"], i)
                }
                
                # éªŒè¯roleå€¼
                valid_roles = {"user", "assistant", "system"}
                if validated_msg["role"] not in valid_roles:
                    logger.warning(f"æ¶ˆæ¯ {i} çš„roleæ— æ•ˆ: {validated_msg['role']}, è®¾ç½®ä¸º'user'")
                    validated_msg["role"] = "user"
                
                validated_messages.append(validated_msg)
                
            except Exception as e:
                logger.error(f"éªŒè¯æ¶ˆæ¯ {i} å¤±è´¥: {e}, æ¶ˆæ¯å†…å®¹: {msg}")
                # è·³è¿‡æ— æ•ˆæ¶ˆæ¯ï¼Œä½†å¦‚æœæ‰€æœ‰æ¶ˆæ¯éƒ½æ— æ•ˆåˆ™æŠ›å‡ºå¼‚å¸¸
                continue
        
        if not validated_messages:
            raise ValueError("æ‰€æœ‰è¾“å…¥æ¶ˆæ¯éƒ½æ— æ•ˆï¼Œæ— æ³•è¿›è¡ŒAPIè°ƒç”¨")
        
        logger.debug(f"æ¶ˆæ¯éªŒè¯å®Œæˆ: {len(messages)} -> {len(validated_messages)}")
        return validated_messages
    
    def _validate_and_clean_content(self, content: Any, msg_index: int) -> str:
        """éªŒè¯å’Œæ¸…ç†æ¶ˆæ¯å†…å®¹"""
        if content is None:
            return ""
        
        if isinstance(content, str):
            return content
        
        if isinstance(content, (dict, list)):
            try:
                # å°†å¤æ‚å¯¹è±¡è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
                json_str = json.dumps(content, ensure_ascii=False, indent=2)
                logger.debug(f"æ¶ˆæ¯ {msg_index} çš„å¤æ‚contentå·²è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²")
                return json_str
            except Exception as e:
                logger.warning(f"æ¶ˆæ¯ {msg_index} çš„content JSONåºåˆ—åŒ–å¤±è´¥: {e}")
                return str(content)
        
        # å…¶ä»–ç±»å‹ç›´æ¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        return str(content)
