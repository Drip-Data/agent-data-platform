import json
import logging
import re
from typing import Dict, Any, List

from core.llm.response_parsers.interfaces import IResponseParser

logger = logging.getLogger(__name__)

class ReasoningResponseParser(IResponseParser):
    """
    ç®€åŒ–çš„å“åº”è§£æå™¨ - XMLæµå¼æ¨¡å¼ä¼˜å…ˆ
    ä¸“æ³¨äºXMLæ ‡ç­¾è§£æï¼Œæœ€å°åŒ–å¤æ‚çš„JSONå¤„ç†é€»è¾‘
    """
    
    def __init__(self):
        """åˆå§‹åŒ–å“åº”è§£æå™¨"""
        pass
    
    def set_tool_schema_manager(self, tool_schema_manager):
        """ä¿æŒæ¥å£å…¼å®¹æ€§"""
        pass

    def parse_response(self, response: str, **kwargs) -> Dict[str, Any]:
        """
        ç®€åŒ–çš„å“åº”è§£æ - XMLæµå¼æ¨¡å¼ä¼˜å…ˆ
        
        Args:
            response (str): LLMçš„åŸå§‹å­—ç¬¦ä¸²å“åº”
            **kwargs: é¢å¤–å‚æ•°
            
        Returns:
            Dict[str, Any]: è§£æåçš„æ¨ç†å†³ç­–å­—å…¸
        """
        logger.info(f"ğŸ” è§£æå“åº” - é•¿åº¦: {len(response)} å­—ç¬¦")
        logger.debug(f"å“åº”é¢„è§ˆ: {response[:200]}..." if len(response) > 200 else response)
        
        # ğŸš€ ä¼˜å…ˆæ£€æµ‹XMLæµå¼æ¨¡å¼ (æ ¸å¿ƒè®¾è®¡)
        if self._is_xml_streaming_response(response):
            # æ£€æµ‹æ˜¯å¦ä¸ºSequentialæ¨¡å¼
            if self._is_sequential_xml_response(response):
                logger.info("ğŸ¯ Sequential XMLæµå¼æ¨¡å¼")
                return self._parse_sequential_steps(response)
            else:
                logger.info("ğŸ¯ å•æ­¥XMLæµå¼æ¨¡å¼")
                return self.parse_streaming_response(response)
        
        # ğŸ”§ ç®€å•çš„JSON fallback (å‘åå…¼å®¹)
        logger.info("ğŸ“‹ JSONæ¨¡å¼")
        return self._simple_json_fallback(response)
    
    def _simple_json_fallback(self, response: str) -> Dict[str, Any]:
        """ç®€å•çš„JSON fallbackè§£æ - å‘åå…¼å®¹"""
        try:
            # å°è¯•æå–JSON
            cleaned = response.strip()
            
            # ç§»é™¤markdownåŒ…è£…
            if cleaned.startswith('```json'):
                cleaned = cleaned[7:]
            elif cleaned.startswith('```'):
                cleaned = cleaned[3:]
            if cleaned.endswith('```'):
                cleaned = cleaned[:-3]
            
            cleaned = cleaned.strip()
            
            # æŸ¥æ‰¾JSONå¯¹è±¡
            first_brace = cleaned.find('{')
            last_brace = cleaned.rfind('}')
            
            if first_brace != -1 and last_brace != -1:
                json_text = cleaned[first_brace:last_brace + 1]
                
                # åŸºç¡€æ¸…ç†
                json_text = re.sub(r',\s*}', '}', json_text)
                json_text = re.sub(r'\bTrue\b', 'true', json_text)
                json_text = re.sub(r'\bFalse\b', 'false', json_text)
                json_text = re.sub(r'\bNone\b', 'null', json_text)
                
                # å°è¯•è§£æ
                parsed = json.loads(json_text)
                
                # åŸºæœ¬å­—æ®µè¡¥å…¨
                result = {
                    'thinking': parsed.get('thinking', 'No thinking provided'),
                    'action': parsed.get('action', 'error'),
                    'tool_id': parsed.get('tool_id') or parsed.get('tool', 'microsandbox'),
                    'parameters': parsed.get('parameters', {}),
                    'confidence': parsed.get('confidence', 0.5)
                }
                
                # å‘åå…¼å®¹
                result['tool'] = result['tool_id']
                
                logger.info(f"âœ… JSONè§£ææˆåŠŸ - action: {result['action']}")
                return result
                
        except Exception as e:
            logger.warning(f"JSONè§£æå¤±è´¥: {e}")
        
        # æœ€ç»ˆfallback
        return {
            'thinking': response[:500] if len(response) > 500 else response,
            'action': 'error',
            'tool_id': 'microsandbox',
            'tool': 'microsandbox',
            'parameters': {},
            'confidence': 0.1,
            'error': 'Failed to parse response'
        }
    
    def _is_xml_streaming_response(self, response: str) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºXMLæµå¼å“åº”"""
        xml_indicators = ['<think>', '<microsandbox>', '<deepsearch>', '<browser>', '<search>', '<answer>']
        return any(tag in response for tag in xml_indicators)
    
    def parse_streaming_response(self, response: str) -> Dict[str, Any]:
        """è§£æXMLæµå¼å“åº” - åŸºäºMCP Serverçº§åˆ«çš„æ ‡ç­¾"""
        logger.info("ğŸ¯ å¼€å§‹è§£æXMLæµå¼å“åº”")
        
        # æå–å®Œæ•´thinkingå†…å®¹ï¼ˆä¸æˆªæ–­ï¼‰
        thinking_segments = self._extract_all_xml_tags(response, 'think')
        complete_thinking = '\n\n'.join(thinking_segments)
        logger.debug(f"âœ… æå–thinkingå†…å®¹: {len(complete_thinking)} å­—ç¬¦")
        
        # MCP Serverçº§åˆ«çš„XMLæ ‡ç­¾æ˜ å°„
        xml_to_server_map = {
            'microsandbox': 'microsandbox',
            'deepsearch': 'mcp-deepsearch', 
            'browser': 'browser_use',
            'search': 'mcp-search-tool'
        }
        
        # æ£€æµ‹å·¥å…·è°ƒç”¨
        for xml_tag, server_id in xml_to_server_map.items():
            content = self._extract_xml_tag(response, xml_tag)
            if content:
                logger.info(f"ğŸ”§ æ£€æµ‹åˆ°MCP Serverè°ƒç”¨: {xml_tag} -> {server_id}")
                
                # æå–confidenceå€¼ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                confidence = self._extract_confidence_from_content(content)
                
                # å»é™¤contentä¸­çš„confidenceæ ‡ç­¾ï¼Œä¿ç•™çº¯ç²¹çš„æŒ‡ä»¤
                clean_content = self._remove_confidence_tags(content)
                
                # è®©ç³»ç»Ÿè‡ªåŠ¨é€‰æ‹©æœ€ä½³actionï¼Œä¼ é€’åŸå§‹å†…å®¹
                return {
                    "thinking": complete_thinking,
                    "tool_id": server_id,
                    "action": "auto_select",  # ç‰¹æ®Šæ ‡è®°ï¼Œè®©ç³»ç»Ÿè‡ªå·±é€‰æ‹©
                    "parameters": {"instruction": clean_content.strip()},
                    "confidence": confidence,
                    "xml_source": xml_tag
                }
        
        # æ£€æµ‹ç­”æ¡ˆå®Œæˆ
        answer_content = self._extract_xml_tag(response, 'answer')
        if answer_content:
            logger.info("âœ… æ£€æµ‹åˆ°ä»»åŠ¡å®Œæˆæ ‡å¿—")
            
            # æå–confidenceå€¼ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            confidence = self._extract_confidence_from_content(answer_content)
            clean_answer = self._remove_confidence_tags(answer_content)
            
            return {
                "thinking": complete_thinking,
                "action": "complete_task",
                "final_answer": clean_answer,
                "confidence": confidence if confidence != 0.9 else 1.0  # answeré»˜è®¤é«˜ç½®ä¿¡åº¦
            }
        
        # å¦‚æœåªæœ‰thinkingå†…å®¹ï¼Œç»§ç»­ç­‰å¾…
        if complete_thinking:
            logger.info("ğŸ’­ åªæœ‰thinkingå†…å®¹ï¼Œç­‰å¾…å·¥å…·è°ƒç”¨")
            return {
                "thinking": complete_thinking,
                "action": "continue_thinking",
                "confidence": 0.7
            }
        
        # Fallbackåˆ°ç°æœ‰è§£æé€»è¾‘
        logger.warning("âš ï¸ XMLè§£æå¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»ŸJSONè§£æ")
        return self._fallback_json_parse(response)
    
    def _extract_xml_tag(self, text: str, tag: str) -> str:
        """æå–å•ä¸ªXMLæ ‡ç­¾çš„å†…å®¹"""
        pattern = f'<{tag}>(.*?)</{tag}>'
        match = re.search(pattern, text, re.DOTALL)
        if match:
            content = match.group(1).strip()
            logger.debug(f"âœ… æå–{tag}æ ‡ç­¾å†…å®¹: {len(content)} å­—ç¬¦")
            return content
        return ""
    
    def _extract_all_xml_tags(self, text: str, tag: str) -> List[str]:
        """æå–æ‰€æœ‰åŒåXMLæ ‡ç­¾çš„å†…å®¹"""
        pattern = f'<{tag}>(.*?)</{tag}>'
        matches = re.findall(pattern, text, re.DOTALL)
        contents = [match.strip() for match in matches]
        logger.debug(f"âœ… æå–æ‰€æœ‰{tag}æ ‡ç­¾: {len(contents)} ä¸ª")
        return contents
    
    def _extract_confidence_from_content(self, content: str) -> float:
        """ä»å†…å®¹ä¸­æå–confidenceå€¼"""
        pattern = r'<confidence>(.*?)</confidence>'
        match = re.search(pattern, content, re.DOTALL)
        if match:
            try:
                confidence_value = float(match.group(1).strip())
                # ç¡®ä¿åœ¨æœ‰æ•ˆèŒƒå›´å†…
                confidence_value = max(0.0, min(1.0, confidence_value))
                logger.debug(f"âœ… æå–åˆ°confidenceå€¼: {confidence_value}")
                return confidence_value
            except ValueError:
                logger.warning(f"âš ï¸ æ— æ•ˆçš„confidenceå€¼: {match.group(1)}")
        
        # é»˜è®¤confidenceå€¼
        return 0.9
    
    def _remove_confidence_tags(self, content: str) -> str:
        """ä»å†…å®¹ä¸­ç§»é™¤confidenceæ ‡ç­¾"""
        # ç§»é™¤confidenceæ ‡ç­¾åŠå…¶å†…å®¹
        clean_content = re.sub(r'<confidence>.*?</confidence>', '', content, flags=re.DOTALL)
        # æ¸…ç†å¤šä½™çš„ç©ºç™½è¡Œ
        clean_content = re.sub(r'\n\s*\n', '\n', clean_content.strip())
        return clean_content
    
    def _fallback_json_parse(self, response: str) -> Dict[str, Any]:
        """å›é€€åˆ°ä¼ ç»ŸJSONè§£æ"""
        try:
            # ç§»é™¤XMLæ ‡ç­¾å¹²æ‰°ï¼Œå°è¯•JSONè§£æ
            clean_response = re.sub(r'<[^>]+>.*?</[^>]+>', '', response, flags=re.DOTALL)
            clean_response = clean_response.strip()
            
            if clean_response.startswith('{') and clean_response.endswith('}'):
                parsed = json.loads(clean_response)
                return {
                    'thinking': parsed.get('thinking', 'No thinking provided'),
                    'action': parsed.get('action', 'error'),
                    'tool_id': parsed.get('tool_id', 'microsandbox'),
                    'tool': parsed.get('tool_id', 'microsandbox'),
                    'parameters': parsed.get('parameters', {}),
                    'confidence': parsed.get('confidence', 0.5)
                }
            
            # å®Œå…¨å¤±è´¥ï¼Œè¿”å›åŸºæœ¬å“åº”
            return {
                "thinking": response[:500] if len(response) > 500 else response,
                "action": "error",
                "tool_id": "microsandbox",
                "tool": "microsandbox",
                "parameters": {},
                "error": "æ— æ³•è§£æå“åº”æ ¼å¼",
                "confidence": 0.1
            }
            
        except Exception as e:
            logger.error(f"âŒ Fallbackè§£æä¹Ÿå¤±è´¥: {e}")
            return {
                "thinking": "è§£æå¤±è´¥: " + str(e),
                "action": "error", 
                "tool_id": "microsandbox",
                "tool": "microsandbox",
                "parameters": {},
                "error": str(e),
                "confidence": 0.0
            }
    
    def _is_sequential_xml_response(self, response: str) -> bool:
        """
        æ£€æµ‹æ˜¯å¦ä¸ºSequential XMLå“åº”
        
        Args:
            response: å“åº”å­—ç¬¦ä¸²
            
        Returns:
            æ˜¯å¦ä¸ºSequentialæ¨¡å¼
        """
        # æ£€æµ‹å¤šä¸ªå·¥å…·è°ƒç”¨æ ‡ç­¾
        tool_tags = ['<microsandbox>', '<deepsearch>', '<browser>', '<search>']
        tool_count = sum(1 for tag in tool_tags if tag in response)
        
        # æ£€æµ‹æ˜¯å¦æœ‰<think>å’Œå·¥å…·è°ƒç”¨äº¤æ›¿æ¨¡å¼
        has_thinking_flow = '<think>' in response and any(tag in response for tag in tool_tags)
        
        # æ£€æµ‹å®Œæ•´çš„æ¨ç†æµç¨‹
        has_complete_flow = '<think>' in response and '<answer>' in response
        
        # Sequentialæ¨¡å¼çš„ç‰¹å¾
        is_sequential = (
            tool_count > 1 or  # å¤šä¸ªå·¥å…·è°ƒç”¨
            has_thinking_flow or  # thinking + å·¥å…·è°ƒç”¨
            has_complete_flow  # å®Œæ•´æ¨ç†æµç¨‹
        )
        
        logger.debug(f"ğŸ” Sequentialæ£€æµ‹ - å·¥å…·æ•°: {tool_count}, æ€ç»´æµ: {has_thinking_flow}, å®Œæ•´æµç¨‹: {has_complete_flow}")
        return is_sequential
    
    def _parse_sequential_steps(self, response: str) -> Dict[str, Any]:
        """
        è§£æSequential XMLæ­¥éª¤åºåˆ—
        
        Args:
            response: XMLå“åº”
            
        Returns:
            Sequentialè§£æç»“æœ
        """
        import re
        
        steps = []
        current_pos = 0
        
        # æ­£åˆ™åŒ¹é…æ‰€æœ‰XMLæ ‡ç­¾
        xml_pattern = r'<(think|microsandbox|deepsearch|browser|search|answer)>(.*?)</\1>'
        
        for match in re.finditer(xml_pattern, response, re.DOTALL):
            tag_name = match.group(1)
            content = match.group(2).strip()
            
            step = {
                'type': tag_name,
                'content': content,
                'position': match.span(),
                'needs_execution': tag_name in ['microsandbox', 'deepsearch', 'browser', 'search']
            }
            steps.append(step)
        
        # æå–å®Œæ•´thinking (åˆå¹¶æ‰€æœ‰<think>æ ‡ç­¾)
        thinking_segments = [s['content'] for s in steps if s['type'] == 'think']
        complete_thinking = '\n\n'.join(thinking_segments)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æœ€ç»ˆç­”æ¡ˆ
        answer_steps = [s for s in steps if s['type'] == 'answer']
        final_answer = answer_steps[0]['content'] if answer_steps else ""
        
        # ç»Ÿè®¡å·¥å…·è°ƒç”¨æ­¥éª¤
        execution_steps = [s for s in steps if s['needs_execution']]
        
        logger.info(f"ğŸ¯ Sequentialè§£æå®Œæˆ - æ€»æ­¥éª¤: {len(steps)}, æ‰§è¡Œæ­¥éª¤: {len(execution_steps)}")
        
        return {
            'action': 'sequential_streaming',
            'thinking': complete_thinking,
            'steps': steps,
            'execution_steps': execution_steps,
            'final_answer': final_answer,
            'xml_source': 'sequential',
            'confidence': 0.9,
            # ä¸ºäº†å…¼å®¹ç°æœ‰ç³»ç»Ÿï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªæ‰§è¡Œæ­¥éª¤ä½œä¸ºä¸»è¦å·¥å…·è°ƒç”¨
            'tool_id': execution_steps[0]['type'] if execution_steps else 'microsandbox',
            'parameters': {'instruction': execution_steps[0]['content'] if execution_steps else ''}
        }