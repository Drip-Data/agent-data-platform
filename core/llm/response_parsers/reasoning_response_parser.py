import json
import logging
import re
from typing import Dict, Any, List, Optional

from core.llm.response_parsers.interfaces import IResponseParser
from core.llm.validation_middleware import validation_middleware, ResponseValidationResult, validate_llm_response
from core.unified_tool_manager import get_tool_manager

logger = logging.getLogger(__name__)

class ReasoningResponseParser(IResponseParser):
    """
    ç”¨äºè§£æLLMç”Ÿæˆçš„æ¨ç†å“åº”çš„è§£æå™¨ã€‚
    å¤„ç†å¤æ‚çš„JSONæå–ã€éªŒè¯å’Œä¿®æ­£é€»è¾‘ã€‚
    """
    
    def __init__(self):
        """åˆå§‹åŒ–å“åº”è§£æå™¨"""
        self.tool_schema_manager = None  # é€šè¿‡ä¾èµ–æ³¨å…¥è®¾ç½®
    
    def set_tool_schema_manager(self, tool_schema_manager):
        """ğŸ”’ P0-2ä¿®å¤ï¼šè®¾ç½®å·¥å…·Schemaç®¡ç†å™¨ä»¥æ”¯æŒåŠ¨æ€éªŒè¯"""
        self.tool_schema_manager = tool_schema_manager
        logger.debug("âœ… å“åº”è§£æå™¨å·²è¿æ¥å·¥å…·Schemaç®¡ç†å™¨")

    def parse_response(self, response: str, **kwargs) -> Dict[str, Any]:
        """
        è§£æLLMçš„åŸå§‹å­—ç¬¦ä¸²å“åº”ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºç»“æ„åŒ–çš„æ¨ç†å†³ç­–å­—å…¸ã€‚
        
        Args:
            response (str): LLMçš„åŸå§‹å­—ç¬¦ä¸²å“åº”ã€‚
            **kwargs: é¢å¤–çš„å‚æ•°ï¼Œç›®å‰æœªä½¿ç”¨ï¼Œä½†ä¿ç•™ä»¥ç¬¦åˆæ¥å£ã€‚

        Returns:
            Dict[str, Any]: åŒ…å«è§£æåæ¨ç†å†³ç­–çš„å­—å…¸ã€‚
        """
        logger.info(f"ğŸ” å¼€å§‹è§£æLLMå“åº” - é•¿åº¦: {len(response)} å­—ç¬¦, ç±»å‹: {type(response)}")
        logger.debug(f"å“åº”å†…å®¹é¢„è§ˆ: {response[:200]}..." if len(response) > 200 else response)
        
        # ğŸ”§ ä¿®å¤ï¼šè‡ªåŠ¨å¤„ç†è¶…é•¿å“åº”ï¼Œé¿å…å¡ä½
        MAX_RESPONSE_LENGTH = 5000  # é™åˆ¶å“åº”é•¿åº¦ä¸º5000å­—ç¬¦
        if len(response) > MAX_RESPONSE_LENGTH:
            logger.warning(f"âš ï¸ å“åº”è¿‡é•¿ ({len(response)} å­—ç¬¦)ï¼Œå¯ç”¨æ™ºèƒ½æˆªæ–­...")
            response = self._smart_truncate_response(response, MAX_RESPONSE_LENGTH)
            logger.info(f"âœ… æ™ºèƒ½æˆªæ–­å®Œæˆï¼Œæ–°é•¿åº¦: {len(response)} å­—ç¬¦")
        
        try:
            # é¦–å…ˆå°è¯•ç›´æ¥è§£æJSON
            response_clean = response.strip()
            
            # ğŸ” å¢å¼ºçš„JSONæå– - å¤„ç†å„ç§æ ¼å¼
            json_patterns = [
                r'```json\s*(\{.*?\})\s*```',  # markdownä»£ç å—
                r'```\s*(\{.*?\})\s*```',      # æ™®é€šä»£ç å—  
                r'(\{[^{}]*"thinking"[^{}]*\})', # åŒ…å«thinkingçš„JSON
                r'(\{.*?\})',                  # ä»»ä½•JSONå¯¹è±¡
            ]
            
            json_text = None
            for pattern in json_patterns:
                match = re.search(pattern, response_clean, re.DOTALL)
                if match:
                    json_text = match.group(1)
                    logger.debug(f"ä½¿ç”¨æ¨¡å¼æå–åˆ°JSON: {pattern}")
                    break
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONå—ï¼Œå°è¯•ç›´æ¥è§£æ
            if not json_text:
                # ç§»é™¤å¯èƒ½çš„markdownä»£ç å—åŒ…è£…
                if response_clean.startswith('```json'):
                    response_clean = response_clean[7:]
                if response_clean.endswith('```'):
                    response_clean = response_clean[:-3]
                json_text = response_clean.strip()
            
            # ğŸ” ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
            if json_text:
                # ä¿®å¤è¢«æˆªæ–­çš„JSON
                if not json_text.endswith('}') and json_text.count('{') > json_text.count('}'):
                    missing_braces = json_text.count('{') - json_text.count('}')
                    json_text += '}' * missing_braces
                    logger.warning(f"ğŸ”§ ä¿®å¤äº† {missing_braces} ä¸ªç¼ºå¤±çš„å³æ‹¬å·")
                
                # ğŸ†• P3å¢å¼ºï¼šä¿®å¤ç‰¹å®šçš„åˆ†éš”ç¬¦é”™è¯¯
                json_text = self._fix_delimiter_errors(json_text)
                
                # ğŸ”§ æ–°å¢ï¼šä¿®å¤æ§åˆ¶å­—ç¬¦é—®é¢˜ - è§£å†³ "Invalid control character" é”™è¯¯
                json_text = self._fix_control_characters(json_text)
                
                # ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é”™è¯¯
                json_text = self._fix_json_formatting_errors(json_text)
                
                # å°è¯•è§£æJSON
                try:
                    parsed = json.loads(json_text)
                    logger.debug("JSONè§£ææˆåŠŸ")
                    
                    # ğŸ” æ™ºèƒ½å­—æ®µè¡¥å…¨å’ŒéªŒè¯
                    result = self._validate_and_complete_parsed_response(parsed)
                    
                    # âœ¨ æ–°å¢ï¼šç»“æ„åŒ–é¢„æ ¡éªŒ
                    validation_result = self._apply_structured_validation(result)
                    if validation_result.is_valid:
                        if validation_result.corrected:
                            logger.info("âœ… ç»“æ„åŒ–æ ¡éªŒé€šè¿‡ï¼ˆå·²è‡ªåŠ¨çº æ­£ï¼‰")
                            result = validation_result.data
                        else:
                            logger.debug("âœ… ç»“æ„åŒ–æ ¡éªŒé€šè¿‡")
                    else:
                        logger.warning(f"âš ï¸ ç»“æ„åŒ–æ ¡éªŒå¤±è´¥: {validation_result.error}")
                        # ç»§ç»­ä½¿ç”¨åŸæœ‰çš„éªŒè¯æœºåˆ¶ä½œä¸ºå¤‡é€‰
                    
                    logger.info(f"âœ… å“åº”è§£ææˆåŠŸ - action: {result.get('action')}, tool: {result.get('tool_id') or result.get('tool')}, confidence: {result.get('confidence')}")
                    return result
                    
                except json.JSONDecodeError as json_error:
                    logger.warning(f"âŒ JSONè§£æå¤±è´¥: {json_error}")
                    
                    # ğŸ”§ å¤šå±‚çº§ä¿®å¤ç­–ç•¥ï¼Œå‡å°‘å¯¹fallbackçš„ä¾èµ–
                    repair_attempts = [
                        ("è½»é‡ä¿®å¤", lambda x: self._lightweight_json_repair(x)),
                        ("æ¿€è¿›ä¿®å¤", lambda x: self._aggressive_json_fix(x)),
                        ("ç»“æ„é‡å»º", lambda x: self._reconstruct_json_structure(x)),
                        ("å¥å£®å­—æ®µæå–", lambda x: self._robust_extract_fields(response)),  # æ–°å¢å¥å£®æå–å™¨
                    ]
                    
                    for repair_name, repair_func in repair_attempts:
                        try:
                            if repair_name == "å¥å£®å­—æ®µæå–":
                                # å¥å£®å­—æ®µæå–å™¨ç›´æ¥è¿”å›ç»“æœå­—å…¸
                                result = repair_func(json_text)
                                if result and result.get('action') != 'error':
                                    logger.info(f"âœ… ä½¿ç”¨{repair_name}æˆåŠŸæå–å­—æ®µ")
                                    return result
                            else:
                                # å…¶ä»–ä¿®å¤å™¨è¿”å›ä¿®å¤åçš„JSONå­—ç¬¦ä¸²
                                fixed_json = repair_func(json_text)
                                if fixed_json and fixed_json != json_text:
                                    parsed = json.loads(fixed_json)
                                    result = self._validate_and_complete_parsed_response(parsed)
                                    logger.info(f"âœ… ä½¿ç”¨{repair_name}æˆåŠŸè§£æJSON")
                                    return result
                        except json.JSONDecodeError as e:
                            logger.debug(f"âš ï¸ {repair_name}å¤±è´¥: {e}")
                            continue
                        except Exception as e:
                            logger.debug(f"âš ï¸ {repair_name}å¼‚å¸¸: {e}")
                            continue
                    
                    # å¦‚æœæ‰€æœ‰ä¿®å¤éƒ½å¤±è´¥ï¼Œæœ€åå°è¯•ä»åŸå§‹å“åº”ä¸­æ™ºèƒ½æå–
                    logger.warning("ğŸ”„ å°è¯•ä»åŸå§‹å“åº”æ™ºèƒ½æå–å­—æ®µ")
                    smart_extracted = self._smart_extract_from_response(response)
                    if smart_extracted and smart_extracted.get('action') != 'error':
                        logger.info("âœ… æ™ºèƒ½æå–æˆåŠŸï¼Œé¿å…ä½¿ç”¨fallback")
                        return smart_extracted
            
        except Exception as e:
            logger.error(f"âŒ å“åº”è§£æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        
        # ğŸ” å¢å¼ºçš„å¤‡ç”¨è§£ææ–¹æ³•
        logger.warning("ğŸ”„ ä½¿ç”¨å¤‡ç”¨è§£ææ–¹æ³•")
        return self._fallback_parse_response(response)
    
    def _validate_and_complete_parsed_response(self, parsed: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯å¹¶è¡¥å…¨è§£æåçš„å“åº”"""
        result = {}
        
        # è¡¥å…¨thinkingå­—æ®µ
        result['thinking'] = parsed.get('thinking', f"LLMå“åº”ç¼ºå°‘thinkingå­—æ®µ: {str(parsed)[:200]}")
        
        # è¡¥å…¨å¹¶éªŒè¯actionå­—æ®µ
        action = parsed.get('action', 'error')
        
        # è¡¥å…¨å¹¶éªŒè¯tool_idå­—æ®µ - å…ˆæ¨æ–­tool_idï¼Œå†éªŒè¯action
        tool_id = parsed.get('tool_id') or parsed.get('tool')
        
        # ğŸ” æ™ºèƒ½æ¨æ–­å·¥å…·IDï¼ˆä¼˜å…ˆä½¿ç”¨ç°æœ‰ä¸“ä¸šå·¥å…·ï¼‰
        if not tool_id:
            # ä½¿ç”¨æ™ºèƒ½æ˜ å°„ - ä¼˜å…ˆåŸºäºactionæ¨æ–­
            action_to_tool_mapping = {
                'research': 'mcp-deepsearch',
                'quick_research': 'mcp-deepsearch', 
                'comprehensive_research': 'mcp-deepsearch',
                'microsandbox_execute': 'microsandbox-mcp-server',
                'microsandbox_install_package': 'microsandbox-mcp-server',
                # ğŸ”§ P0ç´§æ€¥ä¿®å¤1: ä¿®æ­£browseråŠ¨ä½œæ˜ å°„ä¸ºå®é™…å­˜åœ¨çš„åŠ¨ä½œ
                'browser_navigate': 'browser-use-mcp-server',
                'browser_use_execute_task': 'browser-use-mcp-server',
                'browser_click_element': 'browser-use-mcp-server',
                'browser_input_text': 'browser-use-mcp-server',
                'browser_extract_content': 'browser-use-mcp-server',
                'browser_search_google': 'browser-use-mcp-server',
                'search_and_install_tools': 'mcp-search-tool',
                'analyze_tool_needs': 'mcp-search-tool',
                'search_file_content': 'mcp-search-tool',
                'list_code_definitions': 'mcp-search-tool'
            }
            
            if action in action_to_tool_mapping:
                tool_id = action_to_tool_mapping[action]
                logger.debug(f"è‡ªåŠ¨æ¨æ–­å·¥å…·ID: {tool_id} (åŸºäºaction: {action})")
            elif any(keyword in result['thinking'].lower() for keyword in ['deepsearch', 'ç ”ç©¶', 'research']):
                tool_id = 'mcp-deepsearch'
                logger.debug(f"åŸºäºthinkingå†…å®¹æ¨æ–­å·¥å…·ID: {tool_id} (ç ”ç©¶ç±»ä»»åŠ¡)")
            elif any(keyword in result['thinking'].lower() for keyword in ['microsandbox', 'ä»£ç ', 'code', 'python']):
                tool_id = 'microsandbox-mcp-server' 
                logger.debug(f"åŸºäºthinkingå†…å®¹æ¨æ–­å·¥å…·ID: {tool_id} (ä»£ç æ‰§è¡Œ)")
            elif any(keyword in result['thinking'].lower() for keyword in ['browser', 'æµè§ˆ', 'ç½‘é¡µ']):
                tool_id = 'browser-use-mcp-server'
                logger.debug(f"åŸºäºthinkingå†…å®¹æ¨æ–­å·¥å…·ID: {tool_id} (ç½‘é¡µæµè§ˆ)")
            elif 'search' in result['thinking'].lower() and 'install' in result['thinking'].lower():
                tool_id = 'mcp-search-tool'
                logger.debug(f"åŸºäºthinkingå†…å®¹æ¨æ–­å·¥å…·ID: {tool_id} (å·¥å…·æœç´¢)")
        
        # ç°åœ¨ä½¿ç”¨æ­£ç¡®æ¨æ–­çš„tool_idæ¥éªŒè¯action
        action = self._validate_and_correct_action(action, tool_id)
        result['action'] = action
        result['tool_id'] = tool_id
        result['tool'] = tool_id  # å‘åå…¼å®¹
        
        # è¡¥å…¨parameterså­—æ®µ
        parameters = parsed.get('parameters', {})
        
        # ğŸ” åŸºäºactionæ™ºèƒ½è¡¥å…¨å‚æ•°
        if action in ['search_and_install_tools', 'analyze_tool_needs'] and not parameters.get('task_description'):
            # ä»thinkingä¸­æå–ä»»åŠ¡æè¿°
            thinking = result['thinking']
            if 'TASK ANALYSIS:' in thinking:
                task_desc_start = thinking.find('TASK ANALYSIS:') + len('TASK ANALYSIS:')
                task_desc_end = thinking.find('STEP 2', task_desc_start)
                if task_desc_end > task_desc_start:
                    task_desc = thinking[task_desc_start:task_desc_end].strip()
                    parameters['task_description'] = task_desc[:200]  # é™åˆ¶é•¿åº¦
        
        result['parameters'] = parameters
        
        # è¡¥å…¨å¹¶éªŒè¯confidenceå­—æ®µ
        confidence = parsed.get('confidence', 0.5)
        if not isinstance(confidence, (int, float)) or confidence < 0 or confidence > 1:
            confidence = 0.5
        result['confidence'] = confidence
        
        return result
    
    def _fallback_parse_response(self, response: str) -> Dict[str, Any]:
        """å¢å¼ºçš„å¤‡ç”¨è§£ææ–¹æ³• - ä¼˜åŒ–ç‰ˆæœ¬"""
        logger.info("ğŸ”„ æ‰§è¡Œå¢å¼ºå¤‡ç”¨è§£æ")
        
        # æ™ºèƒ½æˆªæ–­é•¿å“åº”ï¼Œä¼˜å…ˆä¿ç•™JSONç»“æ„
        if len(response) > 8000:
            logger.warning(f"âš ï¸ å“åº”è¿‡é•¿({len(response)}å­—ç¬¦)ï¼Œè¿›è¡Œæ™ºèƒ½æˆªæ–­")
            response = self._smart_truncate_response(response, 8000)
        
        # ğŸ” å¢å¼ºçš„å­—æ®µæå–
        result = {
            'thinking': self._extract_thinking_field(response),
            'action': self._extract_action_field(response),
            'tool_id': self._extract_tool_id_field(response),
            'parameters': self._extract_parameters_field(response),
            'confidence': self._extract_confidence_field(response)
        }
        
        # ğŸ” éªŒè¯å’Œçº æ­£action
        # éªŒè¯å’Œçº æ­£action
        result['action'] = self._validate_and_correct_action(result['action'], result['tool_id'])
        
        # ğŸ” æ™ºèƒ½æ¨æ–­å’Œä¿®æ­£
        result = self._smart_inference_and_correction(result, response)
        
        # å‘åå…¼å®¹
        result['tool'] = result['tool_id']
        
        logger.debug(f"å¤‡ç”¨è§£æç»“æœ: action={result['action']}, tool_id={result['tool_id']}")
        return result
    
    def _extract_thinking_field(self, response: str) -> str:
        """æå–thinkingå­—æ®µ"""
        patterns = [
            r'"thinking":\s*"([^"]*(?:\\.[^"]*)*)"',
            r'thinking["\']?\s*[:=]\s*["\']([^"\']*)["\']',
            r'STEP 1[^:]*:([^"]*?)(?:STEP 2|$)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, response, re.DOTALL | re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œè¿”å›å“åº”çš„å‰500å­—ç¬¦
        return response[:500]
    
    def _extract_action_field(self, response: str) -> str:
        """æå–actionå­—æ®µ"""
        patterns = [
            r'"action":\s*"([^"]+)"',
            r'action["\']?\s*[:=]\s*["\']([^"\']+)["\']',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, response, re.IGNORECASE)
            if match:
                return match.group(1)
        
        # ğŸ” åŸºäºä»»åŠ¡å†…å®¹æ™ºèƒ½æ¨æ–­actionï¼ˆä¼˜å…ˆä½¿ç”¨ç°æœ‰å·¥å…·ï¼‰
        response_lower = response.lower()
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç‰¹å®šå·¥å…·çš„æ˜ç¡®è°ƒç”¨
        if any(keyword in response_lower for keyword in ['deepsearch', 'ç ”ç©¶', 'research']):
            return 'research'
        elif any(keyword in response_lower for keyword in ['microsandbox', 'ä»£ç ', 'code', 'python', 'æ‰§è¡Œ']):
            return 'microsandbox_execute'  
        elif any(keyword in response_lower for keyword in ['browser', 'æµè§ˆ', 'ç½‘é¡µ', 'navigate']):
            return 'browser_navigate'
        elif any(keyword in response_lower for keyword in ['complete', 'finish', 'done']):
            return 'complete_task'
        # åªåœ¨çœŸæ­£éœ€è¦æœç´¢æ–°å·¥å…·æ—¶æ‰ä½¿ç”¨æœç´¢åŠ¨ä½œ
        elif any(keyword in response_lower for keyword in ['analyze', 'need']) and 'install' not in response_lower:
            return 'analyze_tool_needs'
        elif 'install' in response_lower and 'search' in response_lower:
            return 'search_and_install_tools'
        
        return 'error'
    
    def _extract_tool_id_field(self, response: str) -> Optional[str]:
        """æå–tool_idå­—æ®µ"""
        patterns = [
            r'"tool_id":\s*"([^"]+)"',
            r'"tool":\s*"([^"]+)"',
            r'tool_id["\']?\s*[:=]\s*["\']([^"\']+)["\']',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, response, re.IGNORECASE)
            if match:
                return match.group(1)
        
        return None
    
    def _extract_parameters_field(self, response: str) -> Dict[str, Any]:
        """æå–parameterså­—æ®µ"""
        
        # å°è¯•æå–å®Œæ•´çš„parameterså¯¹è±¡
        params_match = re.search(r'"parameters":\s*(\{[^}]*\})', response, re.DOTALL)
        if params_match:
            try:
                return json.loads(params_match.group(1))
            except:
                pass
        
        # å¤‡ç”¨æ–¹æ¡ˆï¼šæå–å¸¸è§å‚æ•°
        params = {}
        
        # æå–task_description
        task_desc_patterns = [
            r'"task_description":\s*"([^"]*)"',
            r'task_description["\']?\s*[:=]\s*["\']([^"\']*)["\']',
        ]
        
        for pattern in task_desc_patterns:
            match = re.search(pattern, response, re.IGNORECASE)
            if match:
                params['task_description'] = match.group(1)
                break
        
        return params
    
    def _extract_confidence_field(self, response: str) -> float:
        """æå–confidenceå­—æ®µ"""
        
        patterns = [
            r'"confidence":\s*([0-9.]+)',
            r'confidence["\']?\s*[:=]\s*([0-9.]+)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, response, re.IGNORECASE)
            if match:
                try:
                    confidence = float(match.group(1))
                    return max(0.0, min(1.0, confidence))
                except:
                    pass
        
        return 0.5
    
    def _smart_inference_and_correction(self, result: Dict[str, Any], response: str) -> Dict[str, Any]:
        """
        ğŸ”§ ã€æ ¸å¿ƒä¿®å¤ã€‘æ™ºèƒ½æ¨æ–­å’Œä¿®æ­£ç»“æœ - ä½¿ç”¨ç»Ÿä¸€å·¥å…·ç®¡ç†å™¨
        
        è§£å†³å·¥å…·IDæ˜ å°„ä¸ä¸€è‡´çš„å…³é”®æ–¹æ³•ï¼š
        - ä½¿ç”¨ç»Ÿä¸€å·¥å…·ç®¡ç†å™¨è·å–æ ‡å‡†å·¥å…·ID
        - åŠ¨æ€ç”ŸæˆåŠ¨ä½œåˆ°å·¥å…·çš„æ˜ å°„å…³ç³»
        - é¿å…ç¡¬ç¼–ç æ—§ç‰ˆå·¥å…·ID
        """
        
        # é™åˆ¶æ–‡æœ¬é•¿åº¦ï¼Œæé«˜æ€§èƒ½
        response_sample = response[:1000].lower()  # åªæ£€æŸ¥å‰1000å­—ç¬¦
        
        # ğŸŒŸ ã€å…³é”®ä¿®å¤ã€‘ä½¿ç”¨ç»Ÿä¸€å·¥å…·ç®¡ç†å™¨åŠ¨æ€æ„å»ºæ˜ å°„
        tool_manager = get_tool_manager()
        
        # æ„å»ºåŠ¨ä½œåˆ°æ ‡å‡†å·¥å…·IDçš„æ˜ å°„ï¼ˆä½¿ç”¨ç»Ÿä¸€å·¥å…·ç®¡ç†å™¨ç¡®ä¿ä¸€è‡´æ€§ï¼‰
        action_to_tool_mapping = {}
        try:
            # DeepSearchå·¥å…·çš„åŠ¨ä½œæ˜ å°„
            deepsearch_id = tool_manager.get_standard_id('deepsearch')
            for action in ['research', 'quick_research', 'comprehensive_research']:
                action_to_tool_mapping[action] = deepsearch_id
            
            # MicroSandboxå·¥å…·çš„åŠ¨ä½œæ˜ å°„
            microsandbox_id = tool_manager.get_standard_id('microsandbox')
            microsandbox_actions = tool_manager.get_tool_actions(microsandbox_id)
            for action in microsandbox_actions:
                action_to_tool_mapping[action] = microsandbox_id
            
            # Browser Useå·¥å…·çš„åŠ¨ä½œæ˜ å°„
            browser_id = tool_manager.get_standard_id('browser_use')
            browser_actions = tool_manager.get_tool_actions(browser_id)
            for action in browser_actions:
                action_to_tool_mapping[action] = browser_id
            
            # Search Toolå·¥å…·çš„åŠ¨ä½œæ˜ å°„
            search_id = tool_manager.get_standard_id('mcp-search-tool')
            search_actions = tool_manager.get_tool_actions(search_id)
            for action in search_actions:
                action_to_tool_mapping[action] = search_id
                
            logger.debug(f"ğŸ”§ åŠ¨æ€æ„å»ºåŠ¨ä½œæ˜ å°„: {len(action_to_tool_mapping)} ä¸ªåŠ¨ä½œ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ æ„å»ºåŠ¨ä½œæ˜ å°„å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ˜ å°„: {e}")
            # å¤‡ç”¨æ˜ å°„ï¼ˆä½¿ç”¨æ ‡å‡†IDï¼‰
            action_to_tool_mapping = {
                'research': 'deepsearch',
                'quick_research': 'deepsearch', 
                'comprehensive_research': 'deepsearch',
                'microsandbox_execute': 'microsandbox',
                'microsandbox_install_package': 'microsandbox',
                'browser_navigate': 'browser_use',
                'browser_extract_content': 'browser_use',
                'browser_click_element': 'browser_use',
                'search_and_install_tools': 'mcp-search-tool',
                'analyze_tool_needs': 'mcp-search-tool'
            }
        
        # å¦‚æœæ²¡æœ‰tool_idï¼ŒåŸºäºactionæ™ºèƒ½æ¨æ–­
        if not result['tool_id'] and result['action'] in action_to_tool_mapping:
            result['tool_id'] = action_to_tool_mapping[result['action']]
            logger.debug(f"ğŸ¯ åŸºäºaction({result['action']})æ™ºèƒ½æ¨æ–­æ ‡å‡†tool_id: {result['tool_id']}")
        
        # ğŸ”§ ã€å…³é”®ä¿®å¤ã€‘å¦‚æœactionæ˜¯errorï¼ŒåŸºäºå“åº”å†…å®¹æ™ºèƒ½æ¨æ–­å·¥å…·å’ŒåŠ¨ä½œï¼ˆä½¿ç”¨æ ‡å‡†IDï¼‰
        if result['action'] == 'error':
            try:
                if any(keyword in response_sample for keyword in ['deepsearch', 'ç ”ç©¶', 'research']):
                    result['action'] = 'research'
                    result['tool_id'] = tool_manager.get_standard_id('deepsearch')
                    logger.debug(f"ğŸ”§ ä¿®æ­£ä¸ºä½¿ç”¨æ ‡å‡†å·¥å…·è¿›è¡Œç ”ç©¶: {result['tool_id']}")
                elif any(keyword in response_sample for keyword in ['microsandbox', 'ä»£ç ', 'code', 'python', 'æ‰§è¡Œ']):
                    result['action'] = 'microsandbox_execute'
                    result['tool_id'] = tool_manager.get_standard_id('microsandbox')
                    logger.debug(f"ğŸ”§ ä¿®æ­£ä¸ºä½¿ç”¨æ ‡å‡†å·¥å…·æ‰§è¡Œä»£ç : {result['tool_id']}")
                elif any(keyword in response_sample for keyword in ['browser', 'æµè§ˆ', 'ç½‘é¡µ', 'navigate']):
                    result['action'] = 'browser_navigate'
                    result['tool_id'] = tool_manager.get_standard_id('browser_use')
                    logger.debug(f"ğŸ”§ ä¿®æ­£ä¸ºä½¿ç”¨æ ‡å‡†å·¥å…·æµè§ˆç½‘é¡µ: {result['tool_id']}")
                elif any(keyword in response_sample for keyword in ['mcp-search', 'search_and_install', 'tool']) and 'install' in response_sample:
                    result['action'] = 'search_and_install_tools'
                    result['tool_id'] = tool_manager.get_standard_id('mcp-search-tool')
                    logger.debug(f"ğŸ”§ ä¿®æ­£ä¸ºä½¿ç”¨æ ‡å‡†å·¥å…·æœç´¢: {result['tool_id']}")
            except Exception as e:
                logger.warning(f"âš ï¸ æ™ºèƒ½ä¿®æ­£å¤±è´¥ï¼Œä¿æŒåŸå§‹ç»“æœ: {e}")
        
        # å¦‚æœparametersä¸ºç©ºä½†actionéœ€è¦å‚æ•°ï¼Œå°è¯•ç”Ÿæˆ
        if not result['parameters'] and result['action'] in ['search_and_install_tools', 'analyze_tool_needs']:
            # ä»thinkingä¸­æå–ä»»åŠ¡ç›¸å…³ä¿¡æ¯ï¼ˆé™åˆ¶å¤„ç†é•¿åº¦ï¼‰
            thinking = result['thinking'][:500]  # åªå¤„ç†å‰500å­—ç¬¦
            params = {}
            
            if 'ä»»åŠ¡' in thinking or 'task' in thinking.lower():
                # æå–å¯èƒ½çš„ä»»åŠ¡æè¿°
                lines = thinking.split('\n')[:10]  # æœ€å¤šæ£€æŸ¥10è¡Œ
                for line in lines:
                    if 'ä»»åŠ¡' in line or 'task' in line.lower():
                        # ç®€åŒ–çš„ä»»åŠ¡æè¿°æå–
                        task_desc = line.strip()[:100]
                        params['task_description'] = task_desc
                        break
            
            if params:
                result['parameters'] = params
                logger.info(f"ğŸ”§ ç”Ÿæˆå‚æ•°: {params}")
        
        return result
    
    def _fix_json_formatting_errors(self, json_text: str) -> str:
        """ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é”™è¯¯ - å¢å¼ºç‰ˆæœ¬"""
        # ğŸ”§ æ–°å¢ï¼šä¿®å¤ä¸­æ–‡æ ‡ç‚¹ç¬¦å·é—®é¢˜ - è§£å†³ "Expecting ':' delimiter" é”™è¯¯
        json_text = self._fix_chinese_punctuation(json_text)
        
        # ä¿®å¤æœªç»ˆæ­¢çš„å­—ç¬¦ä¸² - å¤„ç†"Unterminated string"é”™è¯¯
        json_text = self._fix_unterminated_strings(json_text)
        
        # ä¿®å¤ç¼ºå¤±å­—æ®µå¯¼è‡´çš„è¿ç»­é€—å·é—®é¢˜
        json_text = self._fix_missing_fields(json_text)
        
        # ğŸ”§ ä¿®å¤æ—¥å¿—ä¸­å‘ç°çš„å…·ä½“é”™è¯¯æ¨¡å¼
        
        # 1. ä¿®å¤ "Expecting ':' delimiter" é”™è¯¯
        json_text = self._fix_missing_colons(json_text)
        
        # 2. ä¿®å¤ "Expecting ',' delimiter" é”™è¯¯ 
        json_text = self._fix_missing_commas(json_text)
        
        # 3. ä¿®å¤ "Expecting property name enclosed in double quotes" é”™è¯¯
        json_text = self._fix_property_names(json_text)
        
        # 4. ä¿®å¤ "Extra data" é”™è¯¯
        json_text = self._fix_extra_data(json_text)
        
        # ä¿®å¤å¸¸è§çš„é€—å·é”™è¯¯
        json_text = re.sub(r',\s*}', '}', json_text)  # ç§»é™¤å¯¹è±¡æœ€åçš„é€—å·
        json_text = re.sub(r',\s*]', ']', json_text)  # ç§»é™¤æ•°ç»„æœ€åçš„é€—å·
        
        # ä¿®å¤ç¼ºå°‘é€—å·çš„æƒ…å†µ
        json_text = re.sub(r'"\s*\n\s*"', '",\n"', json_text)  # å­—ç¬¦ä¸²ä¹‹é—´ç¼ºå°‘é€—å·
        json_text = re.sub(r'}\s*\n\s*"', '},\n"', json_text)  # å¯¹è±¡åç¼ºå°‘é€—å·
        
        # ä¿®å¤å¼•å·é—®é¢˜
        json_text = re.sub(r"'([^']*)':", r'"\1":', json_text)  # å•å¼•å·æ›¿æ¢ä¸ºåŒå¼•å·
        
        # ä¿®å¤å¸ƒå°”å€¼å’Œnull
        json_text = re.sub(r'\bTrue\b', 'true', json_text)
        json_text = re.sub(r'\bFalse\b', 'false', json_text)
        json_text = re.sub(r'\bNone\b', 'null', json_text)
        
        return json_text
    
    def _fix_control_characters(self, json_text: str) -> str:
        """ä¿®å¤JSONä¸­çš„æ§åˆ¶å­—ç¬¦é—®é¢˜ - å…³é”®ä¿®å¤æ–¹æ³•"""
        try:
            # ç§»é™¤æˆ–è½¬ä¹‰å¸¸è§çš„æ§åˆ¶å­—ç¬¦
            control_char_fixes = {
                '\b': '\\b',    # é€€æ ¼ç¬¦
                '\f': '\\f',    # æ¢é¡µç¬¦  
                '\r': '\\r',    # å›è½¦ç¬¦
                '\t': '\\t',    # åˆ¶è¡¨ç¬¦
                '\v': '\\v',    # å‚ç›´åˆ¶è¡¨ç¬¦
                '\0': '',       # ç©ºå­—ç¬¦ï¼Œç›´æ¥ç§»é™¤
            }
            
            for char, replacement in control_char_fixes.items():
                json_text = json_text.replace(char, replacement)
            
            # ç§»é™¤å…¶ä»–ASCIIæ§åˆ¶å­—ç¬¦ (0-31, é™¤äº†å·²å¤„ç†çš„)
            import re
            # ä¿ç•™å¿…è¦çš„æ§åˆ¶å­—ç¬¦ï¼š\n (10), \r (13), \t (9)
            # ç§»é™¤å…¶ä»–æ§åˆ¶å­—ç¬¦
            json_text = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', json_text)
            
            # ä¿®å¤Unicodeæ§åˆ¶å­—ç¬¦
            # ç§»é™¤å¸¸è§çš„Unicodeæ§åˆ¶å­—ç¬¦
            unicode_control_chars = [
                '\u0000', '\u0001', '\u0002', '\u0003', '\u0004', '\u0005', '\u0006', '\u0007',
                '\u0008', '\u000B', '\u000C', '\u000E', '\u000F', '\u0010', '\u0011', '\u0012',
                '\u0013', '\u0014', '\u0015', '\u0016', '\u0017', '\u0018', '\u0019', '\u001A',
                '\u001B', '\u001C', '\u001D', '\u001E', '\u001F', '\u007F'
            ]
            
            for char in unicode_control_chars:
                json_text = json_text.replace(char, '')
            
            # ä¿®å¤ç‰¹å®šçš„æ§åˆ¶å­—ç¬¦é”™è¯¯æ¨¡å¼ï¼ˆåŸºäºæ—¥å¿—ä¸­çš„é”™è¯¯ï¼‰
            # "Invalid control character at: line X column Y"
            
            # 1. ä¿®å¤è¡Œå°¾çš„æ§åˆ¶å­—ç¬¦
            json_text = re.sub(r'[\x00-\x1F]+$', '', json_text, flags=re.MULTILINE)
            
            # 2. ä¿®å¤å­—ç¬¦ä¸²å€¼ä¸­çš„æ§åˆ¶å­—ç¬¦
            def fix_string_control_chars(match):
                content = match.group(1)
                # è½¬ä¹‰æˆ–ç§»é™¤å­—ç¬¦ä¸²ä¸­çš„æ§åˆ¶å­—ç¬¦
                content = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', content)
                # ç¡®ä¿æ¢è¡Œç¬¦æ­£ç¡®è½¬ä¹‰
                content = content.replace('\n', '\\n').replace('\r', '\\r').replace('\t', '\\t')
                return f'": "{content}"'
            
            # ä¿®å¤å­—ç¬¦ä¸²å€¼ä¸­çš„æ§åˆ¶å­—ç¬¦
            json_text = re.sub(r'": "([^"]*)"', fix_string_control_chars, json_text)
            
            # 3. ä¿®å¤JSONç»“æ„ä¸­çš„æ§åˆ¶å­—ç¬¦ï¼ˆåœ¨é”®åå’Œæ ‡ç‚¹ç¬¦å·é™„è¿‘ï¼‰
            json_text = re.sub(r'([\{\[,:])\s*[\x00-\x1F]+\s*', r'\1 ', json_text)
            json_text = re.sub(r'\s*[\x00-\x1F]+\s*([\}\],:])', r' \1', json_text)
            
            logger.debug("å·²ä¿®å¤JSONæ§åˆ¶å­—ç¬¦")
            return json_text
            
        except Exception as e:
            logger.warning(f"ä¿®å¤æ§åˆ¶å­—ç¬¦æ—¶å‡ºé”™: {e}")
            return json_text
    
    def _fix_chinese_punctuation(self, json_text: str) -> str:
        """ä¿®å¤ä¸­æ–‡æ ‡ç‚¹ç¬¦å·é—®é¢˜ - å…³é”®ä¿®å¤æ–¹æ³•"""
        try:
            # ä¿®å¤ä¸­æ–‡å†’å· "ï¼š" -> ":"
            json_text = json_text.replace('ï¼š', ':')
            
            # ä¿®å¤ä¸­æ–‡é€—å· "ï¼Œ" -> ","  
            json_text = json_text.replace('ï¼Œ', ',')
            
            # ä¿®å¤ä¸­æ–‡å¼•å· """ -> '"' å’Œ """ -> '"'
            json_text = json_text.replace('"', '"').replace('"', '"')
            
            # ä¿®å¤ä¸­æ–‡å•å¼•å· "'" -> "'" å’Œ "'" -> "'"
            json_text = json_text.replace(''', "'").replace(''', "'")
            
            # ä¿®å¤ä¸­æ–‡å¥å·ï¼ˆå¦‚æœå‡ºç°åœ¨JSONä¸­ï¼‰"ã€‚" -> "."
            json_text = json_text.replace('ã€‚', '.')
            
            # ä¿®å¤ä¸­æ–‡åˆ†å· "ï¼›" -> ";"
            json_text = json_text.replace('ï¼›', ';')
            
            # å¢å¼ºä¿®å¤ï¼šå¤„ç†æ›´å¤šè¾¹ç•Œæƒ…å†µ
            # ä¿®å¤å±æ€§ååçš„ä¸­æ–‡å†’å·
            json_text = re.sub(r'(["\'])(\s*)ï¼š(\s*)', r'\1\2:\3', json_text)
            
            # ä¿®å¤å€¼åçš„ä¸­æ–‡é€—å·
            json_text = re.sub(r'(["\'\d}])(\s*)ï¼Œ(\s*)', r'\1\2,\3', json_text)
            
            # ä¿®å¤æ··åˆä¸­è‹±æ–‡æ ‡ç‚¹çš„æƒ…å†µ
            json_text = re.sub(r'([a-zA-Z0-9_])(\s*)ï¼š(\s*)', r'\1\2:\3', json_text)
            
            logger.debug("å·²ä¿®å¤ä¸­æ–‡æ ‡ç‚¹ç¬¦å·")
            return json_text
            
        except Exception as e:
            logger.warning(f"ä¿®å¤ä¸­æ–‡æ ‡ç‚¹ç¬¦å·æ—¶å‡ºé”™: {e}")
            return json_text
    
    def _fix_missing_fields(self, json_text: str) -> str:
        """ä¿®å¤ç¼ºå¤±å­—æ®µå¯¼è‡´çš„JSONé”™è¯¯"""
        try:
            # ä¿®å¤è¿ç»­é€—å·é—®é¢˜ï¼ˆç¼ºå¤±å­—æ®µå¯¼è‡´ï¼‰
            json_text = re.sub(r',\s*,', ',', json_text)  # ç§»é™¤è¿ç»­é€—å·
            
            # ä¿®å¤ä»¥é€—å·å¼€å¤´çš„è¡Œï¼ˆç¼ºå¤±å­—æ®µå¯¼è‡´ï¼‰
            lines = json_text.split('\n')
            fixed_lines = []
            
            for i, line in enumerate(lines):
                stripped = line.strip()
                
                # å¦‚æœè¡Œä»¥é€—å·å¼€å¤´ï¼Œè¯´æ˜ä¸Šä¸€è¡Œç¼ºå¤±äº†å­—æ®µ
                if stripped.startswith(','):
                    # æ·»åŠ ä¸€ä¸ªå ä½å­—æ®µ
                    if i > 0 and not fixed_lines[-1].strip().endswith('{'):
                        # æ ¹æ®ä¸Šä¸‹æ–‡æ¨æ–­å¯èƒ½ç¼ºå¤±çš„å­—æ®µ
                        if 'content_identifier' in json_text and '"content_identifier"' not in fixed_lines[-1]:
                            fixed_lines[-1] = fixed_lines[-1].rstrip().rstrip(',') + ','
                            fixed_lines.append('            "content_identifier": "unknown"')
                        elif 'relationship' in json_text and '"relationship"' not in fixed_lines[-1]:
                            fixed_lines[-1] = fixed_lines[-1].rstrip().rstrip(',') + ','
                            fixed_lines.append('            "relationship": "unknown"')
                        else:
                            # é€šç”¨å ä½å­—æ®µ
                            fixed_lines[-1] = fixed_lines[-1].rstrip().rstrip(',') + ','
                            fixed_lines.append('            "missing_field": "placeholder"')
                    
                    # ç§»é™¤å¼€å¤´çš„é€—å·
                    line = line.lstrip().lstrip(',').lstrip()
                    if line:
                        fixed_lines.append('            ' + line)
                else:
                    fixed_lines.append(line)
            
            result = '\n'.join(fixed_lines)
            
            # æœ€åæ¸…ç†å¤šä½™çš„é€—å·å’Œç©ºè¡Œ
            result = re.sub(r',\s*\n\s*,', ',', result)
            result = re.sub(r'\n\s*\n', '\n', result)
            
            return result
            
        except Exception as e:
            logger.warning(f"âš ï¸ ä¿®å¤ç¼ºå¤±å­—æ®µæ—¶å‡ºé”™: {e}")
            return json_text
    
    def _fix_missing_colons(self, json_text: str) -> str:
        """ä¿®å¤ç¼ºå¤±å†’å·çš„é”™è¯¯"""
        try:
            # ä¿®å¤å±æ€§ååç¼ºå¤±å†’å·çš„æƒ…å†µï¼š"key" "value" -> "key": "value"
            json_text = re.sub(r'("[^"]*")\s+("[^"]*")', r'\1: \2', json_text)
            
            # ä¿®å¤å±æ€§ååæœ‰ç­‰å·è€Œä¸æ˜¯å†’å·çš„æƒ…å†µï¼š"key" = "value" -> "key": "value"
            json_text = re.sub(r'("[^"]*")\s*=\s*', r'\1: ', json_text)
            
            return json_text
        except Exception as e:
            logger.warning(f"ä¿®å¤ç¼ºå¤±å†’å·æ—¶å‡ºé”™: {e}")
            return json_text
    
    def _fix_missing_commas(self, json_text: str) -> str:
        """ä¿®å¤ç¼ºå¤±é€—å·çš„é”™è¯¯"""
        try:
            # ä¿®å¤å¯¹è±¡å±æ€§ä¹‹é—´ç¼ºå¤±é€—å·ï¼š}"key" -> },"key"
            json_text = re.sub(r'}\s*"', '},"', json_text)
            
            # ä¿®å¤å­—ç¬¦ä¸²ä¹‹é—´ç¼ºå¤±é€—å·ï¼š"value1" "key2" -> "value1", "key2"
            json_text = re.sub(r'("(?:[^"\\]|\\.)*")\s+("(?:[^"\\]|\\.)*"\s*:)', r'\1, \2', json_text)
            
            # ä¿®å¤æ•°å€¼åç¼ºå¤±é€—å·ï¼š123 "key" -> 123, "key"
            json_text = re.sub(r'(\d+)\s+("[^"]*"\s*:)', r'\1, \2', json_text)
            
            return json_text
        except Exception as e:
            logger.warning(f"ä¿®å¤ç¼ºå¤±é€—å·æ—¶å‡ºé”™: {e}")
            return json_text
    
    def _fix_property_names(self, json_text: str) -> str:
        """ä¿®å¤å±æ€§åæœªåŠ å¼•å·çš„é”™è¯¯"""
        try:
            # ä¿®å¤æœªå¼•ç”¨çš„å±æ€§åï¼škey: "value" -> "key": "value"
            json_text = re.sub(r'(\n\s*)([a-zA-Z_][a-zA-Z0-9_]*)\s*:', r'\1"\2":', json_text)
            
            # ä¿®å¤å¼€å¤´çš„æœªå¼•ç”¨å±æ€§å
            json_text = re.sub(r'^(\s*)([a-zA-Z_][a-zA-Z0-9_]*)\s*:', r'\1"\2":', json_text, flags=re.MULTILINE)
            
            return json_text
        except Exception as e:
            logger.warning(f"ä¿®å¤å±æ€§åæ—¶å‡ºé”™: {e}")
            return json_text
    
    def _fix_extra_data(self, json_text: str) -> str:
        """ä¿®å¤JSONåæœ‰é¢å¤–æ•°æ®çš„é”™è¯¯"""
        try:
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡å¹¶æˆªæ–­å…¶åçš„å†…å®¹
            depth = 0
            in_string = False
            escape_next = False
            end_pos = -1
            
            for i, char in enumerate(json_text):
                if escape_next:
                    escape_next = False
                    continue
                    
                if char == '\\':
                    escape_next = True
                    continue
                    
                if char == '"':
                    in_string = not in_string
                    continue
                    
                if in_string:
                    continue
                    
                if char == '{':
                    depth += 1
                elif char == '}':
                    depth -= 1
                    if depth == 0:
                        end_pos = i + 1
                        break
            
            if end_pos > 0:
                json_text = json_text[:end_pos]
            
            return json_text
        except Exception as e:
            logger.warning(f"ä¿®å¤é¢å¤–æ•°æ®æ—¶å‡ºé”™: {e}")
            return json_text
    
    def _fix_delimiter_errors(self, json_text: str) -> str:
        """ä¿®å¤åˆ†éš”ç¬¦é”™è¯¯"""
        try:
            # è¿™ä¸ªå‡½æ•°å¯èƒ½ä¹‹å‰ç¼ºå¤±ï¼Œæ·»åŠ åŸºæœ¬å®ç°
            # ä¿®å¤åˆ†å·ä»£æ›¿é€—å·çš„æƒ…å†µ
            json_text = re.sub(r'("[^"]*")\s*;\s*("[^"]*")', r'\1, \2', json_text)
            
            # ä¿®å¤å…¶ä»–å¸¸è§åˆ†éš”ç¬¦é”™è¯¯
            json_text = re.sub(r'("[^"]*")\s*\|\s*("[^"]*")', r'\1, \2', json_text)
            
            return json_text
        except Exception as e:
            logger.warning(f"ä¿®å¤åˆ†éš”ç¬¦é”™è¯¯æ—¶å‡ºé”™: {e}")
            return json_text
    
    def _fix_unterminated_strings(self, json_text: str) -> str:
        """ä¿®å¤æœªç»ˆæ­¢çš„å­—ç¬¦ä¸²é”™è¯¯"""
        try:
            # å¤„ç†å­—ç¬¦ä¸²ä¸­çš„æœªè½¬ä¹‰æ¢è¡Œç¬¦
            # å°†å­—ç¬¦ä¸²å€¼ä¸­çš„çœŸå®æ¢è¡Œç¬¦æ›¿æ¢ä¸º\\n
            def replace_newlines_in_strings(match):
                content = match.group(1)
                # åªè½¬ä¹‰æœªè½¬ä¹‰çš„æ¢è¡Œç¬¦
                content = content.replace('\n', '\\n')
                content = content.replace('\r', '\\r')
                content = content.replace('\t', '\\t')
                return f'"{content}"'
            
            # åŒ¹é…å­—ç¬¦ä¸²å€¼ï¼ˆä¸åŒ…æ‹¬é”®åï¼‰
            json_text = re.sub(r':\s*"([^"]*(?:\n[^"]*)*)"', replace_newlines_in_strings, json_text)
            
            # å¤„ç†å­—ç¬¦ä¸²ä¸­çš„æœªè½¬ä¹‰å¼•å·
            # æŸ¥æ‰¾å¯èƒ½æœ‰é—®é¢˜çš„å­—ç¬¦ä¸²å¹¶ä¿®å¤
            lines = json_text.split('\n')
            fixed_lines = []
            
            for line in lines:
                # æ£€æŸ¥æ˜¯å¦æœ‰æœªç»ˆæ­¢çš„å­—ç¬¦ä¸²ï¼ˆå¥‡æ•°ä¸ªå¼•å·ï¼‰
                quote_count = line.count('"')
                if quote_count % 2 == 1 and not line.strip().endswith('",') and not line.strip().endswith('"'):
                    # å¯èƒ½æ˜¯æœªç»ˆæ­¢çš„å­—ç¬¦ä¸²ï¼Œå°è¯•ä¿®å¤
                    if '": "' in line:
                        # æ‰¾åˆ°æœ€åä¸€ä¸ª": "å¹¶ç¡®ä¿å­—ç¬¦ä¸²æ­£ç¡®ç»ˆæ­¢
                        last_colon_quote = line.rfind('": "')
                        if last_colon_quote != -1:
                            before = line[:last_colon_quote + 4]
                            after = line[last_colon_quote + 4:]
                            # è½¬ä¹‰å†…éƒ¨å¼•å·å¹¶ç¡®ä¿å­—ç¬¦ä¸²ç»ˆæ­¢
                            after = after.replace('"', '\\"')
                            if not after.endswith('"'):
                                after += '"'
                            line = before + after
                
                fixed_lines.append(line)
            
            return '\n'.join(fixed_lines)
            
        except Exception as e:
            logger.warning(f"âš ï¸ ä¿®å¤æœªç»ˆæ­¢å­—ç¬¦ä¸²æ—¶å‡ºé”™: {e}")
            return json_text
    
    def _aggressive_json_fix(self, json_text: str) -> Optional[str]:
        """æ›´æ¿€è¿›çš„JSONä¿®å¤æ–¹æ³•"""
        try:
            # é¦–å…ˆåº”ç”¨åŸºæœ¬çš„å­—ç¬¦ä¸²ä¿®å¤
            json_text = self._fix_unterminated_strings(json_text)
            
            # å°è¯•ä¿®å¤æˆªæ–­çš„JSON
            if not json_text.strip().endswith('}'):
                # æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„å­—æ®µ
                lines = json_text.split('\n')
                valid_lines = []
                brace_count = 0
                in_string = False
                
                for line in lines:
                    # æ£€æŸ¥æ˜¯å¦åœ¨å­—ç¬¦ä¸²å†…éƒ¨ï¼ˆç®€å•æ£€æŸ¥ï¼‰
                    quote_count = line.count('"') - line.count('\\"')
                    if quote_count % 2 == 1:
                        in_string = not in_string
                    
                    # å¦‚æœä¸åœ¨å­—ç¬¦ä¸²å†…éƒ¨ï¼Œæ‰è®¡ç®—æ‹¬å·
                    if not in_string:
                        brace_count += line.count('{') - line.count('}')
                    
                    valid_lines.append(line)
                    
                    # å¦‚æœæ‹¬å·å¹³è¡¡ä¸”è¯¥è¡Œç»“æŸï¼Œå¯èƒ½æ˜¯ä¸ªå¥½çš„æˆªæ–­ç‚¹
                    if not in_string and brace_count == 0 and (line.strip().endswith(',') or line.strip().endswith('"')):
                        break
                
                # è¡¥é½ç¼ºå¤±çš„æ‹¬å·
                if brace_count > 0:
                    valid_lines.append('}' * brace_count)
                
                fixed_json = '\n'.join(valid_lines)
                
                # æ¸…ç†æœ€åçš„é€—å·
                fixed_json = re.sub(r',(\s*})$', r'\1', fixed_json, flags=re.MULTILINE)
                
                return fixed_json
            
            # å¦‚æœJSONçœ‹èµ·æ¥å®Œæ•´ï¼Œä½†ä»ç„¶æœ‰é”™è¯¯ï¼Œå°è¯•æ¸…ç†æ ¼å¼
            json_text = self._clean_json_format(json_text)
            return json_text
                
        except Exception as e:
            logger.debug(f"æ¿€è¿›JSONä¿®å¤å¤±è´¥: {e}")
            
        return None
    
    def _clean_json_format(self, json_text: str) -> str:
        """æ¸…ç†JSONæ ¼å¼ï¼Œå¤„ç†å¸¸è§çš„æ ¼å¼é—®é¢˜"""
        try:
            # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
            json_text = re.sub(r'\s+', ' ', json_text)
            
            # ä¿®å¤å­—ç¬¦ä¸²ä¸­çš„æ§åˆ¶å­—ç¬¦
            json_text = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', json_text)
            
            # ç¡®ä¿å­—ç¬¦ä¸²å€¼è¢«æ­£ç¡®å¼•ç”¨
            # ä¿®å¤æœªå¼•ç”¨çš„å­—ç¬¦ä¸²å€¼ï¼ˆä½†ä¿ç•™æ•°å­—ã€å¸ƒå°”å€¼å’Œnullï¼‰
            def quote_unquoted_strings(match):
                key = match.group(1)
                value = match.group(2).strip()
                
                # å¦‚æœå€¼å·²ç»è¢«å¼•ç”¨æˆ–æ˜¯æ•°å­—/å¸ƒå°”å€¼/nullï¼Œä¿æŒä¸å˜
                if (value.startswith('"') and value.endswith('"')) or \
                   value in ['true', 'false', 'null'] or \
                   re.match(r'^-?\d+(\.\d+)?$', value):
                    return f'"{key}": {value}'
                else:
                    # å¼•ç”¨æœªå¼•ç”¨çš„å­—ç¬¦ä¸²å€¼
                    return f'"{key}": "{value}"'
            
            json_text = re.sub(r'"([^"]+)":\s*([^,}\]]+)', quote_unquoted_strings, json_text)
            
            return json_text
            
        except Exception as e:
            logger.warning(f"âš ï¸ æ¸…ç†JSONæ ¼å¼æ—¶å‡ºé”™: {e}")
            return json_text
    
    def _fix_missing_colons(self, json_text: str) -> str:
        """ä¿®å¤ç¼ºå¤±å†’å·çš„é”™è¯¯ - å¤„ç† 'Expecting ':' delimiter' é”™è¯¯"""
        try:
            # 1. ä¿®å¤å±æ€§ååç¼ºå¤±å†’å·çš„æƒ…å†µ
            # åŒ¹é… "key" value æ¨¡å¼ï¼Œåº”è¯¥æ˜¯ "key": value
            json_text = re.sub(r'"([^"]+)"\s+(["\d\[\{])', r'"\1": \2', json_text)
            
            # 2. ä¿®å¤æ¢è¡Œå¯¼è‡´çš„å†’å·åˆ†ç¦»
            # åŒ¹é… "key"\n value æ¨¡å¼  
            json_text = re.sub(r'"([^"]+)"\s*\n\s*(["\d\[\{])', r'"\1": \2', json_text)
            
            # 3. ä¿®å¤ç‰¹æ®Šæƒ…å†µï¼šthinking å­—æ®µåç¼ºå¤±å†’å·
            json_text = re.sub(r'"thinking"\s+"([^"]*)"', r'"thinking": "\1"', json_text)
            json_text = re.sub(r'"action"\s+"([^"]*)"', r'"action": "\1"', json_text)
            json_text = re.sub(r'"confidence"\s+(\d+\.?\d*)', r'"confidence": \1', json_text)
            
            # 4. ä¿®å¤åœ¨è¡Œé¦–çš„å±æ€§ç¼ºå¤±å†’å·
            lines = json_text.split('\n')
            fixed_lines = []
            for line in lines:
                # æ£€æŸ¥æ˜¯å¦æ˜¯ "å±æ€§å" å€¼ çš„æ¨¡å¼
                if re.match(r'^\s*"[^"]+"\s+[^:]', line.strip()):
                    line = re.sub(r'"([^"]+)"\s+', r'"\1": ', line, 1)
                fixed_lines.append(line)
            
            return '\n'.join(fixed_lines)
            
        except Exception as e:
            logger.warning(f"âš ï¸ ä¿®å¤ç¼ºå¤±å†’å·æ—¶å‡ºé”™: {e}")
            return json_text
    
    def _fix_missing_commas(self, json_text: str) -> str:
        """ä¿®å¤ç¼ºå¤±é€—å·çš„é”™è¯¯ - å¤„ç† 'Expecting ',' delimiter' é”™è¯¯"""
        try:
            # 1. ä¿®å¤å¯¹è±¡å±æ€§ä¹‹é—´ç¼ºå¤±é€—å·
            # åŒ¹é… "key": "value"\n  "key2": "value2" æ¨¡å¼
            json_text = re.sub(r'("\s*)\n\s*(")', r'\1,\n\2', json_text)
            
            # 2. ä¿®å¤æ•°ç»„å…ƒç´ ä¹‹é—´ç¼ºå¤±é€—å·
            # åŒ¹é… }\n  { æ¨¡å¼ï¼ˆå¯¹è±¡æ•°ç»„ï¼‰
            json_text = re.sub(r'(\})\s*\n\s*(\{)', r'\1,\n\2', json_text)
            
            # 3. ä¿®å¤æ•°å€¼åç¼ºå¤±é€—å·
            json_text = re.sub(r'(\d+\.?\d*)\s*\n\s*"', r'\1,\n"', json_text)
            
            # 4. ä¿®å¤å¸ƒå°”å€¼å’Œnullåç¼ºå¤±é€—å·
            json_text = re.sub(r'(true|false|null)\s*\n\s*"', r'\1,\n"', json_text)
            
            # 5. ç‰¹åˆ«å¤„ç†é•¿å­—ç¬¦ä¸²æˆªæ–­å¯¼è‡´çš„é€—å·ç¼ºå¤±
            # å¦‚æœåœ¨ç¬¬6999å­—ç¬¦é™„è¿‘ç¼ºå¤±é€—å·ï¼ˆæ ¹æ®æ—¥å¿—é”™è¯¯ï¼‰
            if len(json_text) > 6990:
                # åœ¨7000å­—ç¬¦é™„è¿‘æŸ¥æ‰¾å¯èƒ½çš„é€—å·ç¼ºå¤±
                substr = json_text[6990:7010]
                if '"' in substr and ',' not in substr:
                    # åœ¨å¼•å·åæ·»åŠ é€—å·
                    json_text = json_text[:6999] + ',' + json_text[6999:]
            
            return json_text
            
        except Exception as e:
            logger.warning(f"âš ï¸ ä¿®å¤ç¼ºå¤±é€—å·æ—¶å‡ºé”™: {e}")
            return json_text
    
    def _fix_property_names(self, json_text: str) -> str:
        """ä¿®å¤å±æ€§åæ ¼å¼é”™è¯¯ - å¤„ç† 'Expecting property name enclosed in double quotes' é”™è¯¯"""
        try:
            # 1. ä¿®å¤æœªå¼•ç”¨çš„å±æ€§å
            json_text = re.sub(r'([^"\s\{\[,]\w+):', r'"\1":', json_text)
            
            # 2. ä¿®å¤å•å¼•å·å±æ€§å
            json_text = re.sub(r"'([^']+)':", r'"\1":', json_text)
            
            # 3. ä¿®å¤é€—å·åç›´æ¥è·Ÿå€¼çš„æƒ…å†µï¼ˆç¼ºå¤±å±æ€§åï¼‰
            # è¿™ç§æƒ…å†µé€šå¸¸å‘ç”Ÿåœ¨content_identifierå­—æ®µç¼ºå¤±
            lines = json_text.split('\n')
            fixed_lines = []
            
            for i, line in enumerate(lines):
                stripped = line.strip()
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ , "value" æˆ– , value æ¨¡å¼ï¼ˆç¼ºå¤±å±æ€§åï¼‰
                if re.match(r'^,\s*"', stripped):
                    # æ ¹æ®ä¸Šä¸‹æ–‡æ·»åŠ åˆé€‚çš„å±æ€§å
                    if 'content_identifier' in json_text.lower():
                        # æ·»åŠ content_identifierå±æ€§
                        indent = len(line) - len(line.lstrip())
                        fixed_lines.append(' ' * indent + '"content_identifier": "unknown",')
                        # ç§»é™¤è¡Œé¦–çš„é€—å·
                        line = line.replace(',', '', 1)
                    elif 'relationship' in json_text.lower():
                        indent = len(line) - len(line.lstrip())
                        fixed_lines.append(' ' * indent + '"relationship": "unknown",')
                        line = line.replace(',', '', 1)
                
                # 4. ä¿®å¤ç¼ºå¤±å¼•å·çš„å±æ€§å
                if ':' in stripped and not stripped.startswith('"'):
                    # æŸ¥æ‰¾å±æ€§å
                    colon_pos = stripped.find(':')
                    prop_name = stripped[:colon_pos].strip()
                    if prop_name and not prop_name.startswith('"'):
                        # æ·»åŠ å¼•å·
                        rest = stripped[colon_pos:]
                        line = line.replace(stripped, f'"{prop_name}"{rest}')
                
                fixed_lines.append(line)
            
            return '\n'.join(fixed_lines)
            
        except Exception as e:
            logger.warning(f"âš ï¸ ä¿®å¤å±æ€§åæ—¶å‡ºé”™: {e}")
            return json_text
    
    def _smart_truncate_response(self, response: str, max_length: int) -> str:
        """æ™ºèƒ½æˆªæ–­å“åº”ï¼Œä¼˜å…ˆä¿ç•™JSONç»“æ„"""
        try:
            if len(response) <= max_length:
                return response
            
            # 1. å°è¯•æ‰¾åˆ°JSONä»£ç å—
            json_patterns = [
                r'```json\s*(\{.*?\})\s*```',
                r'```\s*(\{.*?\})\s*```',
                r'(\{[^{}]*"thinking"[^{}]*\})'
            ]
            
            for pattern in json_patterns:
                match = re.search(pattern, response, re.DOTALL)
                if match:
                    json_content = match.group(1)
                    if len(json_content) <= max_length:
                        # å¦‚æœJSONå†…å®¹ä¸è¶…è¿‡é™åˆ¶ï¼Œè¿”å›å®Œæ•´JSON
                        logger.info(f"ğŸ¯ ä¿ç•™å®Œæ•´JSONç»“æ„ ({len(json_content)} å­—ç¬¦)")
                        return json_content
            
            # 2. å¦‚æœæ²¡æœ‰æ‰¾åˆ°å®Œæ•´JSONï¼Œæ™ºèƒ½æˆªæ–­
            # æŸ¥æ‰¾JSONå¼€å§‹ä½ç½®
            json_start = -1
            for start_char in ['{', '[']:
                pos = response.find(start_char)
                if pos != -1 and (json_start == -1 or pos < json_start):
                    json_start = pos
            
            if json_start != -1 and json_start < max_length:
                # ä»JSONå¼€å§‹ä½ç½®æˆªæ–­
                truncated = response[json_start:json_start + max_length]
                
                # å°è¯•æ‰¾åˆ°ä¸€ä¸ªåˆç†çš„ç»“æŸç‚¹
                # ä¼˜å…ˆåœ¨å®Œæ•´çš„JSONå¯¹è±¡ç»“æŸ
                brace_count = 0
                last_valid_pos = len(truncated)
                
                for i, char in enumerate(truncated):
                    if char == '{':
                        brace_count += 1
                    elif char == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            last_valid_pos = i + 1
                            break
                
                # å¦‚æœæ‰¾åˆ°äº†å®Œæ•´çš„JSONå¯¹è±¡
                if last_valid_pos < len(truncated):
                    result = truncated[:last_valid_pos]
                    logger.info(f"ğŸ¯ æ™ºèƒ½æˆªæ–­ä¿ç•™å®Œæ•´JSONå¯¹è±¡ ({len(result)} å­—ç¬¦)")
                    return result
                
                # å¦åˆ™åœ¨æœ€åä¸€ä¸ªæ¢è¡Œç¬¦å¤„æˆªæ–­
                last_newline = truncated.rfind('\n', 0, max_length - 100)
                if last_newline > max_length // 2:
                    result = truncated[:last_newline]
                    logger.info(f"ğŸ¯ åœ¨æ¢è¡Œç¬¦å¤„æˆªæ–­ ({len(result)} å­—ç¬¦)")
                    return result
                
                logger.info(f"ğŸ¯ ä»JSONå¼€å§‹ä½ç½®æˆªæ–­ ({len(truncated)} å­—ç¬¦)")
                return truncated
            
            # 3. ç®€å•æˆªæ–­ç­–ç•¥
            # å°è¯•åœ¨å¥å­è¾¹ç•Œæˆªæ–­
            truncated = response[:max_length]
            sentence_ends = ['.', '!', '?', 'ã€‚', 'ï¼', 'ï¼Ÿ', '\n']
            
            for end_char in sentence_ends:
                last_pos = truncated.rfind(end_char, max_length - 200)
                if last_pos > max_length // 2:
                    result = truncated[:last_pos + 1]
                    logger.info(f"ğŸ¯ åœ¨å¥å­è¾¹ç•Œæˆªæ–­ ({len(result)} å­—ç¬¦)")
                    return result
            
            # æœ€åçš„ç®€å•æˆªæ–­
            logger.info(f"ğŸ¯ ç®€å•æˆªæ–­ ({max_length} å­—ç¬¦)")
            return response[:max_length]
            
        except Exception as e:
            logger.warning(f"âš ï¸ æ™ºèƒ½æˆªæ–­å¤±è´¥: {e}")
            return response[:max_length]
    
    def _lightweight_json_repair(self, json_text: str) -> Optional[str]:
        """è½»é‡çº§JSONä¿®å¤ï¼Œå¤„ç†å¸¸è§å°é”™è¯¯"""
        try:
            # 1. ä¿®å¤å¸¸è§çš„å¼•å·é”™è¯¯
            json_text = re.sub(r'([^\\])"([^"]*)"([^:])', r'\1"\2"\3', json_text)
            
            # 2. ä¿®å¤ç¼ºå¤±çš„é€—å·ï¼ˆå­—ç¬¦ä¸²åç›´æ¥è·Ÿå­—ç¬¦ä¸²ï¼‰
            json_text = re.sub(r'(")\s*\n\s*(")', r'\1,\n\2', json_text)
            
            # 3. ä¿®å¤å¤šä½™çš„é€—å·
            json_text = re.sub(r',\s*([}\]])', r'\1', json_text)
            
            # 4. ä¿®å¤ç¼ºå¤±çš„å†’å·
            json_text = re.sub(r'"([^"]+)"\s+(["{[])', r'"\1": \2', json_text)
            
            return json_text
            
        except Exception as e:
            logger.debug(f"è½»é‡çº§ä¿®å¤å¤±è´¥: {e}")
            return None
    
    def _reconstruct_json_structure(self, json_text: str) -> Optional[str]:
        """é‡å»ºJSONç»“æ„ï¼Œä»ç ´æŸçš„JSONä¸­æå–å…³é”®ä¿¡æ¯"""
        try:
            # æå–å…³é”®å­—æ®µçš„å€¼
            fields = {}
            
            # æå–thinkingå­—æ®µ
            thinking_match = re.search(r'"thinking":\s*"([^"]*(?:\\.[^"]*)*)"', json_text, re.DOTALL)
            if thinking_match:
                fields['thinking'] = thinking_match.group(1)
            else:
                # æŸ¥æ‰¾STEPå¼€å¤´çš„å†…å®¹ä½œä¸ºthinking
                step_match = re.search(r'(STEP[^"]*?)(?:"|$)', json_text, re.DOTALL)
                if step_match:
                    fields['thinking'] = step_match.group(1)[:500]  # é™åˆ¶é•¿åº¦
            
            # æå–actionå­—æ®µ
            action_match = re.search(r'"action":\s*"([^"]+)"', json_text)
            if action_match:
                fields['action'] = action_match.group(1)
            
            # æå–tool_idå­—æ®µ
            tool_match = re.search(r'"tool_id":\s*"([^"]+)"', json_text)
            if tool_match:
                fields['tool_id'] = tool_match.group(1)
            
            # æå–confidenceå­—æ®µ
            conf_match = re.search(r'"confidence":\s*([0-9.]+)', json_text)
            if conf_match:
                fields['confidence'] = float(conf_match.group(1))
            
            # æå–parameterså­—æ®µï¼ˆç®€åŒ–å¤„ç†ï¼‰
            params_match = re.search(r'"parameters":\s*(\{[^}]*\})', json_text)
            if params_match:
                try:
                    fields['parameters'] = json.loads(params_match.group(1))
                except:
                    fields['parameters'] = {}
            
            # å¦‚æœæå–åˆ°äº†å…³é”®å­—æ®µï¼Œé‡å»ºJSON
            if len(fields) >= 2:  # è‡³å°‘æœ‰2ä¸ªå­—æ®µæ‰é‡å»º
                # æ™ºèƒ½æ¨æ–­é»˜è®¤å·¥å…·åŸºäºä»»åŠ¡å†…å®¹
                default_action = 'error'
                default_tool_id = None
                
                # åŸºäºå†…å®¹æ¨æ–­åˆé€‚çš„é»˜è®¤å€¼
                response_lower = response.lower()
                if any(keyword in response_lower for keyword in ['deepsearch', 'ç ”ç©¶', 'research']):
                    default_action = 'research'
                    default_tool_id = 'mcp-deepsearch'
                elif any(keyword in response_lower for keyword in ['microsandbox', 'ä»£ç ', 'code', 'python', 'æ‰§è¡Œ']):
                    default_action = 'microsandbox_execute'
                    default_tool_id = 'microsandbox-mcp-server'
                elif any(keyword in response_lower for keyword in ['browser', 'æµè§ˆ', 'ç½‘é¡µ', 'navigate']):
                    default_action = 'browser_navigate'
                    default_tool_id = 'browser-use-mcp-server'
                elif 'search' in response_lower and 'install' in response_lower:
                    default_action = 'search_and_install_tools'
                    default_tool_id = 'mcp-search-tool'
                
                reconstructed = {
                    'thinking': fields.get('thinking', 'No thinking extracted'),
                    'action': fields.get('action', default_action),
                    'tool_id': fields.get('tool_id', default_tool_id),
                    'parameters': fields.get('parameters', {}),
                    'confidence': fields.get('confidence', 0.7)
                }
                
                logger.info(f"ğŸ”§ é‡å»ºJSONç»“æ„ï¼Œæå–äº† {len(fields)} ä¸ªå­—æ®µ")
                return json.dumps(reconstructed, ensure_ascii=False)
            
            return None
            
        except Exception as e:
            logger.debug(f"JSONç»“æ„é‡å»ºå¤±è´¥: {e}")
            return None
    
    def _smart_extract_from_response(self, response: str) -> Optional[Dict[str, Any]]:
        """ä»åŸå§‹å“åº”ä¸­æ™ºèƒ½æå–å­—æ®µï¼Œæ— éœ€å®Œæ•´JSON"""
        try:
            result = {}
            
            # 1. æå–thinking - æŸ¥æ‰¾STEPå¼€å¤´æˆ–thinkingå­—æ®µ
            thinking_patterns = [
                r'STEP 1[^:]*:([^"]*?)(?:STEP 2|$)',
                r'"thinking":\s*"([^"]*(?:\\.[^"]*)*)"',
                r'thinking["\']?\s*[:=]\s*["\']([^"\']*)["\']'
            ]
            
            for pattern in thinking_patterns:
                match = re.search(pattern, response, re.DOTALL | re.IGNORECASE)
                if match:
                    result['thinking'] = match.group(1).strip()[:1000]  # é™åˆ¶é•¿åº¦
                    break
            
            if not result.get('thinking'):
                result['thinking'] = response[:300]  # ä½¿ç”¨å“åº”å‰300å­—ç¬¦ä½œä¸ºthinking
            
            # 2. æ™ºèƒ½æ¨æ–­action
            action_keywords = {
                'search_and_install_tools': ['æœç´¢', 'search', 'æŸ¥æ‰¾', 'å·¥å…·', 'tool', 'install'],
                'analyze_tool_needs': ['åˆ†æ', 'analyze', 'éœ€è¦', 'need', 'è¯„ä¼°'],
                'complete_task': ['å®Œæˆ', 'complete', 'ç»“æŸ', 'finish', 'æ€»ç»“', 'summary']
            }
            
            response_lower = response.lower()
            action_scores = {}
            
            for action, keywords in action_keywords.items():
                score = sum(1 for keyword in keywords if keyword in response_lower)
                if score > 0:
                    action_scores[action] = score
            
            if action_scores:
                result['action'] = max(action_scores.items(), key=lambda x: x[1])[0]
            else:
                result['action'] = 'search_and_install_tools'  # é»˜è®¤action
            
            # 3. æ¨æ–­tool_id
            tool_patterns = [
                r'"tool_id":\s*"([^"]+)"',
                r'"tool":\s*"([^"]+)"',
                r'tool["\']?\s*[:=]\s*["\']([^"\']+)["\']'
            ]
            
            for pattern in tool_patterns:
                match = re.search(pattern, response, re.IGNORECASE)
                if match:
                    result['tool_id'] = match.group(1)
                    break
            
            if not result.get('tool_id'):
                # åŸºäºactionæ¨æ–­tool_idï¼ˆä½¿ç”¨æ™ºèƒ½æ˜ å°„ï¼‰
                action_to_tool_mapping = {
                    'research': 'mcp-deepsearch',
                    'quick_research': 'mcp-deepsearch', 
                    'comprehensive_research': 'mcp-deepsearch',
                    'microsandbox_execute': 'microsandbox-mcp-server',
                    'microsandbox_install_package': 'microsandbox-mcp-server',
                    'browser_navigate': 'browser-use-mcp-server',
                    'browser_extract_content': 'browser-use-mcp-server',
                    'browser_click_element': 'browser-use-mcp-server',
                    'search_and_install_tools': 'mcp-search-tool',
                    'analyze_tool_needs': 'mcp-search-tool'
                }
                
                if result['action'] in action_to_tool_mapping:
                    result['tool_id'] = action_to_tool_mapping[result['action']]
                else:
                    # åŸºäºå†…å®¹è¿›ä¸€æ­¥æ¨æ–­
                    response_lower = response.lower()
                    if any(keyword in response_lower for keyword in ['deepsearch', 'ç ”ç©¶', 'research']):
                        result['tool_id'] = 'mcp-deepsearch'
                    elif any(keyword in response_lower for keyword in ['microsandbox', 'ä»£ç ', 'code', 'python']):
                        result['tool_id'] = 'microsandbox-mcp-server'
                    elif any(keyword in response_lower for keyword in ['browser', 'æµè§ˆ', 'ç½‘é¡µ']):
                        result['tool_id'] = 'browser-use-mcp-server'
                    else:
                        result['tool_id'] = 'mcp-deepsearch'  # é»˜è®¤ä½¿ç”¨ç ”ç©¶å·¥å…·
            
            # 4. æå–confidence
            conf_patterns = [
                r'"confidence":\s*([0-9.]+)',
                r'confidence["\']?\s*[:=]\s*([0-9.]+)'
            ]
            
            for pattern in conf_patterns:
                match = re.search(pattern, response)
                if match:
                    try:
                        result['confidence'] = float(match.group(1))
                        break
                    except:
                        pass
            
            if 'confidence' not in result:
                result['confidence'] = 0.8  # é»˜è®¤ç½®ä¿¡åº¦
            
            # 5. æå–æˆ–ç”Ÿæˆparameters
            result['parameters'] = {}
            
            # å°è¯•æå–task_description
            if result['action'] in ['search_and_install_tools', 'analyze_tool_needs']:
                # ä»thinkingä¸­æå–ä»»åŠ¡æè¿°
                thinking = result.get('thinking', '')
                if 'TASK ANALYSIS:' in thinking:
                    task_start = thinking.find('TASK ANALYSIS:') + len('TASK ANALYSIS:')
                    task_end = thinking.find('STEP 2', task_start)
                    if task_end == -1:
                        task_end = task_start + 200
                    task_desc = thinking[task_start:task_end].strip()
                    if task_desc:
                        result['parameters']['task_description'] = task_desc[:200]
            
            # å‘åå…¼å®¹
            result['tool'] = result['tool_id']
            
            logger.debug(f"æ™ºèƒ½æå–å®Œæˆ: action={result['action']}, tool_id={result['tool_id']}")
            return result
            
        except Exception as e:
            logger.warning(f"æ™ºèƒ½æå–å¤±è´¥: {e}")
            return None
    
    def _identify_task_type(self, response_lower: str) -> str:
        """æ™ºèƒ½è¯†åˆ«ä»»åŠ¡ç±»å‹"""
        # ç ”ç©¶ç±»ä»»åŠ¡å…³é”®è¯ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        research_keywords = ['deepsearch', 'ç ”ç©¶', 'research', 'asyncio', 'åŸºæœ¬æ¦‚å¿µ', 'ç”¨æ³•', 'æœ€ä½³å®è·µ', 'è°ƒç ”']
        if any(keyword in response_lower for keyword in research_keywords):
            return 'research'
        
        # ä»£ç æ‰§è¡Œç±»ä»»åŠ¡
        code_keywords = ['microsandbox', 'ä»£ç ', 'code', 'python', 'æ‰§è¡Œ', 'execute', 'è¿è¡Œ', 'script']
        if any(keyword in response_lower for keyword in code_keywords):
            return 'code'
        
        # æµè§ˆå™¨ç±»ä»»åŠ¡
        browser_keywords = ['browser', 'æµè§ˆ', 'ç½‘é¡µ', 'navigate', 'url', 'website', 'è®¿é—®']
        if any(keyword in response_lower for keyword in browser_keywords):
            return 'browser'
        
        # å·¥å…·æœç´¢ç±»ä»»åŠ¡ï¼ˆæœ€ä½ä¼˜å…ˆçº§ï¼‰
        tool_search_keywords = ['search_and_install', 'analyze_tool_needs', 'å®‰è£…å·¥å…·', 'æœç´¢å·¥å…·']
        if any(keyword in response_lower for keyword in tool_search_keywords):
            return 'tool_search'
        
        return 'unknown'
    
    def _robust_extract_fields(self, response: str) -> Optional[Dict[str, Any]]:
        """å¥å£®çš„å­—æ®µæå–å™¨ - æœ€ç»ˆé˜²çº¿ï¼Œå¢å¼ºç‰ˆæœ¬withæ™ºèƒ½ä¸Šä¸‹æ–‡åˆ†æ"""
        try:
            logger.debug("ä½¿ç”¨å¥å£®å­—æ®µæå–å™¨")
            result = {}
            
            # ğŸ”§ å¢å¼ºï¼šé¢„å¤„ç†å“åº”ï¼Œæå–å…³é”®ä¿¡æ¯
            response_lower = response.lower()
            
            # æ™ºèƒ½ä»»åŠ¡ç±»å‹è¯†åˆ«ï¼ˆåŸºäºä¸Šä¸‹æ–‡ï¼‰
            task_type = self._identify_task_type(response_lower)
            # è¯†åˆ«ä»»åŠ¡ç±»å‹
            
            # 1. æå–thinkingå­—æ®µ - æ›´æ™ºèƒ½çš„ç­–ç•¥
            thinking_extracted = False
            
            # ç­–ç•¥1: æŸ¥æ‰¾thinkingå­—æ®µï¼ˆå®½æ¾åŒ¹é…ï¼‰
            thinking_patterns = [
                r'["\']?thinking["\']?\s*[:ï¼š]\s*["\']([^"\']*)["\']',
                r'thinking\s*[:ï¼š]\s*([^,}\n]*)',
                r'STEP\s*1[^:]*[:ï¼š]([^"]*?)(?:STEP\s*2|action|tool_id|$)',
                r'ä»»åŠ¡åˆ†æ[^:]*[:ï¼š]([^"]*?)(?:æ­¥éª¤|STEP|action|$)',
                r'Brief\s*[^:]*[:ï¼š]([^"]*?)(?:tool|action|$)'  # æ–°å¢ï¼šé€‚é…ç®€åŒ–æ ¼å¼
            ]
            
            for pattern in thinking_patterns:
                match = re.search(pattern, response, re.DOTALL | re.IGNORECASE)
                if match:
                    thinking_content = match.group(1).strip()
                    if len(thinking_content) > 10:  # ç¡®ä¿å†…å®¹æœ‰æ„ä¹‰
                        result['thinking'] = thinking_content[:500]  # ç¼©çŸ­thinkingé•¿åº¦
                        thinking_extracted = True
                        logger.debug(f"ğŸ” æå–thinkingæˆåŠŸ (æ¨¡å¼: {pattern[:30]}...)")
                        break
            
            if not thinking_extracted:
                # å¤‡ç”¨ç­–ç•¥ï¼šåŸºäºä»»åŠ¡ç±»å‹ç”Ÿæˆç®€åŒ–thinking
                result['thinking'] = f"Task type: {task_type}, using appropriate tool"
                logger.debug("ğŸ” ç”ŸæˆåŸºäºä»»åŠ¡ç±»å‹çš„thinking")
            
            # 2. æå–actionå­—æ®µ - æ™ºèƒ½æ¨æ–­
            action_patterns = [
                r'["\']?action["\']?\s*[:ï¼š]\s*["\']([^"\']*)["\']',
                r'action\s*[:ï¼š]\s*([a-zA-Z_]+)',
                r'éœ€è¦(æœç´¢|æŸ¥æ‰¾|å®‰è£…).*å·¥å…·',
                r'(æœç´¢|search).*å·¥å…·',
                r'(åˆ†æ|analyze).*éœ€è¦'
            ]
            
            action_found = False
            for pattern in action_patterns:
                match = re.search(pattern, response, re.IGNORECASE)
                if match:
                    if 'æœç´¢' in match.group(0) or 'search' in match.group(0).lower():
                        result['action'] = 'search_and_install_tools'
                    elif 'åˆ†æ' in match.group(0) or 'analyze' in match.group(0).lower():
                        result['action'] = 'analyze_tool_needs'
                    else:
                        extracted_action = match.group(1) if len(match.groups()) > 0 else 'search_and_install_tools'
                        result['action'] = extracted_action
                    action_found = True
                    # actionæå–æˆåŠŸ
                    break
            
            if not action_found:
                # ğŸ”§ å¢å¼ºï¼šåŸºäºè¯†åˆ«çš„ä»»åŠ¡ç±»å‹æ™ºèƒ½æ¨æ–­action
                action_mapping = {
                    'research': 'research',
                    'code': 'microsandbox_execute', 
                    'browser': 'browser_navigate',
                    'tool_search': 'search_and_install_tools',
                    'unknown': 'research'  # é»˜è®¤ä¸ºç ”ç©¶ä»»åŠ¡
                }
                
                result['action'] = action_mapping.get(task_type, 'research')
                # åŸºäºä»»åŠ¡ç±»å‹æ¨æ–­action
            
            # 3. æå–tool_idå­—æ®µ
            tool_patterns = [
                r'["\']?tool_id["\']?\s*[:ï¼š]\s*["\']([^"\']*)["\']',
                r'["\']?tool["\']?\s*[:ï¼š]\s*["\']([^"\']*)["\']',
                r'å·¥å…·ID\s*[:ï¼š]\s*([^\s,}]*)',
                r'ä½¿ç”¨.*å·¥å…·\s*[:ï¼š]?\s*([a-zA-Z0-9_-]+)'
            ]
            
            tool_found = False
            for pattern in tool_patterns:
                match = re.search(pattern, response, re.IGNORECASE)
                if match:
                    tool_id = match.group(1).strip()
                    if tool_id and len(tool_id) > 2:  # ç¡®ä¿tool_idæœ‰æ„ä¹‰
                        result['tool_id'] = tool_id
                        tool_found = True
                        # tool_idæå–æˆåŠŸ
                        break
            
            if not tool_found:
                # åŸºäºactionæ¨æ–­tool_idï¼ˆä½¿ç”¨æ™ºèƒ½æ˜ å°„ï¼‰
                action_to_tool_mapping = {
                    'research': 'mcp-deepsearch',
                    'quick_research': 'mcp-deepsearch', 
                    'comprehensive_research': 'mcp-deepsearch',
                    'microsandbox_execute': 'microsandbox-mcp-server',
                    'microsandbox_install_package': 'microsandbox-mcp-server',
                    'browser_navigate': 'browser-use-mcp-server',
                    'browser_extract_content': 'browser-use-mcp-server',
                    'browser_click_element': 'browser-use-mcp-server',
                    'search_and_install_tools': 'mcp-search-tool',
                    'analyze_tool_needs': 'mcp-search-tool'
                }
                
                if result['action'] in action_to_tool_mapping:
                    result['tool_id'] = action_to_tool_mapping[result['action']]
                else:
                    # åŸºäºå†…å®¹è¿›ä¸€æ­¥æ¨æ–­
                    response_lower = response.lower()
                    if any(keyword in response_lower for keyword in ['deepsearch', 'ç ”ç©¶', 'research']):
                        result['tool_id'] = 'mcp-deepsearch'
                    elif any(keyword in response_lower for keyword in ['microsandbox', 'ä»£ç ', 'code', 'python']):
                        result['tool_id'] = 'microsandbox-mcp-server'
                    elif any(keyword in response_lower for keyword in ['browser', 'æµè§ˆ', 'ç½‘é¡µ']):
                        result['tool_id'] = 'browser-use-mcp-server'
                    else:
                        result['tool_id'] = 'mcp-deepsearch'  # é»˜è®¤ä½¿ç”¨ç ”ç©¶å·¥å…·
                
                # åŸºäºactionæ¨æ–­tool_id
            
            # 4. æå–æˆ–ç”Ÿæˆparameters
            result['parameters'] = {}
            
            # å°è¯•æå–task_description
            if result['action'] in ['search_and_install_tools', 'analyze_tool_needs']:
                # ä»thinkingä¸­æå–ä»»åŠ¡æè¿°çš„å…³é”®éƒ¨åˆ†
                thinking = result.get('thinking', '')
                
                # æŸ¥æ‰¾ä»»åŠ¡ç›¸å…³çš„æè¿°
                task_patterns = [
                    r'ä»»åŠ¡[:ï¼š]([^ã€‚\n]*)',
                    r'TASK[^:]*[:ï¼š]([^.\n]*)',
                    r'éœ€è¦([^ã€‚\n]*å·¥å…·[^ã€‚\n]*)',
                    r'è¦æ±‚([^ã€‚\n]*)'
                ]
                
                for pattern in task_patterns:
                    match = re.search(pattern, thinking, re.IGNORECASE)
                    if match:
                        task_desc = match.group(1).strip()
                        if len(task_desc) > 5:
                            result['parameters']['task_description'] = task_desc[:200]
                            # task_descriptionæå–æˆåŠŸ
                            break
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å…·ä½“çš„ä»»åŠ¡æè¿°ï¼Œä½¿ç”¨thinkingçš„æ‘˜è¦
                if not result['parameters'].get('task_description'):
                    # æå–thinkingä¸­çš„å…³é”®è¯ä½œä¸ºä»»åŠ¡æè¿°
                    keywords = re.findall(r'[\u4e00-\u9fff]+|[a-zA-Z]+', thinking)
                    if keywords:
                        task_summary = ' '.join(keywords[:15])  # å–å‰15ä¸ªè¯
                        result['parameters']['task_description'] = task_summary
                        # ç”Ÿæˆtask_descriptionæ‘˜è¦
            
            # 5. éªŒè¯å’Œçº æ­£actionï¼ˆé‡è¦ï¼šå¥å£®æå–å™¨ä¹Ÿéœ€è¦éªŒè¯ï¼‰
            result['action'] = self._validate_and_correct_action(result['action'], result['tool_id'])
            
            # 6. è®¾ç½®confidenceå’Œå…¶ä»–å­—æ®µ
            result['confidence'] = 0.6  # å¥å£®æå–å™¨çš„ç½®ä¿¡åº¦è¾ƒä½
            result['tool'] = result['tool_id']  # å‘åå…¼å®¹
            
            # 7. éªŒè¯æå–ç»“æœçš„è´¨é‡
            if len(result.get('thinking', '')) < 5:
                logger.warning("å¥å£®æå–å™¨: thinkingå­—æ®µè´¨é‡ä¸è¶³")
                return None
            
            if not result.get('action') or not result.get('tool_id'):
                logger.warning("å¥å£®æå–å™¨: ç¼ºå°‘å…³é”®å­—æ®µ")
                return None
            
            logger.debug(f"å¥å£®å­—æ®µæå–æˆåŠŸ: action={result['action']}, tool_id={result['tool_id']}")
            return result
            
        except Exception as e:
            logger.error(f"å¥å£®å­—æ®µæå–å™¨å¤±è´¥: {e}")
            return None
    
    def _apply_structured_validation(self, result: Dict[str, Any]) -> ResponseValidationResult:
        """
        åº”ç”¨ç»“æ„åŒ–å·¥å…·æ ¡éªŒ
        ä½¿ç”¨æ–°çš„é¢„æ ¡éªŒä¸­é—´ä»¶è¿›è¡Œä¸¥æ ¼çš„Schemaæ ¡éªŒ
        """
        try:
            # ä½¿ç”¨æ ¡éªŒä¸­é—´ä»¶
            is_valid, validated_data, error = validation_middleware.validate_before_llm_call(result)
            
            if is_valid:
                # æ£€æŸ¥æ•°æ®æ˜¯å¦è¢«ä¿®æ”¹ï¼ˆè‡ªåŠ¨çº æ­£ï¼‰
                corrected = (result != validated_data)
                return ResponseValidationResult(True, validated_data, None, corrected)
            else:
                return ResponseValidationResult(False, result, error, False)
                
        except Exception as e:
            logger.debug(f"ç»“æ„åŒ–æ ¡éªŒè¿‡ç¨‹å‡ºé”™: {str(e)}")
            return ResponseValidationResult(False, result, str(e), False)

    def _validate_and_correct_action(self, action: str, tool_id: Optional[str]) -> str:
        """
        ğŸ”§ ã€æ ¸å¿ƒä¿®å¤ã€‘éªŒè¯å’Œçº æ­£action - ä½¿ç”¨ç»Ÿä¸€å·¥å…·ç®¡ç†å™¨
        
        è§£å†³åŠ¨ä½œéªŒè¯ä¸ä¸€è‡´çš„é—®é¢˜ï¼š
        - ä½¿ç”¨ç»Ÿä¸€å·¥å…·ç®¡ç†å™¨è¿›è¡ŒåŠ¨ä½œéªŒè¯
        - æ”¯æŒæ™ºèƒ½çº æ­£å’Œå»ºè®®
        - é¿å…å¤æ‚çš„å¼‚æ­¥è°ƒç”¨é—®é¢˜
        """
        # å¦‚æœæ²¡æœ‰tool_idï¼Œæ— æ³•éªŒè¯
        if not tool_id:
            return action
        
        # ğŸŒŸ ã€å…³é”®ä¿®å¤ã€‘ä½¿ç”¨ç»Ÿä¸€å·¥å…·ç®¡ç†å™¨è¿›è¡ŒåŒæ­¥éªŒè¯
        try:
            tool_manager = get_tool_manager()
            
            # å…ˆè§„èŒƒåŒ–tool_id
            standard_tool_id = tool_manager.get_standard_id(tool_id)
            
            # æ£€æŸ¥åŠ¨ä½œæ˜¯å¦æœ‰æ•ˆ
            if tool_manager.is_valid_action(standard_tool_id, action):
                logger.debug(f"âœ… åŠ¨ä½œéªŒè¯é€šè¿‡: {standard_tool_id}.{action}")
                return action
            
            # å¦‚æœåŠ¨ä½œæ— æ•ˆï¼Œå°è¯•æ™ºèƒ½çº æ­£
            valid_actions = tool_manager.get_tool_actions(standard_tool_id)
            
            # å°è¯•æ¨¡ç³ŠåŒ¹é…
            normalized_action = action.lower().replace('_', '').replace('-', '')
            for valid_action in valid_actions:
                normalized_valid = valid_action.lower().replace('_', '').replace('-', '')
                if normalized_action == normalized_valid:
                    logger.warning(f"âš ï¸ Actionæ™ºèƒ½çº æ­£: {action} -> {valid_action}")
                    return valid_action
            
            # å¦‚æœæ— æ³•çº æ­£ï¼Œè®°å½•è­¦å‘Šå¹¶è¿”å›é»˜è®¤åŠ¨ä½œ
            default_action = tool_manager.get_default_action(standard_tool_id)
            logger.warning(f"ActionéªŒè¯å¤±è´¥: {action} ä¸å­˜åœ¨äº {standard_tool_id}ï¼Œå°è¯•çº æ­£")
            logger.warning(f"ğŸ”§ æœ‰æ•ˆåŠ¨ä½œ: {valid_actions}")
            logger.warning(f"ğŸ¯ ä½¿ç”¨é»˜è®¤åŠ¨ä½œ: {default_action}")
            
            return default_action
            
        except Exception as e:
            logger.warning(f"âš ï¸ åŠ¨ä½œéªŒè¯å¤±è´¥ï¼Œä¿æŒåŸå§‹åŠ¨ä½œ: {e}")
            return action
    
    
    def _fix_delimiter_errors(self, json_text: str) -> str:
        """ä¿®å¤ç‰¹å®šçš„åˆ†éš”ç¬¦é”™è¯¯ - P3å¢å¼ºæ–¹æ³•"""
        try:
            # ğŸ”§ P3ä¿®å¤ï¼šå¤„ç†"Expecting ':' delimiter: line 2 column 13"ç±»é”™è¯¯
            
            # 0. é¢„å¤„ç†ï¼šç§»é™¤BOMå’Œç‰¹æ®Šå­—ç¬¦
            json_text = json_text.replace('\ufeff', '').replace('\u200b', '')  # ç§»é™¤BOMå’Œé›¶å®½å­—ç¬¦
            
            # 1. é€šç”¨JSONä¿®å¤
            # ä¿®å¤å¸¸è§çš„å±æ€§åç¼ºå°‘å¼•å·é—®é¢˜ - ä½†æ’é™¤å·²ç»æœ‰å¼•å·çš„
            json_text = re.sub(r'([^"\w])(\w+):', r'\1"\2":', json_text)
            # ä¿®å¤å­—ç¬¦ä¸²å€¼ç¼ºå°‘å¼•å·é—®é¢˜ - æ›´ç²¾ç¡®çš„æ¨¡å¼
            json_text = re.sub(r':\s*([^",\[\]\{\}\s\d][^",\[\]\{\}]*?)([,\]\}])', r': "\1"\2', json_text)
            
            # 1. ä¿®å¤ç¬¬2è¡Œé™„è¿‘çš„åˆ†éš”ç¬¦é”™è¯¯
            lines = json_text.split('\n')
            if len(lines) >= 2:
                # æ£€æŸ¥ç¬¬2è¡Œï¼ˆç´¢å¼•1ï¼‰æ˜¯å¦æœ‰åˆ†éš”ç¬¦é—®é¢˜
                line2 = lines[1].strip()
                if '"' in line2 and ':' not in line2 and not line2.startswith('}'):
                    # å¯èƒ½æ˜¯å±æ€§ååç¼ºå°‘å†’å·
                    # æŸ¥æ‰¾ "å±æ€§å" åé¢æ²¡æœ‰å†’å·çš„æƒ…å†µ
                    fixed_line2 = re.sub(r'"([^"]+)"\s+([^:])', r'"\1": \2', line2)
                    if fixed_line2 != line2:
                        logger.debug("ğŸ”§ ä¿®å¤ç¬¬2è¡Œç¼ºå¤±å†’å·")
                        lines[1] = fixed_line2
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å±æ€§åå’Œå€¼ä¹‹é—´ç¼ºå°‘å†’å·
                if '"' in line2 and '"' in line2[1:]:
                    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå’Œç¬¬äºŒä¸ªå¼•å·ä¹‹é—´çš„éƒ¨åˆ†
                    quote_match = re.match(r'^(\s*"[^"]+")(\s*)([^:].*)$', line2)
                    if quote_match:
                        prop_name = quote_match.group(1)
                        spacing = quote_match.group(2)
                        value_part = quote_match.group(3)
                        lines[1] = f"{prop_name}:{spacing}{value_part}"
                        logger.debug("ğŸ”§ ä¿®å¤å±æ€§åå’Œå€¼ä¹‹é—´ç¼ºå°‘å†’å·")
            
            # 2. ä¿®å¤ç‰¹å®šä½ç½®çš„åˆ†éš”ç¬¦é”™è¯¯ï¼ˆåŸºäºcolumn 13çš„æç¤ºï¼‰
            if len(lines) >= 2 and len(lines[1]) >= 13:
                char_at_13 = lines[1][12] if len(lines[1]) > 12 else ''
                if char_at_13 and char_at_13 not in [':', ',', '"', ' ']:
                    # åœ¨ç¬¬13ä½ç½®é™„è¿‘å¯èƒ½ç¼ºå°‘åˆ†éš”ç¬¦
                    line = lines[1]
                    before = line[:12]
                    after = line[12:]
                    
                    # å¦‚æœå‰é¢æœ‰å¼•å·ï¼Œå¯èƒ½éœ€è¦å†’å·
                    if before.count('"') % 2 == 0 and '"' in before:
                        lines[1] = before + ':' + after
                        logger.debug("ğŸ”§ ä¿®å¤ç¬¬13åˆ—ä½ç½®ç¼ºå°‘å†’å·")
                        logger.debug("ğŸ”§ åœ¨ç¬¬13åˆ—ä½ç½®æ·»åŠ å†’å·")
                    # å¦‚æœéœ€è¦é€—å·
                    elif before.endswith('"') or before.endswith('}'):
                        lines[1] = before + ',' + after
                        logger.debug("ğŸ”§ åœ¨ç¬¬13åˆ—ä½ç½®æ·»åŠ é€—å·")
            
            # 3. ä¿®å¤é€šç”¨çš„åˆ†éš”ç¬¦ç¼ºå¤±
            for i, line in enumerate(lines):
                # ä¿®å¤ "key" value æ¨¡å¼ç¼ºå°‘å†’å·
                fixed_line = re.sub(r'"([^"]+)"\s+(["\d\[\{])', r'"\1": \2', line)
                # ä¿®å¤ "key"åç›´æ¥è·Ÿå€¼è€Œæ— å†’å·çš„æƒ…å†µ
                fixed_line = re.sub(r'"([^"]+)"\s*([^:\s,\]\}][^,\]\}]*)', r'"\1": "\2"', fixed_line)
                if fixed_line != line:
                    lines[i] = fixed_line
                    logger.debug(f"ğŸ”§ ä¿®å¤ç¬¬{i+1}è¡Œç¼ºå¤±å†’å·")
            
            # 4. å°è¯•æ›´æ¿€è¿›çš„ä¿®å¤ç­–ç•¥
            result = '\n'.join(lines)
            
            # æ£€æŸ¥æ˜¯å¦ä»æœ‰JSONé”™è¯¯ï¼Œå¦‚æœæœ‰åˆ™å°è¯•æ›´æ¿€è¿›çš„ä¿®å¤
            try:
                json.loads(result)
                return result  # å·²ç»æ˜¯æœ‰æ•ˆJSON
            except json.JSONDecodeError as e:
                if "Expecting ':' delimiter" in str(e):
                    logger.debug("ğŸ”§ ä½¿ç”¨æ¿€è¿›ä¿®å¤ç­–ç•¥")
                    # å°è¯•é€å­—ç¬¦ä¿®å¤
                    result = self._aggressive_delimiter_fix(result)
            
            return result
            
        except Exception as e:
            logger.warning(f"âš ï¸ ä¿®å¤åˆ†éš”ç¬¦é”™è¯¯æ—¶å‡ºç°å¼‚å¸¸: {e}")
            return json_text
    
    def _aggressive_delimiter_fix(self, json_text: str) -> str:
        """æ¿€è¿›çš„åˆ†éš”ç¬¦ä¿®å¤ç­–ç•¥"""
        try:
            # å°†æ–‡æœ¬è½¬æ¢ä¸ºå­—ç¬¦åˆ—è¡¨ä»¥ä¾¿ä¿®æ”¹
            chars = list(json_text)
            in_string = False
            escape_next = False
            i = 0
            
            while i < len(chars):
                char = chars[i]
                
                if escape_next:
                    escape_next = False
                    i += 1
                    continue
                
                if char == '\\':
                    escape_next = True
                    i += 1
                    continue
                
                if char == '"':
                    in_string = not in_string
                    i += 1
                    continue
                
                if not in_string:
                    # åœ¨JSONç»“æ„ä¸­ï¼Œå¯»æ‰¾å¯èƒ½ç¼ºå°‘å†’å·çš„ä½ç½®
                    if char == '"' and i + 1 < len(chars):
                        # å¯»æ‰¾ä¸‹ä¸€ä¸ªéç©ºç™½å­—ç¬¦
                        j = i + 1
                        while j < len(chars) and chars[j] in ' \t\n\r':
                            j += 1
                        
                        if j < len(chars) and chars[j] != ':' and chars[j] not in ',}]':
                            # å¯èƒ½ç¼ºå°‘å†’å·ï¼Œæ’å…¥å†’å·
                            chars.insert(j, ':')
                            chars.insert(j + 1, ' ')
                            logger.debug(f"ğŸ”§ åœ¨ä½ç½®{j}æ’å…¥å†’å·")
                            i = j + 2
                            continue
                
                i += 1
            
            return ''.join(chars)
            
        except Exception as e:
            logger.warning(f"âš ï¸ æ¿€è¿›ä¿®å¤å¤±è´¥: {e}")
            return json_text