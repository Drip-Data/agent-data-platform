import json
import logging
import re
from typing import Dict, Any, List, Optional

from core.llm.response_parsers.interfaces import IResponseParser

logger = logging.getLogger(__name__)

class ReasoningResponseParser(IResponseParser):
    """
    ç”¨äºè§£æLLMç”Ÿæˆçš„æ¨ç†å“åº”çš„è§£æå™¨ã€‚
    å¤„ç†å¤æ‚çš„JSONæå–ã€éªŒè¯å’Œä¿®æ­£é€»è¾‘ã€‚
    """

    def parse_response(self, response: str, **kwargs) -> Dict[str, Any]:
        """
        è§£æLLMçš„åŸå§‹å­—ç¬¦ä¸²å“åº”ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºç»“æ„åŒ–çš„æ¨ç†å†³ç­–å­—å…¸ã€‚
        
        Args:
            response (str): LLMçš„åŸå§‹å­—ç¬¦ä¸²å“åº”ã€‚
            **kwargs: é¢å¤–çš„å‚æ•°ï¼Œç›®å‰æœªä½¿ç”¨ï¼Œä½†ä¿ç•™ä»¥ç¬¦åˆæ¥å£ã€‚

        Returns:
            Dict[str, Any]: åŒ…å«è§£æåæ¨ç†å†³ç­–çš„å­—å…¸ã€‚
        """
        logger.info(f"ğŸ” è§£æLLMå“åº” (é•¿åº¦: {len(response)})")
        
        try:
            # é¦–å…ˆå°è¯•ç›´æ¥è§£æJSON
            response_clean = response.strip()
            
            # ğŸ” å¢å¼ºçš„JSONæå– - å¤„ç†å„ç§æ ¼å¼
            json_patterns = [
                r'```json\s*(\{.*?\})\s*```',  # markdownä»£ç å—
                r'```\s*(\{.*?\})\s*```',      # æ™®é€šä»£ç å—  
                r'(\{[^{}]*"thinking"[^{}]*\})', # åŒ…å«thinkingçš„JSON
                r'(\{.*?\})',                  # ä»»ä½•JSONå¯¹è±¡
            ]
            
            json_text = None
            for pattern in json_patterns:
                match = re.search(pattern, response_clean, re.DOTALL)
                if match:
                    json_text = match.group(1)
                    logger.info(f"âœ… ä½¿ç”¨æ¨¡å¼æå–åˆ°JSON: {pattern}")
                    break
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONå—ï¼Œå°è¯•ç›´æ¥è§£æ
            if not json_text:
                # ç§»é™¤å¯èƒ½çš„markdownä»£ç å—åŒ…è£…
                if response_clean.startswith('```json'):
                    response_clean = response_clean[7:]
                if response_clean.endswith('```'):
                    response_clean = response_clean[:-3]
                json_text = response_clean.strip()
            
            # ğŸ” ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
            if json_text:
                # ä¿®å¤è¢«æˆªæ–­çš„JSON
                if not json_text.endswith('}') and json_text.count('{') > json_text.count('}'):
                    missing_braces = json_text.count('{') - json_text.count('}')
                    json_text += '}' * missing_braces
                    logger.warning(f"ğŸ”§ ä¿®å¤äº† {missing_braces} ä¸ªç¼ºå¤±çš„å³æ‹¬å·")
                
                # ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é”™è¯¯
                json_text = self._fix_json_formatting_errors(json_text)
                
                # å°è¯•è§£æJSON
                try:
                    parsed = json.loads(json_text)
                    logger.info("âœ… JSONè§£ææˆåŠŸ")
                    
                    # ğŸ” æ™ºèƒ½å­—æ®µè¡¥å…¨å’ŒéªŒè¯
                    result = self._validate_and_complete_parsed_response(parsed)
                    
                    logger.info(f"ğŸ¯ æœ€ç»ˆè§£æç»“æœ: action={result.get('action')}, tool_id={result.get('tool_id')}, confidence={result.get('confidence')}")
                    return result
                    
                except json.JSONDecodeError as json_error:
                    logger.warning(f"âŒ JSONè§£æå¤±è´¥: {json_error}")
                    
                    # ğŸ”§ å¤šå±‚çº§ä¿®å¤ç­–ç•¥ï¼Œå‡å°‘å¯¹fallbackçš„ä¾èµ–
                    repair_attempts = [
                        ("è½»é‡ä¿®å¤", lambda x: self._lightweight_json_repair(x)),
                        ("æ¿€è¿›ä¿®å¤", lambda x: self._aggressive_json_fix(x)),
                        ("ç»“æ„é‡å»º", lambda x: self._reconstruct_json_structure(x)),
                        ("å¥å£®å­—æ®µæå–", lambda x: self._robust_extract_fields(response)),  # æ–°å¢å¥å£®æå–å™¨
                    ]
                    
                    for repair_name, repair_func in repair_attempts:
                        try:
                            if repair_name == "å¥å£®å­—æ®µæå–":
                                # å¥å£®å­—æ®µæå–å™¨ç›´æ¥è¿”å›ç»“æœå­—å…¸
                                result = repair_func(json_text)
                                if result and result.get('action') != 'error':
                                    logger.info(f"âœ… ä½¿ç”¨{repair_name}æˆåŠŸæå–å­—æ®µ")
                                    return result
                            else:
                                # å…¶ä»–ä¿®å¤å™¨è¿”å›ä¿®å¤åçš„JSONå­—ç¬¦ä¸²
                                fixed_json = repair_func(json_text)
                                if fixed_json and fixed_json != json_text:
                                    parsed = json.loads(fixed_json)
                                    result = self._validate_and_complete_parsed_response(parsed)
                                    logger.info(f"âœ… ä½¿ç”¨{repair_name}æˆåŠŸè§£æJSON")
                                    return result
                        except json.JSONDecodeError as e:
                            logger.debug(f"âš ï¸ {repair_name}å¤±è´¥: {e}")
                            continue
                        except Exception as e:
                            logger.debug(f"âš ï¸ {repair_name}å¼‚å¸¸: {e}")
                            continue
                    
                    # å¦‚æœæ‰€æœ‰ä¿®å¤éƒ½å¤±è´¥ï¼Œæœ€åå°è¯•ä»åŸå§‹å“åº”ä¸­æ™ºèƒ½æå–
                    logger.warning("ğŸ”„ å°è¯•ä»åŸå§‹å“åº”æ™ºèƒ½æå–å­—æ®µ")
                    smart_extracted = self._smart_extract_from_response(response)
                    if smart_extracted and smart_extracted.get('action') != 'error':
                        logger.info("âœ… æ™ºèƒ½æå–æˆåŠŸï¼Œé¿å…ä½¿ç”¨fallback")
                        return smart_extracted
            
        except Exception as e:
            logger.error(f"âŒ å“åº”è§£æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        
        # ğŸ” å¢å¼ºçš„å¤‡ç”¨è§£ææ–¹æ³•
        logger.warning("ğŸ”„ ä½¿ç”¨å¤‡ç”¨è§£ææ–¹æ³•")
        return self._fallback_parse_response(response)
    
    def _validate_and_complete_parsed_response(self, parsed: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯å¹¶è¡¥å…¨è§£æåçš„å“åº”"""
        result = {}
        
        # è¡¥å…¨thinkingå­—æ®µ
        result['thinking'] = parsed.get('thinking', f"LLMå“åº”ç¼ºå°‘thinkingå­—æ®µ: {str(parsed)[:200]}")
        
        # è¡¥å…¨å¹¶éªŒè¯actionå­—æ®µ
        action = parsed.get('action', 'error')
        result['action'] = action
        
        # è¡¥å…¨å¹¶éªŒè¯tool_idå­—æ®µ
        tool_id = parsed.get('tool_id') or parsed.get('tool')
        
        # ğŸ” æ™ºèƒ½æ¨æ–­å·¥å…·ID
        if not tool_id:
            if action in ['search_and_install_tools', 'analyze_tool_needs']:
                tool_id = 'mcp-search-tool'
                logger.info(f"ğŸ”§ è‡ªåŠ¨æ¨æ–­å·¥å…·ID: {tool_id} (åŸºäºaction: {action})")
            elif 'search' in result['thinking'].lower() or 'install' in result['thinking'].lower():
                tool_id = 'mcp-search-tool'
                logger.info(f"ğŸ”§ åŸºäºthinkingå†…å®¹æ¨æ–­å·¥å…·ID: {tool_id}")
        
        result['tool_id'] = tool_id
        result['tool'] = tool_id  # å‘åå…¼å®¹
        
        # è¡¥å…¨parameterså­—æ®µ
        parameters = parsed.get('parameters', {})
        
        # ğŸ” åŸºäºactionæ™ºèƒ½è¡¥å…¨å‚æ•°
        if action in ['search_and_install_tools', 'analyze_tool_needs'] and not parameters.get('task_description'):
            # ä»thinkingä¸­æå–ä»»åŠ¡æè¿°
            thinking = result['thinking']
            if 'TASK ANALYSIS:' in thinking:
                task_desc_start = thinking.find('TASK ANALYSIS:') + len('TASK ANALYSIS:')
                task_desc_end = thinking.find('STEP 2', task_desc_start)
                if task_desc_end > task_desc_start:
                    task_desc = thinking[task_desc_start:task_desc_end].strip()
                    parameters['task_description'] = task_desc[:200]  # é™åˆ¶é•¿åº¦
        
        result['parameters'] = parameters
        
        # è¡¥å…¨å¹¶éªŒè¯confidenceå­—æ®µ
        confidence = parsed.get('confidence', 0.5)
        if not isinstance(confidence, (int, float)) or confidence < 0 or confidence > 1:
            confidence = 0.5
        result['confidence'] = confidence
        
        return result
    
    def _fallback_parse_response(self, response: str) -> Dict[str, Any]:
        """å¢å¼ºçš„å¤‡ç”¨è§£ææ–¹æ³• - ä¼˜åŒ–ç‰ˆæœ¬"""
        logger.info("ğŸ”„ æ‰§è¡Œå¢å¼ºå¤‡ç”¨è§£æ")
        
        # æ™ºèƒ½æˆªæ–­é•¿å“åº”ï¼Œä¼˜å…ˆä¿ç•™JSONç»“æ„
        if len(response) > 8000:
            logger.warning(f"âš ï¸ å“åº”è¿‡é•¿({len(response)}å­—ç¬¦)ï¼Œè¿›è¡Œæ™ºèƒ½æˆªæ–­")
            response = self._smart_truncate_response(response, 8000)
        
        # ğŸ” å¢å¼ºçš„å­—æ®µæå–
        result = {
            'thinking': self._extract_thinking_field(response),
            'action': self._extract_action_field(response),
            'tool_id': self._extract_tool_id_field(response),
            'parameters': self._extract_parameters_field(response),
            'confidence': self._extract_confidence_field(response)
        }
        
        # ğŸ” æ™ºèƒ½æ¨æ–­å’Œä¿®æ­£
        result = self._smart_inference_and_correction(result, response)
        
        # å‘åå…¼å®¹
        result['tool'] = result['tool_id']
        
        logger.info(f"ğŸ¯ å¤‡ç”¨è§£æç»“æœ: action={result['action']}, tool_id={result['tool_id']}")
        return result
    
    def _extract_thinking_field(self, response: str) -> str:
        """æå–thinkingå­—æ®µ"""
        patterns = [
            r'"thinking":\s*"([^"]*(?:\\.[^"]*)*)"',
            r'thinking["\']?\s*[:=]\s*["\']([^"\']*)["\']',
            r'STEP 1[^:]*:([^"]*?)(?:STEP 2|$)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, response, re.DOTALL | re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œè¿”å›å“åº”çš„å‰500å­—ç¬¦
        return response[:500]
    
    def _extract_action_field(self, response: str) -> str:
        """æå–actionå­—æ®µ"""
        patterns = [
            r'"action":\s*"([^"]+)"',
            r'action["\']?\s*[:=]\s*["\']([^"\']+)["\']',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, response, re.IGNORECASE)
            if match:
                return match.group(1)
        
        # ğŸ” åŸºäºå†…å®¹æ¨æ–­action
        if any(keyword in response.lower() for keyword in ['search', 'install', 'tool']):
            return 'search_and_install_tools'
        elif any(keyword in response.lower() for keyword in ['analyze', 'need']):
            return 'analyze_tool_needs'
        elif any(keyword in response.lower() for keyword in ['complete', 'finish', 'done']):
            return 'complete_task'
        
        return 'error'
    
    def _extract_tool_id_field(self, response: str) -> Optional[str]:
        """æå–tool_idå­—æ®µ"""
        patterns = [
            r'"tool_id":\s*"([^"]+)"',
            r'"tool":\s*"([^"]+)"',
            r'tool_id["\']?\s*[:=]\s*["\']([^"\']+)["\']',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, response, re.IGNORECASE)
            if match:
                return match.group(1)
        
        return None
    
    def _extract_parameters_field(self, response: str) -> Dict[str, Any]:
        """æå–parameterså­—æ®µ"""
        
        # å°è¯•æå–å®Œæ•´çš„parameterså¯¹è±¡
        params_match = re.search(r'"parameters":\s*(\{[^}]*\})', response, re.DOTALL)
        if params_match:
            try:
                return json.loads(params_match.group(1))
            except:
                pass
        
        # å¤‡ç”¨æ–¹æ¡ˆï¼šæå–å¸¸è§å‚æ•°
        params = {}
        
        # æå–task_description
        task_desc_patterns = [
            r'"task_description":\s*"([^"]*)"',
            r'task_description["\']?\s*[:=]\s*["\']([^"\']*)["\']',
        ]
        
        for pattern in task_desc_patterns:
            match = re.search(pattern, response, re.IGNORECASE)
            if match:
                params['task_description'] = match.group(1)
                break
        
        return params
    
    def _extract_confidence_field(self, response: str) -> float:
        """æå–confidenceå­—æ®µ"""
        
        patterns = [
            r'"confidence":\s*([0-9.]+)',
            r'confidence["\']?\s*[:=]\s*([0-9.]+)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, response, re.IGNORECASE)
            if match:
                try:
                    confidence = float(match.group(1))
                    return max(0.0, min(1.0, confidence))
                except:
                    pass
        
        return 0.5
    
    def _smart_inference_and_correction(self, result: Dict[str, Any], response: str) -> Dict[str, Any]:
        """æ™ºèƒ½æ¨æ–­å’Œä¿®æ­£ç»“æœ - ä¼˜åŒ–ç‰ˆæœ¬"""
        
        # é™åˆ¶æ–‡æœ¬é•¿åº¦ï¼Œæé«˜æ€§èƒ½
        response_sample = response[:1000].lower()  # åªæ£€æŸ¥å‰1000å­—ç¬¦
        
        # å¦‚æœactionæ˜¯errorä½†å“åº”ä¸­åŒ…å«å·¥å…·ç›¸å…³å†…å®¹ï¼Œå°è¯•ä¿®æ­£
        if result['action'] == 'error':
            if any(keyword in response_sample for keyword in ['mcp-search', 'search_and_install', 'tool']):
                result['action'] = 'search_and_install_tools'
                logger.info("ğŸ”§ ä¿®æ­£actionä¸º: search_and_install_tools")
        
        # å¦‚æœæ²¡æœ‰tool_idä½†actionéœ€è¦å·¥å…·ï¼Œè‡ªåŠ¨è®¾ç½®
        if not result['tool_id'] and result['action'] in ['search_and_install_tools', 'analyze_tool_needs']:
            result['tool_id'] = 'mcp-search-tool'
            logger.info("ğŸ”§ è‡ªåŠ¨è®¾ç½®tool_idä¸º: mcp-search-tool")
        
        # å¦‚æœparametersä¸ºç©ºä½†actionéœ€è¦å‚æ•°ï¼Œå°è¯•ç”Ÿæˆ
        if not result['parameters'] and result['action'] in ['search_and_install_tools', 'analyze_tool_needs']:
            # ä»thinkingä¸­æå–ä»»åŠ¡ç›¸å…³ä¿¡æ¯ï¼ˆé™åˆ¶å¤„ç†é•¿åº¦ï¼‰
            thinking = result['thinking'][:500]  # åªå¤„ç†å‰500å­—ç¬¦
            params = {}
            
            if 'ä»»åŠ¡' in thinking or 'task' in thinking.lower():
                # æå–å¯èƒ½çš„ä»»åŠ¡æè¿°
                lines = thinking.split('\n')[:10]  # æœ€å¤šæ£€æŸ¥10è¡Œ
                for line in lines:
                    if 'ä»»åŠ¡' in line or 'task' in line.lower():
                        # ç®€åŒ–çš„ä»»åŠ¡æè¿°æå–
                        task_desc = line.strip()[:100]
                        params['task_description'] = task_desc
                        break
            
            if params:
                result['parameters'] = params
                logger.info(f"ğŸ”§ ç”Ÿæˆå‚æ•°: {params}")
        
        return result
    
    def _fix_json_formatting_errors(self, json_text: str) -> str:
        """ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é”™è¯¯ - å¢å¼ºç‰ˆæœ¬"""
        # ğŸ”§ æ–°å¢ï¼šä¿®å¤ä¸­æ–‡æ ‡ç‚¹ç¬¦å·é—®é¢˜ - è§£å†³ "Expecting ':' delimiter" é”™è¯¯
        json_text = self._fix_chinese_punctuation(json_text)
        
        # ä¿®å¤æœªç»ˆæ­¢çš„å­—ç¬¦ä¸² - å¤„ç†"Unterminated string"é”™è¯¯
        json_text = self._fix_unterminated_strings(json_text)
        
        # ä¿®å¤ç¼ºå¤±å­—æ®µå¯¼è‡´çš„è¿ç»­é€—å·é—®é¢˜
        json_text = self._fix_missing_fields(json_text)
        
        # ğŸ”§ ä¿®å¤æ—¥å¿—ä¸­å‘ç°çš„å…·ä½“é”™è¯¯æ¨¡å¼
        
        # 1. ä¿®å¤ "Expecting ':' delimiter" é”™è¯¯
        json_text = self._fix_missing_colons(json_text)
        
        # 2. ä¿®å¤ "Expecting ',' delimiter" é”™è¯¯ 
        json_text = self._fix_missing_commas(json_text)
        
        # 3. ä¿®å¤ "Expecting property name enclosed in double quotes" é”™è¯¯
        json_text = self._fix_property_names(json_text)
        
        # ä¿®å¤å¸¸è§çš„é€—å·é”™è¯¯
        json_text = re.sub(r',\s*}', '}', json_text)  # ç§»é™¤å¯¹è±¡æœ€åçš„é€—å·
        json_text = re.sub(r',\s*]', ']', json_text)  # ç§»é™¤æ•°ç»„æœ€åçš„é€—å·
        
        # ä¿®å¤ç¼ºå°‘é€—å·çš„æƒ…å†µ
        json_text = re.sub(r'"\s*\n\s*"', '",\n"', json_text)  # å­—ç¬¦ä¸²ä¹‹é—´ç¼ºå°‘é€—å·
        json_text = re.sub(r'}\s*\n\s*"', '},\n"', json_text)  # å¯¹è±¡åç¼ºå°‘é€—å·
        
        # ä¿®å¤å¼•å·é—®é¢˜
        json_text = re.sub(r"'([^']*)':", r'"\1":', json_text)  # å•å¼•å·æ›¿æ¢ä¸ºåŒå¼•å·
        
        # ä¿®å¤å¸ƒå°”å€¼å’Œnull
        json_text = re.sub(r'\bTrue\b', 'true', json_text)
        json_text = re.sub(r'\bFalse\b', 'false', json_text)
        json_text = re.sub(r'\bNone\b', 'null', json_text)
        
        return json_text
    
    def _fix_chinese_punctuation(self, json_text: str) -> str:
        """ä¿®å¤ä¸­æ–‡æ ‡ç‚¹ç¬¦å·é—®é¢˜ - å…³é”®ä¿®å¤æ–¹æ³•"""
        try:
            # ä¿®å¤ä¸­æ–‡å†’å· "ï¼š" -> ":"
            json_text = json_text.replace('ï¼š', ':')
            
            # ä¿®å¤ä¸­æ–‡é€—å· "ï¼Œ" -> ","  
            json_text = json_text.replace('ï¼Œ', ',')
            
            # ä¿®å¤ä¸­æ–‡å¼•å· """ -> '"' å’Œ """ -> '"'
            json_text = json_text.replace('"', '"').replace('"', '"')
            
            # ä¿®å¤ä¸­æ–‡å•å¼•å· "'" -> "'" å’Œ "'" -> "'"
            json_text = json_text.replace(''', "'").replace(''', "'")
            
            # ä¿®å¤ä¸­æ–‡å¥å·ï¼ˆå¦‚æœå‡ºç°åœ¨JSONä¸­ï¼‰"ã€‚" -> "."
            json_text = json_text.replace('ã€‚', '.')
            
            # ä¿®å¤ä¸­æ–‡åˆ†å· "ï¼›" -> ";"
            json_text = json_text.replace('ï¼›', ';')
            
            logger.debug("ğŸ”§ å·²ä¿®å¤ä¸­æ–‡æ ‡ç‚¹ç¬¦å·")
            return json_text
            
        except Exception as e:
            logger.warning(f"ä¿®å¤ä¸­æ–‡æ ‡ç‚¹ç¬¦å·æ—¶å‡ºé”™: {e}")
            return json_text
    
    def _fix_missing_fields(self, json_text: str) -> str:
        """ä¿®å¤ç¼ºå¤±å­—æ®µå¯¼è‡´çš„JSONé”™è¯¯"""
        try:
            # ä¿®å¤è¿ç»­é€—å·é—®é¢˜ï¼ˆç¼ºå¤±å­—æ®µå¯¼è‡´ï¼‰
            json_text = re.sub(r',\s*,', ',', json_text)  # ç§»é™¤è¿ç»­é€—å·
            
            # ä¿®å¤ä»¥é€—å·å¼€å¤´çš„è¡Œï¼ˆç¼ºå¤±å­—æ®µå¯¼è‡´ï¼‰
            lines = json_text.split('\n')
            fixed_lines = []
            
            for i, line in enumerate(lines):
                stripped = line.strip()
                
                # å¦‚æœè¡Œä»¥é€—å·å¼€å¤´ï¼Œè¯´æ˜ä¸Šä¸€è¡Œç¼ºå¤±äº†å­—æ®µ
                if stripped.startswith(','):
                    # æ·»åŠ ä¸€ä¸ªå ä½å­—æ®µ
                    if i > 0 and not fixed_lines[-1].strip().endswith('{'):
                        # æ ¹æ®ä¸Šä¸‹æ–‡æ¨æ–­å¯èƒ½ç¼ºå¤±çš„å­—æ®µ
                        if 'content_identifier' in json_text and '"content_identifier"' not in fixed_lines[-1]:
                            fixed_lines[-1] = fixed_lines[-1].rstrip().rstrip(',') + ','
                            fixed_lines.append('            "content_identifier": "unknown"')
                        elif 'relationship' in json_text and '"relationship"' not in fixed_lines[-1]:
                            fixed_lines[-1] = fixed_lines[-1].rstrip().rstrip(',') + ','
                            fixed_lines.append('            "relationship": "unknown"')
                        else:
                            # é€šç”¨å ä½å­—æ®µ
                            fixed_lines[-1] = fixed_lines[-1].rstrip().rstrip(',') + ','
                            fixed_lines.append('            "missing_field": "placeholder"')
                    
                    # ç§»é™¤å¼€å¤´çš„é€—å·
                    line = line.lstrip().lstrip(',').lstrip()
                    if line:
                        fixed_lines.append('            ' + line)
                else:
                    fixed_lines.append(line)
            
            result = '\n'.join(fixed_lines)
            
            # æœ€åæ¸…ç†å¤šä½™çš„é€—å·å’Œç©ºè¡Œ
            result = re.sub(r',\s*\n\s*,', ',', result)
            result = re.sub(r'\n\s*\n', '\n', result)
            
            return result
            
        except Exception as e:
            logger.warning(f"âš ï¸ ä¿®å¤ç¼ºå¤±å­—æ®µæ—¶å‡ºé”™: {e}")
            return json_text
    
    def _fix_unterminated_strings(self, json_text: str) -> str:
        """ä¿®å¤æœªç»ˆæ­¢çš„å­—ç¬¦ä¸²é”™è¯¯"""
        try:
            # å¤„ç†å­—ç¬¦ä¸²ä¸­çš„æœªè½¬ä¹‰æ¢è¡Œç¬¦
            # å°†å­—ç¬¦ä¸²å€¼ä¸­çš„çœŸå®æ¢è¡Œç¬¦æ›¿æ¢ä¸º\\n
            def replace_newlines_in_strings(match):
                content = match.group(1)
                # åªè½¬ä¹‰æœªè½¬ä¹‰çš„æ¢è¡Œç¬¦
                content = content.replace('\n', '\\n')
                content = content.replace('\r', '\\r')
                content = content.replace('\t', '\\t')
                return f'"{content}"'
            
            # åŒ¹é…å­—ç¬¦ä¸²å€¼ï¼ˆä¸åŒ…æ‹¬é”®åï¼‰
            json_text = re.sub(r':\s*"([^"]*(?:\n[^"]*)*)"', replace_newlines_in_strings, json_text)
            
            # å¤„ç†å­—ç¬¦ä¸²ä¸­çš„æœªè½¬ä¹‰å¼•å·
            # æŸ¥æ‰¾å¯èƒ½æœ‰é—®é¢˜çš„å­—ç¬¦ä¸²å¹¶ä¿®å¤
            lines = json_text.split('\n')
            fixed_lines = []
            
            for line in lines:
                # æ£€æŸ¥æ˜¯å¦æœ‰æœªç»ˆæ­¢çš„å­—ç¬¦ä¸²ï¼ˆå¥‡æ•°ä¸ªå¼•å·ï¼‰
                quote_count = line.count('"')
                if quote_count % 2 == 1 and not line.strip().endswith('",') and not line.strip().endswith('"'):
                    # å¯èƒ½æ˜¯æœªç»ˆæ­¢çš„å­—ç¬¦ä¸²ï¼Œå°è¯•ä¿®å¤
                    if '": "' in line:
                        # æ‰¾åˆ°æœ€åä¸€ä¸ª": "å¹¶ç¡®ä¿å­—ç¬¦ä¸²æ­£ç¡®ç»ˆæ­¢
                        last_colon_quote = line.rfind('": "')
                        if last_colon_quote != -1:
                            before = line[:last_colon_quote + 4]
                            after = line[last_colon_quote + 4:]
                            # è½¬ä¹‰å†…éƒ¨å¼•å·å¹¶ç¡®ä¿å­—ç¬¦ä¸²ç»ˆæ­¢
                            after = after.replace('"', '\\"')
                            if not after.endswith('"'):
                                after += '"'
                            line = before + after
                
                fixed_lines.append(line)
            
            return '\n'.join(fixed_lines)
            
        except Exception as e:
            logger.warning(f"âš ï¸ ä¿®å¤æœªç»ˆæ­¢å­—ç¬¦ä¸²æ—¶å‡ºé”™: {e}")
            return json_text
    
    def _aggressive_json_fix(self, json_text: str) -> Optional[str]:
        """æ›´æ¿€è¿›çš„JSONä¿®å¤æ–¹æ³•"""
        try:
            # é¦–å…ˆåº”ç”¨åŸºæœ¬çš„å­—ç¬¦ä¸²ä¿®å¤
            json_text = self._fix_unterminated_strings(json_text)
            
            # å°è¯•ä¿®å¤æˆªæ–­çš„JSON
            if not json_text.strip().endswith('}'):
                # æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„å­—æ®µ
                lines = json_text.split('\n')
                valid_lines = []
                brace_count = 0
                in_string = False
                
                for line in lines:
                    # æ£€æŸ¥æ˜¯å¦åœ¨å­—ç¬¦ä¸²å†…éƒ¨ï¼ˆç®€å•æ£€æŸ¥ï¼‰
                    quote_count = line.count('"') - line.count('\\"')
                    if quote_count % 2 == 1:
                        in_string = not in_string
                    
                    # å¦‚æœä¸åœ¨å­—ç¬¦ä¸²å†…éƒ¨ï¼Œæ‰è®¡ç®—æ‹¬å·
                    if not in_string:
                        brace_count += line.count('{') - line.count('}')
                    
                    valid_lines.append(line)
                    
                    # å¦‚æœæ‹¬å·å¹³è¡¡ä¸”è¯¥è¡Œç»“æŸï¼Œå¯èƒ½æ˜¯ä¸ªå¥½çš„æˆªæ–­ç‚¹
                    if not in_string and brace_count == 0 and (line.strip().endswith(',') or line.strip().endswith('"')):
                        break
                
                # è¡¥é½ç¼ºå¤±çš„æ‹¬å·
                if brace_count > 0:
                    valid_lines.append('}' * brace_count)
                
                fixed_json = '\n'.join(valid_lines)
                
                # æ¸…ç†æœ€åçš„é€—å·
                fixed_json = re.sub(r',(\s*})$', r'\1', fixed_json, flags=re.MULTILINE)
                
                return fixed_json
            
            # å¦‚æœJSONçœ‹èµ·æ¥å®Œæ•´ï¼Œä½†ä»ç„¶æœ‰é”™è¯¯ï¼Œå°è¯•æ¸…ç†æ ¼å¼
            json_text = self._clean_json_format(json_text)
            return json_text
                
        except Exception as e:
            logger.debug(f"æ¿€è¿›JSONä¿®å¤å¤±è´¥: {e}")
            
        return None
    
    def _clean_json_format(self, json_text: str) -> str:
        """æ¸…ç†JSONæ ¼å¼ï¼Œå¤„ç†å¸¸è§çš„æ ¼å¼é—®é¢˜"""
        try:
            # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
            json_text = re.sub(r'\s+', ' ', json_text)
            
            # ä¿®å¤å­—ç¬¦ä¸²ä¸­çš„æ§åˆ¶å­—ç¬¦
            json_text = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', json_text)
            
            # ç¡®ä¿å­—ç¬¦ä¸²å€¼è¢«æ­£ç¡®å¼•ç”¨
            # ä¿®å¤æœªå¼•ç”¨çš„å­—ç¬¦ä¸²å€¼ï¼ˆä½†ä¿ç•™æ•°å­—ã€å¸ƒå°”å€¼å’Œnullï¼‰
            def quote_unquoted_strings(match):
                key = match.group(1)
                value = match.group(2).strip()
                
                # å¦‚æœå€¼å·²ç»è¢«å¼•ç”¨æˆ–æ˜¯æ•°å­—/å¸ƒå°”å€¼/nullï¼Œä¿æŒä¸å˜
                if (value.startswith('"') and value.endswith('"')) or \
                   value in ['true', 'false', 'null'] or \
                   re.match(r'^-?\d+(\.\d+)?$', value):
                    return f'"{key}": {value}'
                else:
                    # å¼•ç”¨æœªå¼•ç”¨çš„å­—ç¬¦ä¸²å€¼
                    return f'"{key}": "{value}"'
            
            json_text = re.sub(r'"([^"]+)":\s*([^,}\]]+)', quote_unquoted_strings, json_text)
            
            return json_text
            
        except Exception as e:
            logger.warning(f"âš ï¸ æ¸…ç†JSONæ ¼å¼æ—¶å‡ºé”™: {e}")
            return json_text
    
    def _fix_missing_colons(self, json_text: str) -> str:
        """ä¿®å¤ç¼ºå¤±å†’å·çš„é”™è¯¯ - å¤„ç† 'Expecting ':' delimiter' é”™è¯¯"""
        try:
            # 1. ä¿®å¤å±æ€§ååç¼ºå¤±å†’å·çš„æƒ…å†µ
            # åŒ¹é… "key" value æ¨¡å¼ï¼Œåº”è¯¥æ˜¯ "key": value
            json_text = re.sub(r'"([^"]+)"\s+(["\d\[\{])', r'"\1": \2', json_text)
            
            # 2. ä¿®å¤æ¢è¡Œå¯¼è‡´çš„å†’å·åˆ†ç¦»
            # åŒ¹é… "key"\n value æ¨¡å¼  
            json_text = re.sub(r'"([^"]+)"\s*\n\s*(["\d\[\{])', r'"\1": \2', json_text)
            
            # 3. ä¿®å¤ç‰¹æ®Šæƒ…å†µï¼šthinking å­—æ®µåç¼ºå¤±å†’å·
            json_text = re.sub(r'"thinking"\s+"([^"]*)"', r'"thinking": "\1"', json_text)
            json_text = re.sub(r'"action"\s+"([^"]*)"', r'"action": "\1"', json_text)
            json_text = re.sub(r'"confidence"\s+(\d+\.?\d*)', r'"confidence": \1', json_text)
            
            # 4. ä¿®å¤åœ¨è¡Œé¦–çš„å±æ€§ç¼ºå¤±å†’å·
            lines = json_text.split('\n')
            fixed_lines = []
            for line in lines:
                # æ£€æŸ¥æ˜¯å¦æ˜¯ "å±æ€§å" å€¼ çš„æ¨¡å¼
                if re.match(r'^\s*"[^"]+"\s+[^:]', line.strip()):
                    line = re.sub(r'"([^"]+)"\s+', r'"\1": ', line, 1)
                fixed_lines.append(line)
            
            return '\n'.join(fixed_lines)
            
        except Exception as e:
            logger.warning(f"âš ï¸ ä¿®å¤ç¼ºå¤±å†’å·æ—¶å‡ºé”™: {e}")
            return json_text
    
    def _fix_missing_commas(self, json_text: str) -> str:
        """ä¿®å¤ç¼ºå¤±é€—å·çš„é”™è¯¯ - å¤„ç† 'Expecting ',' delimiter' é”™è¯¯"""
        try:
            # 1. ä¿®å¤å¯¹è±¡å±æ€§ä¹‹é—´ç¼ºå¤±é€—å·
            # åŒ¹é… "key": "value"\n  "key2": "value2" æ¨¡å¼
            json_text = re.sub(r'("\s*)\n\s*(")', r'\1,\n\2', json_text)
            
            # 2. ä¿®å¤æ•°ç»„å…ƒç´ ä¹‹é—´ç¼ºå¤±é€—å·
            # åŒ¹é… }\n  { æ¨¡å¼ï¼ˆå¯¹è±¡æ•°ç»„ï¼‰
            json_text = re.sub(r'(\})\s*\n\s*(\{)', r'\1,\n\2', json_text)
            
            # 3. ä¿®å¤æ•°å€¼åç¼ºå¤±é€—å·
            json_text = re.sub(r'(\d+\.?\d*)\s*\n\s*"', r'\1,\n"', json_text)
            
            # 4. ä¿®å¤å¸ƒå°”å€¼å’Œnullåç¼ºå¤±é€—å·
            json_text = re.sub(r'(true|false|null)\s*\n\s*"', r'\1,\n"', json_text)
            
            # 5. ç‰¹åˆ«å¤„ç†é•¿å­—ç¬¦ä¸²æˆªæ–­å¯¼è‡´çš„é€—å·ç¼ºå¤±
            # å¦‚æœåœ¨ç¬¬6999å­—ç¬¦é™„è¿‘ç¼ºå¤±é€—å·ï¼ˆæ ¹æ®æ—¥å¿—é”™è¯¯ï¼‰
            if len(json_text) > 6990:
                # åœ¨7000å­—ç¬¦é™„è¿‘æŸ¥æ‰¾å¯èƒ½çš„é€—å·ç¼ºå¤±
                substr = json_text[6990:7010]
                if '"' in substr and ',' not in substr:
                    # åœ¨å¼•å·åæ·»åŠ é€—å·
                    json_text = json_text[:6999] + ',' + json_text[6999:]
            
            return json_text
            
        except Exception as e:
            logger.warning(f"âš ï¸ ä¿®å¤ç¼ºå¤±é€—å·æ—¶å‡ºé”™: {e}")
            return json_text
    
    def _fix_property_names(self, json_text: str) -> str:
        """ä¿®å¤å±æ€§åæ ¼å¼é”™è¯¯ - å¤„ç† 'Expecting property name enclosed in double quotes' é”™è¯¯"""
        try:
            # 1. ä¿®å¤æœªå¼•ç”¨çš„å±æ€§å
            json_text = re.sub(r'([^"\s\{\[,]\w+):', r'"\1":', json_text)
            
            # 2. ä¿®å¤å•å¼•å·å±æ€§å
            json_text = re.sub(r"'([^']+)':", r'"\1":', json_text)
            
            # 3. ä¿®å¤é€—å·åç›´æ¥è·Ÿå€¼çš„æƒ…å†µï¼ˆç¼ºå¤±å±æ€§åï¼‰
            # è¿™ç§æƒ…å†µé€šå¸¸å‘ç”Ÿåœ¨content_identifierå­—æ®µç¼ºå¤±
            lines = json_text.split('\n')
            fixed_lines = []
            
            for i, line in enumerate(lines):
                stripped = line.strip()
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ , "value" æˆ– , value æ¨¡å¼ï¼ˆç¼ºå¤±å±æ€§åï¼‰
                if re.match(r'^,\s*"', stripped):
                    # æ ¹æ®ä¸Šä¸‹æ–‡æ·»åŠ åˆé€‚çš„å±æ€§å
                    if 'content_identifier' in json_text.lower():
                        # æ·»åŠ content_identifierå±æ€§
                        indent = len(line) - len(line.lstrip())
                        fixed_lines.append(' ' * indent + '"content_identifier": "unknown",')
                        # ç§»é™¤è¡Œé¦–çš„é€—å·
                        line = line.replace(',', '', 1)
                    elif 'relationship' in json_text.lower():
                        indent = len(line) - len(line.lstrip())
                        fixed_lines.append(' ' * indent + '"relationship": "unknown",')
                        line = line.replace(',', '', 1)
                
                # 4. ä¿®å¤ç¼ºå¤±å¼•å·çš„å±æ€§å
                if ':' in stripped and not stripped.startswith('"'):
                    # æŸ¥æ‰¾å±æ€§å
                    colon_pos = stripped.find(':')
                    prop_name = stripped[:colon_pos].strip()
                    if prop_name and not prop_name.startswith('"'):
                        # æ·»åŠ å¼•å·
                        rest = stripped[colon_pos:]
                        line = line.replace(stripped, f'"{prop_name}"{rest}')
                
                fixed_lines.append(line)
            
            return '\n'.join(fixed_lines)
            
        except Exception as e:
            logger.warning(f"âš ï¸ ä¿®å¤å±æ€§åæ—¶å‡ºé”™: {e}")
            return json_text
    
    def _smart_truncate_response(self, response: str, max_length: int) -> str:
        """æ™ºèƒ½æˆªæ–­å“åº”ï¼Œä¼˜å…ˆä¿ç•™JSONç»“æ„"""
        try:
            if len(response) <= max_length:
                return response
            
            # 1. å°è¯•æ‰¾åˆ°JSONä»£ç å—
            json_patterns = [
                r'```json\s*(\{.*?\})\s*```',
                r'```\s*(\{.*?\})\s*```',
                r'(\{[^{}]*"thinking"[^{}]*\})'
            ]
            
            for pattern in json_patterns:
                match = re.search(pattern, response, re.DOTALL)
                if match:
                    json_content = match.group(1)
                    if len(json_content) <= max_length:
                        # å¦‚æœJSONå†…å®¹ä¸è¶…è¿‡é™åˆ¶ï¼Œè¿”å›å®Œæ•´JSON
                        logger.info(f"ğŸ¯ ä¿ç•™å®Œæ•´JSONç»“æ„ ({len(json_content)} å­—ç¬¦)")
                        return json_content
            
            # 2. å¦‚æœæ²¡æœ‰æ‰¾åˆ°å®Œæ•´JSONï¼Œæ™ºèƒ½æˆªæ–­
            # æŸ¥æ‰¾JSONå¼€å§‹ä½ç½®
            json_start = -1
            for start_char in ['{', '[']:
                pos = response.find(start_char)
                if pos != -1 and (json_start == -1 or pos < json_start):
                    json_start = pos
            
            if json_start != -1 and json_start < max_length:
                # ä»JSONå¼€å§‹ä½ç½®æˆªæ–­
                truncated = response[json_start:json_start + max_length]
                
                # å°è¯•æ‰¾åˆ°ä¸€ä¸ªåˆç†çš„ç»“æŸç‚¹
                # ä¼˜å…ˆåœ¨å®Œæ•´çš„JSONå¯¹è±¡ç»“æŸ
                brace_count = 0
                last_valid_pos = len(truncated)
                
                for i, char in enumerate(truncated):
                    if char == '{':
                        brace_count += 1
                    elif char == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            last_valid_pos = i + 1
                            break
                
                # å¦‚æœæ‰¾åˆ°äº†å®Œæ•´çš„JSONå¯¹è±¡
                if last_valid_pos < len(truncated):
                    result = truncated[:last_valid_pos]
                    logger.info(f"ğŸ¯ æ™ºèƒ½æˆªæ–­ä¿ç•™å®Œæ•´JSONå¯¹è±¡ ({len(result)} å­—ç¬¦)")
                    return result
                
                # å¦åˆ™åœ¨æœ€åä¸€ä¸ªæ¢è¡Œç¬¦å¤„æˆªæ–­
                last_newline = truncated.rfind('\n', 0, max_length - 100)
                if last_newline > max_length // 2:
                    result = truncated[:last_newline]
                    logger.info(f"ğŸ¯ åœ¨æ¢è¡Œç¬¦å¤„æˆªæ–­ ({len(result)} å­—ç¬¦)")
                    return result
                
                logger.info(f"ğŸ¯ ä»JSONå¼€å§‹ä½ç½®æˆªæ–­ ({len(truncated)} å­—ç¬¦)")
                return truncated
            
            # 3. ç®€å•æˆªæ–­ç­–ç•¥
            # å°è¯•åœ¨å¥å­è¾¹ç•Œæˆªæ–­
            truncated = response[:max_length]
            sentence_ends = ['.', '!', '?', 'ã€‚', 'ï¼', 'ï¼Ÿ', '\n']
            
            for end_char in sentence_ends:
                last_pos = truncated.rfind(end_char, max_length - 200)
                if last_pos > max_length // 2:
                    result = truncated[:last_pos + 1]
                    logger.info(f"ğŸ¯ åœ¨å¥å­è¾¹ç•Œæˆªæ–­ ({len(result)} å­—ç¬¦)")
                    return result
            
            # æœ€åçš„ç®€å•æˆªæ–­
            logger.info(f"ğŸ¯ ç®€å•æˆªæ–­ ({max_length} å­—ç¬¦)")
            return response[:max_length]
            
        except Exception as e:
            logger.warning(f"âš ï¸ æ™ºèƒ½æˆªæ–­å¤±è´¥: {e}")
            return response[:max_length]
    
    def _lightweight_json_repair(self, json_text: str) -> Optional[str]:
        """è½»é‡çº§JSONä¿®å¤ï¼Œå¤„ç†å¸¸è§å°é”™è¯¯"""
        try:
            # 1. ä¿®å¤å¸¸è§çš„å¼•å·é”™è¯¯
            json_text = re.sub(r'([^\\])"([^"]*)"([^:])', r'\1"\2"\3', json_text)
            
            # 2. ä¿®å¤ç¼ºå¤±çš„é€—å·ï¼ˆå­—ç¬¦ä¸²åç›´æ¥è·Ÿå­—ç¬¦ä¸²ï¼‰
            json_text = re.sub(r'(")\s*\n\s*(")', r'\1,\n\2', json_text)
            
            # 3. ä¿®å¤å¤šä½™çš„é€—å·
            json_text = re.sub(r',\s*([}\]])', r'\1', json_text)
            
            # 4. ä¿®å¤ç¼ºå¤±çš„å†’å·
            json_text = re.sub(r'"([^"]+)"\s+(["{[])', r'"\1": \2', json_text)
            
            return json_text
            
        except Exception as e:
            logger.debug(f"è½»é‡çº§ä¿®å¤å¤±è´¥: {e}")
            return None
    
    def _reconstruct_json_structure(self, json_text: str) -> Optional[str]:
        """é‡å»ºJSONç»“æ„ï¼Œä»ç ´æŸçš„JSONä¸­æå–å…³é”®ä¿¡æ¯"""
        try:
            # æå–å…³é”®å­—æ®µçš„å€¼
            fields = {}
            
            # æå–thinkingå­—æ®µ
            thinking_match = re.search(r'"thinking":\s*"([^"]*(?:\\.[^"]*)*)"', json_text, re.DOTALL)
            if thinking_match:
                fields['thinking'] = thinking_match.group(1)
            else:
                # æŸ¥æ‰¾STEPå¼€å¤´çš„å†…å®¹ä½œä¸ºthinking
                step_match = re.search(r'(STEP[^"]*?)(?:"|$)', json_text, re.DOTALL)
                if step_match:
                    fields['thinking'] = step_match.group(1)[:500]  # é™åˆ¶é•¿åº¦
            
            # æå–actionå­—æ®µ
            action_match = re.search(r'"action":\s*"([^"]+)"', json_text)
            if action_match:
                fields['action'] = action_match.group(1)
            
            # æå–tool_idå­—æ®µ
            tool_match = re.search(r'"tool_id":\s*"([^"]+)"', json_text)
            if tool_match:
                fields['tool_id'] = tool_match.group(1)
            
            # æå–confidenceå­—æ®µ
            conf_match = re.search(r'"confidence":\s*([0-9.]+)', json_text)
            if conf_match:
                fields['confidence'] = float(conf_match.group(1))
            
            # æå–parameterså­—æ®µï¼ˆç®€åŒ–å¤„ç†ï¼‰
            params_match = re.search(r'"parameters":\s*(\{[^}]*\})', json_text)
            if params_match:
                try:
                    fields['parameters'] = json.loads(params_match.group(1))
                except:
                    fields['parameters'] = {}
            
            # å¦‚æœæå–åˆ°äº†å…³é”®å­—æ®µï¼Œé‡å»ºJSON
            if len(fields) >= 2:  # è‡³å°‘æœ‰2ä¸ªå­—æ®µæ‰é‡å»º
                reconstructed = {
                    'thinking': fields.get('thinking', 'No thinking extracted'),
                    'action': fields.get('action', 'search_and_install_tools'),
                    'tool_id': fields.get('tool_id', 'mcp-search-tool'),
                    'parameters': fields.get('parameters', {}),
                    'confidence': fields.get('confidence', 0.7)
                }
                
                logger.info(f"ğŸ”§ é‡å»ºJSONç»“æ„ï¼Œæå–äº† {len(fields)} ä¸ªå­—æ®µ")
                return json.dumps(reconstructed, ensure_ascii=False)
            
            return None
            
        except Exception as e:
            logger.debug(f"JSONç»“æ„é‡å»ºå¤±è´¥: {e}")
            return None
    
    def _smart_extract_from_response(self, response: str) -> Optional[Dict[str, Any]]:
        """ä»åŸå§‹å“åº”ä¸­æ™ºèƒ½æå–å­—æ®µï¼Œæ— éœ€å®Œæ•´JSON"""
        try:
            result = {}
            
            # 1. æå–thinking - æŸ¥æ‰¾STEPå¼€å¤´æˆ–thinkingå­—æ®µ
            thinking_patterns = [
                r'STEP 1[^:]*:([^"]*?)(?:STEP 2|$)',
                r'"thinking":\s*"([^"]*(?:\\.[^"]*)*)"',
                r'thinking["\']?\s*[:=]\s*["\']([^"\']*)["\']'
            ]
            
            for pattern in thinking_patterns:
                match = re.search(pattern, response, re.DOTALL | re.IGNORECASE)
                if match:
                    result['thinking'] = match.group(1).strip()[:1000]  # é™åˆ¶é•¿åº¦
                    break
            
            if not result.get('thinking'):
                result['thinking'] = response[:300]  # ä½¿ç”¨å“åº”å‰300å­—ç¬¦ä½œä¸ºthinking
            
            # 2. æ™ºèƒ½æ¨æ–­action
            action_keywords = {
                'search_and_install_tools': ['æœç´¢', 'search', 'æŸ¥æ‰¾', 'å·¥å…·', 'tool', 'install'],
                'analyze_tool_needs': ['åˆ†æ', 'analyze', 'éœ€è¦', 'need', 'è¯„ä¼°'],
                'complete_task': ['å®Œæˆ', 'complete', 'ç»“æŸ', 'finish', 'æ€»ç»“', 'summary']
            }
            
            response_lower = response.lower()
            action_scores = {}
            
            for action, keywords in action_keywords.items():
                score = sum(1 for keyword in keywords if keyword in response_lower)
                if score > 0:
                    action_scores[action] = score
            
            if action_scores:
                result['action'] = max(action_scores.items(), key=lambda x: x[1])[0]
            else:
                result['action'] = 'search_and_install_tools'  # é»˜è®¤action
            
            # 3. æ¨æ–­tool_id
            tool_patterns = [
                r'"tool_id":\s*"([^"]+)"',
                r'"tool":\s*"([^"]+)"',
                r'tool["\']?\s*[:=]\s*["\']([^"\']+)["\']'
            ]
            
            for pattern in tool_patterns:
                match = re.search(pattern, response, re.IGNORECASE)
                if match:
                    result['tool_id'] = match.group(1)
                    break
            
            if not result.get('tool_id'):
                # åŸºäºactionæ¨æ–­tool_id
                if result['action'] in ['search_and_install_tools', 'analyze_tool_needs']:
                    result['tool_id'] = 'mcp-search-tool'
                else:
                    result['tool_id'] = 'deepsearch-mcp-server'
            
            # 4. æå–confidence
            conf_patterns = [
                r'"confidence":\s*([0-9.]+)',
                r'confidence["\']?\s*[:=]\s*([0-9.]+)'
            ]
            
            for pattern in conf_patterns:
                match = re.search(pattern, response)
                if match:
                    try:
                        result['confidence'] = float(match.group(1))
                        break
                    except:
                        pass
            
            if 'confidence' not in result:
                result['confidence'] = 0.8  # é»˜è®¤ç½®ä¿¡åº¦
            
            # 5. æå–æˆ–ç”Ÿæˆparameters
            result['parameters'] = {}
            
            # å°è¯•æå–task_description
            if result['action'] in ['search_and_install_tools', 'analyze_tool_needs']:
                # ä»thinkingä¸­æå–ä»»åŠ¡æè¿°
                thinking = result.get('thinking', '')
                if 'TASK ANALYSIS:' in thinking:
                    task_start = thinking.find('TASK ANALYSIS:') + len('TASK ANALYSIS:')
                    task_end = thinking.find('STEP 2', task_start)
                    if task_end == -1:
                        task_end = task_start + 200
                    task_desc = thinking[task_start:task_end].strip()
                    if task_desc:
                        result['parameters']['task_description'] = task_desc[:200]
            
            # å‘åå…¼å®¹
            result['tool'] = result['tool_id']
            
            logger.info(f"ğŸ¯ æ™ºèƒ½æå–å®Œæˆ: action={result['action']}, tool_id={result['tool_id']}")
            return result
            
        except Exception as e:
            logger.warning(f"âš ï¸ æ™ºèƒ½æå–å¤±è´¥: {e}")
            return None
    
    def _robust_extract_fields(self, response: str) -> Optional[Dict[str, Any]]:
        """å¥å£®çš„å­—æ®µæå–å™¨ - æœ€ç»ˆé˜²çº¿ï¼Œå³ä½¿JSONå®Œå…¨æ— æ³•è§£æä¹Ÿèƒ½æå–æ ¸å¿ƒä¿¡æ¯"""
        try:
            logger.info("ğŸ›¡ï¸ ä½¿ç”¨å¥å£®å­—æ®µæå–å™¨ä½œä¸ºæœ€ç»ˆé˜²çº¿")
            result = {}
            
            # 1. æå–thinkingå­—æ®µ - ä½¿ç”¨å¤šä¸ªç­–ç•¥
            thinking_extracted = False
            
            # ç­–ç•¥1: æŸ¥æ‰¾thinkingå­—æ®µï¼ˆå®½æ¾åŒ¹é…ï¼‰
            thinking_patterns = [
                r'["\']?thinking["\']?\s*[:ï¼š]\s*["\']([^"\']*)["\']',
                r'thinking\s*[:ï¼š]\s*([^,}\n]*)',
                r'STEP\s*1[^:]*[:ï¼š]([^"]*?)(?:STEP\s*2|action|tool_id|$)',
                r'ä»»åŠ¡åˆ†æ[^:]*[:ï¼š]([^"]*?)(?:æ­¥éª¤|STEP|action|$)'
            ]
            
            for pattern in thinking_patterns:
                match = re.search(pattern, response, re.DOTALL | re.IGNORECASE)
                if match:
                    thinking_content = match.group(1).strip()
                    if len(thinking_content) > 10:  # ç¡®ä¿å†…å®¹æœ‰æ„ä¹‰
                        result['thinking'] = thinking_content[:1000]
                        thinking_extracted = True
                        logger.debug(f"ğŸ” æå–thinkingæˆåŠŸ (æ¨¡å¼: {pattern[:30]}...)")
                        break
            
            if not thinking_extracted:
                # å¤‡ç”¨ç­–ç•¥ï¼šä½¿ç”¨å“åº”çš„å‰éƒ¨åˆ†ä½œä¸ºthinking
                response_clean = re.sub(r'[{}"\[\],]', ' ', response)
                sentences = response_clean.split('.')[:3]  # å–å‰3å¥
                result['thinking'] = '. '.join(sentences)[:500]
                logger.debug("ğŸ” ä½¿ç”¨å“åº”å‰éƒ¨åˆ†ä½œä¸ºthinking")
            
            # 2. æå–actionå­—æ®µ - æ™ºèƒ½æ¨æ–­
            action_patterns = [
                r'["\']?action["\']?\s*[:ï¼š]\s*["\']([^"\']*)["\']',
                r'action\s*[:ï¼š]\s*([a-zA-Z_]+)',
                r'éœ€è¦(æœç´¢|æŸ¥æ‰¾|å®‰è£…).*å·¥å…·',
                r'(æœç´¢|search).*å·¥å…·',
                r'(åˆ†æ|analyze).*éœ€è¦'
            ]
            
            action_found = False
            for pattern in action_patterns:
                match = re.search(pattern, response, re.IGNORECASE)
                if match:
                    if 'æœç´¢' in match.group(0) or 'search' in match.group(0).lower():
                        result['action'] = 'search_and_install_tools'
                    elif 'åˆ†æ' in match.group(0) or 'analyze' in match.group(0).lower():
                        result['action'] = 'analyze_tool_needs'
                    else:
                        extracted_action = match.group(1) if len(match.groups()) > 0 else 'search_and_install_tools'
                        result['action'] = extracted_action
                    action_found = True
                    logger.debug(f"ğŸ” æå–actionæˆåŠŸ: {result['action']}")
                    break
            
            if not action_found:
                # åŸºäºå…³é”®è¯æ¨æ–­action
                if any(keyword in response.lower() for keyword in ['æœç´¢', 'search', 'å·¥å…·', 'tool', 'å®‰è£…', 'install']):
                    result['action'] = 'search_and_install_tools'
                elif any(keyword in response.lower() for keyword in ['åˆ†æ', 'analyze', 'éœ€è¦', 'need']):
                    result['action'] = 'analyze_tool_needs'
                else:
                    result['action'] = 'search_and_install_tools'  # é»˜è®¤
                logger.debug(f"ğŸ” åŸºäºå…³é”®è¯æ¨æ–­action: {result['action']}")
            
            # 3. æå–tool_idå­—æ®µ
            tool_patterns = [
                r'["\']?tool_id["\']?\s*[:ï¼š]\s*["\']([^"\']*)["\']',
                r'["\']?tool["\']?\s*[:ï¼š]\s*["\']([^"\']*)["\']',
                r'å·¥å…·ID\s*[:ï¼š]\s*([^\s,}]*)',
                r'ä½¿ç”¨.*å·¥å…·\s*[:ï¼š]?\s*([a-zA-Z0-9_-]+)'
            ]
            
            tool_found = False
            for pattern in tool_patterns:
                match = re.search(pattern, response, re.IGNORECASE)
                if match:
                    tool_id = match.group(1).strip()
                    if tool_id and len(tool_id) > 2:  # ç¡®ä¿tool_idæœ‰æ„ä¹‰
                        result['tool_id'] = tool_id
                        tool_found = True
                        logger.debug(f"ğŸ” æå–tool_idæˆåŠŸ: {tool_id}")
                        break
            
            if not tool_found:
                # åŸºäºactionæ¨æ–­tool_id
                if result['action'] in ['search_and_install_tools', 'analyze_tool_needs']:
                    result['tool_id'] = 'mcp-search-tool'
                else:
                    result['tool_id'] = 'deepsearch-mcp-server'
                logger.debug(f"ğŸ” åŸºäºactionæ¨æ–­tool_id: {result['tool_id']}")
            
            # 4. æå–æˆ–ç”Ÿæˆparameters
            result['parameters'] = {}
            
            # å°è¯•æå–task_description
            if result['action'] in ['search_and_install_tools', 'analyze_tool_needs']:
                # ä»thinkingä¸­æå–ä»»åŠ¡æè¿°çš„å…³é”®éƒ¨åˆ†
                thinking = result.get('thinking', '')
                
                # æŸ¥æ‰¾ä»»åŠ¡ç›¸å…³çš„æè¿°
                task_patterns = [
                    r'ä»»åŠ¡[:ï¼š]([^ã€‚\n]*)',
                    r'TASK[^:]*[:ï¼š]([^.\n]*)',
                    r'éœ€è¦([^ã€‚\n]*å·¥å…·[^ã€‚\n]*)',
                    r'è¦æ±‚([^ã€‚\n]*)'
                ]
                
                for pattern in task_patterns:
                    match = re.search(pattern, thinking, re.IGNORECASE)
                    if match:
                        task_desc = match.group(1).strip()
                        if len(task_desc) > 5:
                            result['parameters']['task_description'] = task_desc[:200]
                            logger.debug(f"ğŸ” æå–task_descriptionæˆåŠŸ")
                            break
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å…·ä½“çš„ä»»åŠ¡æè¿°ï¼Œä½¿ç”¨thinkingçš„æ‘˜è¦
                if not result['parameters'].get('task_description'):
                    # æå–thinkingä¸­çš„å…³é”®è¯ä½œä¸ºä»»åŠ¡æè¿°
                    keywords = re.findall(r'[\u4e00-\u9fff]+|[a-zA-Z]+', thinking)
                    if keywords:
                        task_summary = ' '.join(keywords[:15])  # å–å‰15ä¸ªè¯
                        result['parameters']['task_description'] = task_summary
                        logger.debug("ğŸ” ç”Ÿæˆtask_descriptionæ‘˜è¦")
            
            # 5. è®¾ç½®confidenceå’Œå…¶ä»–å­—æ®µ
            result['confidence'] = 0.6  # å¥å£®æå–å™¨çš„ç½®ä¿¡åº¦è¾ƒä½
            result['tool'] = result['tool_id']  # å‘åå…¼å®¹
            
            # 6. éªŒè¯æå–ç»“æœçš„è´¨é‡
            if len(result.get('thinking', '')) < 5:
                logger.warning("å¥å£®æå–å™¨: thinkingå­—æ®µè´¨é‡ä¸è¶³")
                return None
            
            if not result.get('action') or not result.get('tool_id'):
                logger.warning("å¥å£®æå–å™¨: ç¼ºå°‘å…³é”®å­—æ®µ")
                return None
            
            logger.info(f"ğŸ›¡ï¸ å¥å£®å­—æ®µæå–æˆåŠŸ: action={result['action']}, tool_id={result['tool_id']}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ å¥å£®å­—æ®µæå–å™¨å¤±è´¥: {e}")
            return None