#!/usr/bin/env python3
"""
å…±äº«å·¥ä½œåŒºç®¡ç†å™¨ - è§£å†³å·¥å…·é—´"ä¿¡æ¯å­¤å²›"é—®é¢˜
æä¾›å®‰å…¨çš„è·¨å·¥å…·æ•°æ®ä¼ é€’æœºåˆ¶
"""

import os
import json
import tempfile
import logging
from pathlib import Path
from typing import Dict, Any, Optional, List
from datetime import datetime, timedelta
import hashlib
import threading
from contextlib import contextmanager
import shutil

logger = logging.getLogger(__name__)

class SharedWorkspaceManager:
    """å…±äº«å·¥ä½œåŒºç®¡ç†å™¨"""
    
    def __init__(self, workspace_root: str = "/tmp/agent_workspace"):
        self.workspace_root = Path(workspace_root)
        self.workspace_root.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºå­ç›®å½•
        self.data_dir = self.workspace_root / "data"
        self.temp_dir = self.workspace_root / "temp" 
        self.session_dir = self.workspace_root / "sessions"
        self.export_dir = self.workspace_root / "exports"
        
        for directory in [self.data_dir, self.temp_dir, self.session_dir, self.export_dir]:
            directory.mkdir(parents=True, exist_ok=True)
            
        self._lock = threading.RLock()
        self._active_sessions = {}
        
        logger.info(f"âœ… å…±äº«å·¥ä½œåŒºåˆå§‹åŒ–å®Œæˆ: {self.workspace_root}")
    
    def create_session(self, session_id: str, metadata: Optional[Dict[str, Any]] = None) -> Path:
        """åˆ›å»ºä¼šè¯å·¥ä½œåŒº"""
        with self._lock:
            session_path = self.session_dir / session_id
            session_path.mkdir(parents=True, exist_ok=True)
            
            # åˆ›å»ºä¼šè¯å…ƒæ•°æ®
            session_metadata = {
                "session_id": session_id,
                "created_at": datetime.now().isoformat(),
                "metadata": metadata or {},
                "active": True,
                "files_created": [],
                "data_exported": []
            }
            
            metadata_file = session_path / "session_metadata.json"
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(session_metadata, f, indent=2, ensure_ascii=False)
            
            self._active_sessions[session_id] = session_path
            logger.info(f"ğŸ“ åˆ›å»ºä¼šè¯å·¥ä½œåŒº: {session_id} -> {session_path}")
            return session_path
    
    def get_session_path(self, session_id: str) -> Optional[Path]:
        """è·å–ä¼šè¯è·¯å¾„"""
        session_path = self.session_dir / session_id
        if session_path.exists():
            return session_path
        return None
    
    def save_data(self, session_id: str, data_key: str, data: Any, 
                  file_format: str = "json") -> Path:
        """ä¿å­˜æ•°æ®åˆ°å…±äº«å·¥ä½œåŒº"""
        session_path = self.get_session_path(session_id)
        if not session_path:
            session_path = self.create_session(session_id)
        
        # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
        safe_key = self._sanitize_filename(data_key)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        if file_format == "json":
            filename = f"{safe_key}_{timestamp}.json"
            file_path = session_path / filename
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
        
        elif file_format == "text":
            filename = f"{safe_key}_{timestamp}.txt"
            file_path = session_path / filename
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(str(data))
        
        elif file_format == "csv":
            filename = f"{safe_key}_{timestamp}.csv"
            file_path = session_path / filename
            if hasattr(data, 'to_csv'):  # pandas DataFrame
                data.to_csv(file_path, index=False)
            else:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(str(data))
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_format}")
        
        # æ›´æ–°ä¼šè¯å…ƒæ•°æ®
        self._update_session_metadata(session_id, "files_created", str(file_path))
        
        logger.info(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜: {data_key} -> {file_path}")
        return file_path
    
    def load_data(self, session_id: str, data_key: str = None, 
                  file_path: str = None) -> Any:
        """ä»å…±äº«å·¥ä½œåŒºåŠ è½½æ•°æ®"""
        session_path = self.get_session_path(session_id)
        if not session_path:
            raise FileNotFoundError(f"ä¼šè¯ä¸å­˜åœ¨: {session_id}")
        
        if file_path:
            # ç›´æ¥ä½¿ç”¨æŒ‡å®šæ–‡ä»¶è·¯å¾„
            target_file = session_path / file_path
        elif data_key:
            # æŸ¥æ‰¾æœ€æ–°çš„åŒ¹é…æ–‡ä»¶
            safe_key = self._sanitize_filename(data_key)
            pattern = f"{safe_key}_*.json"
            matching_files = list(session_path.glob(pattern))
            if not matching_files:
                # å°è¯•å…¶ä»–æ ¼å¼
                for ext in ['txt', 'csv']:
                    pattern = f"{safe_key}_*.{ext}"
                    matching_files = list(session_path.glob(pattern))
                    if matching_files:
                        break
            
            if not matching_files:
                raise FileNotFoundError(f"æœªæ‰¾åˆ°æ•°æ®: {data_key}")
            
            # é€‰æ‹©æœ€æ–°æ–‡ä»¶
            target_file = max(matching_files, key=lambda p: p.stat().st_mtime)
        else:
            raise ValueError("å¿…é¡»æŒ‡å®š data_key æˆ– file_path")
        
        # æ ¹æ®æ–‡ä»¶æ‰©å±•ååŠ è½½æ•°æ®
        if target_file.suffix == '.json':
            with open(target_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
        else:
            with open(target_file, 'r', encoding='utf-8') as f:
                data = f.read()
        
        logger.info(f"ğŸ“‚ æ•°æ®å·²åŠ è½½: {target_file}")
        return data
    
    def list_session_files(self, session_id: str) -> List[Dict[str, Any]]:
        """åˆ—å‡ºä¼šè¯ä¸­çš„æ‰€æœ‰æ–‡ä»¶"""
        session_path = self.get_session_path(session_id)
        if not session_path:
            return []
        
        files = []
        for file_path in session_path.iterdir():
            if file_path.is_file() and file_path.name != "session_metadata.json":
                stat = file_path.stat()
                files.append({
                    "name": file_path.name,
                    "path": str(file_path.relative_to(session_path)),
                    "size": stat.st_size,
                    "modified": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                    "extension": file_path.suffix
                })
        
        return sorted(files, key=lambda x: x['modified'], reverse=True)
    
    def export_for_tool(self, session_id: str, tool_name: str, 
                       data_keys: List[str] = None) -> Dict[str, str]:
        """ä¸ºç‰¹å®šå·¥å…·å¯¼å‡ºæ•°æ®"""
        session_path = self.get_session_path(session_id)
        if not session_path:
            raise FileNotFoundError(f"ä¼šè¯ä¸å­˜åœ¨: {session_id}")
        
        export_map = {}
        
        if data_keys:
            # å¯¼å‡ºæŒ‡å®šçš„æ•°æ®
            for data_key in data_keys:
                try:
                    file_path = self._find_latest_file(session_path, data_key)
                    if file_path:
                        export_map[data_key] = str(file_path)
                except FileNotFoundError:
                    logger.warning(f"æœªæ‰¾åˆ°æ•°æ®: {data_key}")
        else:
            # å¯¼å‡ºæ‰€æœ‰æ•°æ®æ–‡ä»¶
            for file_path in session_path.iterdir():
                if file_path.is_file() and file_path.name != "session_metadata.json":
                    key = file_path.stem.split('_')[0]  # æå–åŸå§‹key
                    export_map[key] = str(file_path)
        
        # æ›´æ–°ä¼šè¯å…ƒæ•°æ®
        export_info = {
            "tool_name": tool_name,
            "exported_at": datetime.now().isoformat(),
            "files": export_map
        }
        self._update_session_metadata(session_id, "data_exported", export_info)
        
        logger.info(f"ğŸ“¤ ä¸ºå·¥å…· {tool_name} å¯¼å‡ºäº† {len(export_map)} ä¸ªæ–‡ä»¶")
        return export_map
    
    def create_prompt_context(self, session_id: str) -> str:
        """ä¸ºLLMåˆ›å»ºå·¥ä½œåŒºä½¿ç”¨æç¤ºä¸Šä¸‹æ–‡"""
        session_path = self.get_session_path(session_id)
        if not session_path:
            return "å½“å‰æ²¡æœ‰æ´»è·ƒçš„å·¥ä½œåŒºä¼šè¯ã€‚"
        
        files = self.list_session_files(session_id)
        
        context = f"""
ğŸ“ å…±äº«å·¥ä½œåŒºçŠ¶æ€ (ä¼šè¯: {session_id})
å·¥ä½œåŒºè·¯å¾„: {session_path}

å¯ç”¨æ–‡ä»¶:
"""
        if files:
            for file_info in files:
                context += f"  â€¢ {file_info['name']} ({file_info['size']} bytes, {file_info['extension']})\n"
        else:
            context += "  æš‚æ— æ–‡ä»¶\n"
        
        context += f"""
ğŸ’¡ å·¥ä½œåŒºä½¿ç”¨æŒ‡å—:
- ä½¿ç”¨ browser_use è·å–çš„æ•°æ®ä¼šè‡ªåŠ¨ä¿å­˜åˆ°å·¥ä½œåŒº
- åœ¨ microsandbox ä¸­å¯ä»¥ç›´æ¥è¯»å–è¿™äº›æ–‡ä»¶è¿›è¡Œåˆ†æ
- å·¥ä½œåŒºè·¯å¾„: {session_path}
- æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: JSON, CSV, TXT

ç¤ºä¾‹ä»£ç :
```python
# åœ¨ microsandbox ä¸­è¯»å– browser_use çš„æ•°æ®
import json
import pandas as pd
from pathlib import Path

workspace = Path("{session_path}")
# è¯»å–æœ€æ–°çš„æ•°æ®æ–‡ä»¶
data_files = list(workspace.glob("*.json"))
if data_files:
    latest_file = max(data_files, key=lambda p: p.stat().st_mtime)
    with open(latest_file, 'r') as f:
        data = json.load(f)
    print(f"åŠ è½½æ•°æ®: {{latest_file.name}}")
```
"""
        return context
    
    def cleanup_expired_sessions(self, max_age_hours: int = 24):
        """æ¸…ç†è¿‡æœŸä¼šè¯"""
        cutoff_time = datetime.now() - timedelta(hours=max_age_hours)
        cleaned_count = 0
        
        for session_path in self.session_dir.iterdir():
            if session_path.is_dir():
                metadata_file = session_path / "session_metadata.json"
                if metadata_file.exists():
                    try:
                        with open(metadata_file, 'r') as f:
                            metadata = json.load(f)
                        
                        created_at = datetime.fromisoformat(metadata['created_at'])
                        if created_at < cutoff_time:
                            shutil.rmtree(session_path)
                            cleaned_count += 1
                            logger.info(f"ğŸ—‘ï¸ æ¸…ç†è¿‡æœŸä¼šè¯: {session_path.name}")
                    
                    except Exception as e:
                        logger.error(f"æ¸…ç†ä¼šè¯æ—¶å‡ºé”™ {session_path}: {e}")
        
        logger.info(f"âœ… æ¸…ç†å®Œæˆï¼Œå…±æ¸…ç† {cleaned_count} ä¸ªè¿‡æœŸä¼šè¯")
        return cleaned_count
    
    def _sanitize_filename(self, filename: str) -> str:
        """ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å"""
        # ç§»é™¤æˆ–æ›¿æ¢ä¸å®‰å…¨å­—ç¬¦
        safe_chars = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789_-"
        return ''.join(c if c in safe_chars else '_' for c in filename)
    
    def _find_latest_file(self, session_path: Path, data_key: str) -> Optional[Path]:
        """æŸ¥æ‰¾æŒ‡å®škeyçš„æœ€æ–°æ–‡ä»¶"""
        safe_key = self._sanitize_filename(data_key)
        
        for ext in ['json', 'txt', 'csv']:
            pattern = f"{safe_key}_*.{ext}"
            matching_files = list(session_path.glob(pattern))
            if matching_files:
                return max(matching_files, key=lambda p: p.stat().st_mtime)
        
        return None
    
    def _update_session_metadata(self, session_id: str, field: str, value: Any):
        """æ›´æ–°ä¼šè¯å…ƒæ•°æ®"""
        session_path = self.get_session_path(session_id)
        if not session_path:
            return
        
        metadata_file = session_path / "session_metadata.json"
        if metadata_file.exists():
            with open(metadata_file, 'r') as f:
                metadata = json.load(f)
            
            if field in metadata and isinstance(metadata[field], list):
                metadata[field].append(value)
            else:
                metadata[field] = value
            
            with open(metadata_file, 'w') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)


# å…¨å±€å…±äº«å·¥ä½œåŒºå®ä¾‹
_workspace_manager = None

def get_workspace_manager() -> SharedWorkspaceManager:
    """è·å–å…¨å±€å…±äº«å·¥ä½œåŒºç®¡ç†å™¨å®ä¾‹"""
    global _workspace_manager
    if _workspace_manager is None:
        _workspace_manager = SharedWorkspaceManager()
    return _workspace_manager


@contextmanager
def workspace_session(session_id: str, metadata: Optional[Dict[str, Any]] = None):
    """å·¥ä½œåŒºä¼šè¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    manager = get_workspace_manager()
    session_path = manager.create_session(session_id, metadata)
    
    try:
        yield manager
    finally:
        # å¯ä»¥åœ¨è¿™é‡Œè¿›è¡Œæ¸…ç†æ“ä½œ
        pass