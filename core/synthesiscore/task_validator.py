#!/usr/bin/env python3
"""
Synthesis ä»»åŠ¡éªŒè¯å™¨
ä¸“æ³¨äºåŒºåˆ†å·¥å…·ä»»åŠ¡ vs æ¨ç†ä»»åŠ¡çš„æ™ºèƒ½éªŒè¯
"""

import asyncio
import logging
from typing import Dict, List, Optional, Any, Tuple
import json
import re

from .interfaces import (
    AtomicTask, DepthExtendedTask, WidthExtendedTask, TaskUnion,
    TaskValidationResult, TaskType, TaskComplexity
)
from .prompts import prompt_manager

logger = logging.getLogger(__name__)


class TaskValidator:
    """
    Synthesis ä»»åŠ¡éªŒè¯å™¨
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. å·¥å…·å¿…è¦æ€§éªŒè¯ï¼šåˆ¤æ–­ä»»åŠ¡æ˜¯å¦å¿…é¡»é€šè¿‡å·¥å…·è°ƒç”¨æ‰èƒ½è§£å†³
    2. æ¨ç†å……åˆ†æ€§éªŒè¯ï¼šåˆ¤æ–­ä»»åŠ¡æ˜¯å¦ä»…é€šè¿‡æ¨ç†å°±èƒ½è§£å†³
    3. åŸå­æ€§éªŒè¯ï¼šç¡®ä¿åŸå­ä»»åŠ¡çš„å•ä¸€æ€§
    4. æ‰©å±•æ€§éªŒè¯ï¼šéªŒè¯æ·±åº¦/å®½åº¦æ‰©å±•çš„åˆç†æ€§
    """
    
    def __init__(self, llm_client, enable_strict_mode: bool = True):
        self.llm_client = llm_client
        self.enable_strict_mode = enable_strict_mode
        
        # LLMé‡è¯•é…ç½®
        self.max_retries = 3
        self.retry_delay = 1.5
        
        logger.info("âœ… TaskValidator åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨æ¨¡æ¿åŒ–Promptç®¡ç†")
    
    async def _call_llm_with_retry(self, prompt: str, operation_name: str) -> str:
        """
        å¸¦é‡è¯•æœºåˆ¶çš„LLMè°ƒç”¨æ–¹æ³•
        """
        last_error = None
        
        for attempt in range(1, self.max_retries + 1):
            try:
                logger.debug(f"ğŸ”„ {operation_name} - éªŒè¯å°è¯• {attempt}/{self.max_retries}")
                # å°†å­—ç¬¦ä¸²promptè½¬æ¢ä¸ºæ¶ˆæ¯åˆ—è¡¨æ ¼å¼
                messages = [{"role": "user", "content": prompt}]
                response = await self.llm_client._call_api(messages)
                logger.debug(f"âœ… {operation_name} - ç¬¬{attempt}æ¬¡éªŒè¯æˆåŠŸ")
                return response
                
            except Exception as e:
                last_error = e
                logger.warning(f"âš ï¸ {operation_name} - ç¬¬{attempt}æ¬¡éªŒè¯å¤±è´¥: {e}")
                
                if attempt < self.max_retries:
                    logger.info(f"â° ç­‰å¾… {self.retry_delay}s åé‡è¯•éªŒè¯...")
                    await asyncio.sleep(self.retry_delay)
                else:
                    logger.error(f"âŒ {operation_name} - æ‰€æœ‰ {self.max_retries} æ¬¡éªŒè¯å°è¯•å‡å¤±è´¥")
                    break
        
        # æŠ›å‡ºè¿è¡Œæ—¶é”™è¯¯ï¼Œä¸å†ä½¿ç”¨ç®€å•å›é€€
        raise RuntimeError(f"{operation_name} éªŒè¯å¤±è´¥ï¼šç»è¿‡ {self.max_retries} æ¬¡é‡è¯•ä»æ— æ³•ä¸LLMæ­£å¸¸é€šä¿¡ã€‚æœ€åé”™è¯¯: {last_error}")
    
    async def validate_task(self, task: TaskUnion) -> TaskValidationResult:
        """éªŒè¯å•ä¸ªä»»åŠ¡"""
        logger.info(f"ğŸ” å¼€å§‹éªŒè¯ä»»åŠ¡: {task.task_id}")
        
        if isinstance(task, AtomicTask):
            return await self._validate_atomic_task(task)
        elif isinstance(task, DepthExtendedTask):
            return await self._validate_depth_extended_task(task)
        elif isinstance(task, WidthExtendedTask):
            return await self._validate_width_extended_task(task)
        else:
            return TaskValidationResult(
                task_id=task.task_id,
                is_valid=False,
                requires_tool=False,
                validation_score=0.0,
                tool_necessity_check=False,
                reasoning_sufficiency_check=False,
                atomicity_check=False,
                errors=[f"æœªçŸ¥ä»»åŠ¡ç±»å‹: {type(task)}"]
            )
    
    async def batch_validate_tasks(self, tasks: List[TaskUnion]) -> List[TaskValidationResult]:
        """æ‰¹é‡éªŒè¯ä»»åŠ¡"""
        logger.info(f"ğŸ” å¼€å§‹æ‰¹é‡éªŒè¯ {len(tasks)} ä¸ªä»»åŠ¡")
        
        # å¹¶å‘éªŒè¯
        validation_tasks = [self.validate_task(task) for task in tasks]
        results = await asyncio.gather(*validation_tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸
        valid_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"âŒ éªŒè¯ä»»åŠ¡ {tasks[i].task_id} å¤±è´¥: {result}")
                valid_results.append(TaskValidationResult(
                    task_id=tasks[i].task_id,
                    is_valid=False,
                    requires_tool=False,
                    validation_score=0.0,
                    tool_necessity_check=False,
                    reasoning_sufficiency_check=False,
                    atomicity_check=False,
                    errors=[f"éªŒè¯å¼‚å¸¸: {str(result)}"]
                ))
            else:
                valid_results.append(result)
        
        logger.info(f"âœ… æ‰¹é‡éªŒè¯å®Œæˆï¼Œæœ‰æ•ˆä»»åŠ¡: {sum(1 for r in valid_results if r.is_valid)}/{len(tasks)}")
        return valid_results
    
    async def _validate_atomic_task(self, task: AtomicTask) -> TaskValidationResult:
        """éªŒè¯åŸå­ä»»åŠ¡"""
        logger.debug(f"ğŸ”¬ éªŒè¯åŸå­ä»»åŠ¡: {task.task_id}")
        
        # 1. å·¥å…·å¿…è¦æ€§æ£€æŸ¥
        tool_necessity = await self._check_tool_necessity(task.question)
        
        # 2. æ¨ç†å……åˆ†æ€§æ£€æŸ¥  
        reasoning_sufficiency = await self._check_reasoning_sufficiency(task.question)
        
        # 3. åŸå­æ€§æ£€æŸ¥
        atomicity = await self._check_atomicity(task.question)
        
        # ç»¼åˆåˆ¤æ–­ï¼ˆæ›´å®½æ¾çš„å·¥å…·å¿…è¦æ€§åˆ¤æ–­ï¼‰
        has_action_keywords = any(keyword in task.question.lower() for keyword in ["æœç´¢", "æŸ¥è¯¢", "è·å–", "ä¸‹è½½", "æ‰§è¡Œ", "è®¡ç®—", "åˆ†æ", "æå–", "è®¿é—®", "ç”Ÿæˆ", "åˆ›å»º"])
        requires_tool = tool_necessity or has_action_keywords
        
        # æ›´å®½æ¾çš„éªŒè¯æ ‡å‡†
        is_valid = atomicity and (requires_tool if self.enable_strict_mode else True)
        
        # è®¡ç®—éªŒè¯åˆ†æ•°
        score = self._calculate_validation_score(
            tool_necessity, reasoning_sufficiency, atomicity
        )
        
        # æ”¶é›†é”™è¯¯å’Œè­¦å‘Š
        errors = []
        warnings = []
        
        if not atomicity:
            errors.append("ä»»åŠ¡ä¸ç¬¦åˆåŸå­æ€§è¦æ±‚ï¼ŒåŒ…å«å¤šä¸ªå­ä»»åŠ¡")
        
        if not requires_tool and self.enable_strict_mode:
            # æ›´å®½æ¾çš„å·¥å…·å¿…è¦æ€§åˆ¤æ–­ - åªæœ‰æ˜æ˜¾çš„çº¯æ¨ç†ä»»åŠ¡æ‰è¢«æ‹’ç»
            if any(keyword in task.question.lower() for keyword in ["æœç´¢", "æŸ¥è¯¢", "è·å–", "ä¸‹è½½", "æ‰§è¡Œ", "è®¡ç®—", "åˆ†æ", "æå–"]):
                # åŒ…å«æ“ä½œæ€§å…³é”®è¯çš„ä»»åŠ¡åº”è¯¥éœ€è¦å·¥å…·ï¼Œè¦†ç›–LLMåˆ¤æ–­
                warnings.append("LLMåˆ¤æ–­å¯èƒ½æœ‰è¯¯ï¼šä»»åŠ¡åŒ…å«æ“ä½œæ€§å…³é”®è¯ï¼Œåº”è¯¥éœ€è¦å·¥å…·")
            else:
                errors.append("ä»»åŠ¡å¯ä»¥ä»…é€šè¿‡æ¨ç†è§£å†³ï¼Œä¸éœ€è¦å·¥å…·è°ƒç”¨")
        elif not requires_tool:
            warnings.append("ä»»åŠ¡å¯èƒ½ä¸éœ€è¦å·¥å…·è°ƒç”¨")
        
        return TaskValidationResult(
            task_id=task.task_id,
            is_valid=is_valid,
            requires_tool=requires_tool,
            validation_score=score,
            tool_necessity_check=tool_necessity,
            reasoning_sufficiency_check=reasoning_sufficiency,
            atomicity_check=atomicity,
            errors=errors,
            warnings=warnings,
            validation_method="llm_comprehensive"
        )
    
    async def _validate_depth_extended_task(self, task: DepthExtendedTask) -> TaskValidationResult:
        """éªŒè¯æ·±åº¦æ‰©å±•ä»»åŠ¡"""
        logger.debug(f"ğŸ”¬ éªŒè¯æ·±åº¦æ‰©å±•ä»»åŠ¡: {task.task_id}")
        
        # éªŒè¯åŸºç¡€ä»»åŠ¡
        base_validation = await self._validate_atomic_task(task.base_task)
        
        # éªŒè¯ä¸­é—´ä»»åŠ¡
        intermediate_validation = await self._validate_atomic_task(task.intermediate_task)
        
        # éªŒè¯è¶…é›†å…³ç³»
        superset_valid = await self._check_superset_relation(
            task.base_task.input_info.content,
            task.superset_input.content
        )
        
        # éªŒè¯ä¿¡æ¯ä¸æ³„éœ²
        info_leak = await self._check_information_leakage(
            task.combined_question,
            task.base_task.answer.answer
        )
        
        is_valid = (base_validation.is_valid and 
                   intermediate_validation.is_valid and 
                   superset_valid and 
                   not info_leak)
        
        errors = []
        errors.extend(base_validation.errors)
        errors.extend(intermediate_validation.errors)
        
        if not superset_valid:
            errors.append("è¶…é›†å…³ç³»éªŒè¯å¤±è´¥")
        if info_leak:
            errors.append("æ£€æµ‹åˆ°ä¿¡æ¯æ³„éœ²")
        
        return TaskValidationResult(
            task_id=task.task_id,
            is_valid=is_valid,
            requires_tool=True,  # æ·±åº¦æ‰©å±•ä»»åŠ¡æ€»æ˜¯éœ€è¦å·¥å…·
            validation_score=min(base_validation.validation_score, intermediate_validation.validation_score),
            tool_necessity_check=True,
            reasoning_sufficiency_check=False,
            atomicity_check=False,  # æ·±åº¦æ‰©å±•ä¸æ˜¯åŸå­ä»»åŠ¡
            errors=errors,
            validation_method="depth_extension_validation"
        )
    
    async def _validate_width_extended_task(self, task: WidthExtendedTask) -> TaskValidationResult:
        """éªŒè¯å®½åº¦æ‰©å±•ä»»åŠ¡"""
        logger.debug(f"ğŸ”¬ éªŒè¯å®½åº¦æ‰©å±•ä»»åŠ¡: {task.task_id}")
        
        # éªŒè¯æ‰€æœ‰ç»„ä»¶ä»»åŠ¡
        component_validations = []
        for component in task.component_tasks:
            validation = await self._validate_atomic_task(component)
            component_validations.append(validation)
        
        # æ£€æŸ¥ä»»åŠ¡åˆå¹¶çš„åˆç†æ€§
        merge_valid = await self._check_merge_reasonableness(
            [t.question for t in task.component_tasks],
            task.merged_question
        )
        
        # æ£€æŸ¥ç­”æ¡ˆç»„åˆçš„æ­£ç¡®æ€§
        answer_combination = await self._check_answer_combination(
            [t.answer.answer for t in task.component_tasks],
            task.merged_answer
        )
        
        all_components_valid = all(v.is_valid for v in component_validations)
        is_valid = all_components_valid and merge_valid and answer_combination
        
        errors = []
        for i, v in enumerate(component_validations):
            if not v.is_valid:
                errors.extend([f"ç»„ä»¶ä»»åŠ¡{i+1}: {err}" for err in v.errors])
        
        if not merge_valid:
            errors.append("ä»»åŠ¡åˆå¹¶ä¸åˆç†")
        if not answer_combination:
            errors.append("ç­”æ¡ˆç»„åˆä¸æ­£ç¡®")
        
        return TaskValidationResult(
            task_id=task.task_id,
            is_valid=is_valid,
            requires_tool=any(v.requires_tool for v in component_validations),
            validation_score=sum(v.validation_score for v in component_validations) / len(component_validations),
            tool_necessity_check=any(v.tool_necessity_check for v in component_validations),
            reasoning_sufficiency_check=all(v.reasoning_sufficiency_check for v in component_validations),
            atomicity_check=False,  # å®½åº¦æ‰©å±•ä¸æ˜¯åŸå­ä»»åŠ¡
            errors=errors,
            validation_method="width_extension_validation"
        )
    
    async def _check_tool_necessity(self, question: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¿…é¡»ä½¿ç”¨å·¥å…·"""
        try:
            # ä½¿ç”¨æ¨¡æ¿åŒ–Prompt
            prompt = prompt_manager.render_template("check_tool_necessity", question=question)
            
            # ä½¿ç”¨é‡è¯•æœºåˆ¶è°ƒç”¨LLM
            response = await self._call_llm_with_retry(prompt, "å·¥å…·å¿…è¦æ€§æ£€æŸ¥")
            
            # å°è¯•JSONè§£æ
            try:
                result = json.loads(response)
                return result.get("requires_tool", False)
            except:
                # å›é€€åˆ°æ–‡æœ¬è§£æ
                if "requires_tool\": true" in response.lower() or "éœ€è¦å·¥å…·" in response:
                    return True
                elif "requires_tool\": false" in response.lower() or "ä¸éœ€è¦å·¥å…·" in response:
                    return False
                else:
                    # é»˜è®¤ä¿å®ˆåˆ¤æ–­
                    return True
        except Exception as e:
            logger.error(f"âŒ å·¥å…·å¿…è¦æ€§æ£€æŸ¥å¤±è´¥: {e}")
            return True
    
    async def _check_reasoning_sufficiency(self, question: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä»…é€šè¿‡æ¨ç†å°±èƒ½è§£å†³"""
        try:
            # ä½¿ç”¨æ¨¡æ¿åŒ–Prompt
            prompt = prompt_manager.render_template("check_reasoning_sufficiency", question=question)
            
            # ä½¿ç”¨é‡è¯•æœºåˆ¶è°ƒç”¨LLM
            response = await self._call_llm_with_retry(prompt, "æ¨ç†å……åˆ†æ€§æ£€æŸ¥")
            
            # å°è¯•JSONè§£æ
            try:
                result = json.loads(response)
                return result.get("reasoning_sufficient", False)
            except:
                # å›é€€åˆ°æ–‡æœ¬è§£æ
                if "reasoning_sufficient\": true" in response.lower() or "ä»…æ¨ç†è¶³å¤Ÿ" in response:
                    return True
                elif "reasoning_sufficient\": false" in response.lower() or "éœ€è¦å¤–éƒ¨" in response:
                    return False
                else:
                    # é»˜è®¤ä¿å®ˆåˆ¤æ–­
                    return False
        except Exception as e:
            logger.error(f"âŒ æ¨ç†å……åˆ†æ€§æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    async def _check_atomicity(self, question: str) -> bool:
        """æ£€æŸ¥åŸå­æ€§"""
        try:
            # ä½¿ç”¨æ¨¡æ¿åŒ–Prompt
            prompt = prompt_manager.render_template("check_atomicity", question=question)
            
            # ä½¿ç”¨é‡è¯•æœºåˆ¶è°ƒç”¨LLM
            response = await self._call_llm_with_retry(prompt, "åŸå­æ€§æ£€æŸ¥")
            
            # å°è¯•JSONè§£æ
            try:
                result = json.loads(response)
                return result.get("is_atomic", True)
            except:
                # å›é€€åˆ°æ–‡æœ¬è§£æ
                if "is_atomic\": true" in response.lower() or "æ˜¯åŸå­ä»»åŠ¡" in response:
                    return True
                elif "is_atomic\": false" in response.lower() or "åŒ…å«å¤šä¸ª" in response:
                    return False
                else:
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤šä¸ªæ­¥éª¤æˆ–å­ä»»åŠ¡çš„å…³é”®è¯
                    step_indicators = ["ç¬¬ä¸€æ­¥", "ç„¶å", "æ¥ç€", "æœ€å", "æ­¥éª¤", "é¦–å…ˆ", "å…¶æ¬¡"]
                    has_multiple_steps = any(indicator in response for indicator in step_indicators)
                    return not has_multiple_steps
                
        except Exception as e:
            logger.error(f"âŒ åŸå­æ€§æ£€æŸ¥å¤±è´¥: {e}")
            return True
    
    async def _check_superset_relation(self, base_input: str, superset_input: str) -> bool:
        """æ£€æŸ¥è¶…é›†å…³ç³»"""
        try:
            # ä½¿ç”¨æ¨¡æ¿åŒ–Prompt
            prompt = prompt_manager.render_template("validate_superset_relation", 
                                                   base_input=base_input, 
                                                   superset_input=superset_input)
            
            # ä½¿ç”¨é‡è¯•æœºåˆ¶è°ƒç”¨LLM
            response = await self._call_llm_with_retry(prompt, "è¶…é›†å…³ç³»æ£€æŸ¥")
            
            # å°è¯•JSONè§£æ
            try:
                result = json.loads(response)
                return result.get("is_superset", False)
            except:
                # å›é€€åˆ°æ–‡æœ¬è§£æ
                return "is_superset\": true" in response.lower() or "æ˜¯" in response
                
        except Exception as e:
            logger.error(f"âŒ è¶…é›†å…³ç³»æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    async def _check_information_leakage(self, question: str, answer: str) -> bool:
        """æ£€æŸ¥ä¿¡æ¯æ³„éœ²"""
        try:
            # ä½¿ç”¨æ¨¡æ¿åŒ–Prompt
            prompt = prompt_manager.render_template("check_information_leakage", 
                                                   question=question, 
                                                   answer=answer)
            
            # ä½¿ç”¨é‡è¯•æœºåˆ¶è°ƒç”¨LLM
            response = await self._call_llm_with_retry(prompt, "ä¿¡æ¯æ³„éœ²æ£€æŸ¥")
            
            # å°è¯•JSONè§£æ
            try:
                result = json.loads(response)
                return result.get("has_leakage", False)
            except:
                # å›é€€åˆ°æ–‡æœ¬è§£æ
                return "has_leakage\": true" in response.lower() or "æ˜¯" in response
                
        except Exception as e:
            logger.error(f"âŒ ä¿¡æ¯æ³„éœ²æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    async def _check_merge_reasonableness(self, component_questions: List[str], merged_question: str) -> bool:
        """æ£€æŸ¥ä»»åŠ¡åˆå¹¶çš„åˆç†æ€§"""
        try:
            # ä½¿ç”¨æ¨¡æ¿åŒ–Prompt
            component_questions_str = "\n".join(f"- {q}" for q in component_questions)
            prompt = prompt_manager.render_template("check_merge_reasonableness", 
                                                   component_questions=component_questions_str, 
                                                   merged_question=merged_question)
            
            # ä½¿ç”¨é‡è¯•æœºåˆ¶è°ƒç”¨LLM
            response = await self._call_llm_with_retry(prompt, "åˆå¹¶åˆç†æ€§æ£€æŸ¥")
            
            # å°è¯•JSONè§£æ
            try:
                result = json.loads(response)
                return result.get("is_reasonable", False)
            except:
                # å›é€€åˆ°æ–‡æœ¬è§£æ
                return "is_reasonable\": true" in response.lower() or "æ˜¯" in response
                
        except Exception as e:
            logger.error(f"âŒ åˆå¹¶åˆç†æ€§æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    async def _check_answer_combination(self, component_answers: List[str], merged_answer: str) -> bool:
        """æ£€æŸ¥ç­”æ¡ˆç»„åˆçš„æ­£ç¡®æ€§"""
        # ç®€å•æ£€æŸ¥ï¼šåˆå¹¶ç­”æ¡ˆåº”åŒ…å«æ‰€æœ‰ç»„ä»¶ç­”æ¡ˆçš„ä¿¡æ¯
        for answer in component_answers:
            if answer.strip() and answer.strip() not in merged_answer:
                return False
        return True
    
    def _calculate_validation_score(self, tool_necessity: bool, reasoning_sufficiency: bool, atomicity: bool) -> float:
        """è®¡ç®—éªŒè¯åˆ†æ•°ï¼ˆæ›´å®½æ¾çš„è¯„åˆ†æ ‡å‡†ï¼‰"""
        score = 0.0
        
        # åŸå­æ€§æƒé‡æœ€é«˜ï¼Œä½†é™ä½è¦æ±‚
        if atomicity:
            score += 0.6  # æé«˜æƒé‡
        
        # å·¥å…·å¿…è¦æ€§æƒé‡é€‚ä¸­
        if tool_necessity:
            score += 0.4  # æé«˜æƒé‡
        
        # å¯¹äºæ˜æ˜¾éœ€è¦å·¥å…·çš„ä»»åŠ¡ï¼Œå³ä½¿LLMåˆ¤æ–­æœ‰è¯¯ä¹Ÿç»™äºˆåŸºç¡€åˆ†æ•°
        return min(1.0, score)  # ç¡®ä¿ä¸è¶…è¿‡1.0
    
