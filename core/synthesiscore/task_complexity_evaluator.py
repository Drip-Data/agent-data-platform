#!/usr/bin/env python3
"""
ä»»åŠ¡å¤æ‚åº¦è¯„ä¼°å™¨
è¯„ä¼°ä»»åŠ¡çš„å¤æ‚åº¦å’Œè´¨é‡ï¼Œç¡®ä¿ç”Ÿæˆçš„ç»¼åˆä»»åŠ¡çœŸæ­£æœ‰æŒ‘æˆ˜æ€§
"""

import logging
import re
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum

from .interfaces import AtomicTask, DepthExtendedTask, WidthExtendedTask, TaskComplexity

logger = logging.getLogger(__name__)

class ComplexityDimension(Enum):
    """å¤æ‚åº¦ç»´åº¦"""
    REASONING_STEPS = "reasoning_steps"      # æ¨ç†æ­¥éª¤æ•°é‡
    TOOL_DIVERSITY = "tool_diversity"        # å·¥å…·å¤šæ ·æ€§
    DOMAIN_BREADTH = "domain_breadth"        # é¢†åŸŸå¹¿åº¦
    INTERDEPENDENCE = "interdependence"      # æ­¥éª¤é—´ä¾èµ–
    COGNITIVE_LOAD = "cognitive_load"        # è®¤çŸ¥è´Ÿè·
    OUTPUT_RICHNESS = "output_richness"      # è¾“å‡ºä¸°å¯Œåº¦

@dataclass
class ComplexityScore:
    """å¤æ‚åº¦è¯„åˆ†"""
    total_score: float
    dimension_scores: Dict[ComplexityDimension, float]
    complexity_level: str
    quality_issues: List[str]
    enhancement_suggestions: List[str]

class TaskComplexityEvaluator:
    """ä»»åŠ¡å¤æ‚åº¦è¯„ä¼°å™¨"""
    
    def __init__(self):
        # å¤æ‚åº¦é˜ˆå€¼å®šä¹‰
        self.complexity_thresholds = {
            "trivial": 0.0,      # æ— æ„ä¹‰çš„æ‰©å±•
            "simple": 2.0,       # ç®€å•æ‰©å±•
            "moderate": 4.0,     # ä¸­ç­‰å¤æ‚åº¦
            "complex": 7.0,      # å¤æ‚ä»»åŠ¡
            "comprehensive": 10.0 # ç»¼åˆæ€§ä»»åŠ¡
        }
        
        # ç»´åº¦æƒé‡
        self.dimension_weights = {
            ComplexityDimension.REASONING_STEPS: 0.25,
            ComplexityDimension.TOOL_DIVERSITY: 0.20,
            ComplexityDimension.DOMAIN_BREADTH: 0.15,
            ComplexityDimension.INTERDEPENDENCE: 0.20,
            ComplexityDimension.COGNITIVE_LOAD: 0.10,
            ComplexityDimension.OUTPUT_RICHNESS: 0.10
        }
    
    def evaluate_depth_extended_task(self, task: DepthExtendedTask) -> ComplexityScore:
        """è¯„ä¼°æ·±åº¦æ‰©å±•ä»»åŠ¡çš„å¤æ‚åº¦"""
        logger.debug(f"ğŸ” è¯„ä¼°æ·±åº¦æ‰©å±•ä»»åŠ¡å¤æ‚åº¦: {task.task_id}")
        
        dimension_scores = {}
        
        # 1. æ¨ç†æ­¥éª¤è¯„ä¼°
        reasoning_score = self._evaluate_reasoning_complexity(
            task.combined_question, 
            task.base_task.question
        )
        dimension_scores[ComplexityDimension.REASONING_STEPS] = reasoning_score
        
        # 2. å·¥å…·å¤šæ ·æ€§è¯„ä¼°
        tool_score = self._evaluate_tool_diversity_depth(task)
        dimension_scores[ComplexityDimension.TOOL_DIVERSITY] = tool_score
        
        # 3. é¢†åŸŸæ·±åº¦è¯„ä¼°
        domain_score = self._evaluate_domain_depth(task.combined_question, task.base_task.domain)
        dimension_scores[ComplexityDimension.DOMAIN_BREADTH] = domain_score
        
        # 4. æ­¥éª¤ä¾èµ–æ€§è¯„ä¼°
        interdependence_score = self._evaluate_step_interdependence(task.combined_question)
        dimension_scores[ComplexityDimension.INTERDEPENDENCE] = interdependence_score
        
        # 5. è®¤çŸ¥è´Ÿè·è¯„ä¼°
        cognitive_score = self._evaluate_cognitive_load(task.combined_question)
        dimension_scores[ComplexityDimension.COGNITIVE_LOAD] = cognitive_score
        
        # 6. è¾“å‡ºä¸°å¯Œåº¦è¯„ä¼°
        output_score = self._evaluate_output_richness(task.combined_answer)
        dimension_scores[ComplexityDimension.OUTPUT_RICHNESS] = output_score
        
        # è®¡ç®—æ€»åˆ†
        total_score = self._calculate_weighted_score(dimension_scores)
        
        # ç¡®å®šå¤æ‚åº¦ç­‰çº§
        complexity_level = self._determine_complexity_level(total_score)
        
        # è¯†åˆ«è´¨é‡é—®é¢˜
        quality_issues = self._identify_quality_issues_depth(task, dimension_scores)
        
        # ç”Ÿæˆæ”¹è¿›å»ºè®®
        enhancement_suggestions = self._generate_enhancement_suggestions_depth(dimension_scores)
        
        return ComplexityScore(
            total_score=total_score,
            dimension_scores=dimension_scores,
            complexity_level=complexity_level,
            quality_issues=quality_issues,
            enhancement_suggestions=enhancement_suggestions
        )
    
    def evaluate_width_extended_task(self, task: WidthExtendedTask) -> ComplexityScore:
        """è¯„ä¼°å®½åº¦æ‰©å±•ä»»åŠ¡çš„å¤æ‚åº¦"""
        logger.debug(f"ğŸ” è¯„ä¼°å®½åº¦æ‰©å±•ä»»åŠ¡å¤æ‚åº¦: {task.task_id}")
        
        dimension_scores = {}
        
        # 1. ååŒå¤æ‚åº¦è¯„ä¼°
        synergy_score = self._evaluate_synergy_complexity(task)
        dimension_scores[ComplexityDimension.REASONING_STEPS] = synergy_score
        
        # 2. å·¥å…·ååŒè¯„ä¼°
        tool_score = self._evaluate_tool_synergy(task)
        dimension_scores[ComplexityDimension.TOOL_DIVERSITY] = tool_score
        
        # 3. è·¨åŸŸæ•´åˆè¯„ä¼°
        domain_score = self._evaluate_cross_domain_integration(task)
        dimension_scores[ComplexityDimension.DOMAIN_BREADTH] = domain_score
        
        # 4. ä¿¡æ¯æµè½¬è¯„ä¼°
        flow_score = self._evaluate_information_flow(task.merged_question)
        dimension_scores[ComplexityDimension.INTERDEPENDENCE] = flow_score
        
        # 5. æ•´åˆéš¾åº¦è¯„ä¼°
        integration_score = self._evaluate_integration_difficulty(task)
        dimension_scores[ComplexityDimension.COGNITIVE_LOAD] = integration_score
        
        # 6. ç³»ç»Ÿæ€§è¾“å‡ºè¯„ä¼°
        system_score = self._evaluate_systematic_output(task.merged_answer)
        dimension_scores[ComplexityDimension.OUTPUT_RICHNESS] = system_score
        
        # è®¡ç®—æ€»åˆ†
        total_score = self._calculate_weighted_score(dimension_scores)
        
        # ç¡®å®šå¤æ‚åº¦ç­‰çº§
        complexity_level = self._determine_complexity_level(total_score)
        
        # è¯†åˆ«è´¨é‡é—®é¢˜
        quality_issues = self._identify_quality_issues_width(task, dimension_scores)
        
        # ç”Ÿæˆæ”¹è¿›å»ºè®®
        enhancement_suggestions = self._generate_enhancement_suggestions_width(dimension_scores)
        
        return ComplexityScore(
            total_score=total_score,
            dimension_scores=dimension_scores,
            complexity_level=complexity_level,
            quality_issues=quality_issues,
            enhancement_suggestions=enhancement_suggestions
        )
    
    def _evaluate_reasoning_complexity(self, extended_question: str, base_question: str) -> float:
        """è¯„ä¼°æ¨ç†å¤æ‚åº¦"""
        # åˆ†ææ­¥éª¤æ•°é‡
        step_patterns = [
            r'\d+\)\s*',  # 1) 2) 3) æ ¼å¼
            r'\d+\.\s*',  # 1. 2. 3. æ ¼å¼
            r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+æ­¥',  # ä¸­æ–‡æ­¥éª¤
            r'é¦–å…ˆ|ç„¶å|æ¥ç€|æœ€å|å…¶æ¬¡',  # è¿æ¥è¯
        ]
        
        step_count = 0
        for pattern in step_patterns:
            matches = re.findall(pattern, extended_question, re.IGNORECASE)
            step_count = max(step_count, len(matches))
        
        # åˆ†æé€»è¾‘è¿æ¥è¯
        logic_words = ['å› æ­¤', 'æ‰€ä»¥', 'åŸºäº', 'ç»“åˆ', 'ç»¼åˆ', 'å¯¹æ¯”', 'åˆ†æ', 'è¯„ä¼°', 'é¢„æµ‹']
        logic_count = sum(1 for word in logic_words if word in extended_question)
        
        # è®¡ç®—å¤æ‚åº¦å¢ç›Š
        base_complexity = len(base_question.split()) * 0.1
        extended_complexity = len(extended_question.split()) * 0.1
        complexity_gain = (extended_complexity - base_complexity) / base_complexity if base_complexity > 0 else 0
        
        # ç»¼åˆè¯„åˆ†
        score = min(10.0, step_count * 1.5 + logic_count * 0.5 + complexity_gain * 2)
        return score
    
    def _evaluate_tool_diversity_depth(self, task: DepthExtendedTask) -> float:
        """è¯„ä¼°æ·±åº¦æ‰©å±•çš„å·¥å…·å¤šæ ·æ€§"""
        # æå–é—®é¢˜ä¸­æ¶‰åŠçš„å·¥å…·ç±»å‹
        tool_indicators = {
            'æœç´¢': ['æœç´¢', 'æŸ¥æ‰¾', 'æ£€ç´¢', 'search'],
            'ä»£ç ': ['ä»£ç ', 'ç¼–ç¨‹', 'å®ç°', 'è®¡ç®—', 'code', 'python'],
            'åˆ†æ': ['åˆ†æ', 'è¯„ä¼°', 'æ¯”è¾ƒ', 'é¢„æµ‹', 'analyze'],
            'å¯è§†åŒ–': ['å›¾è¡¨', 'å¯è§†åŒ–', 'å±•ç¤º', 'chart', 'graph'],
            'ä¸‹è½½': ['ä¸‹è½½', 'è·å–', 'æ”¶é›†', 'download'],
            'æŠ¥å‘Š': ['æŠ¥å‘Š', 'æ–‡æ¡£', 'æ€»ç»“', 'report']
        }
        
        identified_tools = set()
        question = task.combined_question.lower()
        
        for tool_type, indicators in tool_indicators.items():
            if any(indicator in question for indicator in indicators):
                identified_tools.add(tool_type)
        
        # åŸºç¡€å·¥å…·æ•°é‡è¯„åˆ†
        base_score = len(identified_tools) * 1.5
        
        # å·¥å…·ååŒè¯„åˆ†ï¼ˆå¦‚æœæœ‰æ˜ç¡®çš„å·¥å…·é“¾æè¿°ï¼‰
        if 'ç»“åˆ' in question or 'æ•´åˆ' in question or 'ååŒ' in question:
            base_score += 2.0
        
        return min(10.0, base_score)
    
    def _evaluate_domain_depth(self, question: str, base_domain: str) -> float:
        """è¯„ä¼°é¢†åŸŸæ·±åº¦"""
        # ä¸“ä¸šæœ¯è¯­æŒ‡æ ‡
        professional_terms = {
            'é‡‘è': ['æŠ•èµ„', 'è‚¡ç¥¨', 'è´¢æŠ¥', 'ä¼°å€¼', 'é£é™©', 'ROI', 'æ”¶ç›Šç‡'],
            'æ•™è‚²': ['å­¦æœ¯', 'ç ”ç©¶', 'è®ºæ–‡', 'é™¢æ ¡', 'ä¸“ä¸š', 'å°±ä¸š'],
            'ç§‘æŠ€': ['ç®—æ³•', 'æ•°æ®', 'æ¨¡å‹', 'ç³»ç»Ÿ', 'æ¶æ„', 'ä¼˜åŒ–'],
            'ç§‘å­¦ç ”ç©¶': ['å®éªŒ', 'å‡è®¾', 'å˜é‡', 'ç»Ÿè®¡', 'ç›¸å…³æ€§', 'æ˜¾è‘—æ€§']
        }
        
        domain_terms = professional_terms.get(base_domain, [])
        term_count = sum(1 for term in domain_terms if term in question)
        
        # æ·±åº¦æŒ‡æ ‡
        depth_indicators = ['æ·±åº¦', 'ç³»ç»Ÿ', 'å…¨é¢', 'ä¸“ä¸š', 'è¯¦ç»†', 'ç»¼åˆ']
        depth_count = sum(1 for indicator in depth_indicators if indicator in question)
        
        # åˆ†ææ–¹æ³•æŒ‡æ ‡
        analysis_methods = ['æ¯”è¾ƒåˆ†æ', 'è¶‹åŠ¿åˆ†æ', 'ç›¸å…³åˆ†æ', 'å›å½’åˆ†æ', 'é¢„æµ‹æ¨¡å‹']
        method_count = sum(1 for method in analysis_methods if method in question)
        
        score = term_count * 1.0 + depth_count * 1.5 + method_count * 2.0
        return min(10.0, score)
    
    def _evaluate_step_interdependence(self, question: str) -> float:
        """è¯„ä¼°æ­¥éª¤é—´ä¾èµ–æ€§"""
        # ä¾èµ–å…³ç³»æŒ‡æ ‡
        dependency_patterns = [
            r'åŸºäº.*[çš„].*ç»“æœ',  # åŸºäº...çš„ç»“æœ
            r'æ ¹æ®.*[è¿›è¡Œ|å®æ–½]',  # æ ¹æ®...è¿›è¡Œ
            r'ç»“åˆ.*[å’Œ].*',      # ç»“åˆ...å’Œ...
            r'åœ¨.*[åŸºç¡€ä¸Š]',      # åœ¨...åŸºç¡€ä¸Š
            r'åˆ©ç”¨.*[æ¥].*',      # åˆ©ç”¨...æ¥...
        ]
        
        dependency_count = 0
        for pattern in dependency_patterns:
            matches = re.findall(pattern, question, re.IGNORECASE)
            dependency_count += len(matches)
        
        # ä¿¡æ¯æµè½¬æŒ‡æ ‡
        flow_words = ['ä¼ é€’', 'è¾“å…¥', 'è¾“å‡º', 'æµç¨‹', 'ç®¡é“', 'é“¾æ¡']
        flow_count = sum(1 for word in flow_words if word in question)
        
        score = dependency_count * 2.0 + flow_count * 1.5
        return min(10.0, score)
    
    def _evaluate_cognitive_load(self, question: str) -> float:
        """è¯„ä¼°è®¤çŸ¥è´Ÿè·"""
        # å¤æ‚æ¦‚å¿µæ•°é‡
        complex_concepts = ['ç®—æ³•', 'æ¨¡å‹', 'æ¶æ„', 'æ¡†æ¶', 'ç­–ç•¥', 'æœºåˆ¶', 'ä½“ç³»']
        concept_count = sum(1 for concept in complex_concepts if concept in question)
        
        # æŠ½è±¡æ€ç»´è¦æ±‚
        abstract_words = ['æ¦‚å¿µ', 'ç†è®º', 'åŸç†', 'é€»è¾‘', 'æ€ç»´', 'è®¤çŸ¥']
        abstract_count = sum(1 for word in abstract_words if word in question)
        
        # ç»¼åˆåˆ¤æ–­è¦æ±‚
        judgment_words = ['åˆ¤æ–­', 'å†³ç­–', 'é€‰æ‹©', 'æƒè¡¡', 'è¯„åˆ¤', 'å†³å®š']
        judgment_count = sum(1 for word in judgment_words if word in question)
        
        score = concept_count * 1.0 + abstract_count * 1.5 + judgment_count * 2.0
        return min(10.0, score)
    
    def _evaluate_output_richness(self, answer: str) -> float:
        """è¯„ä¼°è¾“å‡ºä¸°å¯Œåº¦"""
        # è¾“å‡ºç±»å‹å¤šæ ·æ€§
        output_types = {
            'æŠ¥å‘Š': ['æŠ¥å‘Š', 'åˆ†æ', 'æ€»ç»“'],
            'å›¾è¡¨': ['å›¾è¡¨', 'å¯è§†åŒ–', 'å›¾å½¢'],
            'æ•°æ®': ['æ•°æ®', 'ç»Ÿè®¡', 'æŒ‡æ ‡'],
            'å»ºè®®': ['å»ºè®®', 'æ¨è', 'æ–¹æ¡ˆ'],
            'é¢„æµ‹': ['é¢„æµ‹', 'é¢„ä¼°', 'å±•æœ›']
        }
        
        identified_outputs = set()
        answer_lower = answer.lower()
        
        for output_type, indicators in output_types.items():
            if any(indicator in answer_lower for indicator in indicators):
                identified_outputs.add(output_type)
        
        # ç»“æ„åŒ–ç¨‹åº¦
        structure_indicators = ['åŒ…å«', 'åˆ†ä¸º', 'ç»„æˆ', 'ç»“æ„', 'å±‚æ¬¡']
        structure_count = sum(1 for indicator in structure_indicators if indicator in answer)
        
        score = len(identified_outputs) * 2.0 + structure_count * 1.0
        return min(10.0, score)
    
    def _evaluate_synergy_complexity(self, task: WidthExtendedTask) -> float:
        """è¯„ä¼°ååŒå¤æ‚åº¦"""
        # ä»»åŠ¡æ•°é‡
        task_count = len(task.component_tasks)
        
        # ååŒæŒ‡æ ‡
        synergy_words = ['ååŒ', 'æ•´åˆ', 'ç»“åˆ', 'èåˆ', 'ç»¼åˆ', 'ç³»ç»Ÿ']
        synergy_count = sum(1 for word in synergy_words if word in task.merged_question)
        
        # å¤æ‚ååŒæ¨¡å¼
        complex_patterns = ['äº¤å‰éªŒè¯', 'ç›¸äº’ä½è¯', 'äº’è¡¥åˆ†æ', 'åŒå‘éªŒè¯']
        pattern_count = sum(1 for pattern in complex_patterns if pattern in task.merged_question)
        
        score = task_count * 1.5 + synergy_count * 1.0 + pattern_count * 3.0
        return min(10.0, score)
    
    def _evaluate_tool_synergy(self, task: WidthExtendedTask) -> float:
        """è¯„ä¼°å·¥å…·ååŒ"""
        # æ”¶é›†æ‰€æœ‰ç»„ä»¶ä»»åŠ¡çš„å·¥å…·
        all_tools = set()
        for component in task.component_tasks:
            if hasattr(component, 'expected_tools'):
                all_tools.update(component.expected_tools)
        
        tool_diversity = len(all_tools)
        
        # å·¥å…·é“¾å¤æ‚åº¦
        chain_indicators = ['æµæ°´çº¿', 'ç®¡é“', 'è‡ªåŠ¨åŒ–', 'æ‰¹å¤„ç†']
        chain_count = sum(1 for indicator in chain_indicators if indicator in task.merged_question)
        
        score = tool_diversity * 2.0 + chain_count * 1.5
        return min(10.0, score)
    
    def _evaluate_cross_domain_integration(self, task: WidthExtendedTask) -> float:
        """è¯„ä¼°è·¨åŸŸæ•´åˆ"""
        # é¢†åŸŸå¤šæ ·æ€§
        domains = set(component.domain for component in task.component_tasks)
        domain_diversity = len(domains)
        
        # è·¨åŸŸæŒ‡æ ‡
        cross_domain_words = ['è·¨é¢†åŸŸ', 'å¤šç»´åº¦', 'ç»¼åˆè§†è§’', 'å…¨é¢åˆ†æ']
        cross_count = sum(1 for word in cross_domain_words if word in task.merged_question)
        
        score = domain_diversity * 2.5 + cross_count * 2.0
        return min(10.0, score)
    
    def _evaluate_information_flow(self, question: str) -> float:
        """è¯„ä¼°ä¿¡æ¯æµè½¬"""
        # æµè½¬æŒ‡æ ‡
        flow_patterns = [
            r'å°†.*ç»“æœ.*ç”¨äº',    # å°†...ç»“æœç”¨äº
            r'åŸºäº.*è¾“å‡º.*è¿›è¡Œ',  # åŸºäº...è¾“å‡ºè¿›è¡Œ
            r'åˆ©ç”¨.*æ•°æ®.*åˆ†æ'   # åˆ©ç”¨...æ•°æ®åˆ†æ
        ]
        
        flow_count = 0
        for pattern in flow_patterns:
            matches = re.findall(pattern, question)
            flow_count += len(matches)
        
        # æ•°æ®ä¼ é€’å¤æ‚åº¦
        transfer_words = ['ä¼ é€’', 'æµè½¬', 'æ±‡æ€»', 'æ•´åˆ', 'åˆå¹¶']
        transfer_count = sum(1 for word in transfer_words if word in question)
        
        score = flow_count * 2.0 + transfer_count * 1.5
        return min(10.0, score)
    
    def _evaluate_integration_difficulty(self, task: WidthExtendedTask) -> float:
        """è¯„ä¼°æ•´åˆéš¾åº¦"""
        # ä»»åŠ¡å¤æ‚åº¦å·®å¼‚
        complexities = []
        for component in task.component_tasks:
            complexity = len(component.question.split()) + (2 if component.requires_tool else 0)
            complexities.append(complexity)
        
        complexity_variance = max(complexities) - min(complexities) if complexities else 0
        
        # æ•´åˆæ–¹æ³•å¤æ‚åº¦
        integration_methods = ['åŠ æƒåˆå¹¶', 'å±‚æ¬¡æ•´åˆ', 'æ¨¡å‹èåˆ', 'å†³ç­–æ ‘']
        method_count = sum(1 for method in integration_methods if method in task.merged_question)
        
        score = complexity_variance * 0.5 + method_count * 2.0
        return min(10.0, score)
    
    def _evaluate_systematic_output(self, answer: str) -> float:
        """è¯„ä¼°ç³»ç»Ÿæ€§è¾“å‡º"""
        # ç³»ç»Ÿæ€§æŒ‡æ ‡
        system_words = ['ç³»ç»Ÿ', 'å¹³å°', 'æ¡†æ¶', 'ä½“ç³»', 'æ¶æ„']
        system_count = sum(1 for word in system_words if word in answer)
        
        # å®Œæ•´æ€§æŒ‡æ ‡
        completeness_words = ['å®Œæ•´', 'å…¨é¢', 'ç«¯åˆ°ç«¯', 'ä¸€ç«™å¼']
        completeness_count = sum(1 for word in completeness_words if word in answer)
        
        score = system_count * 1.5 + completeness_count * 2.0
        return min(10.0, score)
    
    def _calculate_weighted_score(self, dimension_scores: Dict[ComplexityDimension, float]) -> float:
        """è®¡ç®—åŠ æƒæ€»åˆ†"""
        total_score = 0.0
        for dimension, score in dimension_scores.items():
            weight = self.dimension_weights.get(dimension, 0.0)
            total_score += score * weight
        return total_score
    
    def _determine_complexity_level(self, total_score: float) -> str:
        """ç¡®å®šå¤æ‚åº¦ç­‰çº§"""
        for level, threshold in sorted(self.complexity_thresholds.items(), key=lambda x: x[1], reverse=True):
            if total_score >= threshold:
                return level
        return "trivial"
    
    def _identify_quality_issues_depth(self, task: DepthExtendedTask, scores: Dict) -> List[str]:
        """è¯†åˆ«æ·±åº¦æ‰©å±•çš„è´¨é‡é—®é¢˜"""
        issues = []
        
        if scores[ComplexityDimension.REASONING_STEPS] < 3.0:
            issues.append("æ¨ç†æ­¥éª¤è¿‡å°‘ï¼Œç¼ºä¹çœŸæ­£çš„æ·±åº¦æ‰©å±•")
        
        if scores[ComplexityDimension.TOOL_DIVERSITY] < 2.0:
            issues.append("å·¥å…·ä½¿ç”¨å•ä¸€ï¼Œæœªå……åˆ†åˆ©ç”¨å¤šå·¥å…·ååŒ")
        
        if scores[ComplexityDimension.INTERDEPENDENCE] < 2.0:
            issues.append("æ­¥éª¤é—´ç¼ºä¹é€»è¾‘ä¾èµ–å…³ç³»")
        
        # æ£€æŸ¥æ˜¯å¦åªæ˜¯ç®€å•çš„å‰ç¼€æ·»åŠ 
        if task.combined_question.startswith("å…ˆå¤„ç†") and "ç„¶å" in task.combined_question:
            issues.append("ç–‘ä¼¼ç®€å•çš„å‰ç¼€æ·»åŠ ï¼Œè€ŒéçœŸæ­£çš„æ·±åº¦æ‰©å±•")
        
        return issues
    
    def _identify_quality_issues_width(self, task: WidthExtendedTask, scores: Dict) -> List[str]:
        """è¯†åˆ«å®½åº¦æ‰©å±•çš„è´¨é‡é—®é¢˜"""
        issues = []
        
        if scores[ComplexityDimension.REASONING_STEPS] < 3.0:
            issues.append("ååŒå¤æ‚åº¦ä¸è¶³ï¼Œä»»åŠ¡é—´ç¼ºä¹æœ‰æ•ˆæ•´åˆ")
        
        if scores[ComplexityDimension.TOOL_DIVERSITY] < 3.0:
            issues.append("å·¥å…·ååŒæ•ˆæœä¸ä½³")
        
        if scores[ComplexityDimension.INTERDEPENDENCE] < 2.0:
            issues.append("ç¼ºä¹ä¿¡æ¯æµè½¬å’Œæ­¥éª¤ä¾èµ–")
        
        # æ£€æŸ¥æ˜¯å¦åªæ˜¯ç®€å•çš„ä»»åŠ¡åˆ—ä¸¾
        if task.merged_question.count("1)") and task.merged_question.count("2)") and "åŒæ—¶" in task.merged_question:
            issues.append("ç–‘ä¼¼ç®€å•çš„ä»»åŠ¡åˆ—ä¸¾ï¼Œç¼ºä¹çœŸæ­£çš„ååŒè®¾è®¡")
        
        return issues
    
    def _generate_enhancement_suggestions_depth(self, scores: Dict) -> List[str]:
        """ç”Ÿæˆæ·±åº¦æ‰©å±•çš„æ”¹è¿›å»ºè®®"""
        suggestions = []
        
        if scores[ComplexityDimension.REASONING_STEPS] < 5.0:
            suggestions.append("å¢åŠ æ¨ç†æ­¥éª¤ï¼Œè®¾è®¡å¤šå±‚æ¬¡çš„åˆ†ææµç¨‹")
        
        if scores[ComplexityDimension.TOOL_DIVERSITY] < 4.0:
            suggestions.append("æ•´åˆæ›´å¤šå·¥å…·ç±»å‹ï¼Œè®¾è®¡å·¥å…·ååŒä½¿ç”¨æ–¹æ¡ˆ")
        
        if scores[ComplexityDimension.OUTPUT_RICHNESS] < 4.0:
            suggestions.append("ä¸°å¯Œè¾“å‡ºç±»å‹ï¼ŒåŒ…å«å¯è§†åŒ–ã€æŠ¥å‘Šã€å»ºè®®ç­‰å¤šç§å½¢å¼")
        
        return suggestions
    
    def _generate_enhancement_suggestions_width(self, scores: Dict) -> List[str]:
        """ç”Ÿæˆå®½åº¦æ‰©å±•çš„æ”¹è¿›å»ºè®®"""
        suggestions = []
        
        if scores[ComplexityDimension.REASONING_STEPS] < 5.0:
            suggestions.append("è®¾è®¡æ›´å¤æ‚çš„ä»»åŠ¡ååŒæ¨¡å¼")
        
        if scores[ComplexityDimension.DOMAIN_BREADTH] < 4.0:
            suggestions.append("å¢åŠ è·¨é¢†åŸŸæ•´åˆï¼Œæå‡ä»»åŠ¡çš„ç³»ç»Ÿæ€§")
        
        if scores[ComplexityDimension.INTERDEPENDENCE] < 4.0:
            suggestions.append("è®¾è®¡ä¿¡æ¯æµè½¬æœºåˆ¶ï¼Œç¡®ä¿ä»»åŠ¡é—´çš„æœ‰æ•ˆè¿æ¥")
        
        return suggestions