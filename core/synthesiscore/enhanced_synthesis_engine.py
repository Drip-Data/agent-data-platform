#!/usr/bin/env python3
"""
Enhanced Synthesis Engine - å¢å¼ºåˆæˆå¼•æ“
åŸºäºTaskCraftç®—æ³•çš„å®Œæ•´ä»»åŠ¡ç”Ÿæˆå’ŒéªŒè¯ç³»ç»Ÿ
"""

import asyncio
import json
import logging
import time
from typing import Dict, List, Optional, Any, Union
from dataclasses import asdict
from datetime import datetime

from core.interfaces import TrajectoryResult
from core.llm_client import LLMClient
from core.toolscore.mcp_client import MCPToolClient

from .enhanced_interfaces import (
    CorpusContent, AtomicTask, ExtendedTask, CompositeTask, 
    VerificationResult, GenerationMetrics, TaskUnion,
    EnhancedSynthesisConfig
)
from .corpus_ingestor import CorpusIngestor
from .atomic_task_generator import AtomicTaskGenerator
from .depth_extender import DepthExtender
from .width_extender import WidthExtender
from .verification_agent import EnhancedVerificationEngine
from .enhanced_redis_manager import EnhancedSynthesisRedisManager

logger = logging.getLogger(__name__)


class EnhancedSynthesisEngine:
    """å¢å¼ºåˆæˆå¼•æ“ - SynthesisCore v2.0çš„æ ¸å¿ƒå¼•æ“"""
    
    def __init__(self, llm_client: LLMClient, mcp_client: Optional[MCPToolClient] = None,
                 redis_url: str = "redis://localhost:6379"):
        self.llm_client = llm_client
        self.mcp_client = mcp_client
        self.config = EnhancedSynthesisConfig()
        
        # åˆå§‹åŒ–å­ç³»ç»Ÿ
        self.corpus_ingestor = CorpusIngestor(mcp_client)
        self.atomic_generator = AtomicTaskGenerator(llm_client, mcp_client)
        self.depth_extender = DepthExtender(llm_client, mcp_client)
        self.width_extender = WidthExtender(llm_client, mcp_client)
        self.verification_engine = EnhancedVerificationEngine(llm_client, mcp_client)
        self.redis_manager = EnhancedSynthesisRedisManager(redis_url)
        
        # ä¼šè¯çŠ¶æ€
        self.session_id = f"synthesis_{int(time.time())}"
        self.generation_metrics = GenerationMetrics(session_id=self.session_id)
    
    async def initialize(self):
        """åˆå§‹åŒ–å¼•æ“"""
        try:
            await self.redis_manager.initialize()
            logger.info("âœ… Enhanced Synthesis Engine åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            logger.error(f"âŒ Enhanced Synthesis Engine åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def close(self):
        """å…³é—­å¼•æ“"""
        try:
            await self.redis_manager.close()
            logger.info("âœ… Enhanced Synthesis Engine å·²å…³é—­")
        except Exception as e:
            logger.error(f"âŒ Enhanced Synthesis Engine å…³é—­å¤±è´¥: {e}")
    
    async def synthesize_from_trajectories(self, trajectories: List[TrajectoryResult], 
                                         include_depth_extension: bool = True,
                                         include_width_extension: bool = True,
                                         verify_tasks: bool = True) -> Dict[str, Any]:
        """ä»è½¨è¿¹å®Œæ•´åˆæˆä»»åŠ¡"""
        logger.info(f"ğŸš€ å¼€å§‹ä» {len(trajectories)} ä¸ªè½¨è¿¹å®Œæ•´åˆæˆä»»åŠ¡")
        
        start_time = time.time()
        self.generation_metrics.total_trajectories_processed = len(trajectories)
        
        try:
            # Phase 1: è¯­æ–™æå–
            logger.info("ğŸ“– Phase 1: è¯­æ–™æå–")
            corpus_contents = await self.corpus_ingestor.ingest_from_trajectories(trajectories)
            
            if not corpus_contents:
                logger.warning("âš ï¸ æœªæå–åˆ°æœ‰æ•ˆè¯­æ–™")
                return self._build_empty_result("æ— æœ‰æ•ˆè¯­æ–™")
            
            # å­˜å‚¨è¯­æ–™åˆ°Redisé˜Ÿåˆ—
            await self._store_corpus_to_redis(corpus_contents)
            
            # Phase 2: åŸå­ä»»åŠ¡ç”Ÿæˆ
            logger.info("âš›ï¸ Phase 2: åŸå­ä»»åŠ¡ç”Ÿæˆ")
            atomic_tasks = await self.atomic_generator.generate_atomic_tasks_from_corpus(corpus_contents)
            self.generation_metrics.atomic_tasks_generated = len(atomic_tasks)
            
            if not atomic_tasks:
                logger.warning("âš ï¸ æœªç”ŸæˆåŸå­ä»»åŠ¡")
                return self._build_empty_result("æ— åŸå­ä»»åŠ¡ç”Ÿæˆ")
            
            # å­˜å‚¨åŸå­ä»»åŠ¡
            await self._store_atomic_tasks_to_redis(atomic_tasks)
            
            # Phase 3: ä»»åŠ¡æ‰©å±•
            extended_tasks = []
            composite_tasks = []
            
            if include_depth_extension:
                logger.info("ğŸ”„ Phase 3a: æ·±åº¦æ‰©å±•")
                extended_tasks = await self.depth_extender.batch_extend_atomic_tasks(atomic_tasks)
                self.generation_metrics.depth_extended_tasks = len(extended_tasks)
                await self._store_extended_tasks_to_redis(extended_tasks)
            
            if include_width_extension:
                logger.info("ğŸ”— Phase 3b: å®½åº¦æ‰©å±•")
                composite_tasks = await self.width_extender.extend_atomic_tasks_width(atomic_tasks)
                self.generation_metrics.width_extended_tasks = len(composite_tasks)
                await self._store_extended_tasks_to_redis(composite_tasks)
            
            # Phase 4: éªŒè¯
            verification_results = []
            if verify_tasks:
                logger.info("ğŸ” Phase 4: ä»»åŠ¡éªŒè¯")
                all_tasks = atomic_tasks + extended_tasks + composite_tasks
                verification_results = await self.verification_engine.batch_verification(all_tasks)
                
                # ç»Ÿè®¡éªŒè¯ç»“æœ
                passed = sum(1 for r in verification_results if r.recommendation == "accept")
                failed = sum(1 for r in verification_results if r.recommendation == "reject")
                
                self.generation_metrics.verification_passed = passed
                self.generation_metrics.verification_failed = failed
                
                # è®¡ç®—å¹³å‡è´¨é‡åˆ†æ•°
                if verification_results:
                    avg_score = sum(r.overall_score for r in verification_results) / len(verification_results)
                    self.generation_metrics.average_quality_score = avg_score
                
                # å­˜å‚¨éªŒè¯ç»“æœ
                await self._store_verification_results_to_redis(verification_results)
            
            # å®Œæˆç»Ÿè®¡
            processing_time = time.time() - start_time
            self.generation_metrics.processing_time_seconds = processing_time
            self.generation_metrics.end_time = datetime.now().isoformat()
            
            # å­˜å‚¨æŒ‡æ ‡
            await self.redis_manager.metrics_manager.update_generation_metrics(
                self.session_id, self.generation_metrics
            )
            
            # æ„å»ºç»“æœ
            result = {
                "session_id": self.session_id,
                "success": True,
                "corpus_contents": corpus_contents,
                "atomic_tasks": atomic_tasks,
                "extended_tasks": extended_tasks,
                "composite_tasks": composite_tasks,
                "verification_results": verification_results,
                "generation_metrics": asdict(self.generation_metrics),
                "processing_time": processing_time,
                "statistics": await self._generate_comprehensive_statistics(
                    atomic_tasks, extended_tasks, composite_tasks, verification_results
                )
            }
            
            logger.info(f"âœ… ä»»åŠ¡åˆæˆå®Œæˆ - åŸå­: {len(atomic_tasks)}, æ·±åº¦æ‰©å±•: {len(extended_tasks)}, å®½åº¦æ‰©å±•: {len(composite_tasks)} (ç”¨æ—¶: {processing_time:.2f}s)")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ä»»åŠ¡åˆæˆå¤±è´¥: {e}")
            return self._build_error_result(str(e))
    
    async def synthesize_from_external_domains(self, domains: List[str],
                                             include_depth_extension: bool = True,
                                             include_width_extension: bool = True,
                                             verify_tasks: bool = True) -> Dict[str, Any]:
        """ä»å¤–éƒ¨é¢†åŸŸåˆæˆä»»åŠ¡"""
        logger.info(f"ğŸ” å¼€å§‹ä»å¤–éƒ¨é¢†åŸŸåˆæˆä»»åŠ¡: {domains}")
        
        start_time = time.time()
        
        try:
            # Phase 1: å¤–éƒ¨è¯­æ–™é‡‡æ ·
            logger.info("ğŸ“¡ Phase 1: å¤–éƒ¨è¯­æ–™é‡‡æ ·")
            corpus_contents = await self.corpus_ingestor.ingest_external_corpus(domains)
            
            if not corpus_contents:
                logger.warning("âš ï¸ å¤–éƒ¨è¯­æ–™é‡‡æ ·æœªè·å¾—ç»“æœ")
                return self._build_empty_result("å¤–éƒ¨è¯­æ–™é‡‡æ ·å¤±è´¥")
            
            # ä½¿ç”¨è¯­æ–™ç”Ÿæˆä»»åŠ¡ï¼ˆå¤ç”¨è½¨è¿¹å¤„ç†æµç¨‹ï¼‰
            fake_trajectories = []  # å¤–éƒ¨è¯­æ–™ä¸éœ€è¦è½¨è¿¹
            self.generation_metrics.total_trajectories_processed = len(corpus_contents)
            
            # ç›´æ¥ä»è¯­æ–™ç”ŸæˆåŸå­ä»»åŠ¡
            atomic_tasks = await self.atomic_generator.generate_atomic_tasks_from_corpus(corpus_contents)
            self.generation_metrics.atomic_tasks_generated = len(atomic_tasks)
            
            if not atomic_tasks:
                return self._build_empty_result("æ— åŸå­ä»»åŠ¡ç”Ÿæˆ")
            
            # åç»­æµç¨‹ä¸è½¨è¿¹å¤„ç†ç›¸åŒ
            extended_tasks = []
            composite_tasks = []
            
            if include_depth_extension:
                extended_tasks = await self.depth_extender.batch_extend_atomic_tasks(atomic_tasks)
                self.generation_metrics.depth_extended_tasks = len(extended_tasks)
            
            if include_width_extension:
                composite_tasks = await self.width_extender.extend_atomic_tasks_width(atomic_tasks)
                self.generation_metrics.width_extended_tasks = len(composite_tasks)
            
            verification_results = []
            if verify_tasks:
                all_tasks = atomic_tasks + extended_tasks + composite_tasks
                verification_results = await self.verification_engine.batch_verification(all_tasks)
                
                passed = sum(1 for r in verification_results if r.recommendation == "accept")
                failed = sum(1 for r in verification_results if r.recommendation == "reject")
                
                self.generation_metrics.verification_passed = passed
                self.generation_metrics.verification_failed = failed
            
            processing_time = time.time() - start_time
            self.generation_metrics.processing_time_seconds = processing_time
            self.generation_metrics.end_time = datetime.now().isoformat()
            
            result = {
                "session_id": self.session_id,
                "success": True,
                "domains": domains,
                "corpus_contents": corpus_contents,
                "atomic_tasks": atomic_tasks,
                "extended_tasks": extended_tasks,
                "composite_tasks": composite_tasks,
                "verification_results": verification_results,
                "generation_metrics": asdict(self.generation_metrics),
                "processing_time": processing_time
            }
            
            logger.info(f"âœ… å¤–éƒ¨é¢†åŸŸä»»åŠ¡åˆæˆå®Œæˆ: {len(atomic_tasks)} åŸå­ä»»åŠ¡")
            return result
            
        except Exception as e:
            logger.error(f"âŒ å¤–éƒ¨é¢†åŸŸä»»åŠ¡åˆæˆå¤±è´¥: {e}")
            return self._build_error_result(str(e))
    
    async def verify_task_quality(self, task: TaskUnion) -> VerificationResult:
        """éªŒè¯å•ä¸ªä»»åŠ¡è´¨é‡"""
        return await self.verification_engine.comprehensive_task_verification(task)
    
    async def get_session_metrics(self) -> Dict[str, Any]:
        """è·å–ä¼šè¯æŒ‡æ ‡"""
        return asdict(self.generation_metrics)
    
    async def get_global_metrics(self) -> Dict[str, Any]:
        """è·å–å…¨å±€æŒ‡æ ‡"""
        return await self.redis_manager.metrics_manager.get_global_metrics()
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        return await self.redis_manager.health_check()
    
    # å†…éƒ¨è¾…åŠ©æ–¹æ³•
    
    async def _store_corpus_to_redis(self, corpus_contents: List[CorpusContent]):
        """å­˜å‚¨è¯­æ–™åˆ°Redis"""
        try:
            await self.redis_manager.corpus_queue.batch_add_corpus(corpus_contents)
            logger.debug(f"âœ… å·²å­˜å‚¨ {len(corpus_contents)} ä¸ªè¯­æ–™åˆ°Redis")
        except Exception as e:
            logger.error(f"âŒ å­˜å‚¨è¯­æ–™åˆ°Rediså¤±è´¥: {e}")
    
    async def _store_atomic_tasks_to_redis(self, atomic_tasks: List[AtomicTask]):
        """å­˜å‚¨åŸå­ä»»åŠ¡åˆ°Redis"""
        try:
            await self.redis_manager.task_queue.batch_add_tasks(atomic_tasks)
            logger.debug(f"âœ… å·²å­˜å‚¨ {len(atomic_tasks)} ä¸ªåŸå­ä»»åŠ¡åˆ°Redis")
        except Exception as e:
            logger.error(f"âŒ å­˜å‚¨åŸå­ä»»åŠ¡åˆ°Rediså¤±è´¥: {e}")
    
    async def _store_extended_tasks_to_redis(self, extended_tasks: List[Union[ExtendedTask, CompositeTask]]):
        """å­˜å‚¨æ‰©å±•ä»»åŠ¡åˆ°Redis"""
        try:
            await self.redis_manager.task_queue.batch_add_tasks(extended_tasks)
            logger.debug(f"âœ… å·²å­˜å‚¨ {len(extended_tasks)} ä¸ªæ‰©å±•ä»»åŠ¡åˆ°Redis")
        except Exception as e:
            logger.error(f"âŒ å­˜å‚¨æ‰©å±•ä»»åŠ¡åˆ°Rediså¤±è´¥: {e}")
    
    async def _store_verification_results_to_redis(self, verification_results: List[VerificationResult]):
        """å­˜å‚¨éªŒè¯ç»“æœåˆ°Redis"""
        try:
            for result in verification_results:
                await self.redis_manager.verification_queue.add_verification_result(result)
            logger.debug(f"âœ… å·²å­˜å‚¨ {len(verification_results)} ä¸ªéªŒè¯ç»“æœåˆ°Redis")
        except Exception as e:
            logger.error(f"âŒ å­˜å‚¨éªŒè¯ç»“æœåˆ°Rediså¤±è´¥: {e}")
    
    async def _generate_comprehensive_statistics(self, atomic_tasks: List[AtomicTask],
                                               extended_tasks: List[ExtendedTask],
                                               composite_tasks: List[CompositeTask],
                                               verification_results: List[VerificationResult]) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆç»Ÿè®¡ä¿¡æ¯"""
        
        statistics = {
            "task_generation": {
                "atomic_tasks": len(atomic_tasks),
                "depth_extended_tasks": len(extended_tasks),
                "width_extended_tasks": len(composite_tasks),
                "total_tasks": len(atomic_tasks) + len(extended_tasks) + len(composite_tasks)
            },
            "verification": {
                "total_verified": len(verification_results),
                "accepted": sum(1 for r in verification_results if r.recommendation == "accept"),
                "modified": sum(1 for r in verification_results if r.recommendation == "modify"),
                "rejected": sum(1 for r in verification_results if r.recommendation == "reject")
            }
        }
        
        # æ·»åŠ è¯¦ç»†ç»Ÿè®¡
        if atomic_tasks:
            atomic_stats = await self.atomic_generator.get_generation_statistics(atomic_tasks)
            statistics["atomic_task_details"] = atomic_stats
        
        if extended_tasks:
            depth_stats = await self.depth_extender.get_extension_statistics(extended_tasks)
            statistics["depth_extension_details"] = depth_stats
        
        if atomic_tasks and composite_tasks:
            width_stats = await self.width_extender.get_width_extension_statistics(atomic_tasks, composite_tasks)
            statistics["width_extension_details"] = width_stats
        
        # è®¡ç®—æ•ˆç‡æŒ‡æ ‡
        if self.generation_metrics.total_trajectories_processed > 0:
            statistics["efficiency"] = {
                "tasks_per_trajectory": statistics["task_generation"]["total_tasks"] / self.generation_metrics.total_trajectories_processed,
                "verification_pass_rate": self.generation_metrics.verification_pass_rate,
                "generation_efficiency": self.generation_metrics.generation_efficiency
            }
        
        return statistics
    
    def _build_empty_result(self, reason: str) -> Dict[str, Any]:
        """æ„å»ºç©ºç»“æœ"""
        return {
            "session_id": self.session_id,
            "success": False,
            "reason": reason,
            "corpus_contents": [],
            "atomic_tasks": [],
            "extended_tasks": [],
            "composite_tasks": [],
            "verification_results": [],
            "generation_metrics": asdict(self.generation_metrics),
            "processing_time": 0.0
        }
    
    def _build_error_result(self, error: str) -> Dict[str, Any]:
        """æ„å»ºé”™è¯¯ç»“æœ"""
        return {
            "session_id": self.session_id,
            "success": False,
            "error": error,
            "corpus_contents": [],
            "atomic_tasks": [],
            "extended_tasks": [],
            "composite_tasks": [],
            "verification_results": [],
            "generation_metrics": asdict(self.generation_metrics),
            "processing_time": 0.0
        }


class SynthesisCoreV2:
    """SynthesisCore v2.0 - å¯¹å¤–ç»Ÿä¸€æ¥å£"""
    
    def __init__(self, llm_client: LLMClient, mcp_client: Optional[MCPToolClient] = None,
                 redis_url: str = "redis://localhost:6379"):
        self.engine = EnhancedSynthesisEngine(llm_client, mcp_client, redis_url)
        self.config = EnhancedSynthesisConfig()
        
    async def initialize(self):
        """åˆå§‹åŒ–"""
        await self.engine.initialize()
        logger.info("ğŸš€ SynthesisCore v2.0 å·²å¯åŠ¨")
    
    async def close(self):
        """å…³é—­"""
        await self.engine.close()
        logger.info("ğŸ”’ SynthesisCore v2.0 å·²å…³é—­")
    
    async def synthesize_tasks(self, trajectories: List[TrajectoryResult] = None,
                              domains: List[str] = None,
                              mode: str = "full",
                              verify_quality: bool = True) -> Dict[str, Any]:
        """
        ç»Ÿä¸€çš„ä»»åŠ¡åˆæˆæ¥å£
        
        Args:
            trajectories: è½¨è¿¹æ•°æ®ï¼ˆå¯é€‰ï¼‰
            domains: å¤–éƒ¨é¢†åŸŸï¼ˆå¯é€‰ï¼‰
            mode: åˆæˆæ¨¡å¼ (full/atomic_only/depth_only/width_only)
            verify_quality: æ˜¯å¦è¿›è¡Œè´¨é‡éªŒè¯
        """
        
        include_depth = mode in ["full", "depth_only"]
        include_width = mode in ["full", "width_only"]
        
        if trajectories:
            return await self.engine.synthesize_from_trajectories(
                trajectories, include_depth, include_width, verify_quality
            )
        elif domains:
            return await self.engine.synthesize_from_external_domains(
                domains, include_depth, include_width, verify_quality
            )
        else:
            raise ValueError("å¿…é¡»æä¾›trajectoriesæˆ–domainsä¸­çš„è‡³å°‘ä¸€ä¸ª")
    
    async def verify_task(self, task: TaskUnion) -> VerificationResult:
        """éªŒè¯å•ä¸ªä»»åŠ¡"""
        return await self.engine.verify_task_quality(task)
    
    async def get_metrics(self, scope: str = "session") -> Dict[str, Any]:
        """è·å–æŒ‡æ ‡"""
        if scope == "session":
            return await self.engine.get_session_metrics()
        elif scope == "global":
            return await self.engine.get_global_metrics()
        else:
            raise ValueError("scopeå¿…é¡»æ˜¯'session'æˆ–'global'")
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        return await self.engine.health_check()
    
    def get_config(self) -> EnhancedSynthesisConfig:
        """è·å–é…ç½®"""
        return self.config