#!/usr/bin/env python3
"""
Real-Time Extension Trigger - å®æ—¶æ‰©å±•è§¦å‘å™¨
å®ç°è½¨è¿¹å®Œæˆåçš„å®æ—¶ä»»åŠ¡æ‰©å±•ï¼Œé©±åŠ¨æ•°æ®é£è½®é—­ç¯åŠ é€Ÿ
"""

import asyncio
import json
import logging
import time
from typing import Dict, List, Optional, Any, Callable
from dataclasses import asdict
from datetime import datetime

from core.interfaces import TrajectoryResult
from core.llm_client import LLMClient
from core.toolscore.mcp_client import MCPToolClient
from .enhanced_interfaces import (
    AtomicTask, ExtendedTask, CompositeTask, GenerationMetrics,
    AdaptiveExtensionConfig, TaskVerificationMetrics
)
from .enhanced_synthesis_engine import EnhancedSynthesisEngine
from .depth_extender import DepthExtender
from .width_extender import WidthExtender
from .enhanced_verification_agent import EnhancedVerificationAgent, BatchVerificationProcessor

logger = logging.getLogger(__name__)


class ExtensionQueue:
    """æ‰©å±•ä»»åŠ¡é˜Ÿåˆ—"""
    
    def __init__(self, max_size: int = 1000):
        self.queue = asyncio.Queue(maxsize=max_size)
        self.priority_queue = asyncio.Queue(maxsize=100)  # é«˜ä¼˜å…ˆçº§é˜Ÿåˆ—
        self.processing = False
        
    async def put_high_priority(self, item: Dict[str, Any]):
        """æ·»åŠ é«˜ä¼˜å…ˆçº§ä»»åŠ¡"""
        await self.priority_queue.put(item)
    
    async def put_normal(self, item: Dict[str, Any]):
        """æ·»åŠ æ™®é€šä¼˜å…ˆçº§ä»»åŠ¡"""
        await self.queue.put(item)
    
    async def get_next(self) -> Dict[str, Any]:
        """è·å–ä¸‹ä¸€ä¸ªä»»åŠ¡ï¼ˆä¼˜å…ˆå¤„ç†é«˜ä¼˜å…ˆçº§ï¼‰"""
        try:
            # å…ˆæ£€æŸ¥é«˜ä¼˜å…ˆçº§é˜Ÿåˆ—
            return self.priority_queue.get_nowait()
        except asyncio.QueueEmpty:
            # å†æ£€æŸ¥æ™®é€šé˜Ÿåˆ—
            return await self.queue.get()
    
    def qsize(self) -> Dict[str, int]:
        """è·å–é˜Ÿåˆ—å¤§å°"""
        return {
            "high_priority": self.priority_queue.qsize(),
            "normal": self.queue.qsize(),
            "total": self.priority_queue.qsize() + self.queue.qsize()
        }


class RealTimeExtensionTrigger:
    """å®æ—¶æ‰©å±•è§¦å‘å™¨"""
    
    def __init__(self, 
                 llm_client: LLMClient,
                 mcp_client: Optional[MCPToolClient] = None,
                 synthesis_engine: Optional[EnhancedSynthesisEngine] = None):
        
        self.llm_client = llm_client
        self.mcp_client = mcp_client
        
        # æ ¸å¿ƒç»„ä»¶
        self.synthesis_engine = synthesis_engine or EnhancedSynthesisEngine(llm_client, mcp_client)
        self.depth_extender = DepthExtender(llm_client, mcp_client)
        self.width_extender = WidthExtender(llm_client, mcp_client)
        self.verification_agent = EnhancedVerificationAgent(llm_client)
        self.batch_processor = BatchVerificationProcessor(self.verification_agent)
        
        # æ‰©å±•é˜Ÿåˆ—
        self.extension_queue = ExtensionQueue()
        
        # è‡ªé€‚åº”é…ç½®
        self.adaptive_config = AdaptiveExtensionConfig()
        
        # ç»Ÿè®¡æŒ‡æ ‡
        self.metrics = GenerationMetrics(session_id=f"realtime_{int(time.time())}")
        
        # å›è°ƒå‡½æ•°
        self.task_generated_callback: Optional[Callable[[List[Any]], None]] = None
        self.quality_report_callback: Optional[Callable[[Dict[str, Any]], None]] = None
        
        # æ§åˆ¶å¼€å…³
        self.is_running = False
        self.processing_task = None
        
        logger.info("ğŸš€ å®æ—¶æ‰©å±•è§¦å‘å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def start(self):
        """å¯åŠ¨å®æ—¶æ‰©å±•å¤„ç†"""
        if self.is_running:
            logger.warning("âš ï¸ å®æ—¶æ‰©å±•è§¦å‘å™¨å·²åœ¨è¿è¡Œ")
            return
        
        self.is_running = True
        self.processing_task = asyncio.create_task(self._process_extension_queue())
        logger.info("âœ… å®æ—¶æ‰©å±•è§¦å‘å™¨å·²å¯åŠ¨")
    
    async def stop(self):
        """åœæ­¢å®æ—¶æ‰©å±•å¤„ç†"""
        self.is_running = False
        if self.processing_task:
            self.processing_task.cancel()
            try:
                await self.processing_task
            except asyncio.CancelledError:
                pass
        logger.info("ğŸ›‘ å®æ—¶æ‰©å±•è§¦å‘å™¨å·²åœæ­¢")
    
    async def on_trajectory_completed(self, trajectory: TrajectoryResult):
        """è½¨è¿¹å®Œæˆæ—¶çš„å›è°ƒå¤„ç†"""
        logger.info(f"ğŸ“¥ æ¥æ”¶åˆ°è½¨è¿¹å®Œæˆäº‹ä»¶: {trajectory.trajectory_id}")
        
        if not trajectory.is_successful:
            logger.debug(f"âš ï¸ è½¨è¿¹æ‰§è¡Œå¤±è´¥ï¼Œè·³è¿‡æ‰©å±•: {trajectory.trajectory_id}")
            return
        
        try:
            # åˆ›å»ºæ‰©å±•è¯·æ±‚
            extension_request = {
                "type": "immediate_extension",
                "trajectory": trajectory,
                "priority": self._determine_priority(trajectory),
                "timestamp": datetime.now().isoformat(),
                "request_id": f"ext_{int(time.time())}_{trajectory.trajectory_id}"
            }
            
            # æ ¹æ®ä¼˜å…ˆçº§åŠ å…¥é˜Ÿåˆ—
            if extension_request["priority"] == "high":
                await self.extension_queue.put_high_priority(extension_request)
                logger.info(f"ğŸ”¥ é«˜ä¼˜å…ˆçº§æ‰©å±•è¯·æ±‚å·²å…¥é˜Ÿ: {trajectory.trajectory_id}")
            else:
                await self.extension_queue.put_normal(extension_request)
                logger.info(f"ğŸ“ æ™®é€šæ‰©å±•è¯·æ±‚å·²å…¥é˜Ÿ: {trajectory.trajectory_id}")
            
            # æ›´æ–°ç»Ÿè®¡
            self.metrics.total_trajectories_processed += 1
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†è½¨è¿¹å®Œæˆäº‹ä»¶å¤±è´¥ {trajectory.trajectory_id}: {e}")
    
    def _determine_priority(self, trajectory: TrajectoryResult) -> str:
        """ç¡®å®šæ‰©å±•ä¼˜å…ˆçº§"""
        # åŸºäºè½¨è¿¹ç‰¹å¾ç¡®å®šä¼˜å…ˆçº§
        high_priority_conditions = [
            len(trajectory.steps) >= 5,  # å¤æ‚ä»»åŠ¡
            trajectory.task_complexity_score > 0.7,  # é«˜å¤æ‚åº¦
            any("error" not in step.result.lower() for step in trajectory.steps),  # æ— é”™è¯¯æ‰§è¡Œ
            trajectory.processing_time_seconds < 60  # å¿«é€Ÿå®Œæˆ
        ]
        
        if sum(high_priority_conditions) >= 2:
            return "high"
        else:
            return "normal"
    
    async def _process_extension_queue(self):
        """å¤„ç†æ‰©å±•é˜Ÿåˆ—"""
        logger.info("ğŸ”„ å¼€å§‹å¤„ç†æ‰©å±•é˜Ÿåˆ—")
        
        while self.is_running:
            try:
                # è·å–ä¸‹ä¸€ä¸ªæ‰©å±•è¯·æ±‚
                extension_request = await asyncio.wait_for(
                    self.extension_queue.get_next(), 
                    timeout=5.0
                )
                
                # å¤„ç†æ‰©å±•è¯·æ±‚
                await self._handle_extension_request(extension_request)
                
            except asyncio.TimeoutError:
                # é˜Ÿåˆ—ä¸ºç©ºï¼Œç»§ç»­ç­‰å¾…
                continue
            except Exception as e:
                logger.error(f"âŒ å¤„ç†æ‰©å±•é˜Ÿåˆ—å¼‚å¸¸: {e}")
                await asyncio.sleep(1)  # é˜²æ­¢å¼‚å¸¸å¾ªç¯
        
        logger.info("ğŸ›‘ æ‰©å±•é˜Ÿåˆ—å¤„ç†å·²åœæ­¢")
    
    async def _handle_extension_request(self, request: Dict[str, Any]):
        """å¤„ç†å•ä¸ªæ‰©å±•è¯·æ±‚"""
        request_id = request.get("request_id", "unknown")
        trajectory = request.get("trajectory")
        
        logger.info(f"ğŸ”§ å¼€å§‹å¤„ç†æ‰©å±•è¯·æ±‚: {request_id}")
        
        try:
            start_time = time.time()
            
            # 1. ä»è½¨è¿¹ä¸­æå–ç§å­ä»»åŠ¡
            seed_tasks = await self.synthesis_engine.extract_atomic_tasks_from_trajectory(trajectory)
            
            if not seed_tasks:
                logger.warning(f"âš ï¸ æœªä»è½¨è¿¹ä¸­æå–åˆ°ç§å­ä»»åŠ¡: {request_id}")
                return
            
            logger.info(f"âœ… æå–åˆ° {len(seed_tasks)} ä¸ªç§å­ä»»åŠ¡")
            self.metrics.atomic_tasks_generated += len(seed_tasks)
            
            # 2. å¹¶è¡Œæ‰§è¡Œæ·±åº¦å’Œå®½åº¦æ‰©å±•
            depth_task = self._perform_depth_extension(seed_tasks)
            width_task = self._perform_width_extension(seed_tasks)
            
            depth_results, width_results = await asyncio.gather(
                depth_task, width_task, return_exceptions=True
            )
            
            # å¤„ç†æ‰©å±•ç»“æœ
            all_extended_tasks = []
            
            if isinstance(depth_results, list):
                all_extended_tasks.extend(depth_results)
                self.metrics.depth_extended_tasks += len(depth_results)
                logger.info(f"âœ… æ·±åº¦æ‰©å±•ç”Ÿæˆ {len(depth_results)} ä¸ªä»»åŠ¡")
            elif isinstance(depth_results, Exception):
                logger.error(f"âŒ æ·±åº¦æ‰©å±•å¤±è´¥: {depth_results}")
            
            if isinstance(width_results, list):
                all_extended_tasks.extend(width_results)
                self.metrics.width_extended_tasks += len(width_results)
                logger.info(f"âœ… å®½åº¦æ‰©å±•ç”Ÿæˆ {len(width_results)} ä¸ªä»»åŠ¡")
            elif isinstance(width_results, Exception):
                logger.error(f"âŒ å®½åº¦æ‰©å±•å¤±è´¥: {width_results}")
            
            # 3. æ‰¹é‡éªŒè¯æ‰©å±•ä»»åŠ¡
            if all_extended_tasks:
                verification_results = await self._verify_extended_tasks(all_extended_tasks)
                
                # 4. ç­›é€‰é«˜è´¨é‡ä»»åŠ¡
                high_quality_tasks = self._filter_high_quality_tasks(
                    all_extended_tasks, verification_results
                )
                
                # 5. æ·»åŠ åˆ°ä»»åŠ¡æ± å¹¶è§¦å‘å›è°ƒ
                if high_quality_tasks:
                    await self._add_to_task_pool(high_quality_tasks)
                    
                    if self.task_generated_callback:
                        try:
                            self.task_generated_callback(high_quality_tasks)
                        except Exception as e:
                            logger.error(f"âŒ ä»»åŠ¡ç”Ÿæˆå›è°ƒå¤±è´¥: {e}")
                
                # 6. æ›´æ–°è‡ªé€‚åº”é…ç½®
                await self._update_adaptive_config(verification_results)
                
                # 7. ç”Ÿæˆè´¨é‡æŠ¥å‘Š
                quality_report = self._generate_quality_report(verification_results, request)
                if self.quality_report_callback:
                    try:
                        self.quality_report_callback(quality_report)
                    except Exception as e:
                        logger.error(f"âŒ è´¨é‡æŠ¥å‘Šå›è°ƒå¤±è´¥: {e}")
            
            processing_time = time.time() - start_time
            self.metrics.processing_time_seconds += processing_time
            
            logger.info(f"âœ… æ‰©å±•è¯·æ±‚å¤„ç†å®Œæˆ: {request_id} (è€—æ—¶: {processing_time:.2f}ç§’)")
            
        except Exception as e:
            logger.error(f"âŒ æ‰©å±•è¯·æ±‚å¤„ç†å¤±è´¥ {request_id}: {e}")
    
    async def _perform_depth_extension(self, seed_tasks: List[AtomicTask]) -> List[ExtendedTask]:
        """æ‰§è¡Œæ·±åº¦æ‰©å±•"""
        try:
            batch_size = self.adaptive_config.batch_config["batch_size"]
            
            # åˆ†æ‰¹å¤„ç†ä»¥ä¼˜åŒ–æ€§èƒ½
            all_results = []
            for i in range(0, len(seed_tasks), batch_size):
                batch = seed_tasks[i:i + batch_size]
                batch_results = await self.depth_extender.batch_extend_atomic_tasks(batch)
                all_results.extend(batch_results)
            
            return all_results
            
        except Exception as e:
            logger.error(f"âŒ æ·±åº¦æ‰©å±•æ‰§è¡Œå¤±è´¥: {e}")
            return []
    
    async def _perform_width_extension(self, seed_tasks: List[AtomicTask]) -> List[CompositeTask]:
        """æ‰§è¡Œå®½åº¦æ‰©å±•"""
        try:
            return await self.width_extender.extend_atomic_tasks_width(seed_tasks)
        except Exception as e:
            logger.error(f"âŒ å®½åº¦æ‰©å±•æ‰§è¡Œå¤±è´¥: {e}")
            return []
    
    async def _verify_extended_tasks(self, tasks: List[Any]) -> List[TaskVerificationMetrics]:
        """éªŒè¯æ‰©å±•ä»»åŠ¡"""
        try:
            max_concurrent = self.adaptive_config.batch_config["max_concurrent_batches"]
            return await self.batch_processor.batch_verify_tasks(tasks, max_concurrent)
        except Exception as e:
            logger.error(f"âŒ ä»»åŠ¡éªŒè¯å¤±è´¥: {e}")
            return []
    
    def _filter_high_quality_tasks(self, tasks: List[Any], 
                                  verification_results: List[TaskVerificationMetrics]) -> List[Any]:
        """ç­›é€‰é«˜è´¨é‡ä»»åŠ¡"""
        high_quality_tasks = []
        
        for task, verification in zip(tasks, verification_results):
            if verification.verification_passed:
                high_quality_tasks.append(task)
                self.metrics.verification_passed += 1
            else:
                self.metrics.verification_failed += 1
        
        logger.info(f"âœ… ç­›é€‰å‡º {len(high_quality_tasks)} ä¸ªé«˜è´¨é‡ä»»åŠ¡")
        return high_quality_tasks
    
    async def _add_to_task_pool(self, tasks: List[Any]):
        """æ·»åŠ ä»»åŠ¡åˆ°ä»»åŠ¡æ± """
        try:
            # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„ä»»åŠ¡æ± å­˜å‚¨é€»è¾‘
            # æ¯”å¦‚å­˜å‚¨åˆ°Redisã€æ•°æ®åº“ç­‰
            logger.info(f"ğŸ“ {len(tasks)} ä¸ªä»»åŠ¡å·²æ·»åŠ åˆ°ä»»åŠ¡æ± ")
            
            # ç¤ºä¾‹ï¼šå­˜å‚¨åˆ°Redis (éœ€è¦å®é™…çš„Rediså®¢æˆ·ç«¯)
            # await self._store_tasks_to_redis(tasks)
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ ä»»åŠ¡åˆ°ä»»åŠ¡æ± å¤±è´¥: {e}")
    
    async def _update_adaptive_config(self, verification_results: List[TaskVerificationMetrics]):
        """æ›´æ–°è‡ªé€‚åº”é…ç½®"""
        try:
            if not verification_results:
                return
            
            # è®¡ç®—æˆåŠŸç‡
            passed_count = sum(1 for r in verification_results if r.verification_passed)
            success_rate = passed_count / len(verification_results)
            
            # è®°å½•æˆåŠŸç‡å†å²
            for result in verification_results:
                self.adaptive_config.record_success(result.verification_passed)
            
            # è®¡ç®—æ•ˆç‡æŒ‡æ ‡
            efficiency_metrics = {
                "verification_success_rate": success_rate,
                "average_quality_score": sum(r.overall_score for r in verification_results) / len(verification_results),
                "processing_efficiency": self.metrics.generation_efficiency
            }
            
            # è°ƒæ•´é˜ˆå€¼
            self.adaptive_config.adjust_thresholds(success_rate, efficiency_metrics)
            
            logger.debug(f"ğŸ”§ è‡ªé€‚åº”é…ç½®å·²æ›´æ–° (æˆåŠŸç‡: {success_rate:.3f})")
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°è‡ªé€‚åº”é…ç½®å¤±è´¥: {e}")
    
    def _generate_quality_report(self, verification_results: List[TaskVerificationMetrics], 
                               request: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        try:
            analysis = self.batch_processor.analyze_verification_results(verification_results)
            
            report = {
                "request_id": request.get("request_id", "unknown"),
                "timestamp": datetime.now().isoformat(),
                "trajectory_id": request.get("trajectory", {}).get("trajectory_id", "unknown"),
                "processing_summary": {
                    "seed_tasks_generated": self.metrics.atomic_tasks_generated,
                    "depth_extended_tasks": self.metrics.depth_extended_tasks,
                    "width_extended_tasks": self.metrics.width_extended_tasks,
                    "verification_pass_rate": analysis.get("pass_rate", 0.0),
                    "average_quality_score": analysis.get("average_overall_score", 0.0)
                },
                "quality_analysis": analysis,
                "adaptive_config_snapshot": {
                    "current_success_rate": self.adaptive_config.get_current_success_rate(),
                    "depth_threshold": self.adaptive_config.depth_config["superset_confidence_threshold"],
                    "width_threshold": self.adaptive_config.width_config["semantic_similarity_threshold"],
                    "batch_size": self.adaptive_config.batch_config["batch_size"]
                },
                "performance_metrics": {
                    "total_processing_time": self.metrics.processing_time_seconds,
                    "average_time_per_trajectory": (
                        self.metrics.processing_time_seconds / max(self.metrics.total_trajectories_processed, 1)
                    ),
                    "generation_efficiency": self.metrics.generation_efficiency
                }
            }
            
            return report
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆè´¨é‡æŠ¥å‘Šå¤±è´¥: {e}")
            return {"error": str(e)}
    
    # å›è°ƒå‡½æ•°è®¾ç½®
    def set_task_generated_callback(self, callback: Callable[[List[Any]], None]):
        """è®¾ç½®ä»»åŠ¡ç”Ÿæˆå›è°ƒå‡½æ•°"""
        self.task_generated_callback = callback
        logger.info("âœ… ä»»åŠ¡ç”Ÿæˆå›è°ƒå‡½æ•°å·²è®¾ç½®")
    
    def set_quality_report_callback(self, callback: Callable[[Dict[str, Any]], None]):
        """è®¾ç½®è´¨é‡æŠ¥å‘Šå›è°ƒå‡½æ•°"""
        self.quality_report_callback = callback
        logger.info("âœ… è´¨é‡æŠ¥å‘Šå›è°ƒå‡½æ•°å·²è®¾ç½®")
    
    # çŠ¶æ€æŸ¥è¯¢æ–¹æ³•
    def get_status(self) -> Dict[str, Any]:
        """è·å–è§¦å‘å™¨çŠ¶æ€"""
        return {
            "is_running": self.is_running,
            "queue_sizes": self.extension_queue.qsize(),
            "metrics": asdict(self.metrics),
            "adaptive_config": {
                "current_success_rate": self.adaptive_config.get_current_success_rate(),
                "depth_threshold": self.adaptive_config.depth_config["superset_confidence_threshold"],
                "width_threshold": self.adaptive_config.width_config["semantic_similarity_threshold"],
                "batch_size": self.adaptive_config.batch_config["batch_size"]
            }
        }
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æ€»ç»“"""
        if self.metrics.total_trajectories_processed == 0:
            return {"status": "no_data"}
        
        return {
            "total_trajectories": self.metrics.total_trajectories_processed,
            "total_tasks_generated": self.metrics.total_tasks_generated,
            "generation_efficiency": self.metrics.generation_efficiency,
            "verification_pass_rate": self.metrics.verification_pass_rate,
            "average_processing_time": (
                self.metrics.processing_time_seconds / self.metrics.total_trajectories_processed
            ),
            "quality_score": self.metrics.average_quality_score,
            "uptime_seconds": time.time() - self.metrics.start_time
        }


class RealTimeExtensionManager:
    """å®æ—¶æ‰©å±•ç®¡ç†å™¨ - æä¾›ç»Ÿä¸€çš„ç®¡ç†æ¥å£"""
    
    def __init__(self, trigger: RealTimeExtensionTrigger):
        self.trigger = trigger
        self.monitoring_enabled = False
        self.performance_history = []
    
    async def start_monitoring(self, interval_seconds: int = 60):
        """å¼€å§‹æ€§èƒ½ç›‘æ§"""
        self.monitoring_enabled = True
        
        while self.monitoring_enabled:
            try:
                await asyncio.sleep(interval_seconds)
                
                # æ”¶é›†æ€§èƒ½æ•°æ®
                performance_data = {
                    "timestamp": datetime.now().isoformat(),
                    "status": self.trigger.get_status(),
                    "performance": self.trigger.get_performance_summary()
                }
                
                self.performance_history.append(performance_data)
                
                # ä¿æŒå†å²è®°å½•å¤§å°
                if len(self.performance_history) > 100:
                    self.performance_history.pop(0)
                
                # æ—¥å¿—è®°å½•
                status = performance_data["status"]
                queue_total = status["queue_sizes"]["total"]
                success_rate = status["adaptive_config"]["current_success_rate"]
                
                logger.info(f"ğŸ“Š æ€§èƒ½ç›‘æ§ - é˜Ÿåˆ—: {queue_total}, æˆåŠŸç‡: {success_rate:.3f}")
                
            except Exception as e:
                logger.error(f"âŒ æ€§èƒ½ç›‘æ§å¼‚å¸¸: {e}")
    
    def stop_monitoring(self):
        """åœæ­¢æ€§èƒ½ç›‘æ§"""
        self.monitoring_enabled = False
        logger.info("ğŸ›‘ æ€§èƒ½ç›‘æ§å·²åœæ­¢")
    
    def get_monitoring_report(self) -> Dict[str, Any]:
        """è·å–ç›‘æ§æŠ¥å‘Š"""
        if not self.performance_history:
            return {"status": "no_monitoring_data"}
        
        recent_data = self.performance_history[-10:]  # æœ€è¿‘10æ¬¡ç›‘æ§æ•°æ®
        
        # è®¡ç®—è¶‹åŠ¿
        success_rates = [d["status"]["adaptive_config"]["current_success_rate"] for d in recent_data]
        avg_success_rate = sum(success_rates) / len(success_rates)
        
        queue_sizes = [d["status"]["queue_sizes"]["total"] for d in recent_data]
        avg_queue_size = sum(queue_sizes) / len(queue_sizes)
        
        return {
            "monitoring_period": {
                "start": self.performance_history[0]["timestamp"],
                "end": self.performance_history[-1]["timestamp"],
                "data_points": len(self.performance_history)
            },
            "current_status": self.trigger.get_status(),
            "trends": {
                "average_success_rate": avg_success_rate,
                "average_queue_size": avg_queue_size,
                "success_rate_trend": "stable" if max(success_rates) - min(success_rates) < 0.1 else "variable"
            },
            "recommendations": self._generate_monitoring_recommendations(avg_success_rate, avg_queue_size)
        }
    
    def _generate_monitoring_recommendations(self, avg_success_rate: float, avg_queue_size: float) -> List[str]:
        """ç”Ÿæˆç›‘æ§å»ºè®®"""
        recommendations = []
        
        if avg_success_rate < 0.7:
            recommendations.append("æˆåŠŸç‡è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥è´¨é‡éªŒè¯æ ‡å‡†")
        
        if avg_queue_size > 50:
            recommendations.append("é˜Ÿåˆ—ç§¯å‹ä¸¥é‡ï¼Œå»ºè®®å¢åŠ å¤„ç†å¹¶å‘æ•°")
        elif avg_queue_size < 5:
            recommendations.append("é˜Ÿåˆ—ä½¿ç”¨ç‡è¾ƒä½ï¼Œå¯ä»¥è€ƒè™‘é™ä½å¤„ç†èµ„æº")
        
        return recommendations