#!/usr/bin/env python3
"""
Agent Data Platform - Main Entry Point (æ— Dockerç‰ˆæœ¬)
"""

import asyncio
import logging
import os
import sys
from pathlib import Path
import signal
import argparse
from dotenv import load_dotenv
import contextlib
import io
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(project_root / '.env')

class SafeFormatter(logging.Formatter):
    """å®‰å…¨çš„æ—¥å¿—æ ¼å¼åŒ–å™¨ï¼Œå¤„ç†Unicodeå­—ç¬¦"""
    def format(self, record):
        try:
            return super().format(record)
        except UnicodeEncodeError:
            msg = record.getMessage()
            msg = msg.replace('âœ…', '[OK]').replace('âŒ', '[ERROR]').replace('âš ï¸', '[WARN]').replace('ğŸš€', '[START]').replace('ğŸ”§', '[FIX]').replace('â³', '[WAIT]').replace('ğŸ”„', '[PROC]')
            record.msg = msg
            record.args = ()
            return super().format(record)

class UnifiedLogCapture:
    """ç»Ÿä¸€çš„æ—¥å¿—æ•è·ç³»ç»Ÿ - æ•è·æ‰€æœ‰è¾“å‡ºåˆ°å•ä¸ªæ–‡ä»¶"""
    
    def __init__(self, log_file_path: str):
        self.log_file_path = log_file_path
        self.original_stdout = sys.stdout
        self.original_stderr = sys.stderr
        self.log_file = None
        self.original_handlers = []
        
    def __enter__(self):
        # åˆ›å»ºæ—¥å¿—ç›®å½•
        os.makedirs(os.path.dirname(self.log_file_path), exist_ok=True)
        
        # æ‰“å¼€ç»Ÿä¸€æ—¥å¿—æ–‡ä»¶
        self.log_file = open(self.log_file_path, 'a', encoding='utf-8')
        
        # åˆ›å»ºä¸€ä¸ªåŒæ—¶å†™å…¥æ§åˆ¶å°å’Œæ–‡ä»¶çš„åŒ…è£…å™¨
        class UnifiedWriter:
            def __init__(self, console, file_handle):
                self.console = console
                self.file = file_handle
                
            def write(self, text):
                # å†™å…¥æ§åˆ¶å°
                self.console.write(text)
                self.console.flush()
                
                # å†™å…¥ç»Ÿä¸€æ—¥å¿—æ–‡ä»¶
                if text.strip():  # åªå¯¹éç©ºå†…å®¹æ·»åŠ æ—¶é—´æˆ³
                    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰æ—¶é—´æˆ³ï¼Œé¿å…é‡å¤
                    if not text.startswith(timestamp[:10]):  # ç®€å•æ£€æŸ¥æ—¥æœŸéƒ¨åˆ†
                        self.file.write(f"[{timestamp}] {text}")
                    else:
                        self.file.write(text)
                else:
                    self.file.write(text)
                self.file.flush()
                
            def flush(self):
                self.console.flush()
                self.file.flush()
                
            def isatty(self):
                return self.console.isatty() if hasattr(self.console, 'isatty') else False
                
        # æ›¿æ¢stdoutå’Œstderr
        sys.stdout = UnifiedWriter(self.original_stdout, self.log_file)
        sys.stderr = UnifiedWriter(self.original_stderr, self.log_file)
        
        # é‡æ–°é…ç½®æ‰€æœ‰ç°æœ‰çš„logging handlersï¼Œè®©å®ƒä»¬ä¹Ÿè¾“å‡ºåˆ°ç»Ÿä¸€æ—¥å¿—
        self._reconfigure_logging()
        
        return self
        
    def _reconfigure_logging(self):
        """é‡æ–°é…ç½®loggingç³»ç»Ÿï¼Œè®©æ‰€æœ‰æ—¥å¿—éƒ½é€šè¿‡ç»Ÿä¸€è¾“å‡º"""
        # ä¿å­˜åŸå§‹handlers
        root_logger = logging.getLogger()
        self.original_handlers = root_logger.handlers.copy()
        
        # æ¸…é™¤æ‰€æœ‰ç°æœ‰handlers
        for handler in root_logger.handlers[:]:
            root_logger.removeHandler(handler)
            
        # åˆ›å»ºä¸€ä¸ªæ–°çš„StreamHandlerï¼Œå®ƒä¼šå†™å…¥æˆ‘ä»¬é‡å®šå‘çš„stdout
        # è¿™æ ·æ‰€æœ‰loggingè¾“å‡ºéƒ½ä¼šé€šè¿‡æˆ‘ä»¬çš„UnifiedWriter
        unified_handler = logging.StreamHandler(sys.stdout)
        unified_handler.setFormatter(SafeFormatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
        
        # æ·»åŠ æ–°çš„handler
        root_logger.addHandler(unified_handler)
        
        # ç¡®ä¿æ—¥å¿—çº§åˆ«
        root_logger.setLevel(logging.DEBUG)
        
    def __exit__(self, exc_type, exc_val, exc_tb):
        # æ¢å¤åŸå§‹çš„logging handlers
        root_logger = logging.getLogger()
        root_logger.handlers.clear()
        for handler in self.original_handlers:
            root_logger.addHandler(handler)
            
        # æ¢å¤åŸå§‹çš„stdoutå’Œstderr
        sys.stdout = self.original_stdout
        sys.stderr = self.original_stderr
        
        # å…³é—­æ—¥å¿—æ–‡ä»¶
        if self.log_file:
            self.log_file.close()

# ä¿æŒå‘åå…¼å®¹
TerminalOutputCapture = UnifiedLogCapture

# å¯¼å…¥æ ¸å¿ƒç»„ä»¶
from core.config_manager import ConfigManager
from core.metrics import EnhancedMetrics
from core.redis_manager import RedisManager
from core.system_monitor import SystemMonitor
from core.toolscore.toolscore_client import ToolScoreClient as CoreToolScoreClient
from runtimes.reasoning.toolscore_client import ToolScoreClient as RuntimeToolScoreClient
from core.task_processing.task_loader import TaskLoader
from core.task_processing.task_enhancer import TaskEnhancer
from core.task_processing.task_distributor import TaskDistributor
from core.monitoring.queue_monitor import QueueMonitor
from core.llm_client import LLMClient # å¯¼å…¥LLMClient
from core.interfaces import TaskType # å¯¼å…¥TaskType
from core.dispatcher_enhanced import TaskProcessingCoordinator # å¯¼å…¥TaskProcessingCoordinator

from services.service_manager import ServiceManager
from services import (
    redis_service,
    toolscore_service,
    task_api_service,
    runtime_service,
    mcp_server_launcher,
    synthesis_service
)

from core.utils.path_utils import ensure_output_structure
import subprocess

def cleanup_ports():
    """å¢å¼ºçš„ç«¯å£å’Œè¿›ç¨‹æ¸…ç†åŠŸèƒ½"""
    # æ‰©å±•ç«¯å£åˆ—è¡¨ï¼ŒåŒ…å«æ‰€æœ‰å¯èƒ½çš„MCPæœåŠ¡å™¨ç«¯å£
    ports = [8088, 8089, 8090, 8091, 8092, 5555, 8081, 8082, 8080, 8084, 8085, 8086, 8087, 8000]
    
    print("ğŸ§¹ å¼€å§‹å¢å¼ºç«¯å£æ¸…ç†...")
    
    # é¦–å…ˆæ¸…ç†æ‰€æœ‰ç›¸å…³çš„Pythonè¿›ç¨‹
    try:
        print("ğŸ” æœç´¢å¹¶æ¸…ç†ç›¸å…³Pythonè¿›ç¨‹...")
        # æ¸…ç†å¯èƒ½çš„main.pyè¿›ç¨‹
        subprocess.run(['pkill', '-f', 'main.py'], timeout=5, check=False)
        # æ¸…ç†MCPæœåŠ¡å™¨è¿›ç¨‹
        subprocess.run(['pkill', '-f', 'mcp_servers'], timeout=5, check=False)
        subprocess.run(['pkill', '-f', 'microsandbox_server'], timeout=3, check=False)
        subprocess.run(['pkill', '-f', 'browser_use_server'], timeout=3, check=False)
        subprocess.run(['pkill', '-f', 'search_tool_server'], timeout=3, check=False)
        subprocess.run(['pkill', '-f', 'deepsearch_server'], timeout=3, check=False)
        print("âœ… è¿›ç¨‹æ¸…ç†å®Œæˆ")
    except Exception as e:
        print(f"âš ï¸ è¿›ç¨‹æ¸…ç†æ—¶å‡ºé”™: {e}")
    
    # ç­‰å¾…è¿›ç¨‹æ¸…ç†å®Œæˆ
    import time
    time.sleep(2)
    
    # ç„¶åæ¸…ç†ç«¯å£
    for port in ports:
        try:
            result = subprocess.run(
                ['lsof', '-ti', f':{port}'], 
                capture_output=True, text=True, timeout=5
            )
            
            if result.returncode == 0 and result.stdout.strip():
                pids = result.stdout.strip().split('\n')
                for pid in pids:
                    try:
                        subprocess.run(['kill', '-9', pid], timeout=3, check=False)
                        print(f"ğŸ”¥ å¼ºåˆ¶æ¸…ç†ç«¯å£ {port} çš„è¿›ç¨‹ {pid}")
                    except Exception as e:
                        print(f"âš ï¸ æ¸…ç†è¿›ç¨‹ {pid} å¤±è´¥: {e}")
            else:
                print(f"âœ… ç«¯å£ {port} ç©ºé—²")
                
        except Exception as e:
            print(f"âš ï¸ æ£€æŸ¥ç«¯å£ {port} æ—¶å‡ºé”™: {e}")
    
    # æœ€åå†æ¬¡ç­‰å¾…ç¡®ä¿æ¸…ç†å®Œæˆ
    time.sleep(1)
    print("âœ… å¢å¼ºç«¯å£æ¸…ç†å®Œæˆ")

# åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„
ensure_output_structure()
os.makedirs(project_root / 'logs', exist_ok=True)
os.makedirs(project_root / 'config', exist_ok=True)
os.makedirs(project_root / 'data', exist_ok=True)

# é…ç½®æ—¥å¿—

# åˆå§‹çš„åŸºç¡€loggingé…ç½® - å°†è¢«UnifiedLogCaptureé‡æ–°é…ç½®
logging.basicConfig(
    level=logging.DEBUG,  # å¯ç”¨DEBUGçº§åˆ«æ—¥å¿—
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        # æ³¨é‡Šæ‰å•ç‹¬çš„æ–‡ä»¶handlerï¼Œå°†ç”±UnifiedLogCaptureç»Ÿä¸€å¤„ç†
        # logging.FileHandler('logs/toolscore.log', mode='a', encoding='utf-8')
    ]
)

for handler in logging.root.handlers:
    handler.setFormatter(SafeFormatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))

logger = logging.getLogger(__name__)

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="Agent Data Platform")
    parser.add_argument('--config-dir', type=str, default="config", help='é…ç½®æ–‡ä»¶ç›®å½•è·¯å¾„')
    parser.add_argument('--debug', action='store_true', help='å¯ç”¨è°ƒè¯•æ¨¡å¼')
    parser.add_argument('--start-services', action='store_true', help='å¯åŠ¨æ‰€æœ‰æœåŠ¡ï¼ˆé»˜è®¤è¡Œä¸ºï¼‰')
    parser.add_argument('--xml-streaming', action='store_true', default=True, help='å¯ç”¨XML streamingè¾“å‡ºæ ¼å¼ï¼ˆæ˜¾ç¤ºåŸå§‹çš„<think>ã€<search>ã€<answer>æ ‡ç­¾ï¼‰[é»˜è®¤å¯ç”¨]')
    parser.add_argument('--simple-runtime', action='store_true', default=True, help='ä½¿ç”¨ç®€åŒ–è¿è¡Œæ—¶ï¼ˆå‡å°‘å†—ä½™ä»£ç ï¼Œä¸“æ³¨æ ¸å¿ƒåŠŸèƒ½ï¼‰[é»˜è®¤å¯ç”¨]')
    parser.add_argument('--trajectory-storage', type=str, default='daily_grouped', 
                       choices=['individual', 'daily_grouped', 'weekly_grouped', 'monthly_grouped'],
                       help='è½¨è¿¹å­˜å‚¨æ¨¡å¼ï¼šindividual(å•ç‹¬æ–‡ä»¶), daily_grouped(æŒ‰æ—¥åˆ†ç»„), weekly_grouped(æŒ‰å‘¨åˆ†ç»„), monthly_grouped(æŒ‰æœˆåˆ†ç»„)')
    return parser.parse_args()

def setup_signal_handlers(service_manager):
    """è®¾ç½®ä¿¡å·å¤„ç†å™¨ä»¥ä¼˜é›…å…³é—­"""
    def signal_handler(sig, frame):
        logger.info(f"æ”¶åˆ°ä¿¡å· {sig}ï¼Œæ­£åœ¨å¼ºåˆ¶å…³é—­æ‰€æœ‰æœåŠ¡...")
        
        # è®¾ç½®ä¸€ä¸ªçŸ­è¶…æ—¶æ¥å°è¯•ä¼˜é›…å…³é—­
        try:
            # å°è¯•ä½¿ç”¨æœåŠ¡ç®¡ç†å™¨çš„å¼ºåˆ¶åœæ­¢
            service_manager.force_stop_all()
            logger.info("æœåŠ¡ç®¡ç†å™¨å¼ºåˆ¶åœæ­¢å®Œæˆ")
        except Exception as e:
            logger.warning(f"æœåŠ¡ç®¡ç†å™¨å¼ºåˆ¶åœæ­¢å¤±è´¥: {e}")
        
        # æ— è®ºå¦‚ä½•éƒ½æ‰§è¡Œå¼ºåˆ¶æ¸…ç†
        force_cleanup()
        
        # å¼ºåˆ¶é€€å‡º
        logger.info("å¼ºåˆ¶é€€å‡ºç³»ç»Ÿ")
        os._exit(0)
    
    async def emergency_shutdown(service_manager):
        """ç´§æ€¥å…³é—­æµç¨‹"""
        try:
            # è®¾ç½®è¾ƒçŸ­çš„è¶…æ—¶æ—¶é—´
            await asyncio.wait_for(service_manager.stop_all(), timeout=10)
        except asyncio.TimeoutError:
            logger.warning("æœåŠ¡åœæ­¢è¶…æ—¶ï¼Œæ‰§è¡Œå¼ºåˆ¶æ¸…ç†")
            force_cleanup()
        except Exception as e:
            logger.error(f"ç´§æ€¥å…³é—­å¤±è´¥: {e}")
            force_cleanup()
    
    def force_cleanup():
        """å¼ºåˆ¶æ¸…ç†æ‰€æœ‰èµ„æº"""
        logger.info("æ‰§è¡Œå¼ºåˆ¶æ¸…ç†...")
        
        # é¦–å…ˆå°è¯•ä½¿ç”¨ç³»ç»Ÿå‘½ä»¤å¼ºåˆ¶æ¸…ç†MCPæœåŠ¡å™¨è¿›ç¨‹
        try:
            import subprocess
            # æ¸…ç†æ‰€æœ‰MCPæœåŠ¡å™¨ç›¸å…³è¿›ç¨‹
            subprocess.run(['pkill', '-f', 'mcp_servers'], timeout=5, check=False)
            subprocess.run(['pkill', '-f', 'microsandbox_server'], timeout=3, check=False)
            subprocess.run(['pkill', '-f', 'browser_use_server'], timeout=3, check=False)
            subprocess.run(['pkill', '-f', 'search_tool_server'], timeout=3, check=False)
            logger.info("å·²å°è¯•æ¸…ç†MCPæœåŠ¡å™¨è¿›ç¨‹")
        except Exception as e:
            logger.warning(f"æ¸…ç†MCPæœåŠ¡å™¨è¿›ç¨‹å¤±è´¥: {e}")
        
        # å¼ºåˆ¶æ€æ­»æ‰€æœ‰ç›¸å…³è¿›ç¨‹
        try:
            import psutil
            current_pid = os.getpid()
            current_process = psutil.Process(current_pid)
            
            # æ€æ­»æ‰€æœ‰å­è¿›ç¨‹
            for child in current_process.children(recursive=True):
                try:
                    child.terminate()
                    child.wait(timeout=2)
                except:
                    try:
                        child.kill()
                    except:
                        pass
        except ImportError:
            # å¦‚æœæ²¡æœ‰psutilï¼Œä½¿ç”¨ç³»ç»Ÿå‘½ä»¤
            try:
                import subprocess
                subprocess.run(['pkill', '-f', 'python.*main.py'], timeout=5, check=False)
            except:
                pass
        
        # é‡Šæ”¾ç«¯å£
        release_ports([8088, 8089, 8100, 8081, 8082, 8080])
    
    def release_ports(ports):
        """å¼ºåˆ¶é‡Šæ”¾ç«¯å£"""
        for port in ports:
            try:
                import subprocess
                # åœ¨macOSä¸ŠæŸ¥æ‰¾å¹¶æ€æ­»å ç”¨ç«¯å£çš„è¿›ç¨‹
                result = subprocess.run(['lsof', '-ti', f':{port}'], 
                                      capture_output=True, text=True, timeout=5)
                if result.returncode == 0 and result.stdout.strip():
                    pids = result.stdout.strip().split('\n')
                    for pid in pids:
                        try:
                            subprocess.run(['kill', '-9', pid], timeout=3)
                            logger.info(f"å¼ºåˆ¶é‡Šæ”¾ç«¯å£ {port}ï¼Œæ€æ­»è¿›ç¨‹ {pid}")
                        except:
                            pass
            except:
                pass
    
    # æ³¨å†Œä¿¡å·å¤„ç†å™¨
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

async def main_async():
    """å¼‚æ­¥ä¸»å‡½æ•°ï¼Œåº”ç”¨å…¥å£ç‚¹"""
    # å¯åŠ¨å‰å…ˆæ¸…ç†ç«¯å£
    cleanup_ports()
    
    logger.info("=== Agent Data Platform å¯åŠ¨ä¸­ ===")
    logger.debug("ğŸ”§ å¼€å§‹ç³»ç»Ÿåˆå§‹åŒ–æµç¨‹...")
    
    args = parse_arguments()
    logger.debug(f"ğŸ“ å‘½ä»¤è¡Œå‚æ•°: {vars(args)}")
    
    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
        logger.debug("è°ƒè¯•æ¨¡å¼å·²å¯ç”¨ã€‚")

    # 1. åˆå§‹åŒ– ConfigManager
    logger.debug("ğŸ”§ æ­¥éª¤1: åˆå§‹åŒ–ConfigManager...")
    config_manager = ConfigManager(config_dir=args.config_dir)
    logger.debug(f"âœ… ConfigManageråˆå§‹åŒ–å®Œæˆï¼Œé…ç½®ç›®å½•: {args.config_dir}")
    
    # 2. åŠ è½½æ‰€æœ‰å¿…è¦é…ç½®
    logger.debug("ğŸ”§ æ­¥éª¤2: åŠ è½½ç³»ç»Ÿé…ç½®...")
    redis_url = config_manager.get_redis_url()
    logger.debug(f"ğŸ“¡ Redis URL: {redis_url}")
    
    task_file = config_manager.get_task_file_path()
    logger.debug(f"ğŸ“‹ ä»»åŠ¡æ–‡ä»¶è·¯å¾„: {task_file}")
    
    routing_config = config_manager.load_routing_config()
    logger.debug(f"ğŸš¦ è·¯ç”±é…ç½®åŠ è½½å®Œæˆï¼Œä»»åŠ¡ç±»å‹æ˜ å°„: {routing_config.task_type_mapping}")
    
    queue_mapping = {
        TaskType(task_type_str.lower()): queue_name
        for task_type_str, queue_name in routing_config.task_type_mapping.items()
    }
    logger.debug(f"ğŸ“‹ é˜Ÿåˆ—æ˜ å°„: {queue_mapping}")
    
    # 3. å®ä¾‹åŒ–æ ¸å¿ƒç»„ä»¶
    logger.debug("ğŸ”§ æ­¥éª¤3: åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶...")
    metrics = EnhancedMetrics() # Metricså®ä¾‹
    logger.debug("âœ… EnhancedMetricsåˆå§‹åŒ–å®Œæˆ")
    
    redis_manager = RedisManager(redis_url) # RedisManagerå®ä¾‹
    logger.debug("âœ… RedisManageråˆå§‹åŒ–å®Œæˆ")
    
    # ToolScoreæœåŠ¡å¯åŠ¨åï¼Œè·å–å…¶å®é™…ç«¯å£
    ports_config = config_manager.get_ports_config()
    toolscore_mcp_port = ports_config['mcp_servers']['toolscore_mcp']['port']
    toolscore_http_port = ports_config['mcp_servers']['toolscore_http']['port']
    toolscore_http_endpoint = f"http://localhost:{toolscore_http_port}"
    toolscore_websocket_endpoint = f"ws://localhost:{toolscore_mcp_port}/websocket"
    
    # ä¸ºè¿è¡Œæ—¶å®ä¾‹åŒ–ä¸“ç”¨çš„ToolScoreå®¢æˆ·ç«¯
    runtime_toolscore_client = RuntimeToolScoreClient(toolscore_http_endpoint)
    
    # ä¸ºå…¶ä»–æ ¸å¿ƒç»„ä»¶å®ä¾‹åŒ–æ ¸å¿ƒToolScoreå®¢æˆ·ç«¯
    core_toolscore_client = CoreToolScoreClient(config_manager)
    
    # å®ä¾‹åŒ–ç»Ÿä¸€å·¥å…·ç®¡ç†å™¨å’ŒLLMå®¢æˆ·ç«¯
    from core.unified_tool_manager import UnifiedToolManager
    unified_tool_manager = UnifiedToolManager()
    llm_client = LLMClient(config_manager.get_llm_config(), tool_manager=unified_tool_manager)
    
    # Task Processing Components
    task_loader = TaskLoader(task_file)
    task_enhancer = TaskEnhancer(core_toolscore_client, simple_mode=args.simple_runtime)
    task_distributor = TaskDistributor(redis_url, metrics)
    
    # Monitoring Components
    queue_monitor = QueueMonitor(redis_url)
    system_monitor = SystemMonitor(redis_url, config_manager)

    # å®ä¾‹åŒ–Orchestrator
    from core.orchestrator import Orchestrator
    orchestrator = Orchestrator(
        tool_manager=unified_tool_manager,
        llm_client=llm_client,
        redis_manager=redis_manager,
        metrics_manager=metrics
    )

    # åˆ›å»ºæœåŠ¡ç®¡ç†å™¨
    service_manager = ServiceManager()
    
    # æ³¨å†ŒTaskProcessingCoordinator
    service_manager.register_service(
        name="task_processing_coordinator",
        initialize_fn=lambda config: None,
        start_fn=lambda: asyncio.create_task(
            TaskProcessingCoordinator(
                redis_url=redis_url,
                config_manager=config_manager,
                toolscore_client=core_toolscore_client,
                queue_monitor=queue_monitor,
                task_loader=task_loader,
                task_enhancer=task_enhancer,
                task_distributor=task_distributor,
                orchestrator=orchestrator,
                queue_mapping=queue_mapping
            ).start()
        ),
        stop_fn=lambda: logger.info("TaskProcessingCoordinator åœæ­¢ä¸­..."),
        health_check_fn=lambda: True,
        dependencies=["redis", "toolscore"]
    )

    # æ³¨å†Œå…¶ä»–æœåŠ¡
    service_manager.register_service(
        name="redis",
        initialize_fn=lambda config: redis_service.initialize(redis_manager),
        start_fn=redis_service.start,
        stop_fn=redis_service.stop,
        health_check_fn=redis_service.health_check,
        dependencies=[]
    )
    
    service_manager.register_service(
        name="toolscore",
        initialize_fn=lambda config: toolscore_service.initialize(config_manager),
        start_fn=toolscore_service.start,
        stop_fn=toolscore_service.stop,
        health_check_fn=toolscore_service.health_check,
        dependencies=["redis"]
    )
    
    service_manager.register_service(
        name="mcp_servers",
        initialize_fn=lambda config: mcp_server_launcher.initialize(
            config_manager, unified_tool_manager
        ),
        start_fn=mcp_server_launcher.start,
        stop_fn=mcp_server_launcher.stop,
        health_check_fn=mcp_server_launcher.health_check,
        dependencies=["toolscore"]
    )
    
    service_manager.register_service(
        name="task_api",
        initialize_fn=lambda config: task_api_service.initialize(config_manager), # ä¼ å…¥config_managerå®ä¾‹
        start_fn=task_api_service.start,
        stop_fn=task_api_service.stop,
        health_check_fn=task_api_service.health_check,
        dependencies=["redis", "toolscore"]
    )
    
    service_manager.register_service(
        name="runtime",
        initialize_fn=lambda config: runtime_service.initialize(
            config or {},
            config_manager,
            llm_client,
            runtime_toolscore_client,
            unified_tool_manager,
            toolscore_websocket_endpoint,
            redis_manager,
            args.trajectory_storage
        ),
        start_fn=runtime_service.start,
        stop_fn=runtime_service.stop,
        health_check_fn=runtime_service.health_check,
        dependencies=["redis", "toolscore", "mcp_servers"]
    )
    
    # è·å–LLMé…ç½®å¹¶åˆå¹¶åˆ°æœåŠ¡é…ç½®ä¸­
    llm_config = config_manager.get_llm_config()
    synthesis_config = {
        'redis_url': redis_url,
        'TRAJECTORIES_DIR': 'output/trajectories',
        **llm_config  # åˆå¹¶LLMé…ç½®
    }
    
    service_manager.register_service(
        name="synthesis",
        initialize_fn=lambda config: synthesis_service.initialize(
            synthesis_config, 
            tool_manager=unified_tool_manager
        ),
        start_fn=synthesis_service.start,
        stop_fn=synthesis_service.stop,
        health_check_fn=synthesis_service.health_check,
        dependencies=["redis"]
    )
    
    setup_signal_handlers(service_manager)
    
    try:
        logger.debug("ğŸ”§ å¼€å§‹åˆå§‹åŒ–æ‰€æœ‰æœåŠ¡...")
        service_manager.initialize_all({}) # configå‚æ•°å¯èƒ½ä¸å†éœ€è¦ï¼Œå› ä¸ºç»„ä»¶å·²ç›´æ¥å®ä¾‹åŒ–
        logger.debug("âœ… æ‰€æœ‰æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
        
        logger.debug("ğŸš€ å¼€å§‹å¯åŠ¨æ‰€æœ‰æœåŠ¡...")
        await service_manager.start_all()
        logger.debug("âœ… æ‰€æœ‰æœåŠ¡å¯åŠ¨å®Œæˆ")
        
        logger.info("ğŸ‰ æ‰€æœ‰æœåŠ¡å·²å¯åŠ¨ï¼Œç³»ç»Ÿè¿è¡Œä¸­...")
        logger.info("ğŸ“Š ç³»ç»ŸçŠ¶æ€ç›‘æ§å·²å¯ç”¨ï¼ŒæŒ‰ Ctrl+C åœæ­¢")
        
        # ä¿æŒä¸»äº‹ä»¶å¾ªç¯è¿è¡Œ
        startup_time = asyncio.get_event_loop().time()
        while True:
            await asyncio.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡å¹¶è¾“å‡ºçŠ¶æ€
            current_time = asyncio.get_event_loop().time()
            uptime = int(current_time - startup_time)
            logger.debug(f"â° ç³»ç»Ÿè¿è¡Œæ—¶é—´: {uptime//3600}h {(uptime%3600)//60}m {uptime%60}s")
        
    except Exception as e:
        logger.error(f"å¯åŠ¨è¿‡ç¨‹ä¸­å‡ºé”™: {e}", exc_info=True)
        await service_manager.stop_all() # ç¡®ä¿è¿™é‡Œä¹Ÿawait
        sys.exit(1)

def main():
    # è®¾ç½®ç»Ÿä¸€æ—¥å¿—æ•è·
    unified_log_path = os.path.join('logs', 'System.log')
    
    # åœ¨å¼€å§‹æ—¶å†™å…¥åˆ†éš”ç¬¦
    os.makedirs('logs', exist_ok=True)
    with open(unified_log_path, 'a', encoding='utf-8') as f:
        f.write(f"\n{'='*80}\n")
        f.write(f"[ç³»ç»Ÿå¯åŠ¨] {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"{'='*80}\n")
    
    # ä½¿ç”¨ç»Ÿä¸€æ—¥å¿—æ•è·ç³»ç»Ÿæ•è·æ‰€æœ‰è¾“å‡º
    with UnifiedLogCapture(unified_log_path):
        try:
            print(f"ğŸš€ Agent Data Platform å¯åŠ¨ä¸­... (æ‰€æœ‰æ—¥å¿—å°†ç»Ÿä¸€è®°å½•åˆ° {unified_log_path})")
            asyncio.run(main_async())
        except KeyboardInterrupt:
            print("\nâš¡ æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨ä¼˜é›…å…³é—­...")
        except Exception as e:
            print(f"âŒ ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {e}")
            raise
        finally:
            print("ğŸ“ ç»ˆç«¯è¾“å‡ºæ•è·ç»“æŸ")

if __name__ == "__main__":
    main()