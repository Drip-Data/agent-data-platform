"""
å¢å¼ºçš„æ¨ç†è¿è¡Œæ—¶ - ç®€åŒ–ç‰ˆæœ¬
ä¸“æ³¨äºæ ¸å¿ƒåŠŸèƒ½ï¼šLLMæ¨ç†ã€å·¥å…·æ‰§è¡Œã€ä»»åŠ¡å¤„ç†ã€XMLæµå¼è¾“å‡º
"""

import json
import logging
import os
import time
import uuid
from datetime import datetime
from typing import List, Optional, Dict, Any, Tuple
from enum import Enum

from core.interfaces import RuntimeInterface, TaskSpec, TrajectoryResult, TaskExecutionConstants, ErrorMessageConstants
from core.llm.prompt_builders.reasoning_prompt_builder import ReasoningPromptBuilder
from core.utils.path_utils import get_trajectories_dir
from core.streaming.sequential_executor import SequentialStreamingExecutor
from core.memory_manager import MemoryManager
from core.trajectory_enhancer import TrajectoryEnhancer
from core.step_logger import StepDiagnosticLogger
from core.intelligent_status_evaluator import IntelligentStatusEvaluator, intelligent_task_evaluation
from core.intelligent_token_manager import IntelligentTokenManager
from core.context_cache_manager import CacheStrategy
from core.llm_providers.gemini_provider import GeminiProvider


logger = logging.getLogger(__name__)


class TrajectoryStorageMode(Enum):
    """è½¨è¿¹å­˜å‚¨æ¨¡å¼"""
    INDIVIDUAL_FILES = "individual"
    DAILY_GROUPED = "daily_grouped"
    WEEKLY_GROUPED = "weekly_grouped"
    MONTHLY_GROUPED = "monthly_grouped"


from core.unified_tool_manager import UnifiedToolManager

from core.unified_tool_manager import UnifiedToolManager

class EnhancedReasoningRuntime(RuntimeInterface):
    """
    å¢å¼ºçš„æ¨ç†è¿è¡Œæ—¶ - ä¸“æ³¨æ ¸å¿ƒåŠŸèƒ½, å¹¶é›†æˆé«˜çº§æ¨¡å—
    """
    
    def __init__(self, config_manager, llm_client, toolscore_client, tool_manager: UnifiedToolManager, redis_manager=None, 
                 toolscore_websocket_endpoint=None, xml_streaming_mode: bool = False, 
                 trajectory_storage_mode: str = "daily_grouped"):
        self._runtime_id = f"enhanced-reasoning-{uuid.uuid4()}"
        self.config_manager = config_manager
        self.client = llm_client
        self.toolscore_client = toolscore_client
        self.tool_manager = tool_manager
        self.xml_streaming_mode = xml_streaming_mode
        self.trajectory_storage_mode = TrajectoryStorageMode(trajectory_storage_mode)
        self.prompt_builder = ReasoningPromptBuilder(tool_manager=self.tool_manager, streaming_mode=xml_streaming_mode)
        self.is_initialized = False

        # åˆå§‹åŒ–é«˜çº§æ¨¡å—
        self.memory_manager = MemoryManager(redis_manager=redis_manager)
        self.trajectory_enhancer = TrajectoryEnhancer()
        self.sequential_executor = SequentialStreamingExecutor(
            llm_client=self.client, 
            tool_executor=self.toolscore_client,
            memory_manager=self.memory_manager
        )
        self.step_logger = StepDiagnosticLogger()
        self.intelligent_evaluator = IntelligentStatusEvaluator(self.client)
        
        # ğŸ†• åˆå§‹åŒ–Tokenä¼˜åŒ–ç®¡ç†å™¨
        try:
            # ä»LLMå®¢æˆ·ç«¯è·å–Gemini Provider
            gemini_provider = self._get_gemini_provider()
            if gemini_provider:
                self.token_manager = IntelligentTokenManager(
                    gemini_provider=gemini_provider,
                    redis_manager=redis_manager,
                    cache_strategy=CacheStrategy.BALANCED,
                    token_budget_limit=1000000  # 100ä¸‡tokené¢„ç®—
                )
                logger.info("âœ… Tokenç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            else:
                self.token_manager = None
                logger.warning("âš ï¸ æ— æ³•è·å–Gemini Providerï¼ŒTokenç®¡ç†å™¨æœªå¯ç”¨")
        except Exception as e:
            logger.error(f"âŒ Tokenç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.token_manager = None
        
        self.mcp_servers = self._load_mcp_config("config/mcp_servers.json")
    
    def _get_gemini_provider(self) -> Optional[GeminiProvider]:
        """ä»LLMå®¢æˆ·ç«¯è·å–Gemini Providerå®ä¾‹"""
        try:
            # æ£€æŸ¥LLMå®¢æˆ·ç«¯æ˜¯å¦æœ‰providerå±æ€§
            if hasattr(self.client, 'provider') and isinstance(self.client.provider, GeminiProvider):
                return self.client.provider
            
            # æ£€æŸ¥æ˜¯å¦æœ‰providerså­—å…¸
            if hasattr(self.client, 'providers') and 'gemini' in self.client.providers:
                provider = self.client.providers['gemini']
                if isinstance(provider, GeminiProvider):
                    return provider
            
            # å°è¯•ä»é…ç½®åˆ›å»ºæ–°çš„Gemini Provider
            if hasattr(self.config_manager, 'get_llm_config'):
                llm_config = self.config_manager.get_llm_config()
                if 'gemini' in llm_config.get('llm_providers', {}):
                    gemini_config = llm_config['llm_providers']['gemini']
                    if gemini_config.get('enabled', False):
                        return GeminiProvider(gemini_config)
            
            logger.warning("æ— æ³•è·å–Gemini Providerï¼Œå¯èƒ½ä½¿ç”¨çš„æ˜¯å…¶ä»–LLMæä¾›å•†")
            return None
            
        except Exception as e:
            logger.error(f"è·å–Gemini Providerå¤±è´¥: {e}")
            return None
    
    def _load_mcp_config(self, config_path: str) -> dict:
        """ä»JSONæ–‡ä»¶åŠ è½½å¹¶æ ¼å¼åŒ–MCPæœåŠ¡å™¨é…ç½®ã€‚"""
        config = {}
        try:
            with open(config_path, 'r') as f:
                mcp_config = json.load(f)
                for service_name, details in mcp_config.items():
                    # æ ‡å‡†åŒ–æœåŠ¡åç§°ï¼šå»æ‰ "_server" åç¼€ï¼Œä¸ä»£ç æœŸæœ›ä¸€è‡´
                    clean_name = service_name.replace("_server", "")
                    config[clean_name] = f"http://127.0.0.1:{details['port']}"
            logger.info(f"Loaded and formatted MCP server configs: {config}")
            return config
        except FileNotFoundError:
            logger.error(f"Error: MCP config file not found at {config_path}")
            return {}
        except json.JSONDecodeError:
            logger.error(f"Error: Could not decode JSON from {config_path}")
            return {}

    def _parse_execution_block(self, xml_string: str) -> dict:
        """
        ä»LLMç”Ÿæˆçš„XMLæ–‡æœ¬ä¸­è§£æå‡ºæ‰§è¡Œå—ã€‚
        è¿”å›ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«ç±»å‹ï¼ˆsingle, parallel, sequentialï¼‰å’ŒåŠ¨ä½œåˆ—è¡¨ã€‚
        """
        from xml.etree import ElementTree as ET

        actions = []
        block_type = "single" # é»˜è®¤
        try:
            # æ¸…ç†å¹¶åŒ…è£¹XMLï¼Œä»¥ä¾¿å®‰å…¨è§£æ
            clean_xml = f"<root>{xml_string.strip()}</root>"
            root = ET.fromstring(clean_xml)

            # æ£€æŸ¥å¹¶è¡Œæˆ–ä¸²è¡Œå—
            parallel_block = root.find('parallel')
            sequential_block = root.find('sequential')

            if parallel_block is not None:
                block_type = "parallel"
                service_nodes = list(parallel_block)
            elif sequential_block is not None:
                block_type = "sequential"
                service_nodes = list(sequential_block)
            else:
                # å•ä¸ªä»»åŠ¡
                service_nodes = [elem for elem in root if elem.tag not in ['think', 'answer', 'execute_tools']]

            for service_node in service_nodes:
                service_name = service_node.tag
                if len(service_node) > 0:
                    tool_node = service_node[0]
                    tool_name = tool_node.tag
                    tool_input = tool_node.text or ""
                    actions.append({
                        "service": service_name,
                        "tool": tool_name,
                        "input": tool_input.strip()
                    })
        except ET.ParseError as e:
            logger.error(f"XML Parse Error: {e}\nOriginal XML:\n{xml_string}")
            # å°è¯•XMLä¿®å¤å’Œå®¹é”™è§£æ
            try:
                fixed_actions = self._attempt_xml_repair(xml_string)
                if fixed_actions:
                    logger.info(f"âœ… XMLä¿®å¤æˆåŠŸï¼Œè§£æå‡º {len(fixed_actions)} ä¸ªåŠ¨ä½œ")
                    return {"type": block_type, "actions": fixed_actions}
            except Exception as repair_error:
                logger.warning(f"âš ï¸ XMLä¿®å¤å¤±è´¥: {repair_error}")
        
        return {"type": block_type, "actions": actions}

    def _attempt_xml_repair(self, xml_string: str) -> list:
        """
        å°è¯•ä¿®å¤å’Œè§£ææŸåçš„XMLï¼Œå¢å¼ºç³»ç»Ÿçš„å®¹é”™èƒ½åŠ›
        """
        import re
        from xml.etree import ElementTree as ET
        
        actions = []
        
        # æ–¹æ³•1: æ­£åˆ™è¡¨è¾¾å¼æå–å·¥å…·è°ƒç”¨
        try:
            # åŒ¹é…å•ä¸ªå·¥å…·è°ƒç”¨æ¨¡å¼
            tool_pattern = r'<(\w+)>\s*<(\w+)>(.*?)</\2>\s*</\1>'
            matches = re.findall(tool_pattern, xml_string, re.DOTALL)
            
            for service_name, tool_name, tool_input in matches:
                actions.append({
                    "service": service_name,
                    "tool": tool_name,
                    "input": tool_input.strip()
                })
            
            if actions:
                logger.info(f"ğŸ”§ æ­£åˆ™è¡¨è¾¾å¼ä¿®å¤ï¼šæå–åˆ° {len(actions)} ä¸ªå·¥å…·è°ƒç”¨")
                return actions
                
        except Exception as e:
            logger.debug(f"æ­£åˆ™è¡¨è¾¾å¼ä¿®å¤å¤±è´¥: {e}")
        
        # æ–¹æ³•2: å°è¯•è‡ªåŠ¨é—­åˆæ ‡ç­¾
        try:
            # ç®€å•çš„æ ‡ç­¾è‡ªåŠ¨é—­åˆ
            fixed_xml = xml_string
            
            # æŸ¥æ‰¾æœªé—­åˆçš„æ ‡ç­¾
            open_tags = re.findall(r'<([^/>\s]+)[^>]*>', fixed_xml)
            close_tags = re.findall(r'</([^>\s]+)>', fixed_xml)
            
            # ä¸ºæœªé—­åˆçš„æ ‡ç­¾æ·»åŠ é—­åˆæ ‡ç­¾
            for tag in open_tags:
                if tag not in close_tags:
                    fixed_xml += f'</{tag}>'
            
            # åŒ…è£…ä¸ºæ ¹å…ƒç´ å¹¶å°è¯•è§£æ
            clean_xml = f"<root>{fixed_xml.strip()}</root>"
            root = ET.fromstring(clean_xml)
            
            # é€’å½’æå–å·¥å…·è°ƒç”¨
            def extract_tools(element):
                tools = []
                for child in element:
                    if len(child) > 0:  # æœ‰å­å…ƒç´ 
                        for grandchild in child:
                            if grandchild.tag and grandchild.text:
                                tools.append({
                                    "service": child.tag,
                                    "tool": grandchild.tag,
                                    "input": grandchild.text.strip()
                                })
                    tools.extend(extract_tools(child))
                return tools
            
            extracted_tools = extract_tools(root)
            if extracted_tools:
                logger.info(f"ğŸ”§ æ ‡ç­¾é—­åˆä¿®å¤ï¼šæå–åˆ° {len(extracted_tools)} ä¸ªå·¥å…·è°ƒç”¨")
                return extracted_tools
                
        except Exception as e:
            logger.debug(f"æ ‡ç­¾é—­åˆä¿®å¤å¤±è´¥: {e}")
        
        # æ–¹æ³•3: åŸºäºå…³é”®è¯çš„å†…å®¹æå–
        try:
            # è¯†åˆ«å¸¸è§çš„æœåŠ¡åç§°å’Œå·¥å…·åç§°
            service_keywords = ['microsandbox', 'browser_use', 'search', 'deepsearch']
            tool_keywords = ['execute', 'search', 'navigate', 'click', 'type']
            
            # æŒ‰è¡Œåˆ†æï¼Œå¯»æ‰¾å¯èƒ½çš„å·¥å…·è°ƒç”¨
            lines = xml_string.split('\n')
            current_service = None
            current_tool = None
            current_input = []
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                    
                # æ£€æŸ¥æ˜¯å¦æ˜¯æœåŠ¡æ ‡ç­¾
                for service in service_keywords:
                    if f'<{service}>' in line.lower():
                        current_service = service
                        break
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å·¥å…·æ ‡ç­¾
                for tool in tool_keywords:
                    if f'<{tool}>' in line.lower():
                        current_tool = tool
                        current_input = []
                        continue
                
                # æ”¶é›†å·¥å…·è¾“å…¥
                if current_service and current_tool:
                    if f'</{current_tool}>' in line.lower():
                        # å·¥å…·è°ƒç”¨ç»“æŸ
                        if current_input:
                            actions.append({
                                "service": current_service,
                                "tool": current_tool,
                                "input": '\n'.join(current_input)
                            })
                        current_tool = None
                        current_input = []
                    else:
                        current_input.append(line)
            
            if actions:
                logger.info(f"ğŸ”§ å…³é”®è¯æå–ä¿®å¤ï¼šæå–åˆ° {len(actions)} ä¸ªå·¥å…·è°ƒç”¨")
                return actions
                
        except Exception as e:
            logger.debug(f"å…³é”®è¯æå–ä¿®å¤å¤±è´¥: {e}")
        
        return []

    def _attempt_answer_extraction(self, final_trajectory_str: str) -> str:
        """
        å°è¯•ä»æŸåçš„XMLä¸­æå–ç­”æ¡ˆå†…å®¹ï¼Œå¢å¼ºç­”æ¡ˆè§£æçš„å®¹é”™èƒ½åŠ›
        """
        import re
        
        # æ–¹æ³•1: éƒ¨åˆ†åŒ¹é…answeræ ‡ç­¾ï¼ˆå¤„ç†æœªé—­åˆçš„æƒ…å†µï¼‰
        try:
            # æŸ¥æ‰¾ç­”æ¡ˆå¼€å§‹æ ‡ç­¾
            answer_tag = TaskExecutionConstants.XML_TAGS['ANSWER']
            answer_start_pattern = f'<{answer_tag}>'
            
            if answer_start_pattern in final_trajectory_str:
                # æ‰¾åˆ°å¼€å§‹ä½ç½®
                start_pos = final_trajectory_str.find(answer_start_pattern)
                if start_pos != -1:
                    content_start = start_pos + len(answer_start_pattern)
                    
                    # æŸ¥æ‰¾ç»“æŸæ ‡ç­¾
                    answer_end_pattern = f'</{answer_tag}>'
                    end_pos = final_trajectory_str.find(answer_end_pattern, content_start)
                    
                    if end_pos != -1:
                        # æ ‡å‡†æƒ…å†µï¼šæœ‰å®Œæ•´çš„å¼€å§‹å’Œç»“æŸæ ‡ç­¾
                        answer_content = final_trajectory_str[content_start:end_pos].strip()
                        if answer_content:
                            return answer_content
                    else:
                        # å®¹é”™æƒ…å†µï¼šæ²¡æœ‰ç»“æŸæ ‡ç­¾ï¼Œå–åˆ°æ–‡æœ¬æœ«å°¾
                        remaining_text = final_trajectory_str[content_start:].strip()
                        if remaining_text:
                            # å¯»æ‰¾ä¸‹ä¸€ä¸ªXMLæ ‡ç­¾ä½œä¸ºç»“æŸ
                            next_tag_match = re.search(r'<[^>]+>', remaining_text)
                            if next_tag_match:
                                answer_content = remaining_text[:next_tag_match.start()].strip()
                            else:
                                answer_content = remaining_text
                            
                            if answer_content:
                                logger.info(f"ğŸ”§ éƒ¨åˆ†åŒ¹é…ä¿®å¤ï¼šæå–åˆ°æœªé—­åˆçš„answerå†…å®¹")
                                return answer_content
                                
        except Exception as e:
            logger.debug(f"éƒ¨åˆ†åŒ¹é…ä¿®å¤å¤±è´¥: {e}")
        
        # æ–¹æ³•2: åŸºäºå…³é”®è¯çš„æ™ºèƒ½è¯†åˆ«
        try:
            # æŸ¥æ‰¾æœ€åçš„æœ‰æ„ä¹‰æ®µè½
            paragraphs = final_trajectory_str.split('\n\n')
            
            # æŸ¥æ‰¾åŒ…å«ç­”æ¡ˆå…³é”®è¯çš„æ®µè½
            answer_keywords = ['ç­”æ¡ˆ', 'ç»“æœ', 'æœ€ç»ˆ', 'æ€»ç»“', 'ç»“è®º', 'answer', 'result', 'final', 'conclusion']
            
            for paragraph in reversed(paragraphs):
                paragraph = paragraph.strip()
                if len(paragraph) > 20:  # è¶³å¤Ÿé•¿çš„æ®µè½
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«ç­”æ¡ˆå…³é”®è¯
                    if any(keyword in paragraph.lower() for keyword in answer_keywords):
                        # ç§»é™¤XMLæ ‡ç­¾
                        clean_paragraph = re.sub(r'<[^>]*>', '', paragraph).strip()
                        if clean_paragraph:
                            logger.info(f"ğŸ”§ å…³é”®è¯è¯†åˆ«ä¿®å¤ï¼šæ‰¾åˆ°ç­”æ¡ˆæ®µè½")
                            return clean_paragraph[:500]  # é™åˆ¶é•¿åº¦
                            
        except Exception as e:
            logger.debug(f"å…³é”®è¯è¯†åˆ«ä¿®å¤å¤±è´¥: {e}")
        
        # æ–¹æ³•3: æå–æœ€åçš„æœ‰æ•ˆå†…å®¹
        try:
            # ç§»é™¤æ‰€æœ‰XMLæ ‡ç­¾ï¼Œè·å–çº¯æ–‡æœ¬
            clean_text = re.sub(r'<[^>]*>', '', final_trajectory_str).strip()
            
            if clean_text:
                # æŒ‰è¡Œåˆ†å‰²ï¼Œå¯»æ‰¾æœ€åå‡ è¡Œæœ‰æ„ä¹‰çš„å†…å®¹
                lines = [line.strip() for line in clean_text.split('\n') if line.strip()]
                
                if lines:
                    # ä»æœ€åå¼€å§‹å¯»æ‰¾æœ‰æ„ä¹‰çš„è¡Œ
                    meaningful_lines = []
                    for line in reversed(lines[-10:]):  # æ£€æŸ¥æœ€å10è¡Œ
                        if len(line) > 15 and not line.startswith('Step') and not line.startswith('Time'):
                            meaningful_lines.append(line)
                            if len(meaningful_lines) >= 3:  # æœ€å¤šå–3è¡Œ
                                break
                    
                    if meaningful_lines:
                        result = '\n'.join(reversed(meaningful_lines))
                        logger.info(f"ğŸ”§ æ–‡æœ¬æå–ä¿®å¤ï¼šä»çº¯æ–‡æœ¬ä¸­æå–ç­”æ¡ˆ")
                        return result
                        
        except Exception as e:
            logger.debug(f"æ–‡æœ¬æå–ä¿®å¤å¤±è´¥: {e}")
        
        return ""

    async def _execute_tool(self, action: dict) -> str:
        """
        æ ¹æ®å•ä¸ªåŠ¨ä½œå­—å…¸ï¼Œé€šè¿‡toolscore_clientè°ƒç”¨å¯¹åº”çš„MCP Serverå¹¶è¿”å›ç»“æœã€‚
        ğŸ”§ å®Œæ•´ä¿®å¤ï¼šç»Ÿä¸€æ‰€æœ‰å·¥å…·çš„ç»“æœæ ¼å¼åŒ–ï¼Œä½¿ç»“æœæ¸…æ™°æ˜“è¯»
        """
        service_name = action.get('service')
        tool_name = action.get('tool')
        tool_input = action.get('input')

        if not all([service_name, tool_name]):
            return "Error: Invalid action format. 'service' and 'tool' are required."

        # æ˜ å°„æœåŠ¡åˆ°å…¶æœŸæœ›çš„ä¸»è¦å‚æ•°å
        param_mapping = {
            "browser_use": "query",
            "microsandbox": "code",
            "deepsearch": "question"
        }
        # é»˜è®¤å‚æ•°åä¸º 'input'
        param_name = param_mapping.get(service_name, "input")
        parameters = {param_name: tool_input}

        logger.info(f"Executing via toolscore_client: service='{service_name}', tool='{tool_name}', params='{param_name}'")

        try:
            result = await self.toolscore_client.execute_tool(
                tool_id=service_name,
                action=tool_name,
                parameters=parameters
            )
            
            if isinstance(result, dict):
                if result.get('success', True):
                    output = result.get('data', result.get('output', result.get('result', str(result))))
                    
                    # ğŸ”§ å®Œæ•´ä¿®å¤ï¼šä¸ºæ‰€æœ‰å·¥å…·ç»Ÿä¸€ç»“æœæ ¼å¼åŒ–
                    formatted_output = self._format_tool_output(service_name, tool_name, output)
                    return formatted_output
                else:
                    error_msg = result.get('error_message', result.get('error', 'Unknown error'))
                    return f"Tool execution failed: {error_msg}"
            else:
                return str(result)

        except Exception as e:
            logger.error(f"An unexpected error occurred while calling tool '{service_name}/{tool_name}': {e}", exc_info=True)
            return f"An unexpected error occurred while calling {service_name}: {e}"
    
    def _format_tool_output(self, service_name: str, tool_name: str, output) -> str:
        """
        ğŸ”§ å®Œæ•´ä¿®å¤ï¼šç»Ÿä¸€æ ¼å¼åŒ–æ‰€æœ‰å·¥å…·çš„è¾“å‡ºç»“æœï¼Œä½¿å…¶æ¸…æ™°æ˜“è¯»
        
        Args:
            service_name: æœåŠ¡åç§° (microsandbox, deepsearch, browser_useç­‰)
            tool_name: å·¥å…·åç§°
            output: åŸå§‹è¾“å‡ºç»“æœ
            
        Returns:
            str: æ ¼å¼åŒ–åçš„æ¸…æ™°ç»“æœ
        """
        # 1. MicroSandbox - æ™ºèƒ½æå–æ ¸å¿ƒæ‰§è¡Œç»“æœ
        if service_name == 'microsandbox':
            return self._format_microsandbox_output(output)
        
        # 2. DeepSearch - æ ¼å¼åŒ–æœç´¢ç»“æœ
        elif service_name == 'deepsearch':
            if isinstance(output, dict):
                return self._format_deepsearch_output(output)
            elif isinstance(output, list):
                return self._format_deepsearch_list_output(output)
            return str(output)
        
        # 3. Browser Use - æ ¼å¼åŒ–æµè§ˆå™¨æ“ä½œç»“æœ
        elif service_name == 'browser_use':
            if isinstance(output, dict):
                return self._format_browser_use_output(output)
            return str(output)
        
        # 4. Search Tool - æ ¼å¼åŒ–æœç´¢ç»“æœ
        elif service_name == 'search_tool':
            if isinstance(output, dict):
                return self._format_search_tool_output(output)
            return str(output)
        
        # 5. å…¶ä»–å·¥å…· - é€šç”¨æ ¼å¼åŒ–
        else:
            return self._format_generic_output(output)
    
    def _format_deepsearch_output(self, output: dict) -> str:
        """ğŸ”§ æ ¼å¼åŒ–DeepSearchæœç´¢ç»“æœ - ä½¿ç”¨å¸¸é‡é¿å…ç¡¬ç¼–ç """
        try:
            # æå–å…³é”®ä¿¡æ¯
            search_results = output.get('search_results', [])
            query = output.get('query', '')
            summary = output.get('summary', '')
            
            formatted_lines = []
            
            # æ·»åŠ æŸ¥è¯¢ä¿¡æ¯
            if query:
                formatted_lines.append(f"{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['SEARCH_QUERY']}: {query}")
            
            # æ·»åŠ æ‘˜è¦
            if summary:
                formatted_lines.append(f"{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['SEARCH_SUMMARY']}: {summary}")
            
            # æ ¼å¼åŒ–æœç´¢ç»“æœ
            if search_results:
                max_results = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_SEARCH_RESULTS']
                results_text = TaskExecutionConstants.TOOL_FORMAT_PREFIXES['SEARCH_RESULTS'].format(len(search_results))
                formatted_lines.append(results_text)
                
                for i, result in enumerate(search_results[:max_results], 1):
                    if isinstance(result, dict):
                        title = result.get('title', 'æ— æ ‡é¢˜')
                        snippet = result.get('snippet', result.get('content', ''))
                        url = result.get('url', '')
                        
                        formatted_lines.append(f"{i}. {title}")
                        if snippet:
                            # ä½¿ç”¨å¸¸é‡é™åˆ¶snippeté•¿åº¦
                            max_length = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_SNIPPET_LENGTH']
                            snippet_clean = snippet.strip()[:max_length]
                            formatted_lines.append(f"   {snippet_clean}...")
                        if url:
                            formatted_lines.append(f"   æ¥æº: {url}")
                        formatted_lines.append("")  # ç©ºè¡Œåˆ†éš”
            
            result_text = '\n'.join(formatted_lines).strip()
            return result_text if result_text else "æœç´¢å®Œæˆï¼Œä½†æœªæ‰¾åˆ°ç›¸å…³ç»“æœ"
            
        except Exception as e:
            logger.warning(f"Failed to format DeepSearch output: {e}")
            max_content = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_CONTENT_LENGTH']
            return f"DeepSearchæœç´¢å®Œæˆï¼ŒåŸå§‹ç»“æœ: {str(output)[:max_content]}..."
    
    def _format_deepsearch_list_output(self, output: list) -> str:
        """ğŸ”§ æ ¼å¼åŒ–DeepSearchåˆ—è¡¨ç»“æœ - ä½¿ç”¨å¸¸é‡é¿å…ç¡¬ç¼–ç """
        try:
            if not output:
                return "æœç´¢å®Œæˆï¼Œä½†æœªæ‰¾åˆ°ç›¸å…³ç»“æœ"
            
            results_text = TaskExecutionConstants.TOOL_FORMAT_PREFIXES['SEARCH_RESULTS'].format(len(output))
            formatted_lines = [results_text]
            
            max_results = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_SEARCH_RESULTS']
            for i, item in enumerate(output[:max_results], 1):
                if isinstance(item, dict):
                    title = item.get('title', f'ç»“æœ {i}')
                    content = item.get('content', item.get('snippet', ''))
                    
                    formatted_lines.append(f"{i}. {title}")
                    if content:
                        max_length = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_SNIPPET_LENGTH']
                        content_clean = str(content).strip()[:max_length]
                        formatted_lines.append(f"   {content_clean}...")
                    formatted_lines.append("")
                else:
                    formatted_lines.append(f"{i}. {str(item)[:100]}...")
            
            return '\n'.join(formatted_lines).strip()
            
        except Exception as e:
            logger.warning(f"Failed to format DeepSearch list output: {e}")
            return f"DeepSearchæœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(output)} ä¸ªç»“æœ"
    
    def _format_browser_use_output(self, output: dict) -> str:
        """ğŸ”§ å®Œæ•´ä¿®å¤ï¼šæ ¼å¼åŒ–Browser Useæ“ä½œç»“æœï¼Œç¡®ä¿æœç´¢ç»“æœä¸ä¸¢å¤±"""
        try:
            # æå–å…³é”®ä¿¡æ¯ - å¢å¼ºå­—æ®µæå–
            action = output.get('action', output.get('operation', TaskExecutionConstants.TOOL_FORMAT_PREFIXES['BROWSER_ACTION']))
            status = output.get('status', output.get('success', output.get('result', True)))
            content = output.get('content', output.get('data', output.get('text', '')))
            url = output.get('url', output.get('current_url', ''))
            error = output.get('error', output.get('error_message', ''))
            
            # ğŸ”§ æ–°å¢ï¼šä¸“é—¨å¤„ç†æœç´¢ç»“æœ
            search_results = output.get('search_results', output.get('results', []))
            query = output.get('query', output.get('search_query', ''))
            
            formatted_lines = []
            
            # çŠ¶æ€ä¿¡æ¯
            status_text = "æˆåŠŸ" if status else "å¤±è´¥"
            formatted_lines.append(f"{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['BROWSER_ACTION']}: {action} - {status_text}")
            
            # æœç´¢æŸ¥è¯¢ä¿¡æ¯
            if query:
                formatted_lines.append(f"æœç´¢æŸ¥è¯¢: {query}")
            
            # URLä¿¡æ¯
            if url:
                formatted_lines.append(f"{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['PAGE_URL']}: {url}")
            
            # é”™è¯¯ä¿¡æ¯
            if error:
                formatted_lines.append(f"{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['ERROR_INFO']}: {error}")
            
            # ğŸ”§ ä¼˜å…ˆå¤„ç†æœç´¢ç»“æœ
            if search_results and isinstance(search_results, list):
                max_results = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_SEARCH_RESULTS']
                formatted_lines.append(f"æœç´¢ç»“æœ({len(search_results)}ä¸ª):")
                
                for i, result in enumerate(search_results[:max_results], 1):
                    if isinstance(result, dict):
                        title = result.get('title', result.get('name', f'ç»“æœ{i}'))
                        snippet = result.get('snippet', result.get('description', result.get('content', '')))
                        result_url = result.get('url', result.get('link', ''))
                        
                        formatted_lines.append(f"{i}. {title}")
                        if snippet:
                            max_snippet = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_SNIPPET_LENGTH']
                            clean_snippet = str(snippet).strip()[:max_snippet]
                            formatted_lines.append(f"   {clean_snippet}...")
                        if result_url:
                            formatted_lines.append(f"   é“¾æ¥: {result_url}")
                        formatted_lines.append("")
                    else:
                        formatted_lines.append(f"{i}. {str(result)[:100]}...")
            
            # å¤„ç†æ™®é€šå†…å®¹ä¿¡æ¯
            elif content:
                max_content = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_CONTENT_LENGTH']
                # å¦‚æœå†…å®¹æ˜¯HTMLï¼Œå°è¯•æå–æ–‡æœ¬
                if isinstance(content, str) and ('<html>' in content.lower() or '<div>' in content.lower()):
                    # ç®€å•çš„HTMLæ–‡æœ¬æå–
                    import re
                    text_content = re.sub(r'<[^>]+>', '', content)
                    text_content = re.sub(r'\s+', ' ', text_content).strip()
                    if text_content:
                        formatted_lines.append(f"{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['PAGE_CONTENT']}: {text_content[:max_content]}...")
                else:
                    formatted_lines.append(f"{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['OPERATION_RESULT']}: {str(content)[:max_content]}...")
            
            # ğŸ”§ å¢å¼ºï¼šå¦‚æœæ²¡æœ‰æœ‰ç”¨å†…å®¹ï¼Œæä¾›æ›´è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
            result_text = '\n'.join(formatted_lines).strip()
            if not result_text or len(result_text) < 20:
                # å¦‚æœæ ¼å¼åŒ–ç»“æœå¤ªçŸ­ï¼Œè¯´æ˜å¯èƒ½æœ‰é—®é¢˜ï¼Œæä¾›åŸå§‹æ•°æ®çš„æ‘˜è¦
                logger.warning(f"Browser Use output seems incomplete. Raw keys: {list(output.keys())}")
                if output:
                    return f"æµè§ˆå™¨æ“ä½œæ‰§è¡Œï¼Œè¿”å›æ•°æ®å­—æ®µ: {', '.join(output.keys())}\nåŸå§‹æ•°æ®: {str(output)[:300]}..."
                else:
                    return "æµè§ˆå™¨æ“ä½œæ‰§è¡Œå®Œæˆï¼Œä½†æœªè¿”å›æ•°æ®"
            
            return result_text
            
        except Exception as e:
            logger.error(f"Failed to format Browser Use output: {e}")
            max_content = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_CONTENT_LENGTH']
            return f"æµè§ˆå™¨æ“ä½œå®Œæˆï¼ŒåŸå§‹ç»“æœ: {str(output)[:max_content]}..."
    
    def _format_search_tool_output(self, output: dict) -> str:
        """ğŸ”§ æ ¼å¼åŒ–Search Toolæœç´¢ç»“æœ - ä½¿ç”¨å¸¸é‡é¿å…ç¡¬ç¼–ç """
        try:
            # æå–æœç´¢ç»“æœ
            results = output.get('results', output.get('files', []))
            query = output.get('query', '')
            count = output.get('count', len(results) if isinstance(results, list) else 0)
            
            formatted_lines = []
            
            # æœç´¢ä¿¡æ¯
            if query:
                formatted_lines.append(f"{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['FILE_SEARCH']}: {query}")
            
            file_results_text = TaskExecutionConstants.TOOL_FORMAT_PREFIXES['FILE_RESULTS'].format(count)
            formatted_lines.append(file_results_text)
            
            # æ ¼å¼åŒ–æ–‡ä»¶åˆ—è¡¨
            if isinstance(results, list):
                max_files = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_FILE_RESULTS']
                for i, result in enumerate(results[:max_files], 1):
                    if isinstance(result, dict):
                        file_path = result.get('path', result.get('file', ''))
                        matches = result.get('matches', result.get('content', ''))
                        
                        formatted_lines.append(f"{i}. {file_path}")
                        if matches:
                            formatted_lines.append(f"   åŒ¹é…å†…å®¹: {str(matches)[:100]}...")
                    else:
                        formatted_lines.append(f"{i}. {str(result)}")
            
            return '\n'.join(formatted_lines).strip()
            
        except Exception as e:
            logger.warning(f"Failed to format Search Tool output: {e}")
            return f"æ–‡ä»¶æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {count} ä¸ªç»“æœ"
    
    def _format_microsandbox_output(self, output) -> str:
        """ğŸ”§ ä¸“ç”¨MicroSandboxç»“æœæ ¼å¼åŒ– - æå–æ ¸å¿ƒæ‰§è¡Œå†…å®¹"""
        try:
            if isinstance(output, dict):
                # ä¼˜å…ˆæå–stdoutï¼ˆä¸»è¦è¾“å‡ºï¼‰
                if 'stdout' in output:
                    stdout_content = str(output['stdout']).strip()
                    if stdout_content:
                        return stdout_content
                
                # å¦‚æœæ²¡æœ‰stdoutï¼Œæ£€æŸ¥åµŒå¥—ç»“æ„
                if 'result' in output and isinstance(output['result'], dict):
                    nested_result = output['result']
                    if 'stdout' in nested_result:
                        stdout_content = str(nested_result['stdout']).strip()
                        if stdout_content:
                            return stdout_content
                
                # æ£€æŸ¥stderré”™è¯¯ä¿¡æ¯
                stderr_content = ""
                if 'stderr' in output:
                    stderr_content = str(output['stderr']).strip()
                elif 'result' in output and isinstance(output['result'], dict) and 'stderr' in output['result']:
                    stderr_content = str(output['result']['stderr']).strip()
                
                if stderr_content:
                    return f"æ‰§è¡Œé”™è¯¯: {stderr_content}"
                
                # æ£€æŸ¥è¿”å›ä»£ç 
                return_code = output.get('return_code') or (output.get('result', {}).get('return_code') if isinstance(output.get('result'), dict) else None)
                if return_code == 0:
                    return "ä»£ç æ‰§è¡ŒæˆåŠŸï¼Œä½†æ— è¾“å‡ºå†…å®¹"
                elif return_code is not None:
                    return f"ä»£ç æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ä»£ç : {return_code}"
            
            # å…¶ä»–æƒ…å†µè¿”å›ç®€åŒ–çš„å­—ç¬¦ä¸²
            output_str = str(output).strip()
            if len(output_str) > 200:
                return f"æ‰§è¡Œå®Œæˆ: {output_str[:200]}..."
            return output_str if output_str else "ä»£ç æ‰§è¡Œå®Œæˆ"
            
        except Exception as e:
            logger.warning(f"Failed to format MicroSandbox output: {e}")
            return f"ä»£ç æ‰§è¡Œå®Œæˆ: {str(output)[:100]}..."
    
    def _format_generic_output(self, output) -> str:
        """é€šç”¨å·¥å…·è¾“å‡ºæ ¼å¼åŒ–"""
        try:
            if isinstance(output, dict):
                # å°è¯•æå–æœ‰ç”¨ä¿¡æ¯
                if 'result' in output:
                    return str(output['result'])
                elif 'content' in output:
                    return str(output['content'])
                elif 'data' in output:
                    return str(output['data'])
                elif 'message' in output:
                    return str(output['message'])
                else:
                    # è¿‡æ»¤æ‰æŠ€æœ¯æ€§å­—æ®µï¼Œåªä¿ç•™æœ‰æ„ä¹‰çš„å†…å®¹
                    meaningful_fields = {}
                    skip_fields = {'success', 'status', 'code', 'timestamp', 'metadata', 'headers'}
                    
                    for key, value in output.items():
                        if key not in skip_fields and value:
                            meaningful_fields[key] = value
                    
                    if meaningful_fields:
                        return str(meaningful_fields)
            
            return str(output)
            
        except Exception as e:
            logger.warning(f"Failed to format generic output: {e}")
            return str(output)

    async def _execute_parallel(self, actions: list) -> list:
        """å¹¶å‘æ‰§è¡Œå¤šä¸ªåŠ¨ä½œã€‚"""
        import asyncio
        if not actions:
            return []
        
        tasks = [self._execute_tool(action) for action in actions]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¯èƒ½å‘ç”Ÿçš„å¼‚å¸¸ï¼Œç¡®ä¿è¿”å›å­—ç¬¦ä¸²åˆ—è¡¨
        return [str(res) if not isinstance(res, Exception) else f"Error: {res}" for res in results]
    
    @property
    def runtime_id(self) -> str:
        return self._runtime_id
    
    async def capabilities(self) -> List[str]:
        """è·å–è¿è¡Œæ—¶èƒ½åŠ›"""
        return ['llm_reasoning', 'tool_execution', 'xml_streaming', 'memory', 'trajectory_enhancement', 'error_recovery']
    
    async def health_check(self) -> bool:
        """å¥åº·æ£€æŸ¥"""
        try:
            if hasattr(self.toolscore_client, 'health_check'):
                return await self.toolscore_client.health_check()
            return True
        except Exception:
            return False
    
    async def initialize(self):
        """åˆå§‹åŒ–è¿è¡Œæ—¶"""
        logger.info("ğŸš€ åˆå§‹åŒ–Enhanced Reasoning Runtime")
        if not self.client:
            raise RuntimeError("LLMå®¢æˆ·ç«¯æœªé…ç½®")
        if not self.toolscore_client:
            raise RuntimeError("å·¥å…·å®¢æˆ·ç«¯æœªé…ç½®")
        self.is_initialized = True
        logger.info("âœ… Enhanced Reasoning Runtime åˆå§‹åŒ–å®Œæˆ")
    
    async def execute(self, task: TaskSpec) -> TrajectoryResult:
        """æ‰§è¡Œä»»åŠ¡"""
        logger.info(f"ğŸ§  å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task.description}")
        if not self.is_initialized:
            await self.initialize()
        
        if self.xml_streaming_mode:
            return await self._execute_xml_streaming(task)
        else:
            # ä¿ç•™æ ‡å‡†æ¨¡å¼ä½œä¸ºå¤‡é€‰ï¼Œä½†ä¸»è¦æµç¨‹æ˜¯XMLæµ
            return await self._execute_standard(task)
    
    async def _execute_xml_streaming(self, task: TaskSpec) -> TrajectoryResult:
        """
        æ‰§è¡ŒåŸºäºXMLçš„ã€æ”¯æŒå•æ­¥ã€å¹¶è¡Œå’Œä¸²è¡Œå·¥å…·è°ƒç”¨çš„ä¸»æ§åˆ¶å¾ªç¯ã€‚
        """
        logger.info(f"ğŸ¯ Orchestrator starting task: {task.description}")
        start_time = time.time()
        
        # ğŸ” å¯åŠ¨æ­¥éª¤çº§æ—¥å¿—è®°å½•
        self.step_logger.start_task(task.task_id, task.description)
        
        # å‡†å¤‡å†å²è®°å½•
        available_tools = await self._get_available_tools()
        tool_descriptions = await self._get_tool_descriptions()
        history = self.prompt_builder.build_prompt(
            task_description=task.description,
            available_tools=available_tools,
            tool_descriptions=tool_descriptions,
            history=[]
        )
        
        full_trajectory = [] # è®°å½•å®Œæ•´çš„äº¤äº’è½¨è¿¹

        max_steps = task.max_steps or 20
        for step in range(max_steps):
            logger.info(f"--- Starting Step {step + 1}/{max_steps} ---")
            
            # ğŸ” å¼€å§‹æ­¥éª¤æ—¥å¿—è®°å½•
            self.step_logger.start_step(step)
            
            # 1. ğŸ†• Tokenä¼˜åŒ– - ä¼˜åŒ–æ¶ˆæ¯ä»¥å‡å°‘tokenæ¶ˆè€—
            original_history = history.copy()
            optimized_history = history
            optimization_info = {}
            
            if self.token_manager:
                try:
                    optimized_history, optimization_info = await self.token_manager.optimize_messages_with_cache(
                        history, 
                        model=getattr(self.client, 'model', 'gemini-2.5-flash'),
                        session_id=getattr(task, 'session_id', task.task_id)
                    )
                    if optimization_info.get('tokens_saved', 0) > 0:
                        logger.info(f"ğŸ’° Tokenä¼˜åŒ–: èŠ‚çœ {optimization_info['tokens_saved']} tokens "
                                  f"(${optimization_info['cost_saved']:.6f})")
                except Exception as e:
                    logger.warning(f"Tokenä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ¶ˆæ¯: {e}")
                    optimized_history = history
            
            # 2. è°ƒç”¨LLMï¼Œè®¾ç½®åŠ¨æ€åœæ­¢åºåˆ—
            stop_sequences = ["<execute_tools />", "<execute_tools></execute_tools>", "</answer>"]
            llm_start_time = time.time()
            response_text = await self.client._call_api(optimized_history, stop_sequences=stop_sequences)
            llm_end_time = time.time()
            
            # 3. ğŸ†• Tokenä½¿ç”¨ç»Ÿè®¡å’Œè®°å½•
            token_usage = {}
            if self.token_manager:
                try:
                    # è®¡ç®—å®é™…tokenä½¿ç”¨
                    prompt_text = " ".join([msg.get('content', '') for msg in optimized_history if isinstance(msg, dict)])
                    prompt_tokens = await self.token_manager.count_tokens_accurately(prompt_text)
                    completion_tokens = await self.token_manager.count_tokens_accurately(response_text)
                    
                    # è®°å½•tokenä½¿ç”¨
                    await self.token_manager.record_token_usage(
                        prompt_tokens=prompt_tokens,
                        completion_tokens=completion_tokens,
                        model=getattr(self.client, 'model', 'gemini-2.5-flash'),
                        task_id=task.task_id,
                        session_id=getattr(task, 'session_id', None),
                        cached_tokens=optimization_info.get('tokens_saved', 0)
                    )
                    
                    token_usage = {
                        'prompt_tokens': prompt_tokens,
                        'completion_tokens': completion_tokens,
                        'total_tokens': prompt_tokens + completion_tokens,
                        'cached_tokens': optimization_info.get('tokens_saved', 0),
                        'model': getattr(self.client, 'model', 'gemini-2.5-flash'),
                        'data_source': 'api_provided'
                    }
                except Exception as e:
                    logger.warning(f"Tokenç»Ÿè®¡å¤±è´¥: {e}")
            
            # 4. ğŸ” è®°å½•LLMè°ƒç”¨ï¼ˆåŒ…å«è¯¦ç»†tokenä¿¡æ¯ï¼‰
            triggered_stop = self._detect_triggered_stop_sequence(response_text, stop_sequences)
            self.step_logger.log_llm_call(
                prompt=original_history,  # ä½¿ç”¨åŸå§‹æ¶ˆæ¯è®°å½•å®Œæ•´å†…å®¹
                raw_response=response_text,
                stop_sequence=triggered_stop,
                start_time=llm_start_time,
                end_time=llm_end_time,
                token_usage=token_usage  # ğŸ†• ä¼ é€’è¯¦ç»†çš„tokenä½¿ç”¨ä¿¡æ¯
            )
            
            history.append({"role": "assistant", "content": response_text})
            full_trajectory.append({"role": "assistant", "content": response_text})

            # ğŸ”§ ä¿®å¤ï¼šæ›´æ™ºèƒ½çš„ç­”æ¡ˆæ£€æµ‹é€»è¾‘
            answer_tag = TaskExecutionConstants.XML_TAGS['ANSWER']
            answer_start_tag = f"<{answer_tag}>"
            answer_end_tag = f"</{answer_tag}>"
            
            # æ£€æµ‹ç­”æ¡ˆæ ‡ç­¾ï¼ˆå¼€å§‹æ ‡ç­¾æˆ–ç»“æŸæ ‡ç­¾ï¼‰
            has_answer_start = answer_start_tag in response_text
            has_answer_end = answer_end_tag in response_text
            has_boxed_content = "\\boxed{" in response_text
            
            if has_answer_end or (has_answer_start and has_boxed_content):
                logger.info("âœ… Final Answer detected. Task complete.")
                # ğŸ” è®°å½•è§£æç»“æœï¼ˆåŒ…å«ç­”æ¡ˆçš„æƒ…å†µï¼‰
                parsing_start_time = time.time()
                think_content = self.step_logger._extract_think_content(response_text)
                answer_content = self.step_logger._extract_answer_content(response_text)
                parsing_end_time = time.time()
                
                self.step_logger.log_parsing_result(
                    think_content=think_content,
                    execution_block=None,
                    answer_content=answer_content,
                    actions=[],
                    parsing_errors=[],
                    start_time=parsing_start_time,
                    end_time=parsing_end_time
                )
                self.step_logger.finish_step("task_completed_with_answer")
                break

            # ğŸ” è®°å½•è§£æé˜¶æ®µ
            parsing_start_time = time.time()
            execution_block = self._parse_execution_block(response_text)
            actions = execution_block.get("actions", [])
            think_content = self.step_logger._extract_think_content(response_text)
            execution_block_text = self.step_logger._extract_execution_block(response_text)
            parsing_end_time = time.time()
            
            self.step_logger.log_parsing_result(
                think_content=think_content,
                execution_block=execution_block_text,
                answer_content=None,
                actions=actions,
                parsing_errors=[],
                start_time=parsing_start_time,
                end_time=parsing_end_time
            )
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ä»…åŒ…å«æ€è€ƒçš„æœ€ç»ˆç­”æ¡ˆ
            think_tag = TaskExecutionConstants.XML_TAGS['THINK']
            answer_tag = TaskExecutionConstants.XML_TAGS['ANSWER']
            execute_tools_tag = TaskExecutionConstants.XML_TAGS['EXECUTE_TOOLS']
            
            if not actions and f"<{think_tag}>" in response_text and f"<{execute_tools_tag} />" not in response_text:
                logger.info("âœ… Detected a thought-only response, considering it the final answer.")
                # æå–æ€è€ƒå†…å®¹ä½œä¸ºæœ€ç»ˆç­”æ¡ˆ
                try:
                    import re
                    match = re.search(f"<{think_tag}>(.*)</{think_tag}>", response_text, re.DOTALL)
                    if match:
                        final_thought = match.group(1).strip()
                        answer_content = f"<{answer_tag}>{final_thought}</{answer_tag}>"
                        history.append({"role": "assistant", "content": answer_content})
                        full_trajectory.append({"role": "assistant", "content": answer_content})
                except Exception:
                    pass # å¦‚æœè§£æå¤±è´¥ï¼Œåˆ™æ­£å¸¸ç»§ç»­
                # ğŸ” å®Œæˆæ­¥éª¤è®°å½•
                self.step_logger.finish_step("thought_only_final_answer")
                break

            # ğŸ”§ æ ¹æœ¬ä¿®å¤ï¼šæ™ºèƒ½åˆ¤æ–­æ˜¯å¦éœ€è¦æ³¨å…¥"æ— åŠ¨ä½œ"æ¶ˆæ¯
            if not actions:
                # ğŸ”§ Priority 3 å¢å¼ºï¼šè®¡åˆ’-æ‰§è¡Œæ¡¥æ¢æœºåˆ¶ - å½»åº•è§£å†³è®¡åˆ’-æ‰§è¡Œè„±èŠ‚é—®é¢˜
                plan_content = self._extract_detailed_plan(response_text)
                if plan_content and self._has_executable_plan(plan_content):
                    logger.info("ğŸ¯ æ£€æµ‹åˆ°è¯¦ç»†è®¡åˆ’ä½†ç¼ºå°‘æ‰§è¡ŒåŠ¨ä½œï¼Œå¼•å¯¼LLMå¼€å§‹æ‰§è¡Œ")
                    
                    # ğŸ”§ æ–°å¢ï¼šåˆ†æè®¡åˆ’ä¸­çš„ç¬¬ä¸€æ­¥å…·ä½“åŠ¨ä½œ
                    first_action = self._extract_first_executable_action(plan_content)
                    if first_action:
                        execution_guidance = (
                            f"You have created a detailed plan. Now please start executing the first step: {first_action}. "
                            "Use the appropriate tool call with the exact XML format and end with <execute_tools />. "
                            "Remember: plans are not answers - execution is required."
                        )
                    else:
                        execution_guidance = (
                            "You have created a detailed plan. Now please start executing the first step of your plan. "
                            "Use the appropriate tool call with the exact XML format and end with <execute_tools />. "
                            "Remember: plans are not answers - execution is required."
                        )
                    
                    result_xml = self._format_result(execution_guidance)
                    history.append({"role": "assistant", "content": result_xml})
                    full_trajectory.append({"role": "assistant", "content": result_xml})
                    # ğŸ” å®Œæˆæ­¥éª¤è®°å½•
                    self.step_logger.finish_step("plan_execution_guidance_injected")
                    continue
                
                elif self._should_inject_no_action_message(response_text):
                    logger.warning("No executable actions found in LLM response. Injecting guidance.")
                    result_xml = self._format_result("No executable action detected in this step.")
                    history.append({"role": "assistant", "content": result_xml})
                    full_trajectory.append({"role": "assistant", "content": result_xml})
                    # ğŸ” å®Œæˆæ­¥éª¤è®°å½•
                    self.step_logger.finish_step("no_action_injected")
                else:
                    logger.info("âœ… Detected thought-only response without tool execution - this is normal.")
                    # ğŸ” å®Œæˆæ­¥éª¤è®°å½•
                    self.step_logger.finish_step("thought_only_normal")
                continue

            # 4. æ ¹æ®ç±»å‹åˆ†å‘æ‰§è¡Œ
            results = []
            block_type = execution_block.get("type")

            # å¯¹äºä¸²è¡Œå—ï¼Œæˆ‘ä»¬åªæ‰§è¡Œç¬¬ä¸€ä¸ªåŠ¨ä½œã€‚LLMå°†åœ¨ä¸‹ä¸€è½®æ ¹æ®ç»“æœå†³å®šåç»­æ­¥éª¤ã€‚
            if block_type == "sequential":
                logger.info(f"Executing first action of sequential block.")
                if actions:
                    result_data = await self._execute_tool_with_logging(actions[0], 0)
                    results = [result_data["formatted_result"]]
            elif block_type == "parallel":
                logger.info(f"Executing parallel block with {len(actions)} actions.")
                results = await self._execute_parallel_with_logging(actions)
            else: # single
                if actions:
                    logger.info(f"Executing single action.")
                    result_data = await self._execute_tool_with_logging(actions[0], 0)
                    results = [result_data["formatted_result"]]

            # 5. æ ¼å¼åŒ–å¹¶ä¸ºæ¯ä¸ªç»“æœæ³¨å…¥å•ç‹¬çš„<result>æ ‡ç­¾
            for res in results:
                result_xml = self._format_result(res)
                history.append({"role": "assistant", "content": result_xml})
                full_trajectory.append({"role": "assistant", "content": result_xml})
                
            # ğŸ” å®Œæˆæ­¥éª¤è®°å½•
            self.step_logger.finish_step()

        else:
            logger.warning(f"Max steps ({max_steps}) reached. Terminating task.")
            # ğŸ” å®Œæˆæœ€åä¸€ä¸ªæ­¥éª¤è®°å½•
            if self.step_logger.current_step_data:
                self.step_logger.finish_step("max_steps_reached")

        # ä»»åŠ¡ç»“æŸï¼Œå¤„ç†æœ€ç»ˆç»“æœ
        final_trajectory_str = "\n".join(item["content"] for item in full_trajectory)
        total_duration = time.time() - start_time
        
        # ğŸ”§ æ ¹æœ¬ä¿®å¤ï¼šåŒºåˆ†æ­¥æ•°é™åˆ¶å’ŒçœŸæ­£å¤±è´¥
        max_steps_reached = len(full_trajectory) >= max_steps
        
        # ğŸ§  æ–°æ™ºèƒ½è¯„ä¼°ï¼šä½¿ç”¨è¯­ä¹‰ç†è§£å’Œç»“æœé©±åŠ¨çš„åˆ¤å®šé€»è¾‘
        final_result = self._extract_final_result(final_trajectory_str)
        
        try:
            success, confidence_score, evaluation_reasoning = await self._intelligent_task_success_evaluation(
                task_input=task.description,
                final_trajectory_str=final_trajectory_str,
                full_trajectory=full_trajectory,
                final_output=final_result
            )
            logger.info(f"ğŸ§  æ™ºèƒ½è¯„ä¼°: æˆåŠŸ={success}, ç½®ä¿¡åº¦={confidence_score:.2f}, ç†ç”±={evaluation_reasoning}")
        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•: {e}")
            success = self._determine_task_success(final_trajectory_str, full_trajectory)
            confidence_score = 0.5
            evaluation_reasoning = "ä½¿ç”¨ä¼ ç»Ÿè¯„ä¼°æ–¹æ³•"
        
        # ğŸ”§ æ–°å¢ï¼šå¦‚æœè¾¾åˆ°æœ€å¤§æ­¥æ•°ä½†æ²¡æœ‰æ˜ç¡®çš„ç­”æ¡ˆï¼Œé™ä½æˆåŠŸåˆ¤å®šæ ‡å‡†
        if max_steps_reached:
            answer_tag = TaskExecutionConstants.XML_TAGS['ANSWER']
            has_explicit_answer = f"<{answer_tag}>" in final_trajectory_str
            has_boxed_content = "\\boxed{" in final_trajectory_str
            
            if not has_explicit_answer and not has_boxed_content:
                # è¾¾åˆ°æœ€å¤§æ­¥æ•°ä¸”æ²¡æœ‰æ˜ç¡®ç­”æ¡ˆï¼Œæ ‡è®°ä¸ºéƒ¨åˆ†æˆåŠŸä½†éœ€è¦è¯´æ˜
                logger.warning(f"ä»»åŠ¡è¾¾åˆ°æœ€å¤§æ­¥æ•°({max_steps})ä½†æ²¡æœ‰æ˜ç¡®ç­”æ¡ˆæ ‡è®°")
                # æ ¹æ®æ˜¯å¦æœ‰å·¥å…·æ‰§è¡Œç»“æœæ¥åˆ¤å®š
                tool_success_rate = self._calculate_tool_success_rate()
                success = tool_success_rate > 0.5  # è‡³å°‘50%çš„å·¥å…·æ‰§è¡ŒæˆåŠŸæ‰è®¤ä¸ºéƒ¨åˆ†æˆåŠŸ
        
        # ğŸ”§ æ ¹æœ¬ä¿®å¤ï¼šåŠ¨æ€æå–çœŸå®çš„æœ€ç»ˆç»“æœï¼Œè€ƒè™‘æ­¥æ•°é™åˆ¶æƒ…å†µ
        if max_steps_reached:
            final_result = f"å·²è¾¾æœ€å¤§æ­¥éª¤({max_steps})ï¼Œä»»åŠ¡è¢«ä¸­æ­¢ã€‚å½“å‰è¿›å±•ï¼š{self._extract_final_result(final_trajectory_str)}"
        else:
            final_result = self._extract_final_result(final_trajectory_str)

        # ğŸ” å®Œæˆä»»åŠ¡æ­¥éª¤æ—¥å¿—è®°å½•
        final_status = "success" if success else "failure"
        await self.step_logger.finalize_task(final_status, final_result)

        xml_output = {
            "timestamp": datetime.now().isoformat(),
            "task_id": task.task_id,
            "task_description": task.description,
            "duration": total_duration,
            "success": success,
            "final_result": final_result,
            "raw_response": final_trajectory_str,
        }
        
        await self._save_xml_output(xml_output)

        # ğŸ”§ ä¿®å¤ï¼šä»step_loggerè·å–å®é™…çš„æ‰§è¡Œæ­¥éª¤
        actual_steps = await self.step_logger.get_execution_steps()
        
        # ğŸ§  æ„å»ºæ™ºèƒ½è¯„ä¼°å…ƒæ•°æ®
        intelligent_evaluation = {
            'confidence_score': confidence_score,
            'evaluation_reasoning': evaluation_reasoning,
            'evaluation_method': 'intelligent_semantic' if 'evaluation_reasoning' in locals() and 'LLM' in evaluation_reasoning else 'traditional_rule_based',
            'max_steps_reached': max_steps_reached,
            'trajectory_length': len(full_trajectory)
        }
        
        return TrajectoryResult(
            task_name=task.task_id,
            task_id=task.task_id, 
            task_description=task.description,
            runtime_id=self._runtime_id,
            steps=actual_steps,  # ğŸ”§ ä½¿ç”¨å®é™…æ­¥éª¤è€Œä¸æ˜¯ç©ºæ•°ç»„
            success=success,
            final_result=final_result,  # ğŸ”§ ä½¿ç”¨åŠ¨æ€æå–çš„ç»“æœ
            total_duration=total_duration,
            metadata={
                'full_trajectory': full_trajectory,
                'intelligent_evaluation': intelligent_evaluation  # ğŸ§  æ–°å¢æ™ºèƒ½è¯„ä¼°ä¿¡æ¯
            }
        )

    def _format_result(self, result: str) -> str:
        """ğŸ”§ æ ¹æœ¬ä¿®å¤ï¼šæ ¼å¼åŒ–å·¥å…·ç»“æœï¼Œä½¿ç”¨å¸¸é‡æ›¿ä»£ç¡¬ç¼–ç """
        if not result:
            no_action_msg = TaskExecutionConstants.NO_ACTION_PERFORMED
            return f"<{TaskExecutionConstants.XML_TAGS['RESULT']}>{no_action_msg}</{TaskExecutionConstants.XML_TAGS['RESULT']}>"
        return f"<{TaskExecutionConstants.XML_TAGS['RESULT']}>{result}</{TaskExecutionConstants.XML_TAGS['RESULT']}>"
    
    async def _execute_standard(self, task: TaskSpec) -> TrajectoryResult:
        """æ ‡å‡†æ‰§è¡Œæ¨¡å¼ (ä½œä¸ºå¤‡ç”¨) - ğŸ”§ å·²ä¿®å¤ç¡¬ç¼–ç é—®é¢˜"""
        logger.warning("æ‰§è¡Œæ ‡å‡†ï¼ˆReActï¼‰æ¨¡å¼ï¼Œæ­¤æ¨¡å¼åŠŸèƒ½æœ‰é™ã€‚")
        # ç®€å•å®ç°æ ‡å‡†æ¨¡å¼
        start_time = time.time()
        response = ""
        try:
            # ç®€å•çš„LLMè°ƒç”¨
            messages = self.prompt_builder.build_prompt(
                task_description=task.description,
                available_tools=[],
                tool_descriptions="",
                streaming_mode=False
            )
            response = await self.client._call_api(messages)
            
            # ğŸ§  æ ‡å‡†æ¨¡å¼ä¹Ÿä½¿ç”¨æ™ºèƒ½è¯„ä¼°ï¼ˆç®€åŒ–ç‰ˆï¼‰
            final_result = self._extract_final_result(response)
            
            try:
                success, confidence_score, evaluation_reasoning = await self._intelligent_task_success_evaluation(
                    task_input=task.description,
                    final_trajectory_str=response,
                    full_trajectory=[{'content': response, 'timestamp': time.time()}],
                    final_output=final_result
                )
                logger.info(f"ğŸ§  æ ‡å‡†æ¨¡å¼æ™ºèƒ½è¯„ä¼°: æˆåŠŸ={success}, ç½®ä¿¡åº¦={confidence_score:.2f}")
            except Exception as eval_e:
                logger.error(f"âŒ æ ‡å‡†æ¨¡å¼æ™ºèƒ½è¯„ä¼°å¤±è´¥: {eval_e}")
                success = self._determine_task_success(response, [])
                confidence_score = 0.5
                evaluation_reasoning = "é™çº§åˆ°ä¼ ç»Ÿè¯„ä¼°"
            
        except Exception as e:
            logger.error(f"æ ‡å‡†æ¨¡å¼æ‰§è¡Œå¤±è´¥: {e}")
            success = False
            final_result = f"æ‰§è¡Œå¤±è´¥: {str(e)}"
            response = f"Error: {str(e)}"
            confidence_score = 0.0
            evaluation_reasoning = f"æ‰§è¡Œå¼‚å¸¸: {str(e)}"
        
        total_duration = time.time() - start_time
        
        # ğŸ§  æ„å»ºæ ‡å‡†æ¨¡å¼çš„æ™ºèƒ½è¯„ä¼°å…ƒæ•°æ®
        intelligent_evaluation = {
            'confidence_score': confidence_score,
            'evaluation_reasoning': evaluation_reasoning,
            'evaluation_method': 'intelligent_semantic_standard_mode',
            'max_steps_reached': False,
            'trajectory_length': 1
        }
        
        # æ„å»ºè¿”å›å¯¹è±¡
        from core.interfaces import TrajectoryResult
        trajectory = TrajectoryResult(
            task_name=task.task_id,
            task_id=task.task_id,
            task_description=task.description,
            runtime_id=self._runtime_id,
            steps=[],
            success=success,
            final_result=final_result,  # ğŸ”§ ä½¿ç”¨åŠ¨æ€æå–çš„ç»“æœ
            total_duration=total_duration,
            metadata={
                'mode': 'standard', 
                'raw_response': response,
                'intelligent_evaluation': intelligent_evaluation  # ğŸ§  æ–°å¢æ™ºèƒ½è¯„ä¼°ä¿¡æ¯
            }
        )
        
        return trajectory

    async def _get_available_tools(self) -> List[str]:
        """è·å–å¯ç”¨å·¥å…·åˆ—è¡¨"""
        try:
            tools = await self.toolscore_client.get_available_tools()
            return [str(tool) for tool in tools] if isinstance(tools, list) else []
        except Exception as e:
            logger.warning(f"è·å–å·¥å…·åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    async def _get_tool_descriptions(self) -> str:
        """è·å–å·¥å…·æè¿°"""
        try:
            descriptions = await self.toolscore_client.get_tool_descriptions()
            return descriptions if descriptions else "å·¥å…·æè¿°è·å–å¤±è´¥"
        except Exception as e:
            logger.warning(f"è·å–å·¥å…·æè¿°å¤±è´¥: {e}")
            return "å·¥å…·æè¿°è·å–å¤±è´¥"

    async def _intelligent_task_success_evaluation(
        self, 
        task_input: str, 
        final_trajectory_str: str, 
        full_trajectory: List, 
        final_output: str
    ) -> Tuple[bool, float, str]:
        """
        ğŸ§  æ™ºèƒ½ä»»åŠ¡æˆåŠŸè¯„ä¼° - æ–°çš„ä¸»è¦çŠ¶æ€åˆ¤å®šæ–¹æ³•
        
        ä½¿ç”¨è¯­ä¹‰ç†è§£å’Œç»“æœé©±åŠ¨çš„åˆ¤å®šé€»è¾‘ï¼Œæ›¿ä»£ä¼ ç»Ÿçš„æ ¼å¼é©±åŠ¨æ–¹æ³•
        
        Args:
            task_input: åŸå§‹ä»»åŠ¡è¾“å…¥
            final_trajectory_str: å®Œæ•´è½¨è¿¹å­—ç¬¦ä¸²
            full_trajectory: è½¨è¿¹æ­¥éª¤åˆ—è¡¨
            final_output: æœ€ç»ˆè¾“å‡ºå†…å®¹
            
        Returns:
            Tuple[is_success, confidence_score, reasoning]
        """
        try:
            # æå–å·¥å…·æ‰§è¡Œç»“æœ
            tool_results = []
            for step in full_trajectory:
                if isinstance(step, dict) and 'tool_execution' in step:
                    tool_results.append(step['tool_execution'])
            
            # è°ƒç”¨æ™ºèƒ½è¯„ä¼°å™¨
            is_success, confidence, reasoning = await intelligent_task_evaluation(
                llm_client=self.client,
                task_input=task_input,
                trajectory=full_trajectory,
                final_output=final_output,
                tool_results=tool_results
            )
            
            logger.info(f"ğŸ§  æ™ºèƒ½çŠ¶æ€è¯„ä¼°ç»“æœ: æˆåŠŸ={is_success}, ç½®ä¿¡åº¦={confidence:.2f}, ç†ç”±={reasoning}")
            
            return is_success, confidence, reasoning
            
        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½çŠ¶æ€è¯„ä¼°å¤±è´¥: {e}")
            # é™çº§åˆ°ä¼ ç»Ÿæ–¹æ³•
            traditional_success = self._determine_task_success(final_trajectory_str, full_trajectory)
            return traditional_success, 0.5, f"é™çº§è¯„ä¼°: {traditional_success}"

    def _determine_task_success(self, final_trajectory_str: str, full_trajectory: List) -> bool:
        """ğŸ”§ Priority 1 ä¿®å¤ï¼šå½»åº•è§£å†³"è§„åˆ’å³æˆåŠŸ"ç³»ç»Ÿæ€§æ¼æ´
        
        æ ¸å¿ƒåŸåˆ™ï¼šå¿…é¡»æœ‰å®é™…å·¥å…·æ‰§è¡Œæˆ–æ˜ç¡®ç­”æ¡ˆæ ‡ç­¾ï¼Œä»…æœ‰è§„åˆ’/æ€è€ƒå†…å®¹ä¸èƒ½åˆ¤å®šä¸ºæˆåŠŸ
        
        Args:
            final_trajectory_str: å®Œæ•´è½¨è¿¹å­—ç¬¦ä¸²
            full_trajectory: è½¨è¿¹æ­¥éª¤åˆ—è¡¨
        
        Returns:
            bool: ä»»åŠ¡æ˜¯å¦æˆåŠŸå®Œæˆ
        """
        # ğŸ”§ æœ€é«˜ä¼˜å…ˆçº§ï¼šæ£€æŸ¥å®é™…å·¥å…·æ‰§è¡ŒçŠ¶æ€
        tool_success_rate = self._calculate_tool_success_rate()
        has_successful_tools = tool_success_rate > 0.0
        
        # 1. æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„ç­”æ¡ˆæ ‡ç­¾ï¼ˆå¿…é¡»æœ‰ç»“æŸæ ‡ç­¾ï¼‰
        answer_tag = TaskExecutionConstants.XML_TAGS['ANSWER']
        has_complete_answer = f'</{answer_tag}>' in final_trajectory_str
        has_boxed_answer = "\\boxed{" in final_trajectory_str  # æ•°å­¦ç­”æ¡ˆæ ¼å¼
        
        # 2. æ£€æŸ¥æ˜¯å¦æœ‰æœªå¤„ç†çš„å…³é”®é”™è¯¯æŒ‡ç¤ºå™¨
        has_critical_errors = any(
            indicator in final_trajectory_str.lower() 
            for indicator in TaskExecutionConstants.FAILURE_INDICATORS
        )
        
        # 3. æ£€æŸ¥æ˜¯å¦æœ‰å®é™…çš„å·¥å…·æ‰§è¡Œæˆæœ
        result_tag = TaskExecutionConstants.XML_TAGS['RESULT']
        has_tool_results = f'<{result_tag}>' in final_trajectory_str and TaskExecutionConstants.NO_ACTION_PERFORMED not in final_trajectory_str
        
        # 4. ğŸ”§ æ–°å¢ï¼šæ£€æŸ¥æ˜¯å¦åªæœ‰æ€è€ƒå†…å®¹ï¼ˆ"è§„åˆ’å³æˆåŠŸ"æ£€æµ‹ï¼‰
        think_tag = TaskExecutionConstants.XML_TAGS['THINK']
        execute_tools_tag = TaskExecutionConstants.XML_TAGS['EXECUTE_TOOLS']
        
        has_only_thinking = (f'<{think_tag}>' in final_trajectory_str and 
                           not has_tool_results and 
                           not has_complete_answer and
                           not has_boxed_answer and
                           f'<{execute_tools_tag}>' not in final_trajectory_str)
        
        # ğŸ”§ Priority 4 æ–°å¢ï¼šå¤šå·¥å…·ååŒè´¨é‡è¯„ä¼°
        multi_tool_quality = self._evaluate_multi_tool_coordination_quality(final_trajectory_str)
        
        # ğŸ”§ Priority 1 æ ¸å¿ƒä¿®å¤ï¼šä¸¥æ ¼çš„æˆåŠŸåˆ¤å®šé€»è¾‘
        success = False
        
        # åœºæ™¯1ï¼šæœ‰å®é™…å·¥å…·æ‰§è¡ŒæˆåŠŸ + æœ‰å®Œæ•´ç­”æ¡ˆ + æœ‰æ„ä¹‰ç»“æœ = æ˜ç¡®æˆåŠŸ
        if has_successful_tools and (has_complete_answer or has_boxed_answer) and not has_critical_errors and self._has_meaningful_tool_results(final_trajectory_str):
            success = True
            logger.info("ğŸ¯ åˆ¤å®šæˆåŠŸï¼šå·¥å…·æ‰§è¡ŒæˆåŠŸ + å®Œæ•´ç­”æ¡ˆ + æœ‰æ„ä¹‰ç»“æœ")
        
        # åœºæ™¯2ï¼šæœ‰å®é™…å·¥å…·æ‰§è¡ŒæˆåŠŸ + æœ‰å®é™…ç»“æœè¾“å‡º = æ½œåœ¨æˆåŠŸ
        elif has_successful_tools and has_tool_results and not has_critical_errors:
            success = True
            logger.info("ğŸ¯ åˆ¤å®šæˆåŠŸï¼šå·¥å…·æ‰§è¡ŒæˆåŠŸ + æœ‰å®é™…ç»“æœ")
        
        # åœºæ™¯3ï¼šğŸ”§ Priority 4 æ–°å¢ï¼šå¤šå·¥å…·ååŒæˆåŠŸåœºæ™¯
        elif multi_tool_quality['is_coordinated'] and multi_tool_quality['quality_score'] > TaskExecutionConstants.MULTI_TOOL_COORDINATION['RESULT_INTEGRATION']['quality_threshold']:
            success = True
            logger.info(f"ğŸ¯ åˆ¤å®šæˆåŠŸï¼šå¤šå·¥å…·ååŒå®Œæˆï¼Œè´¨é‡åˆ†æ•°={multi_tool_quality['quality_score']:.2f}")
        
        # åœºæ™¯4ï¼šçº¯æ¨ç†ä»»åŠ¡ï¼šæœ‰å®Œæ•´ç­”æ¡ˆæ ‡ç­¾ï¼ˆå¿…é¡»æœ‰ç»“æŸæ ‡ç­¾æˆ–boxedæ ¼å¼ï¼‰
        elif (has_complete_answer or has_boxed_answer) and not has_critical_errors:
            success = True
            logger.info("ğŸ¯ åˆ¤å®šæˆåŠŸï¼šçº¯æ¨ç†ä»»åŠ¡ï¼Œæœ‰å®Œæ•´ç­”æ¡ˆæ ‡ç­¾")
        
        # åœºæ™¯5ï¼šğŸ”§ "è§„åˆ’å³æˆåŠŸ"æ¼æ´é˜²æŠ¤ - åªæœ‰æ€è€ƒå†…å®¹æ—¶æ˜ç¡®æ‹’ç»
        elif has_only_thinking:
            success = False
            logger.warning('ğŸš¨ "è§„åˆ’å³æˆåŠŸ"æ¼æ´é˜²æŠ¤ï¼šä»…æœ‰æ€è€ƒå†…å®¹ï¼Œä¸è®¤å®šä¸ºæˆåŠŸ')
        
        # åœºæ™¯6ï¼šä»»ä½•å…³é”®é”™è¯¯éƒ½å¯¼è‡´å¤±è´¥
        elif has_critical_errors:
            success = False
            logger.info("ğŸ¯ åˆ¤å®šå¤±è´¥ï¼šæ£€æµ‹åˆ°å…³é”®é”™è¯¯")
        
        # åœºæ™¯7ï¼šå…¶ä»–æƒ…å†µé»˜è®¤å¤±è´¥
        else:
            success = False
            logger.info("ğŸ¯ åˆ¤å®šå¤±è´¥ï¼šæœªæ»¡è¶³æˆåŠŸæ¡ä»¶")
        
        logger.info(f"ğŸ¯ Successåˆ¤å®šè¯¦æƒ…: tool_success_rate={tool_success_rate:.2f}, "
                   f"has_complete_answer={has_complete_answer}, has_boxed_answer={has_boxed_answer}, "
                   f"has_tool_results={has_tool_results}, has_only_thinking={has_only_thinking}, "
                   f"has_critical_errors={has_critical_errors}, final_success={success}")
        
        return success
    
    def _calculate_tool_success_rate(self) -> float:
        """è®¡ç®—å½“å‰ä»»åŠ¡ä¸­å·¥å…·æ‰§è¡Œçš„æˆåŠŸç‡"""
        if not hasattr(self, 'step_logger') or not self.step_logger.current_task_data:
            return 0.0
        
        total_executions = 0
        successful_executions = 0
        
        for step in self.step_logger.current_task_data.get('steps', []):
            for tool_exec in step.get('tool_executions', []):
                total_executions += 1
                if tool_exec.get('execution_status') == 'success':
                    successful_executions += 1
        
        return successful_executions / total_executions if total_executions > 0 else 0.0
    
    def _analyze_error_type(self, error_message: str) -> str:
        """ğŸ”§ æ™ºèƒ½é”™è¯¯ç±»å‹åˆ†æ"""
        error_msg_lower = error_message.lower()
        
        # å‚æ•°é”™è¯¯
        if any(indicator in error_msg_lower for indicator in ['parameter', 'param', 'å‚æ•°', 'æ— æ•ˆå‚æ•°']):
            return "parameter_error"
        
        # å·¥å…·ä¸å­˜åœ¨é”™è¯¯
        if any(indicator in error_msg_lower for indicator in ['ä¸æ”¯æŒ', 'not support', 'ä¸å­˜åœ¨', 'not found']):
            return "tool_not_found"
        
        # ç½‘ç»œ/è¿æ¥é”™è¯¯
        if any(indicator in error_msg_lower for indicator in ['timeout', 'connection', 'network', 'connect', 'è¶…æ—¶']):
            return "network_error"
        
        # éªŒè¯é”™è¯¯
        if any(indicator in error_msg_lower for indicator in ['validation', 'validate', 'éªŒè¯å¤±è´¥']):
            return "validation_error"
        
        # æƒé™é”™è¯¯
        if any(indicator in error_msg_lower for indicator in ['permission', 'access', 'æƒé™', 'forbidden']):
            return "permission_error"
        
        return "unknown_error"
    
    def _format_error_with_recovery_suggestion(self, error_message: str, error_type: str, service_name: str, tool_name: str) -> str:
        """ğŸ”§ æ ¼å¼åŒ–é”™è¯¯ä¿¡æ¯å¹¶æä¾›æ¢å¤å»ºè®®"""
        base_error = f"Tool execution failed: {error_message}"
        
        recovery_suggestions = {
            "parameter_error": f"ğŸ’¡ å»ºè®®: æ£€æŸ¥ {service_name} çš„ {tool_name} å·¥å…·å‚æ•°æ ¼å¼ã€‚å‚è€ƒå·¥å…·å®šä¹‰ä¸­çš„æ­£ç¡®å‚æ•°åç§°ã€‚",
            "tool_not_found": f"ğŸ’¡ å»ºè®®: å·¥å…· {tool_name} åœ¨ {service_name} ä¸­ä¸å­˜åœ¨ã€‚æ£€æŸ¥å·¥å…·åç§°æ˜¯å¦æ­£ç¡®ï¼Œæˆ–å°è¯•ä½¿ç”¨å…¶ä»–å·¥å…·ã€‚",
            "network_error": f"ğŸ’¡ å»ºè®®: ç½‘ç»œè¿æ¥é—®é¢˜ã€‚ç­‰å¾…å‡ ç§’åé‡è¯•ï¼Œæˆ–å°è¯•ä½¿ç”¨æ›¿ä»£å·¥å…·ã€‚",
            "validation_error": f"ğŸ’¡ å»ºè®®: è¾“å…¥æ•°æ®éªŒè¯å¤±è´¥ã€‚æ£€æŸ¥è¾“å…¥æ ¼å¼å’Œå†…å®¹æ˜¯å¦ç¬¦åˆè¦æ±‚ã€‚",
            "permission_error": f"ğŸ’¡ å»ºè®®: æƒé™ä¸è¶³ã€‚æ£€æŸ¥æœåŠ¡é…ç½®æˆ–å°è¯•å…¶ä»–æ–¹æ³•ã€‚",
            "unknown_error": f"ğŸ’¡ å»ºè®®: æœªçŸ¥é”™è¯¯ã€‚å°è¯•ç®€åŒ–è¾“å…¥æˆ–ä½¿ç”¨å…¶ä»–å·¥å…·æ›¿ä»£ã€‚"
        }
        
        suggestion = recovery_suggestions.get(error_type, recovery_suggestions["unknown_error"])
        return f"{base_error}\n{suggestion}"
    
    def _extract_final_result(self, final_trajectory_str: str) -> str:
        """ğŸ”§ å®Œæ•´ä¿®å¤ï¼šä¼˜åŒ–æœ€ç»ˆç»“æœæå–ä¼˜å…ˆçº§ï¼Œç¡®ä¿å®é™…ç»“æœä¼˜äºæ€è€ƒè¿‡ç¨‹
        
        Args:
            final_trajectory_str: å®Œæ•´è½¨è¿¹å­—ç¬¦ä¸²
        
        Returns:
            str: æå–çš„æœ€ç»ˆç»“æœ
        """
        import re
        
        # ğŸ”§ ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šæå–answeræ ‡ç­¾å†…å®¹ï¼Œä¼˜å…ˆæå–\boxed{}æ ¼å¼
        answer_tag = TaskExecutionConstants.XML_TAGS['ANSWER']
        answer_pattern = f'<{answer_tag}>(.*?)</{answer_tag}>'
        answer_match = re.search(answer_pattern, final_trajectory_str, re.DOTALL)
        if answer_match:
            answer_content = answer_match.group(1).strip()
            if answer_content and len(answer_content) > 0:
                # ğŸ”§ æ–°å¢ï¼šä¼˜å…ˆæå–\boxed{}å†…çš„æ¸…æ´å†…å®¹
                boxed_pattern = r'\\boxed\{(.*?)\}'
                boxed_match = re.search(boxed_pattern, answer_content, re.DOTALL)
                if boxed_match:
                    clean_answer = boxed_match.group(1).strip()
                    logger.info(f"âœ… ä»\\boxed{{}}æå–æ¸…æ´æœ€ç»ˆç»“æœ: {clean_answer[:100]}...")
                    return clean_answer
                else:
                    # å¦‚æœæ²¡æœ‰\boxed{}æ ¼å¼ï¼Œè¿”å›åŸå§‹answerå†…å®¹
                    logger.info(f"âœ… ä»<answer>æ ‡ç­¾æå–æœ€ç»ˆç»“æœ: {answer_content[:100]}...")
                    return answer_content
        else:
            # ğŸ”§ å®¹é”™æœºåˆ¶ï¼šå¦‚æœæ ‡å‡†ç­”æ¡ˆæ ‡ç­¾è§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤
            answer_content = self._attempt_answer_extraction(final_trajectory_str)
            if answer_content:
                logger.info(f"ğŸ”§ å®¹é”™æå–ç­”æ¡ˆæˆåŠŸ: {answer_content[:100]}...")
                return answer_content
        
        # ğŸ”§ ç¬¬äºŒä¼˜å…ˆçº§ï¼šæå–æœ€åçš„æœ‰æ•ˆå·¥å…·æ‰§è¡Œç»“æœï¼ˆé"No action"ï¼‰
        result_tag = TaskExecutionConstants.XML_TAGS['RESULT']
        result_pattern = f'<{result_tag}>(.*?)</{result_tag}>'
        result_matches = re.findall(result_pattern, final_trajectory_str, re.DOTALL)
        
        # è¿‡æ»¤å‡ºæœ‰æ•ˆçš„å·¥å…·æ‰§è¡Œç»“æœ
        valid_results = []
        for result in result_matches:
            result_clean = result.strip()
            # æ’é™¤æ— æ„ä¹‰çš„ç»“æœ
            if (result_clean and 
                TaskExecutionConstants.NO_ACTION_PERFORMED not in result_clean and
                "No executable action detected" not in result_clean and
                len(result_clean) > 10):
                valid_results.append(result_clean)
        
        if valid_results:
            # ğŸ”§ ä¼˜åŒ–ï¼šé€‰æ‹©æœ€æœ‰ä»·å€¼çš„ç»“æœ
            best_result = self._select_best_tool_result(valid_results)
            logger.info(f"ğŸ”§ ä»å·¥å…·æ‰§è¡Œç»“æœæå–æœ€ç»ˆç­”æ¡ˆ: {best_result[:100]}...")
            return best_result
        
        # ğŸ”§ ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼šæå–æ•°å€¼è®¡ç®—ç»“æœï¼ˆé’ˆå¯¹æ•°å­¦é—®é¢˜ï¼‰
        # æŸ¥æ‰¾æ•°å€¼ç»“æœæ¨¡å¼
        calculation_patterns = [
            r'ç»“æœ[ï¼š:]\s*([0-9.e-]+\s*[A-Za-z]*)',  # "ç»“æœ: 9.43e-07 A"
            r'ç­”æ¡ˆ[ï¼š:]\s*([0-9.e-]+\s*[A-Za-z]*)',  # "ç­”æ¡ˆ: 42"
            r'photocurrent[ï¼š:]\s*([0-9.e-]+\s*[A-Za-z]*)',  # "photocurrent: 9.43e-07 A"
            r'([0-9.e-]+\s*[A-Za-z]*)\s*(?:å®‰åŸ¹|A|ç“¦ç‰¹|W|ç±³|m)',  # å•ä½æ¨¡å¼
        ]
        
        for pattern in calculation_patterns:
            matches = re.findall(pattern, final_trajectory_str, re.IGNORECASE)
            if matches:
                # ğŸ”§ æ·»åŠ ä¸Šä¸‹æ–‡éªŒè¯ - ç¡®ä¿ç»“æœæ¥è‡ªå®é™…çš„å·¥å…·æ‰§è¡Œ
                calculation_result = matches[-1].strip()
                if self._validate_calculation_context(final_trajectory_str, calculation_result):
                    logger.info(f"ğŸ§® ä»è®¡ç®—ç»“æœæå–æœ€ç»ˆç­”æ¡ˆ: {calculation_result}")
                    return f"è®¡ç®—ç»“æœ: {calculation_result}"
                else:
                    logger.warning(f"âš ï¸ è®¡ç®—ç»“æœ {calculation_result} æœªé€šè¿‡ä¸Šä¸‹æ–‡éªŒè¯ï¼Œè·³è¿‡")
        
        # ğŸ”§ ç¬¬å››ä¼˜å…ˆçº§ï¼šæå–æœç´¢ç­”æ¡ˆï¼ˆé’ˆå¯¹é—®ç­”ç±»ä»»åŠ¡ï¼‰
        # æŸ¥æ‰¾IORAç­‰ä¸“æœ‰åè¯çš„è§£é‡Š
        info_patterns = [
            r'IORA[æ˜¯ä¸º].*?[ã€‚.]',  # IORAç›¸å…³è§£é‡Š
            r'æ–°åŠ å¡å›½ç«‹å¤§å­¦.*?[ã€‚.]',  # å¤§å­¦ç›¸å…³ä¿¡æ¯
            r'([A-Z]{3,}\s*(?:æ˜¯|ä¸º|æŒ‡).*?[ã€‚.])',  # ç¼©å†™è§£é‡Šæ¨¡å¼
        ]
        
        for pattern in info_patterns:
            matches = re.findall(pattern, final_trajectory_str, re.DOTALL)
            if matches:
                info_result = matches[-1].strip()
                logger.info(f"ğŸ“– ä»ä¿¡æ¯æ£€ç´¢æå–æœ€ç»ˆç­”æ¡ˆ: {info_result[:100]}...")
                return info_result
        
        # ğŸ”§ ç¬¬äº”ä¼˜å…ˆçº§ï¼šæ™ºèƒ½æå–æœ€åçš„thinkå†…å®¹ï¼ˆé™ä½ä¼˜å…ˆçº§ï¼‰
        think_tag = TaskExecutionConstants.XML_TAGS['THINK']
        think_pattern = f'<{think_tag}>(.*?)</{think_tag}>'
        think_matches = re.findall(think_pattern, final_trajectory_str, re.DOTALL)
        if think_matches:
            last_think = think_matches[-1].strip()
            # åªæœ‰åœ¨æ²¡æœ‰å…¶ä»–ç»“æœæ—¶æ‰ä½¿ç”¨æ€è€ƒå†…å®¹ï¼Œä¸”éœ€è¦è¶³å¤Ÿé•¿
            if last_think and len(last_think) > 50:
                logger.info(f"ğŸ“ ä»æ€è€ƒè¿‡ç¨‹æå–ç»“æœ: {last_think[:100]}...")
                return f"åˆ†æè¿‡ç¨‹: {last_think[:200]}..."
        
        # ğŸ”§ ç¬¬å…­ä¼˜å…ˆçº§ï¼šæå–å¯è§çš„æœ‰æ„ä¹‰æ–‡æœ¬
        visible_content = re.sub(r'<[^>]+>', '', final_trajectory_str).strip()
        if visible_content and len(visible_content) > 20:
            # å¯»æ‰¾æœ€åçš„æœ‰æ„ä¹‰å†…å®¹
            lines = [line.strip() for line in visible_content.split('\n') if line.strip()]
            meaningful_lines = []
            
            for line in lines[-10:]:  # æ£€æŸ¥æœ€å10è¡Œ
                # è¿‡æ»¤æ‰æ— æ„ä¹‰çš„è¡Œ
                if (len(line) > 10 and 
                    not line.startswith('---') and
                    'Starting Step' not in line and
                    'executable action' not in line):
                    meaningful_lines.append(line)
            
            if meaningful_lines:
                final_content = ' '.join(meaningful_lines[-3:])  # å–æœ€å3è¡Œæœ‰æ„ä¹‰å†…å®¹
                logger.info(f"ğŸ“„ ä»å¯è§æ–‡æœ¬æå–ç»“æœ: {final_content[:100]}...")
                return final_content
        
        # æœ€åå¤‡é€‰ï¼šè¿”å›ä»»åŠ¡å®ŒæˆçŠ¶æ€  
        logger.warning("âš ï¸ æ— æ³•æå–å…·ä½“çš„æœ€ç»ˆç»“æœï¼Œè¿”å›é»˜è®¤å®Œæˆæ¶ˆæ¯")
        return TaskExecutionConstants.TASK_COMPLETED_NO_ANSWER
    
    def _select_best_tool_result(self, valid_results: list) -> str:
        """é€‰æ‹©æœ€æœ‰ä»·å€¼çš„å·¥å…·æ‰§è¡Œç»“æœ"""
        if not valid_results:
            return ""
        
        import re
        
        # ä¼˜å…ˆçº§è¯„åˆ†
        scored_results = []
        for result in valid_results:
            score = 0
            result_lower = result.lower()
            
            # åŒ…å«æ•°å€¼è®¡ç®—çš„ç»“æœå¾—åˆ†æ›´é«˜
            if re.search(r'[0-9.e-]+', result):
                score += 10
            
            # åŒ…å«ä¸“ä¸šæœ¯è¯­çš„ç»“æœå¾—åˆ†æ›´é«˜
            if any(term in result_lower for term in ['iora', 'university', 'å¤§å­¦', 'ç»“æœ', 'ç­”æ¡ˆ']):
                score += 8
            
            # é•¿åº¦é€‚ä¸­çš„ç»“æœå¾—åˆ†æ›´é«˜
            if 20 <= len(result) <= 300:
                score += 5
            
            # åŒ…å«æœç´¢ç»“æœçš„å¾—åˆ†æ›´é«˜
            if 'æœç´¢ç»“æœ' in result or 'search' in result_lower:
                score += 7
            
            scored_results.append((score, result))
        
        # è¿”å›å¾—åˆ†æœ€é«˜çš„ç»“æœ
        scored_results.sort(key=lambda x: x[0], reverse=True)
        return scored_results[0][1]
    
    def _should_inject_no_action_message(self, response_text: str) -> bool:
        """ğŸ”§ å®Œæ•´ä¿®å¤ï¼šä¸¥æ ¼æ§åˆ¶æ— åŠ¨ä½œæ¶ˆæ¯æ³¨å…¥ï¼Œå½»åº•æ¶ˆé™¤å†—ä½™æ¶ˆæ¯
        
        Args:
            response_text: LLMå“åº”æ–‡æœ¬
        
        Returns:
            bool: æ˜¯å¦éœ€è¦æ³¨å…¥æ— åŠ¨ä½œæ¶ˆæ¯
        """
        import re
        
        # ğŸ”§ å¢å¼ºæ£€æµ‹ï¼šå¦‚æœæœ‰ä»»ä½•XMLæ ‡ç­¾ï¼Œéƒ½è®¤ä¸ºæœ‰å†…å®¹
        xml_tags = TaskExecutionConstants.XML_TAGS
        all_possible_tags = [
            f"<{xml_tags['THINK']}>", f"</{xml_tags['THINK']}>",
            f"<{xml_tags['ANSWER']}>", f"</{xml_tags['ANSWER']}>", 
            f"<{xml_tags['RESULT']}>", f"</{xml_tags['RESULT']}>",
            f"<{xml_tags['OBSERVATION']}>", f"</{xml_tags['OBSERVATION']}>",
            f"<{xml_tags['CONCLUSION']}>", f"</{xml_tags['CONCLUSION']}>",
            "<execute_tools/>", "<execute_tools></execute_tools>"
        ]
        
        # 1. æ£€æµ‹ä»»ä½•XMLç»“æ„åŒ–å†…å®¹
        for tag in all_possible_tags:
            if tag in response_text:
                logger.info(f"ğŸ’­ æ£€æµ‹åˆ°XMLæ ‡ç­¾ {tag}ï¼Œæ— éœ€æ³¨å…¥æ— åŠ¨ä½œæ¶ˆæ¯")
                return False
        
        # 2. æ£€æµ‹ä»»ä½•å·¥å…·æœåŠ¡å™¨æ ‡ç­¾
        server_tags = ["<microsandbox>", "<deepsearch>", "<browser_use>", "<search_tool>"]
        for tag in server_tags:
            if tag in response_text:
                logger.info(f"ğŸ”§ æ£€æµ‹åˆ°å·¥å…·æ ‡ç­¾ {tag}ï¼Œæ— éœ€æ³¨å…¥æ— åŠ¨ä½œæ¶ˆæ¯")
                return False
        
        # 3. æ£€æµ‹æœ‰æ„ä¹‰çš„æ–‡æœ¬å†…å®¹ï¼ˆæ›´ä¸¥æ ¼çš„æ ‡å‡†ï¼‰
        clean_text = re.sub(r'<[^>]+>', '', response_text).strip()
        
        # å¦‚æœæœ‰è¶³å¤Ÿçš„æœ‰æ„ä¹‰æ–‡æœ¬å†…å®¹
        if len(clean_text) > 20:  # é™ä½é˜ˆå€¼ï¼Œæ›´å®½æ¾
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ„ä¹‰çš„å†…å®¹ï¼ˆéç©ºç™½ã€éé‡å¤å­—ç¬¦ï¼‰
            meaningful_chars = len(re.sub(r'\s+', '', clean_text))
            if meaningful_chars > 10:
                logger.info(f"ğŸ“ æ£€æµ‹åˆ°æœ‰æ„ä¹‰æ–‡æœ¬å†…å®¹({meaningful_chars}å­—ç¬¦)ï¼Œæ— éœ€æ³¨å…¥æ— åŠ¨ä½œæ¶ˆæ¯")
                return False
        
        # 4. ğŸ”§ æ–°å¢ï¼šæ£€æµ‹ä»»åŠ¡å®Œæˆçš„ç‰¹æ®Šæƒ…å†µ
        completion_indicators = [
            "ä»»åŠ¡å®Œæˆ", "execution completed", "calculation complete",
            "æœç´¢å®Œæˆ", "æ“ä½œå®Œæˆ", "å¤„ç†å®Œæˆ", "åˆ†æå®Œæˆ"
        ]
        
        response_lower = response_text.lower()
        for indicator in completion_indicators:
            if indicator.lower() in response_lower:
                logger.info(f"âœ… æ£€æµ‹åˆ°å®ŒæˆæŒ‡ç¤ºè¯ '{indicator}'ï¼Œæ— éœ€æ³¨å…¥æ— åŠ¨ä½œæ¶ˆæ¯")
                return False
        
        # 5. ğŸ”§ æ–°å¢ï¼šå¦‚æœå“åº”åŒ…å«ä»»ä½•æ•°å­—ã€å­—æ¯æˆ–ä¸­æ–‡å­—ç¬¦çš„æœ‰æ„ä¹‰ç»„åˆ
        if re.search(r'[a-zA-Z\u4e00-\u9fff]{3,}', response_text):
            logger.info("ğŸ“„ æ£€æµ‹åˆ°æœ‰æ„ä¹‰çš„æ–‡æœ¬ç»„åˆï¼Œæ— éœ€æ³¨å…¥æ— åŠ¨ä½œæ¶ˆæ¯")
            return False
        
        # 6. ğŸ”§ ç‰¹æ®Šæƒ…å†µï¼šå¦‚æœå“åº”æ˜¯ç©ºçš„æˆ–è€…åªæœ‰ç©ºç™½ç¬¦
        if not response_text or response_text.isspace():
            logger.warning("âš ï¸ æ£€æµ‹åˆ°å®Œå…¨ç©ºçš„å“åº”ï¼Œéœ€è¦æ³¨å…¥æŒ‡å¯¼æ¶ˆæ¯")
            return True
        
        # 7. ğŸ”§ æœ€ä¸¥æ ¼çš„åˆ¤æ–­ï¼šåªæœ‰åœ¨å“åº”çœŸçš„æ²¡æœ‰ä»»ä½•æœ‰ç”¨ä¿¡æ¯æ—¶æ‰æ³¨å…¥
        # æ£€æŸ¥æ˜¯å¦åªåŒ…å«æ— æ„ä¹‰çš„é‡å¤å­—ç¬¦æˆ–ç¬¦å·
        if len(set(response_text.replace(' ', '').replace('\n', ''))) < 3:
            logger.warning(f"âš ï¸ æ£€æµ‹åˆ°æ— æ„ä¹‰çš„é‡å¤å†…å®¹ï¼Œéœ€è¦æ³¨å…¥æŒ‡å¯¼æ¶ˆæ¯")
            return True
        
        # é»˜è®¤æƒ…å†µï¼šä¸æ³¨å…¥æ— åŠ¨ä½œæ¶ˆæ¯ï¼ˆæ›´ä¿å®ˆçš„ç­–ç•¥ï¼‰
        logger.info("ğŸ¯ å“åº”åŒ…å«å†…å®¹ï¼Œæ— éœ€æ³¨å…¥æ— åŠ¨ä½œæ¶ˆæ¯")
        return False
    
    def _extract_detailed_plan(self, response_text: str) -> Optional[str]:
        """ğŸ”§ æ–°å¢ï¼šä»å“åº”ä¸­æå–è¯¦ç»†è®¡åˆ’å†…å®¹"""
        import re
        
        # æ£€æŸ¥thinkæ ‡ç­¾ä¸­çš„å†…å®¹
        think_tag = TaskExecutionConstants.XML_TAGS['THINK']
        think_pattern = f'<{think_tag}>(.*?)</{think_tag}>'
        think_match = re.search(think_pattern, response_text, re.DOTALL)
        
        if think_match:
            think_content = think_match.group(1).strip()
            return think_content
        
        # å¦‚æœæ²¡æœ‰thinkæ ‡ç­¾ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–å½¢å¼çš„è®¡åˆ’å†…å®¹
        # å¯»æ‰¾åŒ…å«æ­¥éª¤ã€è®¡åˆ’å…³é”®è¯çš„å†…å®¹
        plan_indicators = [
            'step', 'phase', 'first', 'next', 'then', 'need to', 'will',
            'æ­¥éª¤', 'é˜¶æ®µ', 'é¦–å…ˆ', 'ç„¶å', 'æ¥ä¸‹æ¥', 'éœ€è¦', 'å°†ä¼š'
        ]
        
        lines = response_text.split('\n')
        plan_lines = []
        
        for line in lines:
            line_lower = line.lower()
            if any(indicator in line_lower for indicator in plan_indicators):
                plan_lines.append(line.strip())
        
        if plan_lines and len('\n'.join(plan_lines)) > 50:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„è®¡åˆ’å†…å®¹
            return '\n'.join(plan_lines)
        
        return None
    
    def _has_executable_plan(self, plan_content: str) -> bool:
        """ğŸ”§ æ–°å¢ï¼šåˆ¤æ–­è®¡åˆ’å†…å®¹æ˜¯å¦åŒ…å«å¯æ‰§è¡Œçš„å…·ä½“æ­¥éª¤"""
        if not plan_content or len(plan_content) < 30:
            return False
        
        plan_lower = plan_content.lower()
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å·¥å…·ç›¸å…³çš„æ‰§è¡Œæ„å›¾
        tool_indicators = [
            'search', 'execute', 'run', 'call', 'use', 'browser', 'python', 'code',
            'æœç´¢', 'æ‰§è¡Œ', 'è¿è¡Œ', 'è°ƒç”¨', 'ä½¿ç”¨', 'æµè§ˆå™¨', 'ä»£ç ', 'å·¥å…·'
        ]
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ˜ç¡®çš„æ‰§è¡Œæ­¥éª¤
        execution_indicators = [
            'step 1', 'first step', 'start by', 'begin with', 'initially',
            'ç¬¬ä¸€æ­¥', 'é¦–å…ˆ', 'å¼€å§‹', 'å…ˆ', 'ç¬¬1æ­¥'
        ]
        
        # æ£€æŸ¥å·¥å…·æœåŠ¡å™¨åç§°
        service_indicators = [
            'microsandbox', 'deepsearch', 'browser_use', 'search_tool'
        ]
        
        has_tools = any(indicator in plan_lower for indicator in tool_indicators)
        has_execution_steps = any(indicator in plan_lower for indicator in execution_indicators)
        has_services = any(indicator in plan_lower for indicator in service_indicators)
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤šä¸ªæ­¥éª¤ï¼ˆè¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªè¯¦ç»†è®¡åˆ’ï¼‰
        step_count = (
            plan_lower.count('step') + plan_lower.count('æ­¥éª¤') + 
            plan_lower.count('first') + plan_lower.count('then') + 
            plan_lower.count('next') + plan_lower.count('é¦–å…ˆ') + 
            plan_lower.count('ç„¶å') + plan_lower.count('æ¥ä¸‹æ¥')
        )
        
        has_multiple_steps = step_count >= 2
        
        # å¦‚æœæœ‰å·¥å…·æ„å›¾ã€æ‰§è¡Œæ­¥éª¤ã€æˆ–å¤šæ­¥è®¡åˆ’ï¼Œè®¤ä¸ºè¿™æ˜¯å¯æ‰§è¡Œè®¡åˆ’
        is_executable = (has_tools and has_execution_steps) or has_services or has_multiple_steps
        
        logger.debug(f"ğŸ” è®¡åˆ’åˆ†æ: å·¥å…·={has_tools}, æ‰§è¡Œæ­¥éª¤={has_execution_steps}, "
                    f"æœåŠ¡={has_services}, å¤šæ­¥éª¤={has_multiple_steps}, å¯æ‰§è¡Œ={is_executable}")
        
        return is_executable
    
    def _extract_first_executable_action(self, plan_content: str) -> Optional[str]:
        """ğŸ”§ Priority 3 æ–°å¢ï¼šä»è®¡åˆ’ä¸­æå–ç¬¬ä¸€ä¸ªå¯æ‰§è¡Œçš„å…·ä½“åŠ¨ä½œ"""
        import re
        
        plan_lower = plan_content.lower()
        lines = plan_content.split('\n')
        
        # å¯»æ‰¾æ˜ç¡®çš„ç¬¬ä¸€æ­¥éª¤
        first_step_patterns = [
            r'(?:step\s*1|first\s*step|ç¬¬ä¸€æ­¥|é¦–å…ˆ)[:\s]*(.*?)(?:\n|$)',
            r'(?:1\.|â‘ |å¼€å§‹|start)[:\s]*(.*?)(?:\n|$)',
            r'(?:éœ€è¦|need\s*to|will|åº”è¯¥)[:\s]*(.*?)(?:\n|$)'
        ]
        
        for pattern in first_step_patterns:
            match = re.search(pattern, plan_lower, re.IGNORECASE | re.DOTALL)
            if match:
                action = match.group(1).strip()
                # æ¸…ç†å¹¶ç®€åŒ–åŠ¨ä½œæè¿°
                if len(action) > 10 and len(action) < 200:
                    return action
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ç¡®çš„ç¬¬ä¸€æ­¥ï¼Œå°è¯•ä»è®¡åˆ’ä¸­æå–å·¥å…·ç›¸å…³çš„åŠ¨ä½œ
        tool_action_patterns = [
            r'(search\s+for\s+[^.\n]+)',
            r'(execute\s+[^.\n]+)',
            r'(run\s+[^.\n]+)',
            r'(use\s+[^.\n]+)',
            r'(æœç´¢[^ã€‚\n]+)',
            r'(æ‰§è¡Œ[^ã€‚\n]+)',
            r'(è¿è¡Œ[^ã€‚\n]+)',
            r'(ä½¿ç”¨[^ã€‚\n]+)'
        ]
        
        for pattern in tool_action_patterns:
            match = re.search(pattern, plan_lower)
            if match:
                action = match.group(1).strip()
                if len(action) > 5 and len(action) < 150:
                    return action
        
        return None
    
    def _validate_calculation_context(self, trajectory_str: str, calculation_result: str) -> bool:
        """ğŸ”§ æ–°å¢ï¼šéªŒè¯è®¡ç®—ç»“æœæ˜¯å¦æ¥è‡ªçœŸå®çš„å·¥å…·æ‰§è¡Œä¸Šä¸‹æ–‡"""
        import re
        
        # 1. æ£€æŸ¥ç»“æœæ˜¯å¦å‡ºç°åœ¨å·¥å…·æ‰§è¡Œç»“æœæ ‡ç­¾å†…
        result_tag = TaskExecutionConstants.XML_TAGS['RESULT']
        result_pattern = f'<{result_tag}>(.*?)</{result_tag}>'
        result_blocks = re.findall(result_pattern, trajectory_str, re.DOTALL)
        
        # æ£€æŸ¥è®¡ç®—ç»“æœæ˜¯å¦åœ¨ä»»ä½•resultå—ä¸­
        for result_block in result_blocks:
            if calculation_result in result_block:
                logger.debug("âœ… è®¡ç®—ç»“æœåœ¨å·¥å…·æ‰§è¡Œç»“æœä¸­æ‰¾åˆ°")
                return True
        
        # 2. æ£€æŸ¥ç»“æœæ˜¯å¦åœ¨å·¥å…·æ‰§è¡Œçš„ä¸Šä¸‹æ–‡ä¸­ï¼ˆé™„è¿‘æœ‰å·¥å…·è°ƒç”¨ï¼‰
        # æŸ¥æ‰¾ç»“æœåœ¨è½¨è¿¹ä¸­çš„ä½ç½®
        result_index = trajectory_str.find(calculation_result)
        if result_index == -1:
            logger.debug("âŒ æœªæ‰¾åˆ°è®¡ç®—ç»“æœåœ¨è½¨è¿¹ä¸­çš„ä½ç½®")
            return False
        
        # æ£€æŸ¥ç»“æœå‰å500å­—ç¬¦å†…æ˜¯å¦æœ‰å·¥å…·æ‰§è¡Œæ ‡è®°
        context_start = max(0, result_index - 500)
        context_end = min(len(trajectory_str), result_index + len(calculation_result) + 500)
        context = trajectory_str[context_start:context_end]
        
        tool_execution_indicators = [
            '<execute_tools', '</execute_tools>', '<result>', '</result>',
            'microsandbox', 'deepsearch', 'browser_use', 'search_tool',
            'ä»£ç æ‰§è¡Œ', 'æ‰§è¡Œç»“æœ', 'å·¥å…·æ‰§è¡Œ', 'è®¡ç®—å®Œæˆ'
        ]
        
        has_tool_context = any(indicator in context for indicator in tool_execution_indicators)
        if has_tool_context:
            logger.debug("âœ… è®¡ç®—ç»“æœåœ¨å·¥å…·æ‰§è¡Œä¸Šä¸‹æ–‡ä¸­")
            return True
        
        # 3. æ£€æŸ¥æ˜¯å¦æ˜¯çº¯æ€è€ƒè¿‡ç¨‹ä¸­çš„è™šå‡è®¡ç®—
        think_tag = TaskExecutionConstants.XML_TAGS['THINK']
        think_pattern = f'<{think_tag}>(.*?)</{think_tag}>'
        think_blocks = re.findall(think_pattern, trajectory_str, re.DOTALL)
        
        for think_block in think_blocks:
            if calculation_result in think_block:
                # å¦‚æœç»“æœåªåœ¨æ€è€ƒè¿‡ç¨‹ä¸­ï¼Œä¸”æ²¡æœ‰å¯¹åº”çš„å·¥å…·æ‰§è¡Œï¼Œåˆ™è®¤ä¸ºæ˜¯è™šå‡çš„
                logger.debug("âš ï¸ è®¡ç®—ç»“æœåªåœ¨æ€è€ƒè¿‡ç¨‹ä¸­å‘ç°ï¼Œå¯èƒ½æ˜¯è™šå‡ç»“æœ")
                return False
        
        # 4. æ£€æŸ¥ç»“æœæ˜¯å¦æœ‰åˆç†çš„æ•°å€¼æ ¼å¼å’Œå•ä½
        # å¦‚æœæ˜¯çº¯å­—æ¯ï¼ˆå¦‚"e"ï¼‰ï¼Œå¾ˆå¯èƒ½æ˜¯è™šå‡ç»“æœ
        if re.match(r'^[a-zA-Z]$', calculation_result.strip()):
            logger.debug("âŒ è®¡ç®—ç»“æœæ˜¯å•ä¸ªå­—æ¯ï¼Œå¯èƒ½æ˜¯è™šå‡ç»“æœ")
            return False
        
        # 5. é»˜è®¤æƒ…å†µï¼šå¦‚æœç»“æœçœ‹èµ·æ¥åˆç†ä¸”æ²¡æœ‰æ˜æ˜¾é—®é¢˜ï¼Œå…è®¸é€šè¿‡
        logger.debug("ğŸ”§ è®¡ç®—ç»“æœé€šè¿‡åŸºæœ¬éªŒè¯")
        return True
    
    def _has_meaningful_tool_results(self, trajectory_str: str) -> bool:
        """ğŸ”§ Priority 2 å¢å¼ºï¼šå·¥å…·ç»“æœè§£æèƒ½åŠ›ï¼Œæ”¯æŒå¤æ‚JSONç»“æ„"""
        import re
        import json
        
        result_tag = TaskExecutionConstants.XML_TAGS['RESULT']
        result_pattern = f'<{result_tag}>(.*?)</{result_tag}>'
        result_blocks = re.findall(result_pattern, trajectory_str, re.DOTALL)
        
        meaningful_results = 0
        for result_block in result_blocks:
            result_clean = result_block.strip()
            
            # æ’é™¤æ— æ„ä¹‰çš„ç»“æœ
            if (len(result_clean) > 20 and  # æœ‰è¶³å¤Ÿçš„å†…å®¹
                TaskExecutionConstants.NO_ACTION_PERFORMED not in result_clean and
                "No executable action detected" not in result_clean and
                "Error:" not in result_clean and
                "failed" not in result_clean.lower()):
                
                # ğŸ”§ Priority 2 æ–°å¢ï¼šå¤æ‚JSONç»“æ„è§£æ
                is_meaningful = self._analyze_complex_result_content(result_clean)
                
                if is_meaningful:
                    meaningful_results += 1
        
        # å¦‚æœæœ‰è‡³å°‘ä¸€ä¸ªæœ‰æ„ä¹‰çš„å·¥å…·ç»“æœï¼Œè®¤ä¸ºå·¥å…·æ‰§è¡Œæœ‰æ„ä¹‰
        has_meaningful = meaningful_results > 0
        logger.debug(f"ğŸ” å·¥å…·ç»“æœåˆ†æ: æ€»ç»“æœå—={len(result_blocks)}, æœ‰æ„ä¹‰ç»“æœ={meaningful_results}, åˆ¤å®š={has_meaningful}")
        
        return has_meaningful
    
    def _analyze_complex_result_content(self, result_content: str) -> bool:
        """ğŸ”§ Priority 2 æ–°å¢ï¼šåˆ†æå¤æ‚ç»“æœå†…å®¹ï¼Œæ”¯æŒJSONã€ä»£ç ã€æœç´¢ç»“æœç­‰"""
        import re
        import json
        
        # 1. æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰ä»·å€¼çš„ä¿¡æ¯æŒ‡ç¤ºè¯
        has_data = any(indicator in result_content.lower() for indicator in [
            'result', 'found', 'success', 'completed', 'ç»“æœ', 'æˆåŠŸ', 'å®Œæˆ',
            'http', 'www', 'search', 'execute', 'calculation', 'answer'
        ])
        
        # 2. æ£€æŸ¥æ˜¯å¦åŒ…å«æ•°å€¼ã€ä»£ç æ‰§è¡Œç»“æœæˆ–æœç´¢ç»“æœ
        has_numerical = re.search(r'\d+', result_content)
        has_technical_content = any(keyword in result_content.lower() for keyword in [
            'python', 'code', 'execute', 'import', 'def', 'return',
            'search results', 'æœç´¢ç»“æœ', 'photocurrent', 'iora'
        ])
        
        # 3. ğŸ”§ æ–°å¢ï¼šJSONç»“æ„è§£æ
        has_structured_data = self._has_structured_json_data(result_content)
        
        # 4. ğŸ”§ æ–°å¢ï¼šç½‘é¡µå†…å®¹è§£æ
        has_web_content = self._has_meaningful_web_content(result_content)
        
        # 5. ğŸ”§ æ–°å¢ï¼šæ–‡ä»¶æœç´¢ç»“æœè§£æ
        has_file_results = self._has_meaningful_file_results(result_content)
        
        # 6. ğŸ”§ æ–°å¢ï¼šè®¡ç®—ç»“æœè§£æ
        has_calculation_results = self._has_calculation_results(result_content)
        
        return (has_data or has_numerical or has_technical_content or 
                has_structured_data or has_web_content or has_file_results or 
                has_calculation_results)
    
    def _has_structured_json_data(self, content: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰æ„ä¹‰çš„JSONç»“æ„æ•°æ®"""
        import json
        import re
        
        # å°è¯•æå–JSONå¯¹è±¡
        json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
        json_matches = re.findall(json_pattern, content, re.DOTALL)
        
        for json_str in json_matches:
            try:
                data = json.loads(json_str)
                if isinstance(data, dict) and len(data) > 0:
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰æ„ä¹‰çš„é”®å€¼å¯¹
                    meaningful_keys = ['result', 'data', 'response', 'output', 'value', 'content']
                    if any(key in data for key in meaningful_keys):
                        return True
            except json.JSONDecodeError:
                continue
        
        return False
    
    def _has_meaningful_web_content(self, content: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰æ„ä¹‰çš„ç½‘é¡µå†…å®¹"""
        import re
        
        # æ£€æŸ¥URLæ¨¡å¼
        url_pattern = r'https?://[^\s<>"\']+|www\.[^\s<>"\']+\.[^\s<>"\']+' 
        has_urls = re.search(url_pattern, content)
        
        # æ£€æŸ¥HTMLæ ‡ç­¾
        html_pattern = r'<[^>]+>'
        has_html = re.search(html_pattern, content)
        
        # æ£€æŸ¥ç½‘é¡µç‰¹æœ‰å†…å®¹
        web_indicators = ['page title', 'page content', 'browser', 'navigation', 'click', 'scroll']
        has_web_terms = any(indicator in content.lower() for indicator in web_indicators)
        
        return has_urls or has_html or has_web_terms
    
    def _has_meaningful_file_results(self, content: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰æ„ä¹‰çš„æ–‡ä»¶æœç´¢ç»“æœ"""
        import re
        
        # æ–‡ä»¶è·¯å¾„æ¨¡å¼
        file_pattern = r'[^\s<>"\']+\.[a-zA-Z0-9]+'
        has_files = re.search(file_pattern, content)
        
        # æ–‡ä»¶æ“ä½œæŒ‡ç¤ºè¯
        file_indicators = ['file', 'directory', 'folder', 'path', 'æ–‡ä»¶', 'ç›®å½•', 'è·¯å¾„']
        has_file_terms = any(indicator in content.lower() for indicator in file_indicators)
        
        # æœç´¢ç»“æœæ•°é‡
        count_pattern = r'found\s+(\d+)|(\d+)\s+results|(\d+)\s+files'
        has_counts = re.search(count_pattern, content.lower())
        
        return has_files or (has_file_terms and has_counts)
    
    def _has_calculation_results(self, content: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«è®¡ç®—ç»“æœ"""
        import re
        
        # æ•°å­¦è¡¨è¾¾å¼å’Œç»“æœ
        math_pattern = r'=\s*[-+]?\d*\.?\d+|result:\s*[-+]?\d*\.?\d+|answer:\s*[-+]?\d*\.?\d+'
        has_math = re.search(math_pattern, content.lower())
        
        # è®¡ç®—ç›¸å…³æœ¯è¯­
        calc_indicators = ['calculation', 'computed', 'evaluated', 'è®¡ç®—', 'ç»“æœ', 'output']
        has_calc_terms = any(indicator in content.lower() for indicator in calc_indicators)
        
        # å¤æ‚æ•°å€¼ï¼ˆç§‘å­¦è®¡æ•°æ³•ã€å°æ•°ç­‰ï¼‰
        complex_num_pattern = r'[-+]?\d*\.?\d+[eE][-+]?\d+|[-+]?\d+\.\d{2,}'
        has_complex_nums = re.search(complex_num_pattern, content)
        
        return has_math or (has_calc_terms and has_complex_nums)
    
    def _evaluate_multi_tool_coordination_quality(self, trajectory_str: str) -> Dict[str, Any]:
        """ğŸ”§ Priority 4 æ–°å¢ï¼šè¯„ä¼°å¤šå·¥å…·ååŒçš„è´¨é‡å’Œæ•ˆæœ"""
        import re
        
        # ç»Ÿè®¡ä½¿ç”¨çš„å·¥å…·ç±»å‹
        used_tools = set()
        result_tag = TaskExecutionConstants.XML_TAGS['RESULT']
        result_pattern = f'<{result_tag}>(.*?)</{result_tag}>'
        result_blocks = re.findall(result_pattern, trajectory_str, re.DOTALL)
        
        # è¯†åˆ«ä½¿ç”¨çš„å·¥å…·æœåŠ¡
        tool_services = ['microsandbox', 'deepsearch', 'browser_use', 'search_tool']
        for service in tool_services:
            if service in trajectory_str.lower():
                used_tools.add(service)
        
        tools_count = len(used_tools)
        is_multi_tool = tools_count >= TaskExecutionConstants.MULTI_TOOL_COORDINATION['RESULT_INTEGRATION']['min_meaningful_tools']
        
        # è¯„ä¼°å·¥å…·ååŒè´¨é‡
        quality_score = 0.0
        coordination_indicators = []
        
        if is_multi_tool:
            # æ£€æŸ¥å·¥å…·é—´çš„æ•°æ®æµè½¬
            data_flow_quality = self._assess_tool_data_flow(trajectory_str, used_tools)
            quality_score += data_flow_quality * 0.4
            coordination_indicators.append(f"æ•°æ®æµè½¬è´¨é‡: {data_flow_quality:.2f}")
            
            # æ£€æŸ¥ç»“æœæ•´åˆè´¨é‡
            integration_quality = self._assess_result_integration(result_blocks)
            quality_score += integration_quality * 0.3
            coordination_indicators.append(f"ç»“æœæ•´åˆè´¨é‡: {integration_quality:.2f}")
            
            # æ£€æŸ¥ä»»åŠ¡å®Œæˆåº¦
            completion_quality = self._assess_task_completion_via_coordination(trajectory_str)
            quality_score += completion_quality * 0.3
            coordination_indicators.append(f"ä»»åŠ¡å®Œæˆåº¦: {completion_quality:.2f}")
        
        return {
            'is_coordinated': is_multi_tool,
            'tools_used': list(used_tools),
            'tools_count': tools_count,
            'quality_score': quality_score,
            'coordination_indicators': coordination_indicators
        }
    
    def _assess_tool_data_flow(self, trajectory_str: str, used_tools: set) -> float:
        """è¯„ä¼°å·¥å…·é—´çš„æ•°æ®æµè½¬è´¨é‡"""
        # æ£€æŸ¥å‰ä¸€ä¸ªå·¥å…·çš„è¾“å‡ºæ˜¯å¦è¢«åç»­å·¥å…·ä½¿ç”¨
        data_flow_score = 0.0
        
        # ç®€åŒ–ç‰ˆï¼šæ£€æŸ¥æ˜¯å¦æœ‰æ˜æ˜¾çš„æ•°æ®ä¼ é€’æ¨¡å¼
        if 'microsandbox' in used_tools and 'deepsearch' in used_tools:
            # æœç´¢ååˆ†ææ¨¡å¼
            if 'search' in trajectory_str.lower() and 'code' in trajectory_str.lower():
                data_flow_score += 0.5
        
        if 'browser_use' in used_tools and 'search_tool' in used_tools:
            # æµè§ˆåæœç´¢æ¨¡å¼
            if 'browse' in trajectory_str.lower() and 'file' in trajectory_str.lower():
                data_flow_score += 0.5
        
        return min(1.0, data_flow_score)
    
    def _assess_result_integration(self, result_blocks: list) -> float:
        """è¯„ä¼°ç»“æœæ•´åˆè´¨é‡"""
        if len(result_blocks) < 2:
            return 0.0
        
        # æ£€æŸ¥ç»“æœé—´çš„å…³è”æ€§
        integration_score = 0.0
        
        # ç®€åŒ–ç‰ˆï¼šæ£€æŸ¥ç»“æœæ˜¯å¦åŒ…å«ç›¸äº’å¼•ç”¨æˆ–è¡¥å……ä¿¡æ¯
        combined_results = ' '.join(result_blocks).lower()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®å¼•ç”¨
        if any(indicator in combined_results for indicator in ['based on', 'according to', 'using the', 'åŸºäº', 'æ ¹æ®']):
            integration_score += 0.4
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç»¼åˆåˆ†æ
        if any(indicator in combined_results for indicator in ['combined', 'integrated', 'overall', 'ç»¼åˆ', 'æ•´åˆ']):
            integration_score += 0.3
        
        # æ£€æŸ¥ç»“æœçš„äº’è¡¥æ€§
        if len(set(result_blocks)) == len(result_blocks):  # æ— é‡å¤ç»“æœ
            integration_score += 0.3
        
        return min(1.0, integration_score)
    
    def _assess_task_completion_via_coordination(self, trajectory_str: str) -> float:
        """è¯„ä¼°é€šè¿‡å·¥å…·ååŒå®Œæˆä»»åŠ¡çš„ç¨‹åº¦"""
        completion_score = 0.0
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ˜ç¡®çš„ä»»åŠ¡å®ŒæˆæŒ‡ç¤º
        completion_indicators = [
            'task completed', 'finished', 'done', 'result', 'conclusion',
            'ä»»åŠ¡å®Œæˆ', 'å®Œæˆ', 'ç»“æœ', 'ç»“è®º', 'ç­”æ¡ˆ'
        ]
        
        trajectory_lower = trajectory_str.lower()
        for indicator in completion_indicators:
            if indicator in trajectory_lower:
                completion_score += 0.2
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°å€¼æˆ–å…·ä½“ç»“æœ
        import re
        if re.search(r'\d+\.?\d*', trajectory_str):
            completion_score += 0.3
        
        return min(1.0, completion_score)
        
    def _detect_success(self, response: str) -> bool:
        """æ£€æµ‹XMLå“åº”æ˜¯å¦æˆåŠŸ - ä¿ç•™å‘åå…¼å®¹æ€§"""
        response_lower = response.lower()
        return ('<answer>' in response_lower) and ('error>' not in response_lower)
    
    def _get_trajectory_file_path(self, task_id: str, is_raw: bool = False) -> str:
        """æ ¹æ®å­˜å‚¨æ¨¡å¼è·å–è½¨è¿¹æ–‡ä»¶è·¯å¾„"""
        out_dir = get_trajectories_dir()
        date_str = datetime.now().strftime("%Y-%m-%d")
        group_dir = os.path.join(out_dir, "grouped", date_str)
        if is_raw:
            return os.path.join(group_dir, f"raw_trajectories_{date_str}.jsonl")
        else:
            return os.path.join(group_dir, f"trajectories_{date_str}.jsonl")
    
    async def _save_xml_output(self, xml_output):
        """ä¿å­˜XMLè¾“å‡ºæ•°æ®åˆ°JSONLæ–‡ä»¶"""
        file_path = self._get_trajectory_file_path(xml_output['task_id'])
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        
        with open(file_path, 'a', encoding='utf-8') as f:
            f.write(json.dumps(xml_output, ensure_ascii=False) + '\n')
        
        logger.info(f"ä¿å­˜XMLæ•°æ®åˆ°: {file_path}")
    
    def _detect_triggered_stop_sequence(self, response_text: str, stop_sequences: list) -> str:
        """æ£€æµ‹è§¦å‘çš„åœæ­¢åºåˆ—"""
        for stop_seq in stop_sequences:
            if stop_seq in response_text:
                return stop_seq
        return "unknown"
    
    async def _execute_tool_with_logging(self, action: dict, execution_index: int) -> dict:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨å¹¶è®°å½•è¯¦ç»†æ—¥å¿—"""
        tool_start_time = time.time()
        
        # æ„å»ºtoolscoreè¯·æ±‚
        service_name = action.get('service')
        tool_name = action.get('tool')
        tool_input = action.get('input')
        
        param_mapping = {
            "browser_use": "query",
            "microsandbox": "code",
            "deepsearch": "question"
        }
        param_name = param_mapping.get(service_name, "input")
        
        toolscore_request = {
            "endpoint": f"http://127.0.0.1:{self._get_service_port(service_name)}/execute_tool",
            "method": "POST",
            "payload": {
                "tool_id": service_name,
                "action": tool_name,
                "parameters": {param_name: tool_input}
            }
        }
        
        # ğŸ”§ æ™ºèƒ½å·¥å…·æ‰§è¡Œä¸é”™è¯¯åˆ†æ
        try:
            raw_result = await self.toolscore_client.execute_tool(
                tool_id=service_name,
                action=tool_name,
                parameters={param_name: tool_input}
            )
            
            formatted_result = self._format_tool_output(service_name, tool_name, raw_result)
            execution_status = "success"
            error_details = None
            
        except Exception as e:
            error_str = str(e)
            error_type = self._analyze_error_type(error_str)
            
            raw_result = {"error": error_str, "success": False, "error_type": error_type}
            formatted_result = self._format_error_with_recovery_suggestion(error_str, error_type, service_name, tool_name)
            execution_status = "failure"
            error_details = error_str
        
        tool_end_time = time.time()
        
        # ğŸ” è®°å½•å·¥å…·æ‰§è¡Œæ—¥å¿—
        self.step_logger.log_tool_execution(
            execution_index=execution_index,
            action=action,
            toolscore_request=toolscore_request,
            raw_response=raw_result,
            formatted_result=formatted_result,
            start_time=tool_start_time,
            end_time=tool_end_time,
            execution_status=execution_status,
            error_details=error_details
        )
        
        return {
            "formatted_result": formatted_result,
            "raw_result": raw_result,
            "execution_status": execution_status
        }
    
    async def _execute_parallel_with_logging(self, actions: list) -> list:
        """å¹¶å‘æ‰§è¡Œå¤šä¸ªå·¥å…·è°ƒç”¨å¹¶è®°å½•æ—¥å¿—"""
        import asyncio
        
        if not actions:
            return []
        
        # åˆ›å»ºå¹¶å‘ä»»åŠ¡
        tasks = [
            self._execute_tool_with_logging(action, i) 
            for i, action in enumerate(actions)
        ]
        
        # å¹¶å‘æ‰§è¡Œ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # æå–æ ¼å¼åŒ–ç»“æœ
        formatted_results = []
        for result in results:
            if isinstance(result, Exception):
                formatted_results.append(f"Error: {result}")
            else:
                formatted_results.append(result["formatted_result"])
        
        return formatted_results
    
    def _get_service_port(self, service_name: str) -> int:
        """è·å–æœåŠ¡ç«¯å£å·"""
        port_mapping = {
            "microsandbox": 8090,
            "deepsearch": 8086,
            "browser_use": 8082,
            "search_tool": 8080
        }
        return port_mapping.get(service_name, 8080)

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        logger.info("ğŸ§¹ æ¸…ç†Enhanced Reasoning Runtimeèµ„æº")
        if self.toolscore_client and hasattr(self.toolscore_client, 'close'):
            await self.toolscore_client.close()
        self.is_initialized = False
        logger.info("âœ… èµ„æºæ¸…ç†å®Œæˆ")
    
