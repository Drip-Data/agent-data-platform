"""
å¢å¼ºæ¨ç†è¿è¡Œæ—¶ - ç®€åŒ–ç‰ˆæœ¬ï¼Œä¸“æ³¨LLMæ¨ç†å’Œæ‰§è¡Œ
ä½¿ç”¨ToolScore APIè¿›è¡Œå·¥å…·ç®¡ç†ï¼Œç§»é™¤å¤æ‚çš„æœ¬åœ°å·¥å…·ç®¡ç†é€»è¾‘
"""

import asyncio
import json
import logging
import os
import time
import uuid
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime
from core.interfaces import RuntimeInterface, TaskSpec, TrajectoryResult, ExecutionStep, ErrorType, ActionType
from core.llm_client import LLMClient
from core.metrics import EnhancedMetrics
from core.toolscore.mcp_client import MCPToolClient
from core.utils.path_utils import get_trajectories_dir
from runtimes.reasoning.toolscore_client import ToolScoreClient
from runtimes.reasoning.real_time_tool_client import RealTimeToolClient
from core.local_python_executor import LocalPythonExecutor
from core.tool_usage_tracker import ToolUsageTracker
from core.memory_manager import MemoryManager
from core.step_planner import StepPlanner
from core.trajectory_enhancer import TrajectoryEnhancer
from core.tool_schema_manager import get_tool_schema_manager, init_tool_schema_manager

# ğŸ†• æ–°å¢ï¼šGuardrailså’ŒValidationCriticé›†æˆ
from core.llm.guardrails_middleware import GuardrailsLLMMiddleware, GuardrailsValidationResult
from core.agents.validation_critic import ValidationCritic, ErrorEvent, ErrorSeverity, ErrorCategory

# ğŸ†• æ–°å¢ï¼šå‚æ•°æ ¡éªŒå™¨
from core.toolscore.parameter_validator import get_parameter_validator, ValidationResult

logger = logging.getLogger(__name__)

class EnhancedReasoningRuntime(RuntimeInterface):
    """å¢å¼ºæ¨ç†è¿è¡Œæ—¶ - ç®€åŒ–ç‰ˆæœ¬ï¼Œä¸“æ³¨LLMæ¨ç†å’Œæ‰§è¡Œ"""
    def __init__(self, config_manager, llm_client, toolscore_client, redis_manager=None, toolscore_websocket_endpoint: Optional[str] = None):
        self._runtime_id = f"enhanced-reasoning-{uuid.uuid4()}"
        self.config_manager = config_manager
        self.client = llm_client
        self.toolscore_client = toolscore_client
        self.metrics = EnhancedMetrics(port=8003)
        
        # åˆå§‹åŒ–è®°å¿†ç®¡ç†å™¨å’Œæ­¥éª¤è§„åˆ’å™¨
        self.memory_manager = MemoryManager(redis_manager=redis_manager)
        self.step_planner = StepPlanner(llm_client=llm_client, memory_manager=self.memory_manager)
        
        # ğŸ” åˆå§‹åŒ–è½¨è¿¹å¢å¼ºå™¨
        self.trajectory_enhancer = TrajectoryEnhancer()
        
        # ä½¿ç”¨é…ç½®ç®¡ç†å™¨è·å–æœåŠ¡ç«¯ç‚¹
        try:
            ports_config = self.config_manager.get_ports_config()
            toolscore_http_port = ports_config['mcp_servers']['toolscore_http']['port']
            toolscore_mcp_port = ports_config['mcp_servers']['toolscore_mcp']['port']
            logger.info(f"DEBUG: Loaded toolscore_http_port: {toolscore_http_port}, toolscore_mcp_port: {toolscore_mcp_port}")
            
            self.toolscore_endpoint = os.getenv('TOOLSCORE_HTTP_URL', f'http://localhost:{toolscore_http_port}')
            # ä½¿ç”¨ toolscore_mcp_port (ä¾‹å¦‚8000) è€Œä¸æ˜¯ toolscore_http_port (8091)
            self.toolscore_websocket_endpoint = toolscore_websocket_endpoint or os.getenv('TOOLSCORE_WS_URL', f'ws://localhost:{toolscore_mcp_port}')
            logger.info(f"DEBUG: Configured toolscore_websocket_endpoint (using mcp_port): {self.toolscore_websocket_endpoint}")
        except Exception as e:
            logger.warning(f"é…ç½®åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç«¯å£: {e}")
            self.toolscore_endpoint = os.getenv('TOOLSCORE_HTTP_URL', 'http://localhost:8091')
            # å¦‚æœé…ç½®åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç«¯å£
            self.toolscore_websocket_endpoint = toolscore_websocket_endpoint or os.getenv('TOOLSCORE_WS_URL', 'ws://localhost:8000')
        
        # è½»é‡çº§å®¢æˆ·ç«¯
        self.real_time_client = RealTimeToolClient(self.toolscore_websocket_endpoint)
        
        # ä¿ç•™MCPå®¢æˆ·ç«¯ç”¨äºç›´æ¥å·¥å…·è°ƒç”¨
        toolscore_url = os.getenv('TOOLSCORE_URL', f'ws://localhost:{toolscore_mcp_port}/websocket')
        self.mcp_client = MCPToolClient(toolscore_url)
        
        # ç­‰å¾…å·¥å…·å®‰è£…çš„ä»»åŠ¡
        self.pending_tool_requests = {}
        # ğŸ“Œ ç¼“å­˜å®æ—¶å·¥å…·äº‹ä»¶ï¼Œä¾¿äºå†™å…¥è½¨è¿¹
        self._tool_event_buffer = []
        
        # ğŸ“ˆ å¤±è´¥å†å²è®°å½•ï¼Œç”¨äºé¿å…é‡å¤å¤±è´¥çš„æ“ä½œ
        self.failure_history = {
            'tool_installations': set(),  # è®°å½•å¤±è´¥çš„å·¥å…·å®‰è£…
            'tool_calls': {},  # è®°å½•å¤±è´¥çš„å·¥å…·è°ƒç”¨
            'search_queries': set()  # è®°å½•å¤±è´¥çš„æœç´¢æŸ¥è¯¢
        }
        
        # ğŸ›¡ï¸ æ–°å¢ï¼šGuardrails LLMä¸­é—´ä»¶
        self.guardrails_middleware = GuardrailsLLMMiddleware()
        
        # ğŸ¯ æ–°å¢ï¼šValidationCriticæ™ºèƒ½é”™è¯¯åˆ†æä»£ç†
        self.validation_critic = ValidationCritic(llm_client, [])
        
        # ğŸ” è¿ç»­å¤±è´¥è®¡æ•°å™¨å’Œé˜ˆå€¼
        self.consecutive_failures = 0
        self.max_consecutive_failures = 3
        self.error_events_buffer = []
        
        # ğŸ”§ å·¥å…·Schemaç®¡ç†å™¨
        self.tool_schema_manager = get_tool_schema_manager()
        
    async def initialize(self):
        """åˆå§‹åŒ–è¿è¡Œæ—¶ - ç®€åŒ–ä¸ºçº¯å·¥å…·æ¶ˆè´¹è€…"""
        logger.info("ğŸš€ åˆå§‹åŒ–Enhanced Reasoning Runtime - ç®€åŒ–ç‰ˆæœ¬")
        
        # ğŸ”’ P0-2ä¿®å¤ï¼šå°†tool_schema_manageræ³¨å…¥åˆ°response_parserä¸­
        if hasattr(self.client, 'reasoning_response_parser'):
            self.client.reasoning_response_parser.set_tool_schema_manager(self.tool_schema_manager)
            logger.info("âœ… å·¥å…·Schemaç®¡ç†å™¨å·²æ³¨å…¥åˆ°å“åº”è§£æå™¨")
        
        # ç­‰å¾…ToolScoreæœåŠ¡å°±ç»ª
        logger.info("â³ ç­‰å¾…ToolScoreæœåŠ¡å°±ç»ª...")
        toolscore_ready = await self.toolscore_client.wait_for_ready()
        if not toolscore_ready:
            logger.error("âŒ ToolScoreæœåŠ¡æœªå°±ç»ªï¼Œå°†ä½¿ç”¨é™çº§æ¨¡å¼")
        else:
            logger.info("âœ… ToolScore HTTPæœåŠ¡å·²å°±ç»ª")
        
        # è¿æ¥å®æ—¶æ›´æ–°
        logger.info(f"ğŸ”Œ æ­£åœ¨è¿æ¥WebSocketç«¯ç‚¹: {self.toolscore_websocket_endpoint}")
        try:
            await self.real_time_client.connect_real_time_updates()
            logger.info("âœ… WebSocketå®æ—¶æ›´æ–°è¿æ¥æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ WebSocketè¿æ¥å¤±è´¥ï¼Œå°†ç»§ç»­è¿è¡Œä½†ä¸ä¼šæ¥æ”¶å®æ—¶æ›´æ–°: {e}")
            # ä¸é˜»æ­¢åˆå§‹åŒ–ç»§ç»­è¿›è¡Œ
        
        # æ³¨å†Œå·¥å…·æ›´æ–°å›è°ƒ
        await self.real_time_client.register_tool_update_callback(
            self._on_new_tool_available
        )
        
        # ğŸ” ç­‰å¾…å…³é”®å·¥å…·å®Œå…¨å°±ç»ª
        logger.info("â³ ç­‰å¾…å…³é”®å·¥å…·å®Œå…¨å°±ç»ª...")
        tools_ready = await self._wait_for_essential_tools(timeout=30)
        if not tools_ready:
            logger.warning("âš ï¸ éƒ¨åˆ†å…³é”®å·¥å…·æœªå°±ç»ªï¼Œå°†åœ¨é™çº§æ¨¡å¼ä¸‹è¿è¡Œ")
        else:
            logger.info("âœ… æ‰€æœ‰å…³é”®å·¥å…·å·²å°±ç»ª")
        
        # ğŸ”§ P1ä¿®å¤1: æ‰§è¡ŒMCPæœåŠ¡å™¨åŒæ­¥éªŒè¯
        logger.info("ğŸ” å¼€å§‹MCPæœåŠ¡å™¨åŒæ­¥éªŒè¯...")
        try:
            validation_report = await self.tool_schema_manager.validate_mcp_sync()
            if validation_report['overall_health'] == 'healthy':
                logger.info("âœ… MCPæœåŠ¡å™¨åŒæ­¥éªŒè¯é€šè¿‡")
            elif validation_report['overall_health'] == 'degraded':
                logger.warning(f"âš ï¸ MCPæœåŠ¡å™¨éƒ¨åˆ†ä¸ä¸€è‡´: {validation_report['summary']}")
                # å°è¯•è‡ªåŠ¨ä¿®å¤
                fix_results = await self.tool_schema_manager.auto_fix_schema_inconsistencies(validation_report)
                logger.info(f"ğŸ”§ è‡ªåŠ¨ä¿®å¤ç»“æœ: {len(fix_results['successful_fixes'])} æˆåŠŸ, {len(fix_results['failed_fixes'])} å¤±è´¥")
            else:
                logger.error(f"âŒ MCPæœåŠ¡å™¨åŒæ­¥éªŒè¯å¤±è´¥: {validation_report.get('error', 'æœªçŸ¥é”™è¯¯')}")
        except Exception as e:
            logger.error(f"âŒ MCPåŒæ­¥éªŒè¯å¼‚å¸¸: {e}")
        
        # å¯åŠ¨å®šæœŸæ¸…ç†ä»»åŠ¡
        asyncio.create_task(self._periodic_cleanup())
        
        # ğŸ”§ P1ä¿®å¤1: å¯åŠ¨å®šæœŸåŒæ­¥éªŒè¯ä»»åŠ¡
        asyncio.create_task(self._periodic_sync_validation())
        
        # ğŸ›¡ï¸ åˆå§‹åŒ–Guardrailsä¸­é—´ä»¶å’Œå·¥å…·Schemaç®¡ç†å™¨
        try:
            logger.debug("ğŸ”§ å¼€å§‹è·å–å¯ç”¨å·¥å…·IDåˆ—è¡¨...")
            available_tools = await self.real_time_client.get_available_tool_ids()
            logger.debug(f"ğŸ“‹ è·å–åˆ°çš„å·¥å…·åˆ—è¡¨: {available_tools}")
            
            # ğŸ”§ åˆå§‹åŒ–å·¥å…·Schemaç®¡ç†å™¨ï¼ˆä¼ å…¥å®¢æˆ·ç«¯å®ä¾‹ï¼‰
            from core.tool_schema_manager import init_tool_schema_manager
            self.tool_schema_manager = init_tool_schema_manager(
                redis_client=None,  # å¦‚æœæœ‰redis_managerå¯ä»¥ä¼ å…¥
                toolscore_client=self.toolscore_client
            )
            logger.info("âœ… å·¥å…·Schemaç®¡ç†å™¨å·²åˆå§‹åŒ–")
            
            if available_tools:
                logger.debug("ğŸ”§ æ›´æ–°Guardrailså’ŒValidationCriticå·¥å…·é…ç½®...")
                self.guardrails_middleware.update_available_tools(available_tools)
                self.validation_critic.update_available_tools(available_tools)
                logger.info(f"âœ… Guardrailså’ŒValidationCriticå·²é…ç½®{len(available_tools)}ä¸ªå·¥å…·: {', '.join(available_tools)}")
            else:
                logger.warning("âš ï¸ æœªè·å–åˆ°å¯ç”¨å·¥å…·åˆ—è¡¨ï¼ŒGuardrailså°†ä½¿ç”¨é»˜è®¤é…ç½®")
        except Exception as e:
            logger.error(f"âŒ Guardrailsåˆå§‹åŒ–å¤±è´¥: {e}")
            logger.debug(f"é”™è¯¯è¯¦æƒ…: {type(e).__name__}: {str(e)}")
            import traceback
            logger.debug(f"å®Œæ•´è¿½è¸ª: {traceback.format_exc()}")
        
        logger.info("âœ… Enhanced Reasoning Runtime å·²æˆåŠŸåˆå§‹åŒ–ä¸ºçº¯æ¨ç†å¼•æ“ï¼ˆé›†æˆGuardrails + ValidationCriticï¼‰")
        
    async def _on_new_tool_available(self, tool_event: Dict[str, Any]):
        """æ–°å·¥å…·å¯ç”¨æ—¶çš„å›è°ƒ"""
        tool_id = tool_event.get("tool_id")
        tool_name = tool_event.get("name", tool_id)
        
        logger.info(f"ğŸ‰ æ£€æµ‹åˆ°æ–°å·¥å…·: {tool_name} ({tool_id})")
        
        # å†™å…¥äº‹ä»¶ç¼“å†²åŒºï¼Œä¾›å½“å‰æ‰§è¡Œä¸­çš„ä»»åŠ¡è®°å½•
        self._tool_event_buffer.append({
            "tool_id": tool_id,
            "name": tool_name,
            "event": tool_event,
            "timestamp": time.time()
        })
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç­‰å¾…è¿™ä¸ªå·¥å…·çš„ä»»åŠ¡
        completed_requests = []
        for task_id, request_info in list(self.pending_tool_requests.items()):
            if self._tool_matches_requirement(tool_event, request_info.get("required_capabilities", [])):
                logger.info(f"ğŸš€ æ¢å¤ç­‰å¾…ä»»åŠ¡: {task_id} (æ–°å·¥å…·: {tool_id})")
                
                # æ‰§è¡Œæ¢å¤å›è°ƒ
                callback = request_info.get("resume_callback")
                if callback:
                    try:
                        await callback(tool_event)
                    except Exception as e:
                        logger.error(f"ä»»åŠ¡æ¢å¤å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")
                
                completed_requests.append(task_id)
        
        # æ¸…ç†å·²å®Œæˆçš„è¯·æ±‚
        for task_id in completed_requests:
            self.pending_tool_requests.pop(task_id, None)
    
    def _tool_matches_requirement(self, tool_event: Dict[str, Any], 
                                required_capabilities: List[str]) -> bool:
        """æ£€æŸ¥å·¥å…·æ˜¯å¦æ»¡è¶³éœ€æ±‚"""
        if not required_capabilities:
            return True
        
        tool_capabilities = tool_event.get("capabilities", [])
        tool_capability_names = []
        
        # æå–èƒ½åŠ›åç§°
        for cap in tool_capabilities:
            if isinstance(cap, dict):
                tool_capability_names.append(cap.get("name", ""))
            elif isinstance(cap, str):
                tool_capability_names.append(cap)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…çš„èƒ½åŠ›
        for required_cap in required_capabilities:
            for tool_cap in tool_capability_names:
                if required_cap.lower() in tool_cap.lower() or tool_cap.lower() in required_cap.lower():
                    return True
        
        return False
    
    async def _wait_for_essential_tools(self, timeout: int = 30) -> bool:
        """ç­‰å¾…å…³é”®å·¥å…·å®Œå…¨å°±ç»ª"""
        essential_tools = [
            'deepsearch',
            'microsandbox', 
            'browser_use',
            'mcp-search-tool'
        ]
        
        start_time = time.time()
        check_interval = 1  # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡
        
        while time.time() - start_time < timeout:
            try:
                # è·å–å½“å‰å¯ç”¨å·¥å…·
                available_tools = await self.toolscore_client.get_available_tools()
                if not available_tools:
                    logger.debug("ğŸ” ToolScoreæœåŠ¡è¿”å›ç©ºå·¥å…·åˆ—è¡¨ï¼Œç»§ç»­ç­‰å¾…...")
                    await asyncio.sleep(check_interval)
                    continue
                
                # æ£€æŸ¥å¿…éœ€å·¥å…·æ˜¯å¦éƒ½å·²å°±ç»ª
                available_tool_ids = [tool.get('id', '') for tool in available_tools if isinstance(tool, dict)]
                available_tool_ids.extend([tool_id for tool_id in available_tools if isinstance(tool_id, str)])
                
                missing_tools = [tool for tool in essential_tools if tool not in available_tool_ids]
                
                if not missing_tools:
                    logger.info(f"âœ… æ‰€æœ‰å…³é”®å·¥å…·å·²å°±ç»ª: {essential_tools}")
                    
                    # é¢å¤–éªŒè¯ï¼šç¡®ä¿å·¥å…·ç¡®å®å¯ä»¥å“åº”
                    await self._verify_tools_connectivity(essential_tools)
                    
                    return True
                else:
                    logger.debug(f"â³ ç­‰å¾…å·¥å…·å°±ç»ª... ç¼ºå°‘: {missing_tools}")
                
                await asyncio.sleep(check_interval)
                
            except Exception as e:
                logger.debug(f"âš ï¸ æ£€æŸ¥å·¥å…·çŠ¶æ€æ—¶å‡ºé”™: {e}")
                await asyncio.sleep(check_interval)
        
        logger.warning(f"âš ï¸ è¶…æ—¶ç­‰å¾…å…³é”®å·¥å…·å°±ç»ª ({timeout}ç§’)")
        return False
    
    async def _verify_tools_connectivity(self, tool_ids: List[str]):
        """éªŒè¯å·¥å…·è¿é€šæ€§"""
        for tool_id in tool_ids:
            try:
                # å‘é€è½»é‡çº§æµ‹è¯•è¯·æ±‚éªŒè¯è¿é€šæ€§
                if tool_id == 'deepsearch':
                    # æµ‹è¯•DeepSearchè¿é€šæ€§
                    test_params = {"question": "test connectivity", "max_results": 1}
                    # è¿™é‡Œä¸å®é™…è°ƒç”¨ï¼Œåªæ˜¯æ£€æŸ¥å·¥å…·æ˜¯å¦åœ¨æ³¨å†Œè¡¨ä¸­
                    pass
                elif tool_id == 'microsandbox':
                    # æµ‹è¯•MicroSandboxè¿é€šæ€§
                    pass
                elif tool_id == 'browser_use':
                    # æµ‹è¯•Browserè¿é€šæ€§
                    pass
                elif tool_id == 'mcp-search-tool':
                    # æµ‹è¯•Search Toolè¿é€šæ€§
                    pass
                
                logger.debug(f"âœ… å·¥å…·è¿é€šæ€§éªŒè¯é€šè¿‡: {tool_id}")
                
            except Exception as e:
                logger.warning(f"âš ï¸ å·¥å…·è¿é€šæ€§éªŒè¯å¤±è´¥: {tool_id} - {e}")
            
    async def _periodic_cleanup(self):
        """å®šæœŸæ¸…ç†è¿‡æœŸè¯·æ±‚"""
        while True:
            try:
                await asyncio.sleep(60)  # æ¯åˆ†é’Ÿæ¸…ç†ä¸€æ¬¡
                await self.real_time_client.cleanup_expired_requests()

                # æ¸…ç†æœ¬åœ°çš„è¿‡æœŸè¯·æ±‚
                current_time = time.time()
                expired_requests = []
                for task_id, request_info in self.pending_tool_requests.items():
                    if current_time - request_info.get("timestamp", 0) > 300:  # 5åˆ†é’Ÿè¿‡æœŸ
                        expired_requests.append(task_id)

                for task_id in expired_requests:
                    self.pending_tool_requests.pop(task_id, None)
                    logger.info(f"æ¸…ç†è¿‡æœŸä»»åŠ¡è¯·æ±‚: {task_id}")
                
            except Exception as e:
                    logger.error(f"å®šæœŸæ¸…ç†ä»»åŠ¡å¼‚å¸¸: {e}")

    async def _periodic_sync_validation(self):
        """ğŸ”§ P1ä¿®å¤1: å®šæœŸMCPåŒæ­¥éªŒè¯"""
        while True:
            try:
                # æ¯5åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡åŒæ­¥éªŒè¯
                await asyncio.sleep(300)
                
                logger.debug("ğŸ” æ‰§è¡Œå®šæœŸMCPåŒæ­¥éªŒè¯...")
                validation_report = await self.tool_schema_manager.validate_mcp_sync()
                
                if validation_report['overall_health'] == 'unhealthy':
                    logger.warning(f"âš ï¸ MCPåŒæ­¥éªŒè¯å‘ç°é—®é¢˜: {validation_report['summary']}")
                    
                    # å°è¯•è‡ªåŠ¨ä¿®å¤
                    fix_results = await self.tool_schema_manager.auto_fix_schema_inconsistencies(validation_report)
                    if fix_results['successful_fixes']:
                        logger.info(f"âœ… è‡ªåŠ¨ä¿®å¤äº† {len(fix_results['successful_fixes'])} ä¸ªSchemaä¸ä¸€è‡´é—®é¢˜")
                    
                    # è®°å½•åˆ°åº¦é‡ç³»ç»Ÿ
                    if hasattr(self, 'metrics'):
                        self.metrics.record_mcp_sync_issues(validation_report, fix_results)
                
                elif validation_report['overall_health'] == 'healthy':
                    logger.debug("âœ… MCPåŒæ­¥éªŒè¯æ­£å¸¸")
                
            except Exception as e:
                logger.error(f"âŒ å®šæœŸåŒæ­¥éªŒè¯å¼‚å¸¸: {e}")

    @property
    def runtime_id(self) -> str:
        return self._runtime_id

    async def capabilities(self) -> list:
        """è·å–è¿è¡Œæ—¶èƒ½åŠ›"""
        return ['llm_reasoning', 'tool_execution', 'dynamic_tool_request']

    async def health_check(self) -> bool:
        """å¥åº·æ£€æŸ¥"""
        try:
            # æ£€æŸ¥LLMå®¢æˆ·ç«¯
            await self.client.generate_reasoning("health check", [], [])
            
            # æ£€æŸ¥ToolScoreè¿æ¥
            toolscore_healthy = await self.toolscore_client.health_check()
            
            return toolscore_healthy
        except:
            return False

    async def execute(self, task: TaskSpec) -> TrajectoryResult:
        """æ‰§è¡Œä»»åŠ¡"""
        logger.info(f"ğŸ§  å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task.description}")
        start_time = time.time()
        trajectory_id = task.task_id
        success = False
        final_trajectory_error_type = None
        final_trajectory_error_message = None
        
        # ğŸ”§ å­˜å‚¨å½“å‰ä»»åŠ¡æè¿°ç”¨äºå‚æ•°è¡¥é½
        self.current_task_description = task.description
        
        steps: List[ExecutionStep] = []
        max_steps = task.max_steps or 10  # ä½¿ç”¨åŠ¨æ€max_stepsï¼Œé»˜è®¤ä¸º10
        # ğŸ”„ Sprint 1: å¢å¼ºé‡è¯•ç­–ç•¥ (P1 é—®é¢˜ä¿®å¤)
        max_retries = 3  # å¢åŠ é‡è¯•æ¬¡æ•°
        base_retry_delay = 1  # åŸºç¡€å»¶è¿Ÿæ—¶é—´
        # é‡è¯•å†å²è·Ÿè¸ª
        retry_history = {}
        current_outputs = []  # ç”¨äºå­˜å‚¨æ¯æ­¥çš„è¾“å‡º
        
        # ğŸ” å¯åŠ¨è½¨è¿¹å¢å¼ºå’Œèµ„æºè¿½è¸ª
        tracking_info = self.trajectory_enhancer.start_task_tracking(trajectory_id)
        logger.info(f"ğŸ” è½¨è¿¹è¿½è¸ªå·²å¯åŠ¨: {tracking_info}")
        
        # ç”Ÿæˆä¼šè¯IDç”¨äºè®°å¿†ç®¡ç†
        session_id = f"session_{trajectory_id}_{int(start_time)}"
        
        logger.info(f"ğŸ“Š ä»»åŠ¡é…ç½®: max_steps={max_steps}, session_id={session_id}")
        
        # ğŸ” æ–°å¢ï¼šæ”¶é›†LLMäº¤äº’ä¿¡æ¯
        current_step_llm_interactions = []
        
        # ğŸ”§ æ–°å¢ï¼šå·¥å…·ä½¿ç”¨è·Ÿè¸ªå™¨
        tool_tracker = ToolUsageTracker()
        
        # ğŸ”§ è·å–åŠ¨æ€å·¥å…·æè¿°ï¼ˆæ›¿æ¢ç¡¬ç¼–ç æè¿°ï¼‰
        logger.info("ğŸ“‹ ä½¿ç”¨å·¥å…·Schemaç®¡ç†å™¨è·å–åŠ¨æ€å·¥å…·æè¿°...")
        try:
            # ä½¿ç”¨ToolSchemaManagerè·å–åŠ¨æ€å·¥å…·æè¿°
            available_tools_description = await self.tool_schema_manager.generate_llm_tools_description()
            logger.info(f"ğŸ“‹ è·å–åˆ°åŠ¨æ€å·¥å…·æè¿°é•¿åº¦: {len(available_tools_description)} å­—ç¬¦")
            logger.info(f"ğŸ“‹ åŠ¨æ€å·¥å…·æè¿°é¢„è§ˆ: {available_tools_description[:500]}...")
        except Exception as e:
            logger.warning(f"âš ï¸ åŠ¨æ€å·¥å…·æè¿°è·å–å¤±è´¥ï¼Œå›é€€åˆ°é™æ€æ–¹å¼: {e}")
            # å›é€€åˆ°åŸæœ‰æ–¹å¼
            available_tools_description = await self.real_time_client.get_fresh_tools_for_llm(
                fallback_client=self.toolscore_client
            )
            logger.info(f"ğŸ“‹ ä½¿ç”¨é™æ€æ–¹å¼è·å–å·¥å…·æè¿°é•¿åº¦: {len(available_tools_description)} å­—ç¬¦")
            logger.info(f"ğŸ“‹ é™æ€å·¥å…·æè¿°é¢„è§ˆ: {available_tools_description[:500]}...")
        
        # ğŸ”§ è®°å½•å¯ç”¨å·¥å…·ä¿¡æ¯
        tool_tracker.set_available_tools(available_tools_description)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨å·¥å…·
        if "æš‚æ— å¯ç”¨å·¥å…·" in available_tools_description or len(available_tools_description.strip()) == 0:
            logger.warning("âš ï¸ æ£€æµ‹åˆ°æš‚æ— å¯ç”¨å·¥å…·ï¼Œå¯èƒ½å­˜åœ¨å·¥å…·æ³¨å†Œé—®é¢˜")

        # === è®°å½•é¦–æ¬¡æš´éœ²ç»™ LLM çš„å·¥å…·é›†åˆ ===
        step_start_time = time.time()
        expose_step = ExecutionStep(
            step_id=1,  # å›ºå®šä¸ºç¬¬1æ­¥ï¼šå·¥å…·æš´éœ²
            action_type=ActionType.TOOL_CALL,
            action_params={"tools_snapshot": available_tools_description},
            observation="Tools exposed to LLM for planning",
            success=True,
            event_source="system",
            triggering_event="task_initialization"
        )
        step_end_time = time.time()
        expose_step.duration = step_end_time - step_start_time
        expose_step.resource_usage = self.trajectory_enhancer.calculate_step_resource_usage(step_start_time, step_end_time)
        
        # æ·»åŠ å­äº‹ä»¶
        # ä»å·¥å…·æè¿°ä¸­ä¼°ç®—å·¥å…·æ•°é‡
        tools_count = available_tools_description.count('- ') if available_tools_description else 0
        self.trajectory_enhancer.add_sub_event_to_step(
            expose_step, 
            "tools_exposed", 
            f"Exposed {tools_count} tools to LLM",
            {"tools_count": tools_count}
        )
        
        steps.append(expose_step)

        # æ™ºèƒ½ä»»åŠ¡éœ€æ±‚åˆ†æ
        logger.info("ğŸ§  å¼€å§‹æ™ºèƒ½ä»»åŠ¡éœ€æ±‚åˆ†æ...")
                
        # ğŸ” æ–°å¢ï¼šè®°å½•ä»»åŠ¡éœ€æ±‚åˆ†æçš„LLMäº¤äº’
        task_analysis_interactions = []
        original_call_api = self.client._call_api
        async def wrapped_call_api_for_analysis(messages) -> str:
            interaction_start = time.time()
            response = await original_call_api(messages)
            
            from core.interfaces import LLMInteraction
            interaction = LLMInteraction()
            interaction.provider = self.client.provider.value if hasattr(self.client.provider, 'value') else str(self.client.provider)
            interaction.model = getattr(self.client, 'model', 'unknown')
            interaction.context = "task_requirements_analysis"
            interaction.prompt = str(messages) if messages else ""
            interaction.prompt_length = len(str(messages))
            interaction.prompt_type = "task_analysis"
            interaction.response = response
            interaction.response_length = len(response)
            interaction.response_time = time.time() - interaction_start
            task_analysis_interactions.append(interaction)
            return response
        
        # ä¸´æ—¶æ›¿æ¢æ–¹æ³•è¿›è¡Œä»»åŠ¡åˆ†æ
        self.client._call_api = wrapped_call_api_for_analysis
        try:
            # === ä¸Šä¸‹æ–‡æ³¨å…¥ï¼šä¸ºä»»åŠ¡åˆ†ææ·»åŠ è®°å¿†ä¸Šä¸‹æ–‡ ===
            enhanced_task_description = task.description
            try:
                # è·å–è·¨ä¼šè¯æ´å¯Ÿç”¨äºä»»åŠ¡åˆ†æ
                cross_session_insights = await self.memory_manager.get_cross_session_insights(limit=2)
                if cross_session_insights:
                    insights_context = "å†å²ç»éªŒå‚è€ƒ: " + "; ".join(cross_session_insights)
                    enhanced_task_description = f"{task.description}\n\n{insights_context}"
                    logger.debug(f"ğŸ§  ä»»åŠ¡åˆ†æå·²å¢å¼ºå†å²æ´å¯Ÿä¸Šä¸‹æ–‡")
            except Exception as ctx_err:
                logger.warning(f"è·å–ä»»åŠ¡åˆ†æä¸Šä¸‹æ–‡å¤±è´¥: {ctx_err}")
            
            task_requirements = await self.client.analyze_task_requirements(enhanced_task_description)
        finally:
            self.client._call_api = original_call_api
        
        logger.info("âœ… ä»»åŠ¡éœ€æ±‚åˆ†æå®Œæˆ:")
        logger.info(f"   ä»»åŠ¡ç±»å‹: {task_requirements.get('task_type')}")
        logger.info(f"   æ‰€éœ€èƒ½åŠ›: {task_requirements.get('required_capabilities', [])}")
        logger.info(f"   æ¨èå·¥å…·ç±»å‹: {task_requirements.get('tools_needed', [])}")
        logger.info(f"   ç½®ä¿¡åº¦: {task_requirements.get('confidence')}")
        
        # ä¿å­˜ä»»åŠ¡åˆ†æçš„LLMäº¤äº’åˆ°ç¬¬ä¸€æ­¥çš„é¢„å¤‡é˜¶æ®µ
        current_step_llm_interactions.extend(task_analysis_interactions)

        """### è‡ªåŠ¨ç¼ºå£æ£€æµ‹ & ä¿®å¤ ###"""
        try:
            # æ‹‰å–å½“å‰å·²æ³¨å†Œå·¥å…·ï¼ˆåˆ—è¡¨å½¢å¼ï¼‰
            current_tools_meta = await self.toolscore_client.get_available_tools()

            gap_result = await self.toolscore_client.analyze_tool_gap(
                task_description=task.description,
                current_tools=current_tools_meta
            )

            if gap_result and not gap_result.get("has_sufficient_tools", True):
                missing_caps = gap_result.get("gap_analysis", {}).get("missing_capabilities", [])

                logger.info(
                    f"âš  æ£€æµ‹åˆ°èƒ½åŠ›ç¼ºå£ï¼Œç¼ºå°‘: {missing_caps or 'æœªçŸ¥'}. æ­£åœ¨è¯·æ±‚ ToolScore è‡ªåŠ¨å®‰è£…â€¦")

                cap_req_res = await self.toolscore_client.request_tool_capability(
                    task_description=task.description,
                    required_capabilities=missing_caps,
                    auto_install=True
                )

                if cap_req_res.get("success") and cap_req_res.get("installed_tools"):
                    logger.info(
                        f"ğŸ›  å·²è§¦å‘å®‰è£… {len(cap_req_res['installed_tools'])} ä¸ªå·¥å…·ï¼Œæ³¨å†Œç­‰å¾…äº‹ä»¶â€¦")

                    # é€šè¿‡ RealTimeToolClient ç­‰å¾…æ–°å·¥å…·ï¼›æ³¨å†Œå›è°ƒä½†åŒæ—¶è½®è¯¢ï¼Œæœ€å¤š 60s
                    await self.real_time_client.register_pending_request(
                        request_id=f"{task.task_id}-auto-gap-fix", 
                        required_capabilities=missing_caps
                    )

                    wait_start = time.time()
                    WAIT_TIMEOUT = 60
                    while time.time() - wait_start < WAIT_TIMEOUT:
                        # åˆ¤æ–­æ˜¯å¦å·²æ»¡è¶³èƒ½åŠ›
                        fresh_tools = await self.toolscore_client.get_available_tools()
                        fresh_caps_ok = False
                        # fresh_tools ç°åœ¨æ˜¯ä¸€ä¸ªå·¥å…·åç§°åˆ—è¡¨
                        for tool_id in fresh_tools:
                            # ç®€å•æ£€æŸ¥å·¥å…·åç§°æ˜¯å¦åŒ…å«æ‰€éœ€èƒ½åŠ›
                            if any(mc.lower() in tool_id.lower() for mc in missing_caps):
                                fresh_caps_ok = True
                                break
                        if fresh_caps_ok:
                            logger.info("âœ… ç¼ºå£å·¥å…·å·²å°±ä½ï¼Œç»§ç»­ä»»åŠ¡æ‰§è¡Œ")
                            break
                        await asyncio.sleep(2)
                else:
                    logger.warning("ToolScore æœªèƒ½è‡ªåŠ¨å®‰è£…æ‰€éœ€å·¥å…·ï¼Œåç»­å¯èƒ½ä¾èµ– LLM è‡ªè¡Œæ£€ç´¢ã€‚")
        except Exception as auto_gap_err:
            logger.error(f"è‡ªåŠ¨ç¼ºå£æ£€æµ‹/ä¿®å¤è¿‡ç¨‹å¼‚å¸¸: {auto_gap_err}")

        # === ç”Ÿæˆåˆå§‹æ‰§è¡Œè®¡åˆ’ ===
        try:
            logger.info("ğŸ§  ç”Ÿæˆå¤šæ­¥æ‰§è¡Œè®¡åˆ’...")
            available_tool_ids = await self.toolscore_client.get_available_tools()
            initial_plan = await self.step_planner.generate_initial_plan(
                task, available_tool_ids, session_id
            )
            logger.info(f"ğŸ“‹ ç”Ÿæˆæ‰§è¡Œè®¡åˆ’: {len(initial_plan.planned_steps)} æ­¥éª¤, ç½®ä¿¡åº¦: {initial_plan.confidence:.3f}")
            max_steps = min(max_steps, initial_plan.max_steps)  # ä½¿ç”¨è®¡åˆ’ä¸­çš„max_steps
        except Exception as plan_err:
            logger.error(f"ç”Ÿæˆæ‰§è¡Œè®¡åˆ’å¤±è´¥: {plan_err}, ä½¿ç”¨ä¼ ç»Ÿæ‰§è¡Œæ¨¡å¼")
            initial_plan = None

        # ğŸ›¡ï¸ åˆå§‹åŒ–å¾ªç¯æ£€æµ‹æœºåˆ¶
        from collections import defaultdict, deque
        loop_detection = {
            'repeated_actions': defaultdict(int),
            'repeated_errors': defaultdict(int), 
            'recent_tool_calls': deque(maxlen=10),
            'consecutive_failures': 0,
            'start_time': time.time(),
            'last_progress_time': time.time(),
            'max_consecutive_failures': 3,
            'max_repeated_actions': 5,
            'max_execution_time': 300,  # 5åˆ†é’Ÿ
            'progress_timeout': 60      # 1åˆ†é’Ÿæ— è¿›å±•è¶…æ—¶
        }
        logger.info("ğŸ›¡ï¸ å¾ªç¯æ£€æµ‹æœºåˆ¶å·²å¯ç”¨")

        for step_index in range(max_steps):
            step_id = step_index + 2  # ä»2å¼€å§‹ï¼Œå› ä¸º1æ˜¯å·¥å…·æš´éœ²æ­¥éª¤
            # ğŸ›¡ï¸ å¾ªç¯æ£€æµ‹ï¼šæ£€æŸ¥æ˜¯å¦åº”è¯¥ç»ˆæ­¢æ‰§è¡Œ
            current_time = time.time()
            
            # æ£€æŸ¥æ€»æ‰§è¡Œæ—¶é—´
            if current_time - loop_detection['start_time'] > loop_detection['max_execution_time']:
                logger.warning(f"ğŸ›‘ æ‰§è¡Œè¶…æ—¶ç»ˆæ­¢ ({loop_detection['max_execution_time']}ç§’)")
                break
            
            # æ£€æŸ¥æ— è¿›å±•è¶…æ—¶
            time_since_progress = current_time - loop_detection['last_progress_time']
            if time_since_progress > loop_detection['progress_timeout']:
                logger.warning(f"ğŸ›‘ æ— è¿›å±•è¶…æ—¶ç»ˆæ­¢ ({loop_detection['progress_timeout']}ç§’æ— æˆåŠŸæ“ä½œ)")
                break
            
            # æ£€æŸ¥è¿ç»­å¤±è´¥
            if loop_detection['consecutive_failures'] >= loop_detection['max_consecutive_failures']:
                logger.warning(f"ğŸ›‘ è¿ç»­å¤±è´¥è¿‡å¤šç»ˆæ­¢ ({loop_detection['consecutive_failures']}æ¬¡)")
                break
            
            # ğŸ” é‡ç½®å½“å‰æ­¥éª¤çš„LLMäº¤äº’è®°å½•
            current_step_llm_interactions = []
            
            logger.info(f"ğŸ”„ æ‰§è¡Œæ­¥éª¤ {step_id}/{max_steps}")
            
            # ğŸ” é”™è¯¯æ¨¡å¼æ£€æµ‹å’Œæ™ºèƒ½æ¢å¤
            error_pattern_detected = await self._detect_error_patterns(steps, step_id)
            if error_pattern_detected:
                recovery_action = await self._apply_error_recovery(steps, step_id, task)
                if recovery_action == "terminate":
                    logger.warning("ğŸ›‘ é”™è¯¯æ¢å¤å»ºè®®ç»ˆæ­¢ä»»åŠ¡")
                    break
                elif recovery_action == "adjust_strategy":
                    logger.info("ğŸ”§ é”™è¯¯æ¢å¤å»ºè®®è°ƒæ•´ç­–ç•¥")
                    # è°ƒæ•´ç­–ç•¥çš„å…·ä½“å®ç°åœ¨åç»­æ­¥éª¤ä¸­å¤„ç†
            
            tool_start = time.time()
            observation = ""
            current_attempt_err_type = None
            current_attempt_err_msg = None
            tool_success = False
            action_type = ActionType.TOOL_CALL
            thinking = ""
            execution_code = ""
            
            # ğŸ” æ–°å¢ï¼šåŒ…è£…LLMå®¢æˆ·ç«¯ä»¥æ”¶é›†äº¤äº’ä¿¡æ¯
            original_call_api = self.client._call_api
            async def wrapped_call_api(messages) -> str:
                # è®°å½•LLMäº¤äº’å¼€å§‹
                interaction_start = time.time()
                
                # è°ƒç”¨åŸå§‹æ–¹æ³•
                response = await original_call_api(messages)
                
                # è®°å½•LLMäº¤äº’
                from core.interfaces import LLMInteraction
                interaction = LLMInteraction()
                interaction.provider = self.client.provider.value if hasattr(self.client.provider, 'value') else str(self.client.provider)
                interaction.model = getattr(self.client, 'model', 'unknown')
                interaction.context = f"step_{step_id}_reasoning"
                interaction.prompt = str(messages) if messages else ""
                interaction.prompt_length = len(str(messages))
                interaction.prompt_type = "task_execution"
                interaction.response = response
                interaction.response_length = len(response)
                interaction.response_time = time.time() - interaction_start
                current_step_llm_interactions.append(interaction)
                return response
            
            # ä¸´æ—¶æ›¿æ¢æ–¹æ³•
            self.client._call_api = wrapped_call_api
            
            try:
                # === æ™ºèƒ½æ­¥éª¤è§„åˆ’ï¼šä¼˜å…ˆä½¿ç”¨StepPlanner ===
                planned_step = None
                if initial_plan:
                    # ä½¿ç”¨æ­¥éª¤è§„åˆ’å™¨è·å–ä¸‹ä¸€æ­¥
                    try:
                        available_tool_ids = await self.toolscore_client.get_available_tools()
                        planned_step = await self.step_planner.plan_next_step(
                            task, steps, available_tool_ids, session_id
                        )
                        if planned_step:
                            logger.info(f"ğŸ“‹ ä½¿ç”¨è§„åˆ’æ­¥éª¤: {planned_step.action} -> {planned_step.tool_id}")
                            thinking = f"Step {step_id}: æ‰§è¡Œè®¡åˆ’æ­¥éª¤ - {planned_step.action}"
                            action = planned_step.action
                            tool_id = planned_step.tool_id
                            params = planned_step.parameters.copy()
                        else:
                            logger.info("ğŸ“‹ æ­¥éª¤è§„åˆ’å™¨è®¤ä¸ºä»»åŠ¡å¯èƒ½å·²å®Œæˆï¼Œæ£€æŸ¥å®ŒæˆçŠ¶æ€")
                    except Exception as plan_step_err:
                        logger.warning(f"æ­¥éª¤è§„åˆ’å¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ–¹å¼: {plan_step_err}")
                
                # === ä¼ ç»Ÿæ–¹å¼ï¼šå½“æ²¡æœ‰è§„åˆ’æ­¥éª¤æ—¶ ===
                if not planned_step:
                    # è·å–ä¸‹ä¸€ä¸ªåŠ¨ä½œ
                    serializable_steps = [s.to_dict() if hasattr(s, 'to_dict') else s.__dict__ for s in steps]
                    
                    # è·å–å·²æ³¨å†Œå·¥å…·IDåˆ—è¡¨å’Œæè¿°
                    available_tool_ids = await self.toolscore_client.get_available_tools()
                    # available_tool_idsç°åœ¨æ˜¯ä¸€ä¸ªå·¥å…·IDåˆ—è¡¨
                    available_tools_description = await self.real_time_client.get_fresh_tools_for_llm(
                        fallback_client=self.toolscore_client
                    )
                    
                    # === ä¸Šä¸‹æ–‡æ³¨å…¥ï¼šè·å–è®°å¿†ä¸Šä¸‹æ–‡å¹¶æ³¨å…¥åˆ°æ‰§è¡Œä¸Šä¸‹æ–‡ä¸­ ===
                    memory_context = ""
                    cross_session_insights = []
                    try:
                        # è·å–å½“å‰ä¼šè¯çš„ä¸Šä¸‹æ–‡æ‘˜è¦
                        memory_context = await self.memory_manager.generate_context_summary(
                            session_id, max_steps=5
                        )
                        # è·å–è·¨ä¼šè¯æ´å¯Ÿ
                        cross_session_insights = await self.memory_manager.get_cross_session_insights(limit=3)
                        logger.debug(f"ğŸ§  è·å–è®°å¿†ä¸Šä¸‹æ–‡: {len(memory_context)} å­—ç¬¦, {len(cross_session_insights)} æ´å¯Ÿ")
                    except Exception as memory_ctx_err:
                        logger.warning(f"è·å–è®°å¿†ä¸Šä¸‹æ–‡å¤±è´¥: {memory_ctx_err}")
                    
                    # ğŸ”§ P2ä¿®å¤ï¼šæ„å»ºæ™ºèƒ½é”™è¯¯åˆ†æä¸Šä¸‹æ–‡
                    error_analysis_context = await self._build_error_analysis_context(steps, step_id)
                    
                    # æ„å»ºå¢å¼ºçš„æ‰§è¡Œä¸Šä¸‹æ–‡
                    enhanced_execution_context = {
                        "step_number": step_id,
                        "max_steps": max_steps,
                        "session_id": session_id,
                        "memory_context": memory_context,
                        "cross_session_insights": cross_session_insights,
                        "planning_mode": "traditional" if not initial_plan else "planned",
                        "error_analysis": error_analysis_context  # ğŸ†• å¢åŠ é”™è¯¯åˆ†æä¸Šä¸‹æ–‡
                    }
                    
                    # ğŸ”§ å¢å¼ºLLMè°ƒç”¨é”™è¯¯å¤„ç† - é˜²æ­¢æ•°æ®ç±»å‹é”™è¯¯å’Œå¼‚å¸¸ä¼ æ’­
                    try:
                        logger.debug(f"ğŸ” å‡†å¤‡LLMè°ƒç”¨ - ä»»åŠ¡: {task.description[:100]}...")
                        logger.debug(f"   å¯ç”¨å·¥å…·: {len(available_tool_ids)} ä¸ª")
                        logger.debug(f"   å·¥å…·æè¿°é•¿åº¦: {len(available_tools_description)} å­—ç¬¦")
                        logger.debug(f"   å†å²æ­¥éª¤: {len(serializable_steps)} æ­¥")
                        
                        # é¢„éªŒè¯è¾“å…¥å‚æ•°
                        if not isinstance(task.description, str):
                            task_desc = str(task.description) if task.description else "æœªçŸ¥ä»»åŠ¡"
                            logger.warning(f"ä»»åŠ¡æè¿°ç±»å‹å¼‚å¸¸ï¼Œå·²è½¬æ¢: {type(task.description)} -> str")
                        else:
                            task_desc = task.description
                        
                        if not isinstance(available_tool_ids, list):
                            available_tool_ids = [] if available_tool_ids is None else [str(available_tool_ids)]
                            logger.warning(f"å¯ç”¨å·¥å…·IDç±»å‹å¼‚å¸¸ï¼Œå·²è½¬æ¢ä¸ºåˆ—è¡¨")
                        
                        if not isinstance(available_tools_description, str):
                            available_tools_description = str(available_tools_description) if available_tools_description else "æ— å¯ç”¨å·¥å…·"
                            logger.warning(f"å·¥å…·æè¿°ç±»å‹å¼‚å¸¸ï¼Œå·²è½¬æ¢ä¸ºå­—ç¬¦ä¸²")
                        
                        if not isinstance(serializable_steps, list):
                            serializable_steps = [] if serializable_steps is None else [serializable_steps]
                            logger.warning(f"å†å²æ­¥éª¤ç±»å‹å¼‚å¸¸ï¼Œå·²è½¬æ¢ä¸ºåˆ—è¡¨")
                        
                        if not isinstance(enhanced_execution_context, dict):
                            enhanced_execution_context = {} if enhanced_execution_context is None else {"context": str(enhanced_execution_context)}
                            logger.warning(f"æ‰§è¡Œä¸Šä¸‹æ–‡ç±»å‹å¼‚å¸¸ï¼Œå·²è½¬æ¢ä¸ºå­—å…¸")
                        
                        action_result = await self.client.generate_enhanced_reasoning(
                            task_description=task_desc,
                            available_tools=available_tool_ids,  # æ·»åŠ å·²æ³¨å†Œå·¥å…·IDåˆ—è¡¨
                            tool_descriptions=available_tools_description,  # è¯¦ç»†å·¥å…·æè¿°
                            previous_steps=serializable_steps,
                            execution_context=enhanced_execution_context  # åŒ…å«è®°å¿†ä¸Šä¸‹æ–‡çš„æ‰§è¡Œä¸Šä¸‹æ–‡
                        )
                        
                        # éªŒè¯è¿”å›ç»“æœç±»å‹
                        if not isinstance(action_result, dict):
                            logger.error(f"LLMè¿”å›ç»“æœç±»å‹å¼‚å¸¸: {type(action_result)}, å†…å®¹: {action_result}")
                            raise ValueError(f"LLMè¿”å›ç»“æœå¿…é¡»æ˜¯å­—å…¸ç±»å‹ï¼Œå®é™…ç±»å‹: {type(action_result)}")
                        
                        logger.debug(f"âœ… LLMè°ƒç”¨æˆåŠŸï¼Œè¿”å›å­—æ®µ: {list(action_result.keys())}")
                        
                    except Exception as llm_error:
                        logger.error(f"âŒ LLMè°ƒç”¨å¤±è´¥: {llm_error}")
                        logger.error(f"   é”™è¯¯ç±»å‹: {type(llm_error).__name__}")
                        logger.error(f"   å‚æ•°ç±»å‹æ£€æŸ¥:")
                        logger.error(f"     task_description: {type(task.description)}")
                        logger.error(f"     available_tools: {type(available_tool_ids)}")
                        logger.error(f"     tool_descriptions: {type(available_tools_description)}")
                        logger.error(f"     previous_steps: {type(serializable_steps)}")
                        logger.error(f"     execution_context: {type(enhanced_execution_context)}")
                        
                        # åˆ›å»ºå®‰å…¨çš„å¤±è´¥å“åº”
                        action_result = {
                            "thinking": f"LLMè°ƒç”¨å¤±è´¥: {str(llm_error)}",
                            "action": "error",
                            "tool": None,
                            "parameters": {},
                            "confidence": 0.0,
                            "error_details": {
                                "error_type": type(llm_error).__name__,
                                "error_message": str(llm_error),
                                "step_id": step_id
                            }
                        }
                    
                    # ğŸ›¡ï¸ æ–°å¢ï¼šGuardrailsè¾“å‡ºéªŒè¯
                    guardrails_result = await self.guardrails_middleware.validate_output(
                        json.dumps(action_result, ensure_ascii=False),
                        context={"step_id": step_id, "task_description": task.description}
                    )
                    
                    if guardrails_result.is_valid:
                        if guardrails_result.corrections_applied:
                            logger.info(f"ğŸ”§ Guardrailsè‡ªåŠ¨ä¿®æ­£: {guardrails_result.corrections_applied}")
                            action_result = guardrails_result.validated_data
                        else:
                            logger.debug(f"âœ… GuardrailséªŒè¯é€šè¿‡: {guardrails_result.guardrails_used}")
                    else:
                        # GuardrailséªŒè¯å¤±è´¥ï¼Œè§¦å‘ValidationCriticåˆ†æ
                        logger.warning(f"âŒ GuardrailséªŒè¯å¤±è´¥: {guardrails_result.error_message}")
                        
                        # ğŸ¯ åˆ›å»ºé”™è¯¯äº‹ä»¶å¹¶è§¦å‘ValidationCritic
                        error_event = ErrorEvent(
                            error_id=f"guardrails_failure_{step_id}_{int(time.time())}",
                            timestamp=datetime.now(),
                            component="guardrails_middleware",
                            error_type="validation_failure",
                            error_message=guardrails_result.error_message,
                            stack_trace="",
                            severity=ErrorSeverity.MEDIUM,
                            category=ErrorCategory.DATA_ERROR,
                            context={
                                "step_id": step_id,
                                "original_output": action_result,
                                "tool_id": action_result.get('tool_id'),
                                "action": action_result.get('action'),
                                "guardrails_used": guardrails_result.guardrails_used
                            }
                        )
                        
                        self.error_events_buffer.append(error_event)
                        self.consecutive_failures += 1
                        
                        # å¦‚æœè¿ç»­å¤±è´¥è¾¾åˆ°é˜ˆå€¼ï¼Œè§¦å‘ValidationCriticåˆ†æ
                        if self.consecutive_failures >= self.max_consecutive_failures:
                            logger.warning(f"ğŸ¯ è¿ç»­å¤±è´¥{self.consecutive_failures}æ¬¡ï¼Œè§¦å‘ValidationCriticåˆ†æ")
                            
                            try:
                                critic_analysis = await self.validation_critic.review_failed_action(
                                    self.error_events_buffer[-5:],  # æœ€è¿‘5ä¸ªé”™è¯¯
                                    context={"current_step": step_id, "task": task.description}
                                )
                                
                                logger.info(f"ğŸ¯ ValidationCriticåˆ†æå®Œæˆ: {len(critic_analysis.suggestions)}ä¸ªå»ºè®®")
                                
                                # åº”ç”¨æœ€é«˜ç½®ä¿¡åº¦çš„å»ºè®®
                                if critic_analysis.suggestions:
                                    best_suggestion = max(critic_analysis.suggestions, key=lambda s: s.confidence)
                                    if best_suggestion.confidence >= 0.7:
                                        logger.info(f"ğŸ”§ åº”ç”¨ValidationCriticå»ºè®®: {best_suggestion.reasoning}")
                                        action_result = best_suggestion.corrected_request
                                        self.consecutive_failures = 0  # é‡ç½®è®¡æ•°å™¨
                                    else:
                                        logger.warning(f"âš ï¸ ValidationCriticå»ºè®®ç½®ä¿¡åº¦ä¸è¶³: {best_suggestion.confidence}")
                                        
                            except Exception as critic_error:
                                logger.error(f"âŒ ValidationCriticåˆ†æå¤±è´¥: {critic_error}")
                    
                    thinking = action_result.get('thinking', f"Step {step_id}: Analyzing task and deciding next action")
                    action = action_result.get('action')
                    tool_id = action_result.get('tool_id') or action_result.get('tool')
                    params = action_result.get('parameters', {})
                
                # æ·»åŠ actionå’Œtool_idåˆ°paramsä¸­ä»¥ä¿æŒå…¼å®¹æ€§
                if action:
                    params['action'] = action
                if tool_id:
                    params['tool_id'] = tool_id

                execution_code = json.dumps({
                    'action': action,
                    'tool_id': tool_id,
                    'parameters': params
                }, ensure_ascii=False)
            finally:
                # æ¢å¤åŸå§‹æ–¹æ³•
                self.client._call_api = original_call_api

            # ğŸ›¡ï¸ æ–°å¢ï¼šåŸºç¡€å‚æ•°æ ¡éªŒä¸æ™ºèƒ½é‡æ–°ç”Ÿæˆï¼ˆP1ä¿®å¤ï¼‰
            validation_passed, validation_error = await self._validate_tool_parameters(tool_id, action, params)
            if not validation_passed:
                logger.warning(f"âš ï¸ å‚æ•°æ ¡éªŒå¤±è´¥: {validation_error}")
                
                # ğŸ”§ P1ä¿®å¤ï¼šæ™ºèƒ½å‚æ•°é‡æ–°ç”Ÿæˆï¼Œè€Œä¸æ˜¯ç›´æ¥è·³è¿‡
                retry_result = await self._smart_parameter_regeneration(
                    task, tool_id, action, params, validation_error, step_id, thinking, current_outputs
                )
                
                if retry_result["success"]:
                    # é‡æ–°ç”ŸæˆæˆåŠŸï¼Œæ›´æ–°å‚æ•°å¹¶ç»§ç»­
                    logger.info(f"âœ… æ™ºèƒ½å‚æ•°é‡æ–°ç”ŸæˆæˆåŠŸ")
                    params.clear()
                    params.update(retry_result["corrected_params"])
                    execution_code = json.dumps({
                        'action': action,
                        'tool_id': tool_id,
                        'parameters': params
                    }, ensure_ascii=False)
                    
                    # è®°å½•é‡æ–°ç”Ÿæˆæ­¥éª¤
                    regeneration_step = ExecutionStep(
                        step_id=step_id,
                        action_type=ActionType.TOOL_CALL,
                        action_params=params,
                        observation=f"å‚æ•°é‡æ–°ç”ŸæˆæˆåŠŸ: {retry_result['reasoning']}",
                        success=True,
                        thinking=f"é‡æ–°åˆ†æä»»åŠ¡éœ€æ±‚: {retry_result['reasoning']}",
                        execution_code=execution_code,
                        timestamp=time.time(),
                        duration=retry_result.get("duration", 0.1),
                        llm_interactions=retry_result.get("llm_interactions", [])
                    )
                    steps.append(regeneration_step)
                    current_outputs.append(regeneration_step.observation)
                    step_id += 1
                    # ç»§ç»­æ‰§è¡Œå·¥å…·è°ƒç”¨
                else:
                    # é‡æ–°ç”Ÿæˆå¤±è´¥ï¼Œè®°å½•é”™è¯¯æ­¥éª¤
                    logger.error(f"âŒ æ™ºèƒ½å‚æ•°é‡æ–°ç”Ÿæˆå¤±è´¥: {retry_result['error']}")
                    validation_step = ExecutionStep(
                        step_id=step_id,
                        action_type=ActionType.TOOL_CALL,
                        action_params=params,
                        observation=f"å‚æ•°æ ¡éªŒå¤±è´¥ä¸”é‡æ–°ç”Ÿæˆå¤±è´¥: {validation_error}. é‡æ–°ç”Ÿæˆé”™è¯¯: {retry_result['error']}",
                        success=False,
                        thinking=thinking,
                        execution_code=execution_code,
                        error_type=ErrorType.TOOL_ERROR,
                        error_message=f"{validation_error}; é‡æ–°ç”Ÿæˆå¤±è´¥: {retry_result['error']}",
                        timestamp=time.time(),
                        duration=0.1,
                        llm_interactions=current_step_llm_interactions
                    )
                    steps.append(validation_step)
                    current_outputs.append(validation_step.observation)
                    step_id += 1
                    continue  # è·³è¿‡å½“å‰å¾ªç¯ï¼Œç»§ç»­ä¸‹ä¸€æ­¥

            # ğŸš¨ P1-1: æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡å·²çŸ¥å¤±è´¥çš„å·¥å…·/åŠ¨ä½œç»„åˆ
            tool_action_key = f"{tool_id}.{action}"
            should_skip = await self._should_skip_failed_operation(tool_action_key, steps)
            if should_skip:
                logger.warning(f"âš ï¸ è·³è¿‡å·²çŸ¥å¤±è´¥çš„æ“ä½œ: {tool_action_key}")
                # è®°å½•è·³è¿‡æ­¥éª¤
                skip_step = ExecutionStep(
                    step_id=step_id,
                    action_type=ActionType.TOOL_CALL,
                    action_params=params,
                    observation=f"è·³è¿‡å·²çŸ¥å¤±è´¥æ“ä½œ: {tool_action_key}ã€‚è¯·è€ƒè™‘ä½¿ç”¨æ›¿ä»£å·¥å…·æˆ–æ–¹æ³•ã€‚",
                    success=False,
                    thinking=thinking,
                    execution_code=execution_code,
                    error_type=ErrorType.TOOL_ERROR,
                    error_message=f"æ“ä½œ {tool_action_key} åœ¨æœ€è¿‘æ­¥éª¤ä¸­åå¤å¤±è´¥",
                    timestamp=time.time(),
                    duration=0.1,
                    llm_interactions=current_step_llm_interactions
                )
                steps.append(skip_step)
                current_outputs.append(skip_step.observation)
                step_id += 1
                continue  # è·³è¿‡å½“å‰å¾ªç¯ï¼Œç»§ç»­ä¸‹ä¸€æ­¥
            
            # å°è¯•æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼ŒåŒ…å«é‡è¯•æœºåˆ¶
            for attempt in range(max_retries + 1):
                
                # ç‰¹æ®Šå¤„ç†ï¼šæ£€æŸ¥æ˜¯å¦å®Œæˆä»»åŠ¡
                if action == 'complete_task':
                    logger.info("ğŸ¯ LLMè®¤ä¸ºä»»åŠ¡å·²å®Œæˆ")
                    
                    # ğŸ” æ–°å¢ï¼šè®°å½•å®Œæˆä»»åŠ¡çš„æ€»ç»“ç”ŸæˆLLMäº¤äº’
                    complete_summary_interactions = []
                    original_call_api_complete = self.client._call_api
                    async def wrapped_call_api_for_complete_summary(messages) -> str:
                        interaction_start = time.time()
                        response = await original_call_api_complete(messages)
                        
                        from core.interfaces import LLMInteraction
                        interaction = LLMInteraction()
                        interaction.provider = self.client.provider.value if hasattr(self.client.provider, 'value') else str(self.client.provider)
                        interaction.model = getattr(self.client, 'model', 'unknown')
                        interaction.context = f"step_{step_id}_complete_task_summary"
                        interaction.prompt = str(messages) if messages else ""
                        interaction.prompt_length = len(str(messages))
                        interaction.prompt_type = "complete_task_summary"
                        interaction.response = response
                        interaction.response_length = len(response)
                        interaction.response_time = time.time() - interaction_start
                        complete_summary_interactions.append(interaction)
                        return response
                    
                    self.client._call_api = wrapped_call_api_for_complete_summary
                    try:
                        summary = await self.client.generate_task_summary(
                            task.description, [s.__dict__ for s in steps], current_outputs
                        )
                    finally:
                        self.client._call_api = original_call_api_complete
                    
                    # å°†å®Œæˆä»»åŠ¡çš„æ€»ç»“LLMäº¤äº’æ·»åŠ åˆ°å½“å‰æ­¥éª¤
                    current_step_llm_interactions.extend(complete_summary_interactions)
                    success = True
                    observation = summary
                    tool_success = True
                    action_type = ActionType.TOOL_CALL
                    
                    duration = time.time() - tool_start
                    steps.append(ExecutionStep(
                        step_id=step_id,
                        action_type=action_type,
                        action_params=params,
                        observation=observation,
                        success=True,
                        thinking=thinking,
                        execution_code=execution_code,
                        error_type=None,
                        error_message=None,
                        timestamp=time.time(),
                        duration=duration,
                        llm_interactions=current_step_llm_interactions  # ğŸ” æ–°å¢
                    ))
                    break
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å·¥å…·èƒ½åŠ›è¯·æ±‚ï¼ˆåªé’ˆå¯¹çœŸæ­£çš„èƒ½åŠ›è¯·æ±‚ï¼Œä¸æ˜¯ç›´æ¥å·¥å…·è°ƒç”¨ï¼‰
                elif action == 'request_tool_capability':
                    logger.info("ğŸ” æ£€æµ‹åˆ°å·¥å…·èƒ½åŠ›è¯·æ±‚ï¼Œå‘èµ·ToolScore APIè°ƒç”¨")
                    
                    # ä»å‚æ•°ä¸­æå–ä»»åŠ¡æè¿°å’Œèƒ½åŠ›éœ€æ±‚
                    task_desc = params.get('task_description', task.description)
                    required_caps = params.get('required_capabilities', [])
                    reason = params.get('reason', '')
                    
                    # å¦‚æœæœ‰ç†ç”±ï¼Œæå–å¯èƒ½çš„èƒ½åŠ›éœ€æ±‚
                    if reason and not required_caps:
                        # ç®€å•çš„å…³é”®è¯æå–
                        if 'image' in reason.lower() or 'picture' in reason.lower():
                            required_caps = ['image_generation']
                        elif 'file' in reason.lower() or 'document' in reason.lower():
                            required_caps = ['file_processing']
                        elif 'web' in reason.lower() or 'scraping' in reason.lower():
                            required_caps = ['web_scraping']
                    
                    # è°ƒç”¨ToolScore API
                    execution_start_time = time.time()
                    capability_result = await self.toolscore_client.request_tool_capability(
                        task_description=task_desc,
                        required_capabilities=required_caps,
                        auto_install=True
                    )
                    execution_duration = time.time() - execution_start_time
                    
                    if capability_result.get("success"):
                        # å·¥å…·å®‰è£…æˆåŠŸ
                        installed_tools = capability_result.get("installed_tools", [])
                        processing_time = capability_result.get("processing_time_ms", 0)
                        
                        if installed_tools:
                            tool_names = [tool.get("name", tool.get("tool_id", "unknown")) for tool in installed_tools]
                            observation = f"æˆåŠŸå®‰è£…äº† {len(installed_tools)} ä¸ªæ–°å·¥å…·: {', '.join(tool_names)}ã€‚å¤„ç†æ—¶é—´: {processing_time}msã€‚æ–°å·¥å…·ç°åœ¨å¯ä»¥ä½¿ç”¨ã€‚"
                            result_summary = f"å®‰è£…äº†å·¥å…·: {', '.join(tool_names)}"
                            
                            # æ³¨å†Œç­‰å¾…æ–°å·¥å…·çš„å›è°ƒ
                            await self.real_time_client.register_pending_request(
                                request_id=f"{trajectory_id}-step-{step_id}",
                                required_capabilities=required_caps,
                                callback=self._create_tool_available_callback(trajectory_id, step_id)
                            )
                            
                            # æ›´æ–°å·¥å…·åˆ—è¡¨
                            available_tool_ids = await self.toolscore_client.get_available_tools()
                            available_tools_description = await self.real_time_client.get_fresh_tools_for_llm(
                                fallback_client=self.toolscore_client
                            )
                        else:
                            observation = "å·¥å…·å®‰è£…è¯·æ±‚å·²å¤„ç†ï¼Œä½†æœªå®‰è£…æ–°å·¥å…·ã€‚ç°æœ‰å·¥å…·å¯èƒ½å·²æ»¡è¶³éœ€æ±‚ã€‚"
                            result_summary = "æœªå®‰è£…æ–°å·¥å…·"
                        
                        tool_success = True
                    else:
                        # å·¥å…·å®‰è£…å¤±è´¥
                        error_msg = capability_result.get("message", "æœªçŸ¥é”™è¯¯")
                        observation = f"å·¥å…·èƒ½åŠ›è¯·æ±‚å¤±è´¥: {error_msg}"
                        tool_success = False
                        current_attempt_err_type = ErrorType.TOOL_ERROR
                        current_attempt_err_msg = error_msg
                        result_summary = f"å¤±è´¥: {error_msg}"
                    
                    # ğŸ”§ è®°å½•å·¥å…·ä½¿ç”¨ - mcp-search-tool via capability request
                    tool_tracker.record_tool_usage(
                        tool_server_id='mcp-search-tool',
                        action=action if action != 'request_tool_capability' else 'analyze_tool_needs',
                        parameters={
                            "task_description": task_desc,
                            "required_capabilities": required_caps,
                            "reason": reason
                        },
                        result=result_summary,
                        success=tool_success,
                        duration=execution_duration
                    )
                
                # ğŸ” æ–°å¢ï¼šå¤„ç†mcp-search-toolçš„è°ƒç”¨ï¼ˆåªæœ‰å½“tool_idç¡®å®æ˜¯mcp-search-toolæ—¶ï¼‰
                elif tool_id == 'mcp-search-tool':
                    logger.info(f"ğŸ› ï¸ æ£€æµ‹åˆ°mcp-search-toolè°ƒç”¨: action={action}")
                    
                    try:
                        execution_start_time = time.time()
                        # ğŸ” é€šè¿‡ToolScore APIè°ƒç”¨mcp-search-tool
                        if action == 'analyze_tool_needs':
                            # åˆ†æå·¥å…·éœ€æ±‚
                            task_desc = params.get('task_description', task.description)
                            
                            # è°ƒç”¨ToolScoreçš„å·¥å…·åˆ†æAPI
                            analysis_result = await self.toolscore_client.analyze_tool_needs(
                                task_description=task_desc
                            )
                            execution_duration = time.time() - execution_start_time
                            
                            if analysis_result.get("success"):
                                analysis = analysis_result.get("analysis", {})
                                needed_tools = analysis.get("needed_tools", [])
                                recommendations = analysis.get("recommendations", "")
                                
                                observation = f"å·¥å…·éœ€æ±‚åˆ†æå®Œæˆã€‚éœ€è¦çš„å·¥å…·ç±»å‹: {', '.join(needed_tools)}ã€‚å»ºè®®: {recommendations}"
                                tool_success = True
                                result_summary = f"éœ€è¦å·¥å…·: {', '.join(needed_tools)}"
                            else:
                                error_msg = analysis_result.get("message", "åˆ†æå¤±è´¥")
                                observation = f"å·¥å…·éœ€æ±‚åˆ†æå¤±è´¥: {error_msg}"
                                tool_success = False
                                result_summary = f"åˆ†æå¤±è´¥: {error_msg}"
                            
                            # ğŸ”§ è®°å½•å·¥å…·ä½¿ç”¨
                            tool_tracker.record_tool_usage(
                                tool_server_id='mcp-search-tool',
                                action=action,
                                parameters={"task_description": task_desc},
                                result=result_summary,
                                success=tool_success,
                                duration=execution_duration
                            )
                                
                        elif action == 'search_and_install_tools':
                            # æœç´¢å¹¶å®‰è£…å·¥å…·
                            task_desc = params.get('task_description', task.description)
                            reason = params.get('reason', '')
                            
                            # è°ƒç”¨ToolScoreçš„å·¥å…·æœç´¢å’Œå®‰è£…API
                            search_result = await self.toolscore_client.search_and_install_tools(
                                task_description=task_desc,
                                reason=reason
                            )
                            execution_duration = time.time() - execution_start_time
                            
                            if search_result.get("success"):
                                installed_tools = search_result.get("installed_tools", [])
                                
                                if installed_tools:
                                    tool_names = [tool.get("name", tool.get("tool_id", "unknown")) for tool in installed_tools]
                                    observation = f"æˆåŠŸæœç´¢å¹¶å®‰è£…äº† {len(installed_tools)} ä¸ªæ–°å·¥å…·: {', '.join(tool_names)}ã€‚"
                                    result_summary = f"å®‰è£…äº†å·¥å…·: {', '.join(tool_names)}"
                                    
                                    # æ›´æ–°å¯ç”¨å·¥å…·æè¿°
                                    try:
                                        available_tools_description = await self.real_time_client.get_fresh_tools_for_llm(
                                            fallback_client=self.toolscore_client
                                        )
                                        # ğŸ”§ æ›´æ–°å·¥å…·è·Ÿè¸ªå™¨çš„å¯ç”¨å·¥å…·ä¿¡æ¯
                                        tool_tracker.set_available_tools(available_tools_description)
                                        logger.info("âœ… å·²æ›´æ–°å¯ç”¨å·¥å…·åˆ—è¡¨")
                                    except Exception as e:
                                        logger.warning(f"æ›´æ–°å·¥å…·åˆ—è¡¨å¤±è´¥: {e}")
                                else:
                                    observation = "æœç´¢å®Œæˆï¼Œä½†æœªæ‰¾åˆ°åˆé€‚çš„æ–°å·¥å…·ã€‚"
                                    result_summary = "æœªæ‰¾åˆ°åˆé€‚çš„æ–°å·¥å…·"
                                
                                tool_success = True
                            else:
                                error_msg = search_result.get("message", "æœç´¢å¤±è´¥")
                                observation = f"å·¥å…·æœç´¢å¤±è´¥: {error_msg}"
                                tool_success = False
                                result_summary = f"æœç´¢å¤±è´¥: {error_msg}"
                            
                            # ğŸ”§ è®°å½•å·¥å…·ä½¿ç”¨
                            tool_tracker.record_tool_usage(
                                tool_server_id='mcp-search-tool',
                                action=action,
                                parameters={"task_description": task_desc, "reason": reason},
                                result=result_summary,
                                success=tool_success,
                                duration=execution_duration
                            )
                        else:
                            # æœªçŸ¥çš„mcp-search-toolåŠ¨ä½œ
                            observation = f"ä¸æ”¯æŒçš„mcp-search-toolåŠ¨ä½œ: {action}"
                            tool_success = False
                            
                    except Exception as e:
                        logger.error(f"mcp-search-toolè°ƒç”¨å¼‚å¸¸: {e}")
                        observation = f"mcp-search-toolè°ƒç”¨å¤±è´¥: {str(e)}"
                        tool_success = False
                        current_attempt_err_type = ErrorType.TOOL_ERROR
                        current_attempt_err_msg = str(e)
                        
                        # ğŸ”§ å³ä½¿å¼‚å¸¸ä¹Ÿè¦è®°å½•å·¥å…·ä½¿ç”¨
                        execution_duration = time.time() - execution_start_time if 'execution_start_time' in locals() else 0.0
                        tool_tracker.record_tool_usage(
                            tool_server_id='mcp-search-tool',
                            action=action if 'action' in locals() else 'unknown',
                            parameters=params if 'params' in locals() else {},
                            result=f"å¼‚å¸¸: {str(e)}",
                            success=False,
                            duration=execution_duration
                        )

                # å¸¸è§„å·¥å…·è°ƒç”¨
                elif tool_id and action:
                    logger.info(f"ğŸ”§ æ‰§è¡Œå·¥å…·è°ƒç”¨: tool_id={tool_id}, action={action}")
                    logger.debug(f"Attempt {attempt + 1}: Executing action '{action}' with tool_id '{tool_id}'")
                    
                    # æ¸…ç†å‚æ•°
                    cleaned_params = {k: v for k, v in params.items()
                                    if k not in ['action', 'tool_id', 'tool']}

                    # ä¼˜å…ˆå°è¯•ç›´æ¥é€šè¿‡MCPå®¢æˆ·ç«¯è°ƒç”¨ python-executor-mcp-server
                    # ğŸ” ç»Ÿä¸€é€šè¿‡ToolScore HTTP APIæ‰§è¡Œæ‰€æœ‰å·¥å…·
                    try:
                        logger.info(f"ğŸŒ é€šè¿‡ToolScore HTTP APIæ‰§è¡Œå·¥å…·: {tool_id}/{action}")
                        
                        execution_start_time = time.time()
                        execution_result = await self.toolscore_client.execute_tool(
                            tool_id=tool_id,
                            action=action,
                            parameters=cleaned_params
                        )
                        execution_duration = time.time() - execution_start_time
                        
                        tool_success = execution_result.get('success', False)
                        
                        if tool_success:
                            result_data = execution_result.get('result', {})
                            if tool_id == 'python-executor-mcp-server' and isinstance(result_data, dict):
                                stdout = result_data.get('stdout', '').strip()
                                if stdout:
                                    observation = f"Pythonä»£ç æ‰§è¡ŒæˆåŠŸã€‚è¾“å‡º:\n{stdout[:200]}{'...' if len(stdout) > 200 else ''}"
                                    current_outputs.append(stdout)
                                    result_summary = stdout
                                else:
                                    observation = "Pythonä»£ç æ‰§è¡ŒæˆåŠŸï¼Œæ— è¾“å‡ºã€‚"
                                    result_summary = "æ— è¾“å‡º"
                            else:
                                observation = f"å·¥å…·æ‰§è¡ŒæˆåŠŸ: {str(result_data)[:200]}{'...' if len(str(result_data)) > 200 else ''}"
                                current_outputs.append(str(result_data))
                                result_summary = str(result_data)
                        else:
                            error_msg = execution_result.get('error', 'Unknown error')
                            observation = f"å·¥å…·æ‰§è¡Œå¤±è´¥: {error_msg}"
                            current_attempt_err_type = ErrorType.TOOL_ERROR
                            current_attempt_err_msg = error_msg
                            result_summary = f"é”™è¯¯: {error_msg}"
                        
                        # ğŸ”§ è®°å½•å·¥å…·ä½¿ç”¨
                        tool_tracker.record_tool_usage(
                            tool_server_id=tool_id,
                            action=action,
                            parameters=cleaned_params,
                            result=result_summary,
                            success=tool_success,
                            duration=execution_duration
                        )
                        
                        logger.info(f"âœ… å·¥å…·æ‰§è¡Œå®Œæˆ: {tool_id}, æˆåŠŸ: {tool_success}")
                        
                        # ğŸ¯ æ–°å¢ï¼šæˆåŠŸæ—¶é‡ç½®è¿ç»­å¤±è´¥è®¡æ•°å™¨å’Œé”™è¯¯ç¼“å†²åŒº
                        if tool_success:
                            self.consecutive_failures = 0
                            if self.error_events_buffer:
                                logger.debug(f"ğŸ”„ é‡ç½®è¿ç»­å¤±è´¥è®¡æ•°å™¨ï¼Œæ¸…ç†{len(self.error_events_buffer)}ä¸ªé”™è¯¯äº‹ä»¶")
                                self.error_events_buffer.clear()
                    
                    except Exception as e:
                        logger.error(f"å·¥å…·æ‰§è¡Œå¼‚å¸¸: {e}")
                        tool_success = False
                        current_attempt_err_type = ErrorType.TOOL_ERROR
                        current_attempt_err_msg = str(e)
                        observation = f"å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"

                else:
                    # æ— æ•ˆçš„å·¥å…·è°ƒç”¨
                    tool_success = False
                    current_attempt_err_type = ErrorType.SYSTEM_ERROR
                    if not tool_id:
                        current_attempt_err_msg = f"LLMæœªæŒ‡å®štool_idã€‚å°è¯•çš„åŠ¨ä½œ: '{action}'"
                    elif not action:
                        current_attempt_err_msg = f"LLMæœªæŒ‡å®šåŠ¨ä½œã€‚å·¥å…·: '{tool_id}'"
                    else:
                        current_attempt_err_msg = f"LLMå°è¯•è°ƒç”¨å·¥å…· '{tool_id}' æ‰§è¡ŒåŠ¨ä½œ '{action}'ï¼Œä½†å½“å‰ä¸æ”¯æŒæˆ–æ— æ•ˆã€‚"
                    observation = current_attempt_err_msg
                    action_type = ActionType.TOOL_CALL

                # ğŸ”§ å¢å¼ºçš„é”™è¯¯å¤„ç†å’Œæ™ºèƒ½åæ€-çº æ­£é€»è¾‘
                if not tool_success:
                    # ğŸ“ Sprint 2: å¢å¼ºç»“æ„åŒ–é”™è¯¯æ—¥å¿— (P2 é—®é¢˜ä¿®å¤)
                    error_context = {
                        'step_id': step_id,
                        'action': action,
                        'tool_id': tool_id,
                        'attempt': attempt + 1,
                        'max_attempts': max_retries + 1,
                        'error_type': str(current_attempt_err_type),
                        'error_message': current_attempt_err_msg,
                        'timestamp': time.time(),
                        'task_id': task.task_id,
                        'session_context': f"{trajectory_id}_{step_id}"
                    }
                    
                    logger.warning(
                        f"ğŸš¨ æ­¥éª¤å¤±è´¥ [Step {step_id}] {tool_id}.{action} "
                        f"(ç¬¬{attempt + 1}/{max_retries + 1}æ¬¡) | é”™è¯¯: {current_attempt_err_type} | "
                        f"æ¶ˆæ¯: {current_attempt_err_msg[:100]}{'...' if len(current_attempt_err_msg) > 100 else ''}",
                        extra={'error_context': error_context}
                    )

                    # ğŸ§  Sprint 1: å¢å¼ºæ™ºèƒ½é‡è¯•é€»è¾‘ï¼ˆæ›´ç²¾ç»†çš„é”™è¯¯åˆ†ç±»ï¼‰
                    retry_strategy = self._analyze_error_and_determine_strategy(
                        current_attempt_err_type, current_attempt_err_msg, attempt, max_retries
                    )
                    
                    should_reflect = retry_strategy['should_reflect']
                    is_simple_retryable = retry_strategy['is_simple_retryable']
                    should_abort = retry_strategy['should_abort']
                    
                    if should_abort:
                        logger.error(f"ğŸš¨ é”™è¯¯ä¸å¯é‡è¯•ï¼Œåœæ­¢æ‰§è¡Œ: {current_attempt_err_msg}")
                        break
                    
                    if should_reflect and attempt < max_retries:
                        logger.info(f"ğŸ§  å¯åŠ¨æ™ºèƒ½åæ€-çº æ­£æµç¨‹...")
                        
                        # æ„å»ºåæ€promptï¼ŒåŒ…å«é”™è¯¯ä¿¡æ¯å’Œä¸Šä¸‹æ–‡
                        reflection_prompt = await self._build_reflection_prompt(
                            task=task,
                            failed_action=action,
                            failed_tool_id=tool_id,
                            failed_params=params,
                            error_message=current_attempt_err_msg,
                            thinking=thinking,
                            available_tools_description=available_tools_description
                        )
                        
                        try:
                            # è®©LLMåˆ†æé”™è¯¯å¹¶ç”Ÿæˆä¿®æ­£çš„å·¥å…·è°ƒç”¨
                            corrected_response = await self.client.call_llm(reflection_prompt)
                            logger.info(f"ğŸ§  LLMåæ€å“åº” (é•¿åº¦: {len(corrected_response)})")
                            
                            # è§£æä¿®æ­£åçš„å“åº”
                            from core.llm.response_parsers.reasoning_response_parser import ReasoningResponseParser
                            parser = ReasoningResponseParser()
                            corrected_result = parser.parse_response(corrected_response)
                            
                            if corrected_result.get('action') and corrected_result.get('tool_id'):
                                # ä½¿ç”¨ä¿®æ­£åçš„å‚æ•°è¿›è¡Œä¸‹ä¸€æ¬¡å°è¯•
                                action = corrected_result['action']
                                tool_id = corrected_result['tool_id']
                                params = corrected_result.get('parameters', {})
                                thinking = corrected_result.get('thinking', thinking)
                                
                                logger.info(f"ğŸ”§ ä½¿ç”¨ä¿®æ­£åçš„è°ƒç”¨: {tool_id}.{action} with {params}")
                                await asyncio.sleep(1)  # çŸ­æš‚å»¶è¿Ÿ
                                continue  # ç»§ç»­ä¸‹ä¸€æ¬¡å°è¯•
                                
                        except Exception as reflection_error:
                            logger.error(f"âŒ åæ€-çº æ­£å¤±è´¥: {reflection_error}")
                    
                    elif is_simple_retryable and attempt < max_retries:
                        # ğŸ”„ å¢å¼ºé‡è¯•ç­–ç•¥ï¼šæŒ‡æ•°é€€é¿ + å†å²è·Ÿè¸ª
                        retry_key = f"{tool_id}.{action}"
                        
                        # æ›´æ–°é‡è¯•å†å²
                        if retry_key not in retry_history:
                            retry_history[retry_key] = {'count': 0, 'last_error': None, 'first_attempt': time.time()}
                        
                        retry_history[retry_key]['count'] += 1
                        retry_history[retry_key]['last_error'] = current_attempt_err_msg
                        
                        # æŒ‡æ•°é€€é¿ç®—æ³•
                        retry_delay = base_retry_delay * (2 ** attempt)  # 1s, 2s, 4s...
                        retry_delay = min(retry_delay, 10)  # æœ€å¤š10ç§’
                        
                        # æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»ˆæ­¢é‡è¯•ï¼ˆé¿å…æ— æ„ä¹‰çš„é‡å¤ï¼‰
                        if retry_history[retry_key]['count'] > 5:  # å•ä¸ªæ“ä½œæœ€å¤š5æ¬¡
                            logger.warning(f"ğŸš¨ æ“ä½œ {retry_key} é‡è¯•æ¬¡æ•°è¿‡å¤šï¼Œåœæ­¢é‡è¯•")
                            break
                        
                        # ğŸ“ Sprint 2: ç»“æ„åŒ–é‡è¯•æ—¥å¿—
                        retry_context = {
                            'retry_key': retry_key,
                            'current_attempt': attempt + 1,
                            'retry_delay': retry_delay,
                            'total_retries_for_operation': retry_history[retry_key]['count'],
                            'first_attempt_time': retry_history[retry_key]['first_attempt'],
                            'step_id': step_id,
                            'task_id': task.task_id
                        }
                        
                        logger.info(
                            f"ğŸ”„ æ™ºèƒ½é‡è¯• {action} (ç¬¬{attempt+1}æ¬¡, å»¶è¿Ÿ{retry_delay}s, å†å²{retry_history[retry_key]['count']}æ¬¡)",
                            extra={'retry_context': retry_context}
                        )
                        await asyncio.sleep(retry_delay)
                    else:
                        # æ— æ³•é‡è¯•æˆ–å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
                        logger.error(f"ğŸ’¥ æ­¥éª¤ {step_id} æœ€ç»ˆå¤±è´¥ï¼Œæ— æ³•ç»§ç»­é‡è¯•")
                        break
            
            # å®Œæˆä»»åŠ¡æ£€æŸ¥
            exec_code_dict = {}
            if execution_code:
                try:
                    exec_code_dict = json.loads(execution_code)
                except json.JSONDecodeError:
                    pass
            
            if exec_code_dict.get('action') == 'complete_task' and success:
                break

            duration = time.time() - tool_start

            step = ExecutionStep(
                step_id=step_id,
                action_type=action_type,
                action_params=params,
                observation=observation,
                success=tool_success,
                error_type=current_attempt_err_type,
                error_message=current_attempt_err_msg,
                thinking=thinking,
                execution_code=execution_code,
                timestamp=time.time(),
                duration=duration,
                llm_interactions=current_step_llm_interactions  # ğŸ” æ–°å¢
            )
            steps.append(step)
            
            # ğŸ›¡ï¸ å¾ªç¯æ£€æµ‹ï¼šæ›´æ–°çŠ¶æ€å¹¶æ£€æŸ¥é‡å¤æ¨¡å¼
            action_key = f"{action}:{tool_id}"
            loop_detection['repeated_actions'][action_key] += 1
            loop_detection['recent_tool_calls'].append((action, tool_id, tool_success))
            
            # æ›´æ–°å¤±è´¥è®¡æ•°
            if not tool_success:
                loop_detection['consecutive_failures'] += 1
                if current_attempt_err_msg:
                    loop_detection['repeated_errors'][current_attempt_err_msg] += 1
                    
                # æ£€æŸ¥é‡å¤é”™è¯¯
                if loop_detection['repeated_errors'][current_attempt_err_msg] >= 3:
                    logger.warning(f"ğŸ›‘ é‡å¤ç›¸åŒé”™è¯¯3æ¬¡ï¼Œç»ˆæ­¢æ‰§è¡Œ: {current_attempt_err_msg[:100]}")
                    break
            else:
                loop_detection['consecutive_failures'] = 0
                loop_detection['last_progress_time'] = time.time()
            
            # æ£€æŸ¥é‡å¤åŠ¨ä½œ
            if loop_detection['repeated_actions'][action_key] > loop_detection['max_repeated_actions']:
                logger.warning(f"ğŸ›‘ é‡å¤æ‰§è¡Œç›¸åŒåŠ¨ä½œ{loop_detection['repeated_actions'][action_key]}æ¬¡ï¼Œç»ˆæ­¢æ‰§è¡Œ: {action_key}")
                break
            
            # æ£€æŸ¥å·¥å…·è°ƒç”¨æ¨¡å¼å¾ªç¯
            if len(loop_detection['recent_tool_calls']) >= 6:  # è‡³å°‘6æ¬¡è°ƒç”¨æ‰æ£€æµ‹æ¨¡å¼
                recent_actions = [f"{action}:{tool}" for action, tool, _ in list(loop_detection['recent_tool_calls'])[-6:]]
                # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤çš„3æ­¥æ¨¡å¼
                if recent_actions[:3] == recent_actions[3:6]:
                    logger.warning(f"ğŸ›‘ æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨å¾ªç¯æ¨¡å¼ï¼Œç»ˆæ­¢æ‰§è¡Œ: {' -> '.join(recent_actions[:3])}")
                    break
            
            # === è®°å¿†å­˜å‚¨ï¼šå°†æ‰§è¡Œæ­¥éª¤å­˜å‚¨åˆ°è®°å¿†ç®¡ç†å™¨ ===
            try:
                await self.memory_manager.store_conversation_step(
                    task_id=trajectory_id,
                    session_id=session_id,
                    user_input=f"æ­¥éª¤{step_id}: {action} ({tool_id})",
                    agent_output=observation,
                    thinking_summary=thinking,
                    tools_used=[tool_id] if tool_id else [],
                    success=tool_success,
                    error_message=current_attempt_err_msg,
                    metadata={
                        "step_id": step_id,
                        "action": action,
                        "tool_id": tool_id,
                        "duration": duration,
                        "execution_code": execution_code
                    }
                )
                logger.debug(f"ğŸ’¾ æ­¥éª¤ {step_id} å·²å­˜å‚¨åˆ°è®°å¿†ç®¡ç†å™¨")
            except Exception as memory_err:
                logger.warning(f"è®°å¿†å­˜å‚¨å¤±è´¥: {memory_err}")

            # æ£€æŸ¥æ˜¯å¦å®Œæˆ - ä¹Ÿéœ€è¦è®°å½•LLMäº¤äº’
            completion_interactions = []
            original_call_api = self.client._call_api
            async def wrapped_call_api_for_completion(messages) -> str:
                interaction_start = time.time()
                response = await original_call_api(messages)
                
                from core.interfaces import LLMInteraction
                interaction = LLMInteraction()
                interaction.provider = self.client.provider.value if hasattr(self.client.provider, 'value') else str(self.client.provider)
                interaction.model = getattr(self.client, 'model', 'unknown')
                interaction.context = f"step_{step_id}_completion_check"
                interaction.prompt = str(messages) if messages else ""
                interaction.prompt_length = len(str(messages))
                interaction.prompt_type = "completion_check"
                interaction.response = response
                interaction.response_length = len(response)
                interaction.response_time = time.time() - interaction_start
                completion_interactions.append(interaction)
                return response
            
            self.client._call_api = wrapped_call_api_for_completion
            try:
                # === æ™ºèƒ½å®Œæˆæ£€æŸ¥ï¼šä¼˜å…ˆä½¿ç”¨StepPlanner ===
                completion_result = {"completed": False, "reason": ""}
                
                if initial_plan:
                    # ä½¿ç”¨æ­¥éª¤è§„åˆ’å™¨æ£€æŸ¥å®ŒæˆçŠ¶æ€
                    try:
                        planner_completed, planner_reason = await self.step_planner.check_completion(
                            task, steps, current_outputs
                        )
                        completion_result = {"completed": planner_completed, "reason": planner_reason}
                        logger.debug(f"ğŸ¯ æ­¥éª¤è§„åˆ’å™¨å®Œæˆæ£€æŸ¥: {planner_completed}, åŸå› : {planner_reason}")
                    except Exception as planner_err:
                        logger.warning(f"æ­¥éª¤è§„åˆ’å™¨å®Œæˆæ£€æŸ¥å¤±è´¥: {planner_err}")
                
                # === åå¤‡å®Œæˆæ£€æŸ¥ï¼šä½¿ç”¨ä¼ ç»ŸLLMæ–¹å¼ ===
                if not completion_result["completed"]:
                    completion = await self.client.check_task_completion(
                        task.description,
                        [s.__dict__ for s in steps],
                        current_outputs
                    )
                    completion_result = completion
                    
            finally:
                self.client._call_api = original_call_api
            
            # å°†å®Œæˆæ£€æŸ¥çš„LLMäº¤äº’æ·»åŠ åˆ°å½“å‰æ­¥éª¤
            if completion_interactions:
                steps[-1].llm_interactions.extend(completion_interactions)
            
            if completion_result.get('completed'):
                success = True
                logger.info(f"âœ… ä»»åŠ¡å®Œæˆ: {completion_result.get('reason', 'æ£€æŸ¥é€šè¿‡')}")
                break
        
        # ğŸ”§ æ”¹è¿›çš„ä»»åŠ¡å®Œæˆåˆ¤æ–­é€»è¾‘ - æ·»åŠ å®¢è§‚æŒ‡æ ‡éªŒè¯
        if not success and steps:
            completion_analysis = self._analyze_task_completion_objectively(task, steps, current_outputs)
            
            if completion_analysis['should_complete']:
                success = True
                logger.info(f"âœ… åŸºäºå®¢è§‚åˆ†æåˆ¤æ–­ä»»åŠ¡å®Œæˆ: {completion_analysis['reason']}")
                logger.info(f"ğŸ“Š å®Œæˆåº¦åˆ†æ: {completion_analysis['metrics']}")
            else:
                # åªæœ‰åœ¨çœŸæ­£å¤±è´¥æ—¶æ‰è®¾ç½®é”™è¯¯
                final_trajectory_error_type = steps[-1].error_type or ErrorType.EXECUTION_FAILED
                final_trajectory_error_message = completion_analysis['reason']
                logger.warning(f"âŒ ä»»åŠ¡æ‰§è¡Œæœªå®Œæˆ: {final_trajectory_error_message}")
                logger.info(f"ğŸ“Š å¤±è´¥åŸå› åˆ†æ: {completion_analysis['metrics']}")

        total_duration = time.time() - start_time
        
        # ç”Ÿæˆæœ€ç»ˆç»“æœ
        if success and steps:
            last_step_exec_code = {}
            if steps[-1].execution_code:
                try:
                    last_step_exec_code = json.loads(steps[-1].execution_code)
                except json.JSONDecodeError:
                    pass

            if last_step_exec_code.get('action') == 'complete_task':
                final_result = steps[-1].observation
            else:
                # æ™ºèƒ½ç”Ÿæˆæœ€ç»ˆç»“æœ
                browser_content = None
                python_output = None
                
                for step in reversed(steps[-3:]):
                    if not browser_content and 'Successfully retrieved page text' in step.observation:
                        if 'Preview:' in step.observation:
                            preview_start = step.observation.find('Preview:') + len('Preview:')
                            preview_end = step.observation.find('---', preview_start + 10)
                            if preview_end > preview_start:
                                browser_content = step.observation[preview_start:preview_end].strip()
                    
                    if not python_output and 'Python code executed' in step.observation and 'Output' in step.observation:
                        python_output = step.observation
                
                if browser_content:
                    final_result = f"ä»»åŠ¡å®Œæˆã€‚æˆåŠŸè®¿é—®äº†ç½‘ç«™å¹¶è·å–äº†é¡µé¢å†…å®¹ï¼š\n\n{browser_content[:800]}{'...' if len(browser_content) > 800 else ''}"
                elif python_output:
                    final_result = f"ä»»åŠ¡å®Œæˆã€‚{python_output}"
                elif current_outputs:
                    final_result = f"ä»»åŠ¡å®Œæˆã€‚ç”Ÿæˆç»“æœï¼š\n{chr(10).join(current_outputs[-2:])}"
                else:
                    # ğŸ” æ–°å¢ï¼šè®°å½•ä»»åŠ¡æ€»ç»“ç”Ÿæˆçš„LLMäº¤äº’
                    summary_interactions = []
                    original_call_api = self.client._call_api
                    async def wrapped_call_api_for_summary(messages) -> str:
                        interaction_start = time.time()
                        response = await original_call_api(messages)
                        
                        from core.interfaces import LLMInteraction
                        interaction = LLMInteraction()
                        interaction.provider = self.client.provider.value if hasattr(self.client.provider, 'value') else str(self.client.provider)
                        interaction.model = getattr(self.client, 'model', 'unknown')
                        interaction.context = "final_task_summary"
                        interaction.prompt = str(messages) if messages else ""
                        interaction.prompt_length = len(str(messages))
                        interaction.prompt_type = "task_summary"
                        interaction.response = response
                        interaction.response_length = len(response)
                        interaction.response_time = time.time() - interaction_start
                        summary_interactions.append(interaction)
                        return response
                    
                    self.client._call_api = wrapped_call_api_for_summary
                    try:
                        final_result = await self.client.generate_task_summary(
                            task.description, [s.__dict__ for s in steps], current_outputs
                        )
                    finally:
                        self.client._call_api = original_call_api
                    
                    # å°†æ€»ç»“ç”Ÿæˆçš„LLMäº¤äº’æ·»åŠ åˆ°æœ€åä¸€æ­¥
                    if summary_interactions and steps:
                        steps[-1].llm_interactions.extend(summary_interactions)
        else:
            final_result = final_trajectory_error_message or "Task execution failed"

        # åˆ›å»ºè½¨è¿¹ç»“æœ
        trajectory = TrajectoryResult(
            task_name=task.task_id,  # ä½¿ç”¨task_idä½œä¸ºtask_name
            task_id=task.task_id,
            task_description=task.description,
            runtime_id=self.runtime_id,
            steps=steps,
            success=success,
            final_result=final_result,
            total_duration=total_duration,
            error_type=final_trajectory_error_type,
            error_message=final_trajectory_error_message,
            metadata={
                'runtime_id': self.runtime_id,
                'original_task_id': task.task_id,
                # ğŸ”§ æ·»åŠ å·¥å…·ä½¿ç”¨ç»Ÿè®¡
                'tool_usage_stats': tool_tracker.get_usage_statistics()
            },
            # ğŸ”§ æ–°å¢ï¼šå·¥å…·ä½¿ç”¨è·Ÿè¸ªä¿¡æ¯
            available_tools=tool_tracker.get_available_tools_summary(),
            used_tools=tool_tracker.get_used_tools_summary()
        )
        
        # ğŸ” åº”ç”¨è½¨è¿¹å¢å¼º - æ·»åŠ è¯¦ç»†å…ƒæ•°æ®
        enhanced_trajectory = self.trajectory_enhancer.enhance_trajectory(trajectory)
        
        # ä¿å­˜è½¨è¿¹
        await self._save_trajectory(enhanced_trajectory)
        
        # === å°†è¿è¡ŒæœŸé—´æ•è·çš„æ–°å·¥å…·äº‹ä»¶è¿½åŠ åˆ°è½¨è¿¹ ===
        if self._tool_event_buffer:
            for i, ev in enumerate(self._tool_event_buffer):
                steps.append(ExecutionStep(
                    step_id=max([s.step_id for s in steps] + [0]) + i + 1,  # ç¡®ä¿step_idå”¯ä¸€é€’å¢
                    action_type=ActionType.TOOL_CALL,
                    action_params=ev,
                    observation=f"New tool available during execution: {ev.get('name')}",
                    success=True
                ))
            self._tool_event_buffer.clear()
        
        # === ä¼šè¯æ€»ç»“ï¼šä¿å­˜ä¼šè¯æ‘˜è¦åˆ°è®°å¿†ç®¡ç†å™¨ ===
        try:
            # æå–ä¸»è¦è¯é¢˜å’Œæ´å¯Ÿ
            main_topics = [task.description]
            key_insights = []
            
            if success:
                key_insights.append(f"ä»»åŠ¡æˆåŠŸå®Œæˆï¼Œå…±æ‰§è¡Œ{len(steps)}æ­¥ï¼Œè€—æ—¶{total_duration:.2f}ç§’")
                if tool_tracker:
                    used_tools = tool_tracker.get_used_tools_summary()
                    if used_tools:
                        # get_used_tools_summary() è¿”å›å­—å…¸ï¼Œéœ€è¦è·å–é”®åˆ—è¡¨
                        tool_names = list(used_tools.keys())
                        key_insights.append(f"ä¸»è¦ä½¿ç”¨å·¥å…·: {', '.join(tool_names[:3])}")
            else:
                key_insights.append(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {final_trajectory_error_message}")
            
            await self.memory_manager.store_session_summary(
                session_id=session_id,
                main_topics=main_topics,
                key_insights=key_insights
            )
            logger.debug(f"ğŸ’¾ ä¼šè¯æ‘˜è¦å·²ä¿å­˜: {session_id}")
        except Exception as session_err:
            logger.warning(f"ä¿å­˜ä¼šè¯æ‘˜è¦å¤±è´¥: {session_err}")
        
        return trajectory
    
    def _should_skip_failed_operation(self, operation_key: str, tool_id: str, action: str, params: Dict[str, Any]) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡é‡å¤å¤±è´¥çš„æ“ä½œ"""
        # æ£€æŸ¥å·¥å…·è°ƒç”¨å¤±è´¥å†å²
        if operation_key in self.failure_history.get('tool_calls', {}):
            failure_count = self.failure_history['tool_calls'][operation_key].get('count', 0)
            if failure_count >= 2:  # è¿ç»­å¤±è´¥2æ¬¡å°±è·³è¿‡
                return True
        
        # æ£€æŸ¥ç‰¹å®šçš„å·¥å…·å®‰è£…å¤±è´¥
        if action in ['search_and_install_tools', 'request_tool_capability']:
            task_desc = params.get('task_description', '')
            search_key = f"{action}:{hash(task_desc)}"
            if search_key in self.failure_history.get('search_queries', set()):
                return True
                
        return False
    
    def _record_failed_operation(self, category: str, operation_key: str, error_msg: str):
        """è®°å½•å¤±è´¥çš„æ“ä½œ"""
        if category == 'tool_calls':
            if operation_key not in self.failure_history['tool_calls']:
                self.failure_history['tool_calls'][operation_key] = {'count': 0, 'errors': []}
            
            self.failure_history['tool_calls'][operation_key]['count'] += 1
            self.failure_history['tool_calls'][operation_key]['errors'].append(error_msg)
            
        elif category == 'search_queries':
            self.failure_history['search_queries'].add(operation_key)
            
        elif category == 'tool_installations':
            self.failure_history['tool_installations'].add(operation_key)
            
        logger.debug(f"ğŸ“ˆ è®°å½•å¤±è´¥æ“ä½œ: {category}/{operation_key}")
    
    async def _should_skip_failed_operation(self, tool_action_key: str, steps: List[ExecutionStep]) -> bool:
        """
        P1-1: æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡å·²çŸ¥å¤±è´¥çš„å·¥å…·/åŠ¨ä½œç»„åˆ
        åŸºäºæœ€è¿‘çš„å¤±è´¥å†å²å†³å®šæ˜¯å¦è·³è¿‡ç‰¹å®šçš„å·¥å…·è°ƒç”¨
        
        Args:
            tool_action_key: å·¥å…·åŠ¨ä½œé”®ï¼Œæ ¼å¼ä¸º "tool_id.action"
            steps: æ‰§è¡Œæ­¥éª¤å†å²
            
        Returns:
            bool: Trueè¡¨ç¤ºåº”è¯¥è·³è¿‡ï¼ŒFalseè¡¨ç¤ºå¯ä»¥å°è¯•
        """
        try:
            # å¦‚æœæ­¥éª¤å†å²å¤ªå°‘ï¼Œä¸è·³è¿‡
            if len(steps) < 3:
                return False
            
            # åˆ†ææœ€è¿‘çš„æ‰§è¡Œæ­¥éª¤
            recent_steps = steps[-5:]  # æŸ¥çœ‹æœ€è¿‘5æ­¥
            
            # ç»Ÿè®¡ç›¸åŒå·¥å…·/åŠ¨ä½œç»„åˆçš„å¤±è´¥æ¬¡æ•°
            failure_count = 0
            total_attempts = 0
            
            for step in recent_steps:
                if not hasattr(step, 'action_params') or not step.action_params:
                    continue
                
                # é‡æ„å·¥å…·åŠ¨ä½œé”®
                step_tool_id = step.action_params.get('tool_id', '')
                step_action = step.action_params.get('action', '')
                step_key = f"{step_tool_id}.{step_action}"
                
                # å¦‚æœæ˜¯ç›¸åŒçš„å·¥å…·/åŠ¨ä½œç»„åˆ
                if step_key == tool_action_key:
                    total_attempts += 1
                    if not step.success:
                        failure_count += 1
            
            # å¦‚æœåœ¨æœ€è¿‘å°è¯•ä¸­ï¼Œå¤±è´¥ç‡è¶…è¿‡é˜ˆå€¼ï¼Œåˆ™è·³è¿‡
            if total_attempts >= 2:  # è‡³å°‘å°è¯•äº†2æ¬¡
                failure_rate = failure_count / total_attempts
                if failure_rate >= 0.8:  # å¤±è´¥ç‡80%ä»¥ä¸Š
                    logger.warning(f"ğŸš¨ å·¥å…·ç»„åˆ {tool_action_key} å¤±è´¥ç‡è¿‡é«˜ ({failure_count}/{total_attempts})")
                    return True
            
            # æ£€æŸ¥è¿ç»­å¤±è´¥æ¨¡å¼
            consecutive_failures = 0
            for step in reversed(recent_steps):
                if not hasattr(step, 'action_params') or not step.action_params:
                    continue
                
                step_tool_id = step.action_params.get('tool_id', '')
                step_action = step.action_params.get('action', '')
                step_key = f"{step_tool_id}.{step_action}"
                
                if step_key == tool_action_key:
                    if not step.success:
                        consecutive_failures += 1
                    else:
                        break  # ä¸€æ—¦æœ‰æˆåŠŸçš„å°±åœæ­¢è®¡æ•°
                else:
                    break  # ä¸æ˜¯ç›¸åŒæ“ä½œå°±åœæ­¢è®¡æ•°
            
            # å¦‚æœè¿ç»­å¤±è´¥3æ¬¡ä»¥ä¸Šï¼Œè·³è¿‡
            if consecutive_failures >= 3:
                logger.warning(f"ğŸš¨ å·¥å…·ç»„åˆ {tool_action_key} è¿ç»­å¤±è´¥ {consecutive_failures} æ¬¡")
                return True
            
            # æ£€æŸ¥ç‰¹å®šé”™è¯¯ç±»å‹
            for step in reversed(recent_steps):
                if not hasattr(step, 'action_params') or not step.action_params:
                    continue
                
                step_tool_id = step.action_params.get('tool_id', '')
                step_action = step.action_params.get('action', '')
                step_key = f"{step_tool_id}.{step_action}"
                
                if step_key == tool_action_key and not step.success:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸å¯æ¢å¤çš„é”™è¯¯ç±»å‹
                    if step.error_type in [ErrorType.TOOL_ERROR, ErrorType.VALIDATION_ERROR]:
                        error_msg = step.error_message or ""
                        # å¦‚æœæ˜¯æƒé™é”™è¯¯ã€å·¥å…·ä¸å­˜åœ¨ç­‰ä¸¥é‡é”™è¯¯ï¼Œè·³è¿‡
                        critical_errors = [
                            "ä¸æ”¯æŒçš„å·¥å…·åŠ¨ä½œ",
                            "æƒé™æ‹’ç»",
                            "å·¥å…·ä¸å­˜åœ¨",
                            "é…ç½®é”™è¯¯",
                            "è®¤è¯å¤±è´¥"
                        ]
                        if any(critical_error in error_msg for critical_error in critical_errors):
                            logger.warning(f"ğŸš¨ å·¥å…·ç»„åˆ {tool_action_key} é‡åˆ°ä¸å¯æ¢å¤é”™è¯¯: {error_msg}")
                            return True
                    break  # åªæ£€æŸ¥æœ€è¿‘ä¸€æ¬¡ç›¸åŒæ“ä½œ
            
            return False
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥è·³è¿‡å¤±è´¥æ“ä½œæ—¶å‡ºé”™: {e}")
            return False  # å‡ºé”™æ—¶ä¿å®ˆé€‰æ‹©ä¸è·³è¿‡
    
    def _create_tool_available_callback(self, trajectory_id: str, step_id: int):
        """åˆ›å»ºå·¥å…·å¯ç”¨æ—¶çš„å›è°ƒå‡½æ•°ï¼ˆä¸æ¥å—å‚æ•°ï¼‰"""
        async def callback(): # ä¸æ¥å—ä»»ä½•å‚æ•°
            # è¿™ä¸ªå›è°ƒåªæ˜¯ä¸€ä¸ªè§¦å‘å™¨ï¼Œå®é™…çš„å·¥å…·äº‹ä»¶å¤„ç†åœ¨ _on_new_tool_available ä¸­è¿›è¡Œ
            logger.info(f"ğŸ‰ ä»»åŠ¡ {trajectory_id} æ­¥éª¤ {step_id}: æ£€æµ‹åˆ°æ–°å·¥å…·å¯ç”¨ï¼Œæ­£åœ¨æ£€æŸ¥...")
        return callback
    
    def _map_tool_id_to_server(self, tool_id: str) -> str:
        """æ˜ å°„å·¥å…·IDåˆ°å®é™…çš„MCPæœåŠ¡å™¨ID"""
        # ç®€å•çš„æ˜ å°„é€»è¾‘ï¼Œå¯ä»¥æ ¹æ®éœ€è¦æ‰©å±•
        mapping = {
            'python': 'python-executor-mcp-server',
            'python-executor': 'python-executor-mcp-server',
            'browser': 'browser-navigator-mcp-server',
            'browser-navigator': 'browser-navigator-mcp-server',
        }
        
        # ç²¾ç¡®åŒ¹é…
        if tool_id in mapping:
            return mapping[tool_id]
        
        # éƒ¨åˆ†åŒ¹é…
        for key, value in mapping.items():
            if key in tool_id.lower():
                return value
        
        # é»˜è®¤è¿”å›åŸå§‹ID
        return tool_id
    def _format_trajectory_for_readable_output(self, trajectory: TrajectoryResult) -> Dict[str, Any]:
        """æ ¼å¼åŒ–è½¨è¿¹æ•°æ®ä»¥æé«˜å¯è¯»æ€§"""
        trajectory_dict = trajectory.to_dict()
        
        # æ ¼å¼åŒ–stepsï¼Œæ·»åŠ æ¢è¡Œä»¥æé«˜å¯è¯»æ€§
        formatted_steps = []
        for step in trajectory_dict['steps']:
            formatted_step = {
                'step_id': step['step_id'],
                'action_type': step['action_type'],
                'success': step['success']
            }
            
            # æ ¼å¼åŒ–tool_input - æ·»åŠ æ¢è¡Œä½¿å…¶æ›´æ˜“è¯»
            if step.get('tool_input'):
                formatted_step['tool_input'] = step['tool_input']
            
            # æ ¼å¼åŒ–tool_output - æ·»åŠ æ¢è¡Œä½¿å…¶æ›´æ˜“è¯»
            if step.get('tool_output'):
                output = step['tool_output']
                if len(output) > 100:
                    # é•¿è¾“å‡ºæ·»åŠ æ¢è¡Œ
                    formatted_step['tool_output'] = output
                else:
                    formatted_step['tool_output'] = output
            
            # æ·»åŠ å…¶ä»–é‡è¦å­—æ®µ
            if step.get('thinking'):
                formatted_step['thinking'] = step['thinking']
            if step.get('execution_code'):
                formatted_step['execution_code'] = step['execution_code']
            if step.get('error_type'):
                formatted_step['error_type'] = step['error_type']
            if step.get('error_message'):
                formatted_step['error_message'] = step['error_message']
            if step.get('duration'):
                formatted_step['duration'] = round(step['duration'], 3)
                
            formatted_steps.append(formatted_step)
        
        # åˆ›å»ºæ ¼å¼åŒ–çš„è½¨è¿¹å­—å…¸
        formatted_trajectory = {
            'task_id': trajectory_dict['task_id'],
            'task_name': trajectory_dict['task_name'],
            'task_description': trajectory_dict['task_description'],
            'runtime_id': trajectory_dict['runtime_id'],
            'success': trajectory_dict['success'],
            'steps': formatted_steps,
            'final_result': trajectory_dict['final_result'],
            'error_type': trajectory_dict['error_type'],
            'error_message': trajectory_dict['error_message'],
            'total_duration': round(trajectory_dict['total_duration'], 3),
            'metadata': trajectory_dict['metadata'],
            'created_at': trajectory_dict['created_at'],
            'available_tools': trajectory_dict['available_tools'],
            'used_tools': trajectory_dict['used_tools']
        }
        
        return formatted_trajectory

    async def _save_trajectory(self, trajectory: TrajectoryResult):
        """ä¿å­˜è½¨è¿¹åˆ°æ–‡ä»¶"""
        out_dir = get_trajectories_dir()
        
        collection_file = os.path.join(out_dir, "trajectories_collection.json")
        
        trajectories = []
        if os.path.exists(collection_file):
            try:
                with open(collection_file, 'r', encoding='utf-8') as f:
                    trajectories = json.load(f)
                    if not isinstance(trajectories, list):
                        trajectories = []
            except (json.JSONDecodeError, Exception) as e:
                logging.error(f"Error reading trajectories collection: {e}")
                trajectories = []
        
        # ä½¿ç”¨æ ¼å¼åŒ–çš„è½¨è¿¹æ•°æ®
        formatted_trajectory = self._format_trajectory_for_readable_output(trajectory)
        trajectories.append(formatted_trajectory)
        
        with open(collection_file, 'w', encoding='utf-8') as f:
            json.dump(trajectories, f, ensure_ascii=False, indent=2)
        
        logger.info(f"Saved trajectory {trajectory.task_id} to collection")
    
    async def _detect_error_patterns(self, steps: List[ExecutionStep], current_step_id: int) -> bool:
        """æ£€æµ‹é”™è¯¯æ¨¡å¼"""
        if len(steps) < 2:
            return False
        
        # è·å–æœ€è¿‘çš„æ­¥éª¤
        recent_steps = steps[-3:] if len(steps) >= 3 else steps
        
        # æ¨¡å¼1: è¿ç»­ç›¸åŒé”™è¯¯
        same_error_count = 0
        last_error = None
        for step in recent_steps:
            if not step.success:
                current_error = f"{step.error_type}:{step.error_message}"
                if current_error == last_error:
                    same_error_count += 1
                else:
                    same_error_count = 1
                    last_error = current_error
        
        if same_error_count >= 2:
            logger.warning(f"ğŸ” æ£€æµ‹åˆ°é‡å¤é”™è¯¯æ¨¡å¼: {last_error} (è¿ç»­{same_error_count}æ¬¡)")
            return True
        
        # æ¨¡å¼2: ç›¸åŒactionè¿ç»­å¤±è´¥
        same_action_failures = 0
        last_action = None
        for step in recent_steps:
            if not step.success:
                current_action = step.action_params.get('action') if step.action_params else None
                if current_action == last_action and current_action:
                    same_action_failures += 1
                else:
                    same_action_failures = 1
                    last_action = current_action
        
        if same_action_failures >= 2:
            logger.warning(f"ğŸ” æ£€æµ‹åˆ°ç›¸åŒactionè¿ç»­å¤±è´¥: {last_action} (è¿ç»­{same_action_failures}æ¬¡)")
            return True
        
        # æ¨¡å¼3: "LLMæœªæŒ‡å®štool_id"è¿ç»­å‡ºç°
        tool_id_errors = sum(1 for step in recent_steps 
                           if not step.success and "LLMæœªæŒ‡å®štool_id" in str(step.error_message))
        if tool_id_errors >= 2:
            logger.warning(f"ğŸ” æ£€æµ‹åˆ°LLM tool_idé”™è¯¯æ¨¡å¼ (è¿ç»­{tool_id_errors}æ¬¡)")
            return True
        
        # æ¨¡å¼4: "Unsupported action"è¿ç»­å‡ºç°
        action_errors = sum(1 for step in recent_steps 
                          if not step.success and "Unsupported action" in str(step.error_message))
        if action_errors >= 2:
            logger.warning(f"ğŸ” æ£€æµ‹åˆ°ä¸æ”¯æŒactioné”™è¯¯æ¨¡å¼ (è¿ç»­{action_errors}æ¬¡)")
            return True
        
        return False
    
    async def _apply_error_recovery(self, steps: List[ExecutionStep], current_step_id: int, task) -> str:
        """åº”ç”¨é”™è¯¯æ¢å¤ç­–ç•¥"""
        if len(steps) < 2:
            return "continue"
        
        recent_steps = steps[-3:]
        
        # åˆ†æé”™è¯¯ç±»å‹å¹¶åº”ç”¨å¯¹åº”æ¢å¤ç­–ç•¥
        for step in recent_steps:
            if not step.success:
                error_msg = str(step.error_message)
                
                # æ¢å¤ç­–ç•¥1: LLMå“åº”æ ¼å¼é—®é¢˜
                if "LLMæœªæŒ‡å®štool_id" in error_msg or "action" in str(step.action_params):
                    logger.info("ğŸ”§ åº”ç”¨æ¢å¤ç­–ç•¥: é‡æ–°å¼ºåŒ–promptçº¦æŸ")
                    # åœ¨ä¸‹ä¸€æ¬¡LLMè°ƒç”¨æ—¶åº”ç”¨æ›´å¼ºçš„çº¦æŸ
                    self._apply_stricter_prompt_constraints = True
                    return "adjust_strategy"
                
                # æ¢å¤ç­–ç•¥2: ä¸æ”¯æŒçš„action
                if "Unsupported action" in error_msg:
                    logger.info("ğŸ”§ åº”ç”¨æ¢å¤ç­–ç•¥: åˆ‡æ¢åˆ°åŸºç¡€å·¥å…·è°ƒç”¨")
                    # è®°å½•å¤±è´¥çš„actionï¼Œé¿å…é‡å¤ä½¿ç”¨
                    failed_action = step.action_params.get('action') if step.action_params else None
                    if failed_action:
                        if not hasattr(self, '_failed_actions'):
                            self._failed_actions = set()
                        self._failed_actions.add(failed_action)
                        logger.info(f"ğŸš« è®°å½•å¤±è´¥action: {failed_action}")
                    return "adjust_strategy"
                
                # æ¢å¤ç­–ç•¥3: è¿ç»­å·¥å…·è°ƒç”¨å¤±è´¥
                tool_failures = sum(1 for s in recent_steps if not s.success)
                if tool_failures >= 3:
                    logger.warning("ğŸ”§ åº”ç”¨æ¢å¤ç­–ç•¥: ä»»åŠ¡å¯èƒ½è¶…å‡ºå½“å‰å·¥å…·èƒ½åŠ›ï¼Œå»ºè®®ç»ˆæ­¢")
                    return "terminate"
        
        # é»˜è®¤ç­–ç•¥ï¼šè°ƒæ•´approach
        return "adjust_strategy"
    
    def _build_recovery_context(self, steps: List[ExecutionStep]) -> str:
        """æ„å»ºé”™è¯¯æ¢å¤ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        if not steps:
            return ""
        
        recent_failures = [s for s in steps[-3:] if not s.success]
        if not recent_failures:
            return ""
        
        recovery_context = "\nğŸ”§ é”™è¯¯æ¢å¤æŒ‡å¯¼:\n"
        
        # åˆ†æå¤±è´¥æ¨¡å¼
        failed_actions = set()
        failed_tools = set() 
        error_messages = set()
        
        for step in recent_failures:
            if step.action_params:
                action = step.action_params.get('action')
                tool_id = step.action_params.get('tool_id')
                if action:
                    failed_actions.add(action)
                if tool_id:
                    failed_tools.add(tool_id)
            
            if step.error_message:
                error_messages.add(str(step.error_message)[:100])
        
        if failed_actions:
            recovery_context += f"- é¿å…ä½¿ç”¨å¤±è´¥çš„actions: {', '.join(failed_actions)}\n"
        
        if failed_tools:
            recovery_context += f"- é¿å…é‡å¤å¤±è´¥çš„å·¥å…·: {', '.join(failed_tools)}\n"
        
        if error_messages:
            recovery_context += f"- å¸¸è§é”™è¯¯ç±»å‹: {'; '.join(error_messages)}\n"
        
        recovery_context += "- å»ºè®®: å°è¯•ä½¿ç”¨å…¶ä»–å¯ç”¨å·¥å…·æˆ–ä¸åŒçš„å‚æ•°é…ç½®\n"
        recovery_context += "- é‡è¦: ç¡®ä¿ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›å“åº”\n"
        
        return recovery_context

    async def _build_reflection_prompt(self, task, failed_action, failed_tool_id, failed_params, 
                                       error_message, thinking, available_tools_description):
        """æ„å»ºåæ€-çº æ­£promptï¼Œè®©LLMåˆ†æé”™è¯¯å¹¶ç”Ÿæˆä¿®æ­£çš„å·¥å…·è°ƒç”¨"""
        
        prompt_parts = [
            "# ğŸ§  Agent Error Analysis and Correction",
            "",
            "You are an intelligent Agent that needs to analyze a failed tool execution and provide a corrected approach.",
            "",
            f"## ğŸ“‹ Original Task",
            f"**Task**: {task.description}",
            "",
            "## âŒ Failed Execution Details",
            f"**Failed Tool**: {failed_tool_id}",
            f"**Failed Action**: {failed_action}",
            f"**Failed Parameters**: {json.dumps(failed_params, indent=2)}",
            f"**Error Message**: {error_message}",
            "",
            "## ğŸ¤” Previous Thinking Process",
            f"```",
            f"{thinking}",
            f"```",
            "",
            "## ğŸ”§ Available Tools",
            f"{available_tools_description}",
            "",
            "## ğŸ¯ Your Task: Error Analysis and Correction",
            "",
            "Analyze the failure and provide a **corrected** tool call. Common issues to check:",
            "",
            "### For microsandbox:",
            "- âœ… **CRITICAL**: `microsandbox_execute` MUST have `code` parameter",
            "- âœ… Example: `{\"code\": \"print('Hello World')\"}` âœ…",
            "- âŒ Missing `code` parameter = FAILURE",
            "",
            "### For browser_use:",
            "- âœ… **CRITICAL**: `browser_navigate` MUST have `url` parameter",
            "- âœ… Example: `{\"url\": \"https://python.org\"}` âœ…",
            "",
            "### For deepsearch:",
            "- âœ… **CRITICAL**: `research` MUST have `question` parameter",
            "- âœ… Example: `{\"question\": \"Python asyncio basics\"}` âœ…",
            "",
            "## ğŸ“¤ Required Response Format",
            "",
            "Analyze the error and return ONLY this JSON with the **corrected** tool call:",
            "",
            "```json",
            "{",
            '  "thinking": "ERROR ANALYSIS: [What went wrong?] CORRECTION: [How to fix it?]",',
            '  "confidence": 0.9,',
            '  "tool_id": "corrected-tool-id",',
            '  "action": "corrected-action-name",',
            '  "parameters": {',
            '    "corrected_param_1": "value1",',
            '    "corrected_param_2": "value2"',
            '  }',
            "}",
            "```",
            "",
            "**âš ï¸ CRITICAL REQUIREMENTS:**",
            "1. **FIX the specific error mentioned above**",
            "2. **Include ALL required parameters for the chosen tool**",
            "3. **NO other text outside the JSON object**",
            "",
            "Analyze the error and provide the corrected tool call now:"
        ]
        
        return [{"role": "user", "content": "\n".join(prompt_parts)}]

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        logger.info("ğŸ§¹ æ¸…ç†Enhanced Reasoning Runtimeèµ„æº")
        
        # å…³é—­ToolScoreå®¢æˆ·ç«¯
        if self.toolscore_client:
            await self.toolscore_client.close()
        
        # å…³é—­å®æ—¶å®¢æˆ·ç«¯
        if self.real_time_client:
            await self.real_time_client.close()
        
        # æ¸…ç†MCPå®¢æˆ·ç«¯
        if self.mcp_client:
            await self.mcp_client.cleanup()
    
    def _analyze_task_completion_objectively(self, task: TaskSpec, steps: List[ExecutionStep], current_outputs: List[str]) -> Dict[str, Any]:
        """
        å®¢è§‚åˆ†æä»»åŠ¡å®Œæˆåº¦
        
        Args:
            task: ä»»åŠ¡è§„èŒƒ
            steps: æ‰§è¡Œæ­¥éª¤
            current_outputs: å½“å‰è¾“å‡º
            
        Returns:
            åŒ…å«å®Œæˆåº¦åˆ†æç»“æœçš„å­—å…¸
        """
        try:
            # æå–ä»»åŠ¡ä¸­çš„å­ä»»åŠ¡è¦æ±‚
            sub_tasks = self._extract_task_requirements(task.description)
            
            # åˆ†ææ‰§è¡Œæ­¥éª¤
            successful_steps = [s for s in steps if s.success]
            tool_steps = [s for s in steps if s.action_type == ActionType.TOOL_CALL and s.step_id > 1]
            successful_tool_steps = [s for s in tool_steps if s.success]
            
            # ç»Ÿè®¡å·¥å…·ä½¿ç”¨æƒ…å†µ
            used_tools = set()
            for step in successful_tool_steps:
                if hasattr(step, 'tool_id') and step.tool_id:
                    used_tools.add(step.tool_id)
            
            # è®¡ç®—å…³é”®æŒ‡æ ‡
            success_rate = len(successful_steps) / len(steps) if steps else 0
            tool_diversity = len(used_tools)
            output_quality = self._assess_output_quality(current_outputs)
            
            # æ£€æŸ¥å­ä»»åŠ¡å®Œæˆæƒ…å†µ
            sub_task_completion = self._check_sub_task_completion(sub_tasks, successful_tool_steps, current_outputs)
            
            # ç»¼åˆåˆ¤æ–­
            metrics = {
                'total_steps': len(steps),
                'successful_steps': len(successful_steps),
                'success_rate': success_rate,
                'tool_steps': len(tool_steps),
                'successful_tool_steps': len(successful_tool_steps),
                'tool_diversity': tool_diversity,
                'used_tools': list(used_tools),
                'output_quality_score': output_quality['score'],
                'output_total_length': output_quality['total_length'],
                'sub_tasks_identified': len(sub_tasks),
                'sub_tasks_completed': sub_task_completion['completed_count'],
                'sub_task_completion_rate': sub_task_completion['completion_rate']
            }
            
            # å†³ç­–é€»è¾‘
            should_complete = self._decide_completion(metrics, sub_task_completion)
            
            reason = self._generate_completion_reason(should_complete, metrics, sub_task_completion)
            
            return {
                'should_complete': should_complete,
                'reason': reason,
                'metrics': metrics,
                'sub_task_analysis': sub_task_completion
            }
            
        except Exception as e:
            logger.error(f"å®¢è§‚å®Œæˆåº¦åˆ†æå¤±è´¥: {e}")
            return {
                'should_complete': False,
                'reason': f"åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}",
                'metrics': {},
                'sub_task_analysis': {}
            }
    
    def _extract_task_requirements(self, task_description: str) -> List[Dict[str, str]]:
        """ä»ä»»åŠ¡æè¿°ä¸­æå–å­ä»»åŠ¡è¦æ±‚"""
        import re
        
        sub_tasks = []
        
        # åŒ¹é…æ˜ç¡®çš„å·¥å…·è¦æ±‚
        tool_patterns = [
            (r'ç”¨?([A-Za-z\-_]+).*?([ç ”ç©¶|è°ƒç ”|æœç´¢|æŸ¥æ‰¾|åˆ†æ])', 'research'),
            (r'ç”¨?([A-Za-z\-_]*[Ss]andbox[A-Za-z\-_]*).*?([æ‰§è¡Œ|è¿è¡Œ|ç¼–å†™|ä»£ç ])', 'execution'),
            (r'ç”¨?([A-Za-z\-_]*[Ss]earch[A-Za-z\-_]*).*?([æœç´¢|æŸ¥æ‰¾|æ£€ç´¢])', 'search'),
            (r'ç”¨?([A-Za-z\-_]*[Bb]rowser[A-Za-z\-_]*).*?([æµè§ˆ|è®¿é—®|å¯¼èˆª])', 'browse')
        ]
        
        for pattern, task_type in tool_patterns:
            matches = re.findall(pattern, task_description, re.IGNORECASE)
            for match in matches:
                tool_hint = match[0] if isinstance(match, tuple) else match
                action_hint = match[1] if isinstance(match, tuple) and len(match) > 1 else task_type
                
                sub_tasks.append({
                    'type': task_type,
                    'tool_hint': tool_hint,
                    'action_hint': action_hint,
                    'description': f"{action_hint}ä»»åŠ¡(å·¥å…·æç¤º: {tool_hint})"
                })
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ç¡®çš„å·¥å…·è¦æ±‚ï¼ŒæŒ‰æ­¥éª¤åˆ†æ
        if not sub_tasks:
            step_patterns = [
                r'å…ˆ(.+?)(?:ç„¶å|ï¼Œ|ã€‚|$)',
                r'ç„¶å(.+?)(?:æœ€å|ï¼Œ|ã€‚|$)', 
                r'æœ€å(.+?)(?:ï¼Œ|ã€‚|$)',
                r'ç¬¬?[ä¸€äºŒä¸‰1-3]æ­¥?[:ï¼š](.+?)(?:ç¬¬?[äºŒä¸‰å››2-4]æ­¥?|ï¼Œ|ã€‚|$)'
            ]
            
            for pattern in step_patterns:
                matches = re.findall(pattern, task_description, re.IGNORECASE)
                for i, match in enumerate(matches):
                    task_text = match.strip()
                    if len(task_text) > 5:
                        sub_tasks.append({
                            'type': 'general',
                            'tool_hint': '',
                            'action_hint': '',
                            'description': task_text
                        })
        
        return sub_tasks[:5]  # æœ€å¤š5ä¸ªå­ä»»åŠ¡
    
    async def _validate_tool_parameters(self, tool_id: str, action: str, params: Dict[str, Any]) -> Tuple[bool, str]:
        """
        å¢å¼ºå‚æ•°æ ¡éªŒ (P0-1: å‚æ•°æ ¡éªŒ&è‡ªåŠ¨è¡¥é½)
        åœ¨å·¥å…·è°ƒç”¨å‰æ‰§è¡Œå…¨é¢çš„å‚æ•°æ£€æŸ¥ã€éªŒè¯å’Œè‡ªåŠ¨è¡¥é½
        
        Args:
            tool_id: å·¥å…·ID
            action: åŠ¨ä½œåç§°
            params: å‚æ•°å­—å…¸
            
        Returns:
            (is_valid, error_message): æ ¡éªŒç»“æœå’Œé”™è¯¯ä¿¡æ¯
        """
        try:
            # ğŸ›‘ åŸºæœ¬å‚æ•°æ£€æŸ¥
            if not tool_id:
                return False, "å·¥å…·IDä¸èƒ½ä¸ºç©º"
            
            if not action:
                return False, "åŠ¨ä½œåç§°ä¸èƒ½ä¸ºç©º"
            
            if not isinstance(params, dict):
                return False, f"å‚æ•°å¿…é¡»æ˜¯å­—å…¸ç±»å‹ï¼Œå½“å‰ç±»å‹: {type(params)}"
            
            # ğŸ†• P0-1: ä½¿ç”¨å¢å¼ºå‚æ•°æ ¡éªŒå™¨è¿›è¡Œå…¨é¢æ ¡éªŒ
            parameter_validator = get_parameter_validator()
            
            # è·å–å½“å‰ä»»åŠ¡æè¿°ç”¨äºæ™ºèƒ½è¡¥é½
            task_description = getattr(self, 'current_task_description', '')
            
            # æ‰§è¡Œå‚æ•°æ ¡éªŒ
            validation_result = parameter_validator.validate_tool_call(
                tool_id, action, params, task_description
            )
            
            if not validation_result.is_valid:
                # å°è¯•è‡ªåŠ¨è¡¥é½ç¼ºå¤±å‚æ•°
                logger.warning(f"âš ï¸ å‚æ•°æ ¡éªŒå¤±è´¥: {validation_result.error_message}")
                logger.info(f"ğŸ”§ å°è¯•è‡ªåŠ¨è¡¥é½ç¼ºå¤±å‚æ•°: {validation_result.missing_required}")
                
                # ğŸ”§ é¢„å¤„ç†ï¼šæ™ºèƒ½å‚æ•°æ˜ å°„
                mapped_params = self._map_common_parameter_names(tool_id, action, params)
                
                # è‡ªåŠ¨è¡¥é½å‚æ•°
                completed_params = parameter_validator.auto_complete_parameters(
                    tool_id, action, mapped_params, task_description
                )
                
                # é‡æ–°æ ¡éªŒè¡¥é½åçš„å‚æ•°
                retry_validation = parameter_validator.validate_tool_call(
                    tool_id, action, completed_params, task_description
                )
                
                if retry_validation.is_valid:
                    logger.info(f"âœ… å‚æ•°è‡ªåŠ¨è¡¥é½æˆåŠŸï¼Œæ›´æ–°å‚æ•°: {completed_params}")
                    # æ›´æ–°åŸå§‹å‚æ•°å­—å…¸
                    params.clear()
                    params.update(completed_params)
                else:
                    return False, f"å‚æ•°è¡¥é½åä»ç„¶æ— æ•ˆ: {retry_validation.error_message}"
            
            # ğŸ”§ å°è¯•ä½¿ç”¨ToolSchemaManagerè¿›è¡Œé¢å¤–æ ¡éªŒ
            try:
                # æ£€æŸ¥å·¥å…·åŠ¨ä½œæ˜¯å¦å­˜åœ¨
                is_valid_action = await self.tool_schema_manager.validate_tool_action(tool_id, action)
                if not is_valid_action:
                    return False, f"ä¸æ”¯æŒçš„å·¥å…·åŠ¨ä½œ: {tool_id}.{action}"
                
                # è·å–å‚æ•°Schemaè¿›è¡ŒéªŒè¯
                param_schema = await self.tool_schema_manager.get_action_parameters_schema(tool_id, action)
                if param_schema:
                    validation_result = self._validate_against_schema(params, param_schema)
                    if not validation_result[0]:
                        return validation_result
                        
            except Exception as schema_error:
                logger.debug(f"Schemaæ ¡éªŒå¤±è´¥ï¼Œå·²é€šè¿‡å¢å¼ºæ ¡éªŒå™¨: {schema_error}")
            
            # ğŸ›‘ ç‰¹å®šå·¥å…·çš„å…³é”®å‚æ•°æ ¡éªŒï¼ˆç¡¬ç¼–ç è§„åˆ™ï¼‰
            validation_rules = {
                'microsandbox': {
                    'microsandbox_execute': ['code'],
                    'run_code': ['code'],
                    'execute': ['code']
                },
                'browser_use': {
                    'browser_navigate': ['url'],
                    'browser_use_execute_task': ['task'],
                    'browser_click_element': ['index'],
                    'browser_input_text': ['index', 'text'],
                    'browser_extract_content': [],
                    'browser_search_google': ['query']
                },
                'deepsearch': {
                    'research': ['question'],
                    'comprehensive_research': ['question'],
                    'quick_research': ['question']
                },
                'mcp-search-tool': {
                    'analyze_tool_needs': ['task_description'],
                    'search_and_install_tools': ['task_description']
                }
            }
            
            # æŸ¥æ‰¾åŒ¹é…çš„è§„åˆ™
            tool_rules = None
            for rule_tool_id, rules in validation_rules.items():
                if rule_tool_id in tool_id or tool_id in rule_tool_id:
                    tool_rules = rules
                    break
            
            if tool_rules and action in tool_rules:
                required_params = tool_rules[action]
                for required_param in required_params:
                    if required_param not in params:
                        return False, f"ç¼ºå°‘å¿…éœ€å‚æ•°: {required_param} (å·¥å…·: {tool_id}, åŠ¨ä½œ: {action})"
                    
                    param_value = params[required_param]
                    if param_value is None or (isinstance(param_value, str) and not param_value.strip()):
                        return False, f"å‚æ•° {required_param} ä¸èƒ½ä¸ºç©º (å·¥å…·: {tool_id}, åŠ¨ä½œ: {action})"
            
            # ğŸ›‘ é€šç”¨å‚æ•°æ ¼å¼æ ¡éªŒ
            for param_name, param_value in params.items():
                # æ£€æŸ¥URLæ ¼å¼
                if 'url' in param_name.lower() and isinstance(param_value, str):
                    if param_value and not param_value.startswith(('http://', 'https://')):
                        return False, f"å‚æ•° {param_name} å¿…é¡»æ˜¯æœ‰æ•ˆçš„URLæ ¼å¼ (å½“å‰å€¼: {param_value})"
                
                # æ£€æŸ¥ä»£ç å‚æ•°
                if param_name == 'code' and isinstance(param_value, str):
                    if not param_value.strip():
                        return False, f"ä»£ç å‚æ•°ä¸èƒ½ä¸ºç©º"
                    
                    # æ£€æŸ¥å±é™©ä»£ç æ¨¡å¼
                    dangerous_patterns = ['rm -rf', 'del /f', 'format c:', '__import__', 'eval(', 'exec(']
                    for pattern in dangerous_patterns:
                        if pattern in param_value.lower():
                            return False, f"æ£€æµ‹åˆ°æ½œåœ¨å±é™©ä»£ç æ¨¡å¼: {pattern}"
            
            return True, ""
            
        except Exception as e:
            logger.error(f"å‚æ•°æ ¡éªŒå¼‚å¸¸: {e}")
            return False, f"å‚æ•°æ ¡éªŒå¼‚å¸¸: {str(e)}"
    
    def _map_common_parameter_names(self, tool_id: str, action: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ™ºèƒ½å‚æ•°æ˜ å°„ï¼šå°†å¸¸è§çš„å‚æ•°åæ˜ å°„åˆ°å·¥å…·æœŸæœ›çš„å‚æ•°å
        
        Args:
            tool_id: å·¥å…·ID
            action: åŠ¨ä½œå
            params: åŸå§‹å‚æ•°
            
        Returns:
            æ˜ å°„åçš„å‚æ•°å­—å…¸
        """
        try:
            # åˆ›å»ºæ˜ å°„åçš„å‚æ•°å‰¯æœ¬
            mapped_params = params.copy()
            
            # ğŸ”§ P1-1ä¿®å¤ï¼šæ‰©å±•å‚æ•°æ˜ å°„è§„åˆ™è¦†ç›–æ›´å¤šåˆ«å
            parameter_mappings = {
                'deepsearch': {
                    # æ‰€æœ‰åŠ¨ä½œéƒ½ä½¿ç”¨questionå‚æ•°
                    '*': {
                        'task_description': 'question',
                        'query': 'question',
                        'search_query': 'question',
                        'research_topic': 'question',
                        'research_query': 'question',
                        'search_term': 'question',
                        'search_content': 'question',
                        'topic': 'question',
                        'content': 'question',
                        'text': 'question',
                        'keywords': 'question',
                        'subject': 'question',
                        'prompt': 'question',
                        'description': 'question',
                        'objective': 'question',
                        'goal': 'question',
                        'task': 'question',
                        'requirement': 'question',
                        'request': 'question'
                    }
                },
                'mcp-search-tool': {
                    'analyze_tool_needs': {
                        'question': 'task_description',
                        'query': 'task_description',
                        'requirement': 'task_description',
                        'need': 'task_description',
                        'description': 'task_description',
                        'objective': 'task_description',
                        'goal': 'task_description',
                        'purpose': 'task_description',
                        'task': 'task_description',
                        'request': 'task_description',
                        'prompt': 'task_description'
                    },
                    'search_and_install_tools': {
                        'question': 'task_description',
                        'query': 'task_description',
                        'requirement': 'task_description',
                        'need': 'task_description',
                        'description': 'task_description',
                        'objective': 'task_description',
                        'goal': 'task_description',
                        'purpose': 'task_description',
                        'task': 'task_description',
                        'request': 'task_description',
                        'prompt': 'task_description'
                    },
                    'search_file_content': {
                        'query': 'search_term',
                        'search_query': 'search_term',
                        'term': 'search_term',
                        'content': 'search_term',
                        'pattern': 'search_term',
                        'keyword': 'search_term',
                        'text': 'search_term',
                        'string': 'search_term',
                        'phrase': 'search_term',
                        'expression': 'search_term'
                    }
                },
                'microsandbox': {
                    '*': {
                        'script': 'code',
                        'python_code': 'code',
                        'command': 'code',
                        'program': 'code',
                        'source': 'code',
                        'content': 'code',
                        'text': 'code',
                        'snippet': 'code',
                        'instructions': 'code',
                        'implementation': 'code',
                        'algorithm': 'code',
                        'function': 'code',
                        'method': 'code',
                        'procedure': 'code'
                    }
                },
                'browser_use': {
                    # ğŸ”§ P0ç´§æ€¥ä¿®å¤1: ä¿®æ­£browseråŠ¨ä½œåç§°å’Œå‚æ•°æ˜ å°„
                    'browser_navigate': {
                        'link': 'url',
                        'address': 'url',
                        'site': 'url',
                        'website': 'url',
                        'page': 'url',
                        'target': 'url',
                        'destination': 'url',
                        'location': 'url',
                        'path': 'url',
                        'endpoint': 'url',
                        'resource': 'url'
                    },
                    'browser_use_execute_task': {
                        'question': 'task',
                        'objective': 'task',
                        'goal': 'task',
                        'description': 'task',
                        'instruction': 'task'
                    },
                    'browser_click_element': {
                        'element': 'index',
                        'target': 'index',
                        'position': 'index',
                        'number': 'index'
                    },
                    'browser_input_text': {
                        'content': 'text',
                        'input': 'text',
                        'value': 'text',
                        'string': 'text',
                        'message': 'text',
                        'data': 'text'
                    },
                    'browser_extract_content': {
                        # æ²¡æœ‰ç‰¹å®šå‚æ•°æ˜ å°„ï¼Œè¯¥åŠ¨ä½œä¸éœ€è¦å‚æ•°
                    },
                    'browser_search_google': {
                        'search_term': 'query',
                        'search_query': 'query',
                        'keywords': 'query',
                        'term': 'query'
                    }
                },
                # æ–°å¢å·¥å…·æ˜ å°„
                'filesystem': {
                    'read_file': {
                        'filename': 'path',
                        'file': 'path',
                        'filepath': 'path',
                        'file_path': 'path',
                        'location': 'path',
                        'source': 'path',
                        'target': 'path'
                    },
                    'write_file': {
                        'filename': 'path',
                        'file': 'path',
                        'filepath': 'path',
                        'file_path': 'path',
                        'destination': 'path',
                        'target': 'path',
                        'data': 'content',
                        'text': 'content',
                        'body': 'content'
                    },
                    'list_directory': {
                        'directory': 'path',
                        'dir': 'path',
                        'folder': 'path',
                        'location': 'path',
                        'target': 'path'
                    }
                },
                'database': {
                    'execute_query': {
                        'sql': 'query',
                        'statement': 'query',
                        'command': 'query',
                        'script': 'query'
                    },
                    'insert_data': {
                        'table_name': 'table',
                        'target_table': 'table',
                        'destination': 'table',
                        'record': 'data',
                        'row': 'data',
                        'values': 'data'
                    }
                },
                'api-client': {
                    'make_request': {
                        'endpoint': 'url',
                        'api_url': 'url',
                        'target': 'url',
                        'destination': 'url',
                        'payload': 'data',
                        'body': 'data',
                        'content': 'data',
                        'parameters': 'data'
                    }
                },
                'text-processing': {
                    'analyze_text': {
                        'input': 'text',
                        'content': 'text',
                        'data': 'text',
                        'string': 'text',
                        'document': 'text',
                        'passage': 'text'
                    },
                    'transform_text': {
                        'input': 'text',
                        'content': 'text',
                        'source': 'text',
                        'original': 'text'
                    }
                }
            }
            
            # è·å–å·¥å…·çš„æ˜ å°„è§„åˆ™
            if tool_id in parameter_mappings:
                tool_mappings = parameter_mappings[tool_id]
                
                # æŸ¥æ‰¾åŠ¨ä½œç‰¹å®šçš„æ˜ å°„æˆ–é€šç”¨æ˜ å°„
                action_mappings = tool_mappings.get(action, tool_mappings.get('*', {}))
                
                # åº”ç”¨æ˜ å°„
                for old_param, new_param in action_mappings.items():
                    if old_param in mapped_params and new_param not in mapped_params:
                        mapped_params[new_param] = mapped_params[old_param]
                        # å¦‚æœæ–°å‚æ•°åä¸åŒäºæ—§å‚æ•°åï¼Œåˆ é™¤æ—§å‚æ•°
                        if old_param != new_param:
                            del mapped_params[old_param]
                            logger.debug(f"ğŸ”§ å‚æ•°æ˜ å°„: {old_param} -> {new_param}")
            
            # ç§»é™¤ç³»ç»Ÿå†…éƒ¨å‚æ•°
            system_params = {'action', 'tool_id', 'tool', 'thinking', 'reasoning'}
            for sys_param in system_params:
                if sys_param in mapped_params:
                    del mapped_params[sys_param]
                    logger.debug(f"ğŸ§¹ ç§»é™¤ç³»ç»Ÿå‚æ•°: {sys_param}")
            
            return mapped_params
            
        except Exception as e:
            logger.warning(f"âš ï¸ å‚æ•°æ˜ å°„å¤±è´¥: {e}")
            return params

    def _validate_against_schema(self, params: Dict[str, Any], schema: Dict[str, Any]) -> Tuple[bool, str]:
        """
        æ ¹æ®Schemaæ ¡éªŒå‚æ•°
        
        Args:
            params: è¦æ ¡éªŒçš„å‚æ•°
            schema: å‚æ•°Schema
            
        Returns:
            (is_valid, error_message): æ ¡éªŒç»“æœ
        """
        try:
            for param_name, param_config in schema.items():
                param_desc = str(param_config)
                
                # æ£€æŸ¥å¿…éœ€å‚æ•°
                if 'å¿…éœ€' in param_desc or 'required' in param_desc.lower():
                    if param_name not in params:
                        return False, f"ç¼ºå°‘å¿…éœ€å‚æ•°: {param_name}"
                    
                    if params[param_name] is None or (isinstance(params[param_name], str) and not params[param_name].strip()):
                        return False, f"å¿…éœ€å‚æ•° {param_name} ä¸èƒ½ä¸ºç©º"
            
            return True, ""
            
        except Exception as e:
            logger.debug(f"Schemaæ ¡éªŒå¼‚å¸¸: {e}")
            return True, ""  # å®¹é”™å¤„ç†ï¼Œå¦‚æœSchemaæ ¡éªŒå¤±è´¥åˆ™é€šè¿‡
    
    def _assess_output_quality(self, outputs: List[str]) -> Dict[str, Any]:
        """è¯„ä¼°è¾“å‡ºè´¨é‡"""
        if not outputs:
            return {'score': 0.0, 'total_length': 0}
        
        total_length = sum(len(output) for output in outputs)
        
        # åŸºäºé•¿åº¦å’Œå†…å®¹ä¸°å¯Œåº¦è¯„åˆ†
        if total_length == 0:
            score = 0.0
        elif total_length < 100:
            score = 0.2
        elif total_length < 500:
            score = 0.5
        elif total_length < 2000:
            score = 0.8
        else:
            score = 1.0
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç»“æ„åŒ–å†…å®¹
        has_structure = any(
            ('```' in output or 
             output.count('\n') > 3 or 
             any(keyword in output.lower() for keyword in ['ç»“æœ', 'æ€»ç»“', 'åˆ†æ', 'å»ºè®®', 'æ­¥éª¤']))
            for output in outputs
        )
        
        if has_structure:
            score = min(1.0, score + 0.2)
        
        return {
            'score': score,
            'total_length': total_length,
            'has_structure': has_structure
        }
    
    def _check_sub_task_completion(self, sub_tasks: List[Dict], successful_tool_steps: List[ExecutionStep], outputs: List[str]) -> Dict[str, Any]:
        """æ£€æŸ¥å­ä»»åŠ¡å®Œæˆæƒ…å†µ"""
        if not sub_tasks:
            return {
                'completed_count': 0,
                'completion_rate': 0.0,
                'details': []
            }
        
        completed_count = 0
        details = []
        
        # ç»Ÿè®¡å·²ä½¿ç”¨çš„å·¥å…·
        used_tools = set()
        for step in successful_tool_steps:
            if hasattr(step, 'tool_id') and step.tool_id:
                used_tools.add(step.tool_id.lower())
        
        for sub_task in sub_tasks:
            is_completed = False
            evidence = []
            
            # æ£€æŸ¥å·¥å…·åŒ¹é…
            tool_hint = sub_task.get('tool_hint', '').lower()
            task_type = sub_task.get('type', '')
            
            if tool_hint:
                # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸å…³å·¥å…·è¢«ä½¿ç”¨
                tool_matched = any(tool_hint in used_tool for used_tool in used_tools)
                if tool_matched:
                    evidence.append(f"ä½¿ç”¨äº†ç›¸å…³å·¥å…·({tool_hint})")
                    is_completed = True
            
            # åŸºäºä»»åŠ¡ç±»å‹æ£€æŸ¥
            if task_type == 'research' and any('deepsearch' in tool or 'search' in tool for tool in used_tools):
                evidence.append("æ‰§è¡Œäº†ç ”ç©¶/æœç´¢ä»»åŠ¡")
                is_completed = True
            elif task_type == 'execution' and any('sandbox' in tool for tool in used_tools):
                evidence.append("æ‰§è¡Œäº†ä»£ç /æ²™ç®±ä»»åŠ¡")
                is_completed = True
            elif task_type == 'search' and any('search' in tool for tool in used_tools):
                evidence.append("æ‰§è¡Œäº†æœç´¢ä»»åŠ¡")
                is_completed = True
            
            # æ£€æŸ¥è¾“å‡ºä¸­æ˜¯å¦æœ‰ç›¸å…³å†…å®¹
            if outputs and not is_completed:
                output_text = ' '.join(outputs).lower()
                keywords = sub_task.get('description', '').lower().split()[:3]  # å–å‰3ä¸ªå…³é”®è¯
                if any(keyword in output_text for keyword in keywords if len(keyword) > 2):
                    evidence.append("è¾“å‡ºä¸­åŒ…å«ç›¸å…³å†…å®¹")
                    is_completed = True
            
            if is_completed:
                completed_count += 1
            
            details.append({
                'task': sub_task.get('description', ''),
                'completed': is_completed,
                'evidence': evidence
            })
        
        completion_rate = completed_count / len(sub_tasks) if sub_tasks else 0.0
        
        return {
            'completed_count': completed_count,
            'completion_rate': completion_rate,
            'details': details
        }
    
    def _decide_completion(self, metrics: Dict[str, Any], sub_task_completion: Dict[str, Any]) -> bool:
        """åŸºäºæŒ‡æ ‡å†³å®šæ˜¯å¦å®Œæˆ"""
        
        # åŸºæœ¬æ¡ä»¶æ£€æŸ¥
        has_minimum_execution = (
            metrics['successful_tool_steps'] >= 1 and
            metrics['success_rate'] >= 0.5
        )
        
        # è¾“å‡ºè´¨é‡æ£€æŸ¥
        has_quality_output = metrics['output_quality_score'] >= 0.5
        
        # å­ä»»åŠ¡å®Œæˆåº¦æ£€æŸ¥
        sub_task_threshold = 0.6 if metrics['sub_tasks_identified'] > 1 else 0.5
        has_sub_task_completion = sub_task_completion['completion_rate'] >= sub_task_threshold
        
        # å·¥å…·å¤šæ ·æ€§æ£€æŸ¥ï¼ˆå¯¹äºå¤æ‚ä»»åŠ¡ï¼‰
        if metrics['sub_tasks_identified'] >= 3:
            has_tool_diversity = metrics['tool_diversity'] >= 2
        else:
            has_tool_diversity = metrics['tool_diversity'] >= 1
        
        # ç»¼åˆåˆ¤æ–­
        completion_score = (
            (0.3 if has_minimum_execution else 0) +
            (0.2 if has_quality_output else 0) +
            (0.3 if has_sub_task_completion else 0) +
            (0.2 if has_tool_diversity else 0)
        )
        
        return completion_score >= 0.7
    
    def _generate_completion_reason(self, should_complete: bool, metrics: Dict[str, Any], sub_task_completion: Dict[str, Any]) -> str:
        """ç”Ÿæˆå®Œæˆåˆ¤æ–­çš„åŸå› è¯´æ˜"""
        
        if should_complete:
            reasons = []
            if metrics['successful_tool_steps'] > 0:
                reasons.append(f"æˆåŠŸæ‰§è¡Œäº†{metrics['successful_tool_steps']}ä¸ªå·¥å…·æ­¥éª¤")
            if metrics['tool_diversity'] > 1:
                reasons.append(f"ä½¿ç”¨äº†{metrics['tool_diversity']}ç§ä¸åŒå·¥å…·")
            if sub_task_completion['completion_rate'] > 0:
                reasons.append(f"å­ä»»åŠ¡å®Œæˆç‡{sub_task_completion['completion_rate']:.1%}")
            if metrics['output_quality_score'] > 0.5:
                reasons.append(f"è¾“å‡ºè´¨é‡è¯„åˆ†{metrics['output_quality_score']:.1f}")
            
            return f"ä»»åŠ¡å·²å®Œæˆ: {', '.join(reasons)}"
        else:
            problems = []
            if metrics['successful_tool_steps'] == 0:
                problems.append("æ²¡æœ‰æˆåŠŸçš„å·¥å…·æ‰§è¡Œ")
            elif metrics['tool_diversity'] == 0:
                problems.append("æ²¡æœ‰ä½¿ç”¨ä»»ä½•å·¥å…·")
            elif sub_task_completion['completion_rate'] < 0.5:
                problems.append(f"å­ä»»åŠ¡å®Œæˆç‡è¿‡ä½({sub_task_completion['completion_rate']:.1%})")
            elif metrics['output_quality_score'] < 0.3:
                problems.append("è¾“å‡ºè´¨é‡ä¸è¶³")
            
            return f"ä»»åŠ¡æœªå®Œæˆ: {', '.join(problems) if problems else 'æœªè¾¾åˆ°å®Œæˆæ ‡å‡†'}"
    
    def _analyze_error_and_determine_strategy(self, error_type: ErrorType, error_msg: str, 
                                            attempt: int, max_retries: int) -> Dict[str, bool]:
        """
        Sprint 1: å¢å¼ºé”™è¯¯åˆ†æå’Œé‡è¯•ç­–ç•¥å†³ç­– (P1 é—®é¢˜ä¿®å¤)
        
        Args:
            error_type: é”™è¯¯ç±»å‹
            error_msg: é”™è¯¯æ¶ˆæ¯
            attempt: å½“å‰å°è¯•æ¬¡æ•°
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            
        Returns:
            åŒ…å«é‡è¯•ç­–ç•¥å†³ç­–çš„å­—å…¸
        """
        error_msg_lower = error_msg.lower()
        
        # ğŸš¨ ä¸å¯é‡è¯•çš„é”™è¯¯æ¨¡å¼
        non_retryable_patterns = [
            'æƒé™è¢«æ‹’ç»', 'permission denied', 'access denied',
            'æœªæ‰¾åˆ°å·¥å…·', 'tool not found', 'command not found',
            'é…ç½®é”™è¯¯', 'configuration error', 'config error',
            'èº«ä»½éªŒè¯å¤±è´¥', 'authentication failed', 'auth failed'
        ]
        
        should_abort = any(pattern in error_msg_lower for pattern in non_retryable_patterns)
        if should_abort:
            return {'should_reflect': False, 'is_simple_retryable': False, 'should_abort': True}
        
        # ğŸ”„ ç®€å•é‡è¯•çš„é”™è¯¯ç±»å‹ï¼ˆç½‘ç»œã€è¶…æ—¶ã€é™æµç­‰ï¼‰
        simple_retryable_types = [ErrorType.NETWORK_ERROR, ErrorType.TIMEOUT, ErrorType.RATE_LIMIT]
        simple_retryable_patterns = [
            'timeout', 'è¶…æ—¶', 'connection', 'è¿æ¥', 'network', 'ç½‘ç»œ',
            'rate limit', 'é™æµ', 'too many requests', 'è¯·æ±‚è¿‡å¤š',
            'service unavailable', 'æœåŠ¡ä¸å¯ç”¨', 'server error', 'æœåŠ¡å™¨é”™è¯¯'
        ]
        
        is_simple_retryable = (
            error_type in simple_retryable_types or
            any(pattern in error_msg_lower for pattern in simple_retryable_patterns)
        )
        
        # ğŸ§  éœ€è¦åæ€çº æ­£çš„é”™è¯¯æ¨¡å¼
        reflection_patterns = [
            # å‚æ•°é”™è¯¯
            'ä»£ç ä¸èƒ½ä¸ºç©º', 'code cannot be empty', 'missing code',
            'å‚æ•°', 'parameter', 'required', 'missing', 'ç¼ºå°‘',
            'invalid parameter', 'æ— æ•ˆå‚æ•°',
            # åŠ¨ä½œé”™è¯¯
            'unsupported action', 'ä¸æ”¯æŒçš„åŠ¨ä½œ', 'action not found',
            'invalid action', 'æ— æ•ˆåŠ¨ä½œ',
            # å·¥å…·ä½¿ç”¨é”™è¯¯
            'tool usage error', 'å·¥å…·ä½¿ç”¨é”™è¯¯',
            'incorrect usage', 'ä½¿ç”¨ä¸æ­£ç¡®',
            # JSONæ ¼å¼é”™è¯¯
            'json', 'format', 'æ ¼å¼', 'syntax', 'è¯­æ³•'
        ]
        
        needs_reflection = (
            error_type in [ErrorType.TOOL_ERROR, ErrorType.SYSTEM_ERROR] and
            any(pattern in error_msg_lower for pattern in reflection_patterns)
        )
        
        # ğŸ“Š åŸºäºå°è¯•æ¬¡æ•°è°ƒæ•´ç­–ç•¥
        if attempt >= max_retries:
            return {'should_reflect': False, 'is_simple_retryable': False, 'should_abort': False}
        
        # æœ€ç»ˆå†³ç­–
        should_reflect = needs_reflection and attempt < max_retries - 1  # ç•™ä¸€æ¬¡æœºä¼šç»™ç®€å•é‡è¯•
        
        return {
            'should_reflect': should_reflect,
            'is_simple_retryable': is_simple_retryable and not needs_reflection,  # ä¼˜å…ˆåæ€çº æ­£
            'should_abort': False
        }
    
    async def _smart_parameter_regeneration(self, task, tool_id: str, action: str, 
                                         original_params: Dict[str, Any], validation_error: str,
                                         step_id: int, original_thinking: str, 
                                         current_outputs: List[str]) -> Dict[str, Any]:
        """
        æ™ºèƒ½å‚æ•°é‡æ–°ç”Ÿæˆ - P1ä¿®å¤çš„æ ¸å¿ƒæ–¹æ³•
        
        å½“å‚æ•°æ ¡éªŒå¤±è´¥æ—¶ï¼Œé€šè¿‡LLMé‡æ–°åˆ†æä»»åŠ¡éœ€æ±‚ï¼Œç”Ÿæˆæ­£ç¡®çš„å‚æ•°
        """
        try:
            regeneration_start = time.time()
            regeneration_interactions = []
            
            # æ„å»ºæ™ºèƒ½é‡æ–°ç”Ÿæˆçš„Prompt
            error_context = f"""
å‚æ•°æ ¡éªŒå¤±è´¥è¯¦æƒ…ï¼š
- å·¥å…·: {tool_id}
- åŠ¨ä½œ: {action}
- æ ¡éªŒé”™è¯¯: {validation_error}
- åŸå§‹å‚æ•°: {json.dumps(original_params, ensure_ascii=False)}

ä»»åŠ¡æè¿°: {task.description}

æœ€è¿‘çš„æ‰§è¡Œå†å²:
{chr(10).join(current_outputs[-3:]) if current_outputs else "æ— å†å²"}
"""
            
            # è·å–å·¥å…·çš„å®é™…Schemaä¿¡æ¯
            parameter_validator = get_parameter_validator()
            valid_actions = parameter_validator.get_valid_actions(tool_id)
            param_schema = parameter_validator.get_parameter_schema(tool_id, action)
            
            schema_context = ""
            if param_schema:
                required_params = param_schema.get("required", [])
                param_patterns = param_schema.get("patterns", {})
                schema_context = f"""
å·¥å…·èƒ½åŠ›è¯´æ˜:
- å¯ç”¨åŠ¨ä½œ: {valid_actions}
- å½“å‰åŠ¨ä½œ '{action}' çš„å¿…éœ€å‚æ•°: {required_params}
- å‚æ•°ç¤ºä¾‹: {json.dumps(param_patterns, ensure_ascii=False)}
"""
            
            regeneration_prompt = f"""
ğŸ”§ å‚æ•°æ ¡éªŒå¤±è´¥ï¼Œéœ€è¦é‡æ–°ç”Ÿæˆæ­£ç¡®çš„å·¥å…·è°ƒç”¨å‚æ•°

{error_context}

{schema_context}

è¯·é‡æ–°åˆ†æä»»åŠ¡éœ€æ±‚ï¼Œç”Ÿæˆæ­£ç¡®çš„å·¥å…·è°ƒç”¨ã€‚è¯·ç‰¹åˆ«æ³¨æ„ï¼š
1. ç¡®ä¿æä¾›æ‰€æœ‰å¿…éœ€çš„å‚æ•°
2. ä»ä»»åŠ¡æè¿°ä¸­æå–ç›¸å…³ä¿¡æ¯å¡«å…¥å‚æ•°
3. å‚æ•°å€¼å¿…é¡»å…·ä½“ã€å‡†ç¡®ï¼Œä¸èƒ½æ˜¯å ä½ç¬¦

è¯·è¿”å›JSONæ ¼å¼ï¼š
{{
    "thinking": "é‡æ–°åˆ†ææ€è·¯",
    "corrected_parameters": {{
        "param1": "å…·ä½“å€¼",
        "param2": "å…·ä½“å€¼"
    }},
    "reasoning": "ä¿®æ­£ç†ç”±"
}}
"""
            
            # è°ƒç”¨LLMé‡æ–°ç”Ÿæˆå‚æ•°
            original_call_api = self.client._call_api
            async def wrapped_call_api_for_regeneration(messages) -> str:
                interaction_start = time.time()
                response = await original_call_api(messages)
                
                from core.interfaces import LLMInteraction
                interaction = LLMInteraction()
                interaction.provider = self.client.provider.value if hasattr(self.client.provider, 'value') else str(self.client.provider)
                interaction.model = getattr(self.client, 'model', 'unknown')
                interaction.context = "parameter_regeneration"
                interaction.prompt = str(messages) if messages else ""
                interaction.prompt_length = len(str(messages))
                interaction.prompt_type = "parameter_correction"
                interaction.response = response
                interaction.response_length = len(response)
                interaction.response_time = time.time() - interaction_start
                regeneration_interactions.append(interaction)
                return response
            
            self.client._call_api = wrapped_call_api_for_regeneration
            
            try:
                # å°†promptè½¬æ¢ä¸ºæ¶ˆæ¯æ ¼å¼
                regeneration_messages = [
                    {"role": "user", "content": regeneration_prompt}
                ]
                raw_response = await self.client._call_api(regeneration_messages)
                
                # è§£æLLMå“åº”
                import re
                json_match = re.search(r'\{.*\}', raw_response, re.DOTALL)
                if json_match:
                    response_json = json.loads(json_match.group())
                    corrected_params = response_json.get("corrected_parameters", {})
                    reasoning = response_json.get("reasoning", "é‡æ–°ç”Ÿæˆå‚æ•°")
                    
                    # é‡æ–°æ ¡éªŒç”Ÿæˆçš„å‚æ•°
                    final_validation = parameter_validator.validate_tool_call(
                        tool_id, action, corrected_params, task.description
                    )
                    
                    if final_validation.is_valid:
                        logger.info(f"âœ… LLMå‚æ•°é‡æ–°ç”ŸæˆæˆåŠŸ: {reasoning}")
                        return {
                            "success": True,
                            "corrected_params": corrected_params,
                            "reasoning": reasoning,
                            "duration": time.time() - regeneration_start,
                            "llm_interactions": regeneration_interactions
                        }
                    else:
                        logger.warning(f"âŒ LLMé‡æ–°ç”Ÿæˆçš„å‚æ•°ä»ç„¶æ— æ•ˆ: {final_validation.error_message}")
                        return {
                            "success": False,
                            "error": f"é‡æ–°ç”Ÿæˆçš„å‚æ•°ä»ç„¶æ— æ•ˆ: {final_validation.error_message}",
                            "duration": time.time() - regeneration_start,
                            "llm_interactions": regeneration_interactions
                        }
                else:
                    logger.error(f"âŒ LLMå“åº”æ— æ³•è§£æä¸ºJSON: {raw_response}")
                    return {
                        "success": False,
                        "error": f"LLMå“åº”æ ¼å¼é”™è¯¯: {raw_response[:200]}...",
                        "duration": time.time() - regeneration_start,
                        "llm_interactions": regeneration_interactions
                    }
                    
            finally:
                self.client._call_api = original_call_api
                
        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½å‚æ•°é‡æ–°ç”Ÿæˆå¼‚å¸¸: {e}")
            return {
                "success": False,
                "error": f"é‡æ–°ç”Ÿæˆå¼‚å¸¸: {str(e)}",
                "duration": time.time() - regeneration_start if 'regeneration_start' in locals() else 0,
                "llm_interactions": regeneration_interactions if 'regeneration_interactions' in locals() else []
            }
    
    async def _build_error_analysis_context(self, steps: List[ExecutionStep], current_step_id: int) -> Dict[str, Any]:
        """
        æ„å»ºæ™ºèƒ½é”™è¯¯åˆ†æä¸Šä¸‹æ–‡ - P2ä¿®å¤çš„æ ¸å¿ƒæ–¹æ³•
        
        åˆ†æä¹‹å‰æ­¥éª¤ä¸­çš„é”™è¯¯æ¨¡å¼ï¼Œä¸ºLLMæä¾›å…·ä½“çš„çº æ­£æŒ‡å¯¼
        """
        try:
            if len(steps) < 2:
                return {"has_errors": False}
            
            # åˆ†ææœ€è¿‘çš„å¤±è´¥æ­¥éª¤
            recent_failed_steps = []
            repeated_errors = {}
            tool_action_failures = {}
            
            # æ£€æŸ¥æœ€è¿‘5æ­¥çš„é”™è¯¯æ¨¡å¼
            recent_steps = steps[-5:] if len(steps) >= 5 else steps
            
            for step in recent_steps:
                if not step.success and step.error_message:
                    recent_failed_steps.append({
                        "step_id": step.step_id,
                        "tool_id": getattr(step, 'action_params', {}).get('tool_id'),
                        "action": getattr(step, 'action_params', {}).get('action'),
                        "error_message": step.error_message,
                        "error_type": step.error_type.value if step.error_type else "unknown"
                    })
                    
                    # ç»Ÿè®¡é‡å¤é”™è¯¯
                    error_key = step.error_message.lower()[:100]  # å–é”™è¯¯ä¿¡æ¯çš„å‰100å­—ç¬¦ä½œä¸ºkey
                    repeated_errors[error_key] = repeated_errors.get(error_key, 0) + 1
                    
                    # ç»Ÿè®¡å·¥å…·åŠ¨ä½œå¤±è´¥
                    if hasattr(step, 'action_params') and step.action_params:
                        tool_id = step.action_params.get('tool_id')
                        action = step.action_params.get('action')
                        if tool_id and action:
                            tool_action_key = f"{tool_id}.{action}"
                            tool_action_failures[tool_action_key] = tool_action_failures.get(tool_action_key, 0) + 1
            
            if not recent_failed_steps:
                return {"has_errors": False}
            
            # åˆ†æé”™è¯¯æ¨¡å¼
            error_patterns = []
            corrective_guidance = []
            
            # ğŸ” æ£€æŸ¥é‡å¤çš„å‚æ•°é”™è¯¯
            parameter_errors = [step for step in recent_failed_steps 
                              if any(pattern in step["error_message"].lower() 
                                   for pattern in ["ç¼ºå°‘å¿…éœ€å‚æ•°", "missing", "required", "å‚æ•°", "parameter"])]
            
            if parameter_errors:
                error_patterns.append("repeated_parameter_errors")
                missing_params = []
                for step in parameter_errors:
                    if "ç¼ºå°‘å¿…éœ€å‚æ•°" in step["error_message"]:
                        # æå–ç¼ºå°‘çš„å‚æ•°å
                        import re
                        params_match = re.search(r"ç¼ºå°‘å¿…éœ€å‚æ•°[ï¼š:]\s*\[?([^\]]+)\]?", step["error_message"])
                        if params_match:
                            missing_params.extend([p.strip().strip("'\"") for p in params_match.group(1).split(",")])
                
                unique_missing_params = list(set(missing_params))
                corrective_guidance.append(f"âš ï¸ é‡å¤çš„å‚æ•°é”™è¯¯ï¼šè¯·ç¡®ä¿æä¾›å¿…éœ€å‚æ•° {unique_missing_params}ã€‚ä»ä»»åŠ¡æè¿°ä¸­æå–å…·ä½“å€¼ï¼Œä¸è¦ä½¿ç”¨å ä½ç¬¦ã€‚")
            
            # ğŸ” æ£€æŸ¥é‡å¤çš„åŠ¨ä½œé”™è¯¯
            action_errors = [step for step in recent_failed_steps 
                           if any(pattern in step["error_message"].lower() 
                                for pattern in ["ä¸æ”¯æŒçš„åŠ¨ä½œ", "unsupported action", "action not found", "ä¸å­˜åœ¨"])]
            
            if action_errors:
                error_patterns.append("repeated_action_errors")
                corrective_guidance.append("âš ï¸ é‡å¤çš„åŠ¨ä½œé”™è¯¯ï¼šè¯·ä»”ç»†æ£€æŸ¥å·¥å…·çš„å¯ç”¨åŠ¨ä½œåˆ—è¡¨ï¼Œç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„åŠ¨ä½œåç§°ã€‚")
            
            # ğŸ” æ£€æŸ¥é‡å¤çš„å·¥å…·è°ƒç”¨å¤±è´¥
            repeated_tool_failures = {k: v for k, v in tool_action_failures.items() if v >= 2}
            if repeated_tool_failures:
                error_patterns.append("repeated_tool_failures")
                failed_combinations = list(repeated_tool_failures.keys())
                corrective_guidance.append(f"âš ï¸ é‡å¤å¤±è´¥çš„å·¥å…·è°ƒç”¨ï¼š{failed_combinations}. è€ƒè™‘ä½¿ç”¨å…¶ä»–å·¥å…·æˆ–æ–¹æ³•å®Œæˆä»»åŠ¡ã€‚")
            
            # ğŸ” æ£€æŸ¥JSONæ ¼å¼é”™è¯¯
            json_errors = [step for step in recent_failed_steps 
                          if any(pattern in step["error_message"].lower() 
                               for pattern in ["json", "format", "æ ¼å¼", "syntax", "è¯­æ³•"])]
            
            if json_errors:
                error_patterns.append("json_format_errors")
                corrective_guidance.append("âš ï¸ JSONæ ¼å¼é”™è¯¯ï¼šè¯·ç¡®ä¿è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œæ£€æŸ¥æ‹¬å·åŒ¹é…å’Œè¯­æ³•æ­£ç¡®æ€§ã€‚")
            
            # æ„å»ºæœ€ç»ˆçš„é”™è¯¯åˆ†æä¸Šä¸‹æ–‡
            error_analysis = {
                "has_errors": True,
                "recent_failures_count": len(recent_failed_steps),
                "error_patterns": error_patterns,
                "corrective_guidance": corrective_guidance,
                "repeated_errors": {k: v for k, v in repeated_errors.items() if v >= 2},
                "failed_tool_actions": repeated_tool_failures,
                "specific_recommendations": []
            }
            
            # ğŸ¯ ç”Ÿæˆå…·ä½“çš„æ”¹è¿›å»ºè®®
            if "repeated_parameter_errors" in error_patterns:
                error_analysis["specific_recommendations"].append(
                    "åœ¨ç”Ÿæˆå·¥å…·è°ƒç”¨å‰ï¼Œä»”ç»†é˜…è¯»ä»»åŠ¡æè¿°ï¼Œæå–å…·ä½“çš„å‚æ•°å€¼ï¼ˆå¦‚URLã€æŸ¥è¯¢å†…å®¹ã€ä»£ç ç­‰ï¼‰ã€‚"
                )
            
            if "repeated_action_errors" in error_patterns:
                error_analysis["specific_recommendations"].append(
                    "åœ¨é€‰æ‹©åŠ¨ä½œå‰ï¼Œä»”ç»†æŸ¥çœ‹å·¥å…·çš„'å¯ç”¨æ“ä½œ'åˆ—è¡¨ï¼Œé€‰æ‹©ç¡®å®å­˜åœ¨çš„åŠ¨ä½œåç§°ã€‚"
                )
            
            if "repeated_tool_failures" in error_patterns:
                error_analysis["specific_recommendations"].append(
                    "è€ƒè™‘æ¢ç”¨å…¶ä»–å·¥å…·æˆ–å°†ä»»åŠ¡åˆ†è§£ä¸ºæ›´å°çš„æ­¥éª¤æ¥å®Œæˆã€‚"
                )
            
            # å¦‚æœé”™è¯¯è¿‡å¤šï¼Œå»ºè®®é‡æ–°å®¡è§†ä»»åŠ¡
            if len(recent_failed_steps) >= 3:
                error_analysis["specific_recommendations"].append(
                    "å¤šæ¬¡å°è¯•å¤±è´¥ï¼Œå»ºè®®é‡æ–°å®¡è§†ä»»åŠ¡éœ€æ±‚ï¼Œå¯èƒ½éœ€è¦æ”¹å˜è§£å†³æ€è·¯ã€‚"
                )
            
            logger.info(f"ğŸ” é”™è¯¯åˆ†æå®Œæˆ: {len(error_patterns)} ç§æ¨¡å¼, {len(corrective_guidance)} æ¡æŒ‡å¯¼")
            return error_analysis
            
        except Exception as e:
            logger.error(f"âŒ æ„å»ºé”™è¯¯åˆ†æä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return {"has_errors": False, "error": str(e)}

