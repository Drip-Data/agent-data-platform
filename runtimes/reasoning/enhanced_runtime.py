"""
å¢å¼ºçš„æ¨ç†è¿è¡Œæ—¶ - ç®€åŒ–ç‰ˆæœ¬
ä¸“æ³¨äºæ ¸å¿ƒåŠŸèƒ½ï¼šLLMæ¨ç†ã€å·¥å…·æ‰§è¡Œã€ä»»åŠ¡å¤„ç†ã€XMLæµå¼è¾“å‡º
"""

import asyncio
import json
import logging
import os
import re
import time
import uuid
from datetime import datetime
from typing import List, Optional, Dict, Any, Tuple
from enum import Enum

from core.interfaces import RuntimeInterface, TaskSpec, TrajectoryResult, TaskExecutionConstants, ErrorMessageConstants
from core.llm.prompt_builders.reasoning_prompt_builder import ReasoningPromptBuilder
from core.utils.path_utils import get_trajectories_dir
from core.streaming.sequential_executor import SequentialStreamingExecutor
from core.memory_manager import MemoryManager
from core.trajectory_enhancer import TrajectoryEnhancer
from core.step_logger import StepDiagnosticLogger
from core.intelligent_status_evaluator import IntelligentStatusEvaluator, intelligent_task_evaluation
from core.intelligent_token_manager import IntelligentTokenManager
from core.context_cache_manager import CacheStrategy
from core.llm_providers.gemini_provider import GeminiProvider
from core.task_decomposer import TaskDecomposer, TaskComplexity
from core.xml_parser_enhanced import EnhancedXMLParser
from core.context_flow_manager import ContextFlowManager
from core.smart_query_optimizer import SmartQueryOptimizer
from core.tool_result_enhancer import ToolResultEnhancer
from core.utils.json_parameter_parser import JSONParameterParser


logger = logging.getLogger(__name__)


class TrajectoryStorageMode(Enum):
    """è½¨è¿¹å­˜å‚¨æ¨¡å¼"""
    INDIVIDUAL_FILES = "individual"
    DAILY_GROUPED = "daily_grouped"
    WEEKLY_GROUPED = "weekly_grouped"
    MONTHLY_GROUPED = "monthly_grouped"


from core.unified_tool_manager import UnifiedToolManager

from core.unified_tool_manager import UnifiedToolManager

class EnhancedReasoningRuntime(RuntimeInterface):
    """
    å¢å¼ºçš„æ¨ç†è¿è¡Œæ—¶ - ä¸“æ³¨æ ¸å¿ƒåŠŸèƒ½, å¹¶é›†æˆé«˜çº§æ¨¡å—
    """
    
    def __init__(self, config_manager, llm_client, toolscore_client, tool_manager: UnifiedToolManager, redis_manager=None, 
                 toolscore_websocket_endpoint=None, xml_streaming_mode: bool = False, 
                 trajectory_storage_mode: str = "daily_grouped"):
        self._runtime_id = f"enhanced-reasoning-{uuid.uuid4()}"
        self.config_manager = config_manager
        self.client = llm_client
        self.toolscore_client = toolscore_client
        self.tool_manager = tool_manager
        self.xml_streaming_mode = xml_streaming_mode
        self.trajectory_storage_mode = TrajectoryStorageMode(trajectory_storage_mode)
        self.prompt_builder = ReasoningPromptBuilder(tool_manager=self.tool_manager, streaming_mode=xml_streaming_mode)
        self.is_initialized = False

        # åˆå§‹åŒ–é«˜çº§æ¨¡å—
        self.memory_manager = MemoryManager(redis_manager=redis_manager)
        self.trajectory_enhancer = TrajectoryEnhancer()
        self.sequential_executor = SequentialStreamingExecutor(
            llm_client=self.client, 
            tool_executor=self.toolscore_client,
            memory_manager=self.memory_manager
        )
        self.step_logger = StepDiagnosticLogger()
        self.intelligent_evaluator = IntelligentStatusEvaluator(self.client)
        
        # ğŸ†• Stage 3: ä»»åŠ¡åˆ†è§£å™¨å’Œå¢å¼ºXMLè§£æå™¨
        self.task_decomposer = TaskDecomposer()
        self.xml_parser = EnhancedXMLParser()
        logger.info("âœ… Stage 3ç»„ä»¶åˆå§‹åŒ–: TaskDecomposer & EnhancedXMLParser")
        
        # ğŸ”„ Stage 4: ä¸Šä¸‹æ–‡æµç®¡ç†å’Œå·¥å…·ä¼˜åŒ–ç»„ä»¶
        self.context_flow_manager = ContextFlowManager()
        self.query_optimizer = SmartQueryOptimizer()
        self.result_enhancer = ToolResultEnhancer()
        logger.info("âœ… Stage 4ç»„ä»¶åˆå§‹åŒ–: ä¿¡æ¯ä¼ é€’ä¼˜åŒ–ç³»ç»Ÿ")
        
        # ğŸ†• åˆå§‹åŒ–Tokenä¼˜åŒ–ç®¡ç†å™¨
        try:
            # ä»LLMå®¢æˆ·ç«¯è·å–Gemini Provider
            gemini_provider = self._get_gemini_provider()
            if gemini_provider:
                self.token_manager = IntelligentTokenManager(
                    gemini_provider=gemini_provider,
                    redis_manager=redis_manager,
                    cache_strategy=CacheStrategy.BALANCED,
                    token_budget_limit=1000000  # 100ä¸‡tokené¢„ç®—
                )
                logger.info("âœ… Tokenç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            else:
                self.token_manager = None
                logger.info("â„¹ï¸ Tokenç®¡ç†å™¨æœªå¯ç”¨ - å½“å‰LLMæä¾›å•†éGeminiæˆ–Gemini Providerä¸å¯ç”¨")
        except Exception as e:
            logger.warning(f"âš ï¸ Tokenç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.token_manager = None
        
        # ğŸ”§ åˆå§‹åŒ–JSONå‚æ•°è§£æå™¨
        self.json_parameter_parser = JSONParameterParser(tool_manager=self.tool_manager)
        logger.info("âœ… JSONå‚æ•°è§£æå™¨åˆå§‹åŒ–æˆåŠŸ")
        
        self.mcp_servers = self._load_mcp_config("config/mcp_servers.json")
    
    def _get_gemini_provider(self) -> Optional[GeminiProvider]:
        """ä»LLMå®¢æˆ·ç«¯è·å–Gemini Providerå®ä¾‹"""
        try:
            logger.debug("ğŸ” å¼€å§‹æŸ¥æ‰¾Gemini Provider...")
            
            # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºå®¢æˆ·ç«¯å±æ€§
            if hasattr(self.client, 'provider'):
                logger.debug(f"ğŸ” LLMå®¢æˆ·ç«¯providerç±»å‹: {type(self.client.provider)}, å€¼: {getattr(self.client.provider, 'value', 'N/A')}")
            if hasattr(self.client, 'provider_instance'):
                logger.debug(f"ğŸ” LLMå®¢æˆ·ç«¯provider_instanceç±»å‹: {type(self.client.provider_instance)}")
            
            # æ£€æŸ¥LLMå®¢æˆ·ç«¯æ˜¯å¦æœ‰provider_instanceå±æ€§ï¼ˆæ­£ç¡®çš„å±æ€§åï¼‰
            if hasattr(self.client, 'provider_instance') and isinstance(self.client.provider_instance, GeminiProvider):
                logger.info("âœ… æ‰¾åˆ°LLMå®¢æˆ·ç«¯ä¸­çš„Gemini Providerå®ä¾‹")
                return self.client.provider_instance
            
            # æ£€æŸ¥LLMå®¢æˆ·ç«¯æ˜¯å¦ä½¿ç”¨Geminiæä¾›å•†
            if hasattr(self.client, 'provider') and hasattr(self.client.provider, 'value') and self.client.provider.value == 'gemini':
                if hasattr(self.client, 'provider_instance'):
                    logger.info("âœ… é€šè¿‡provideræšä¸¾æ‰¾åˆ°Gemini Providerå®ä¾‹")
                    return self.client.provider_instance
            
            # å°è¯•ä»LLMå®¢æˆ·ç«¯é…ç½®åˆ›å»ºæ–°çš„Gemini Provider
            if hasattr(self.client, 'config'):
                client_config = self.client.config
                provider_name = client_config.get('provider') or client_config.get('default_provider')
                logger.debug(f"ğŸ” LLMå®¢æˆ·ç«¯é…ç½®çš„provider: {provider_name}")
                
                if provider_name and provider_name.lower() == 'gemini':
                    # åˆ›å»ºæ–°çš„Gemini Providerå®ä¾‹
                    gemini_config = client_config.copy()
                    if 'providers' in client_config and 'gemini' in client_config['providers']:
                        gemini_provider_config = client_config['providers']['gemini']
                        gemini_config.update(gemini_provider_config)
                    
                    # ç¡®ä¿APIå¯†é’¥å¯ç”¨
                    if not gemini_config.get('api_key') or not gemini_config.get('gemini_api_key'):
                        import os
                        api_key = os.getenv('GEMINI_API_KEY')
                        if api_key:
                            gemini_config['api_key'] = api_key
                            gemini_config['gemini_api_key'] = api_key
                            logger.debug("ğŸ” ä»ç¯å¢ƒå˜é‡è·å–Gemini API Key")
                    
                    if gemini_config.get('api_key') or gemini_config.get('gemini_api_key'):
                        logger.info("âœ… ä»LLMå®¢æˆ·ç«¯é…ç½®åˆ›å»ºæ–°çš„Gemini Providerå®ä¾‹")
                        return GeminiProvider(gemini_config)
                    else:
                        logger.warning("âš ï¸ Geminié…ç½®å­˜åœ¨ä½†ç¼ºå°‘APIå¯†é’¥")
            
            # æœ€åå°è¯•ï¼šä»é…ç½®ç®¡ç†å™¨è·å–
            if hasattr(self.config_manager, 'get_llm_config'):
                llm_config = self.config_manager.get_llm_config()
                if 'providers' in llm_config and 'gemini' in llm_config['providers']:
                    gemini_config = llm_config['providers']['gemini']
                    if gemini_config.get('enabled', True):  # é»˜è®¤å¯ç”¨
                        # ç¡®ä¿APIå¯†é’¥å¯ç”¨
                        if not gemini_config.get('api_key'):
                            import os
                            api_key = os.getenv('GEMINI_API_KEY')
                            if api_key:
                                gemini_config['api_key'] = api_key
                        
                        logger.info("âœ… ä»é…ç½®ç®¡ç†å™¨åˆ›å»ºGemini Providerå®ä¾‹")
                        return GeminiProvider(gemini_config)
            
            logger.info("â„¹ï¸ æ— æ³•è·å–Gemini Provider - å½“å‰ç³»ç»Ÿä½¿ç”¨éGemini LLMæä¾›å•†")
            return None
            
        except Exception as e:
            logger.error(f"âŒ è·å–Gemini Providerå¤±è´¥: {e}")
            return None
    
    def _load_mcp_config(self, config_path: str) -> dict:
        """ä»JSONæ–‡ä»¶åŠ è½½å¹¶æ ¼å¼åŒ–MCPæœåŠ¡å™¨é…ç½®ã€‚"""
        config = {}
        try:
            with open(config_path, 'r') as f:
                mcp_config = json.load(f)
                for service_name, details in mcp_config.items():
                    # æ ‡å‡†åŒ–æœåŠ¡åç§°ï¼šå»æ‰ "_server" åç¼€ï¼Œä¸ä»£ç æœŸæœ›ä¸€è‡´
                    clean_name = service_name.replace("_server", "")
                    config[clean_name] = f"http://127.0.0.1:{details['port']}"
            logger.info(f"Loaded and formatted MCP server configs: {config}")
            return config
        except FileNotFoundError:
            logger.error(f"Error: MCP config file not found at {config_path}")
            return {}
        except json.JSONDecodeError:
            logger.error(f"Error: Could not decode JSON from {config_path}")
            return {}

    def _parse_execution_block(self, xml_string: str) -> dict:
        """
        ä»LLMç”Ÿæˆçš„XMLæ–‡æœ¬ä¸­è§£æå‡ºæ‰§è¡Œå—ã€‚
        è¿”å›ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«ç±»å‹ï¼ˆsingle, parallel, sequentialï¼‰å’ŒåŠ¨ä½œåˆ—è¡¨ã€‚
        """
        from xml.etree import ElementTree as ET

        actions = []
        block_type = "single" # é»˜è®¤
        try:
            # æ¸…ç†å¹¶åŒ…è£¹XMLï¼Œä»¥ä¾¿å®‰å…¨è§£æ
            clean_xml = f"<root>{xml_string.strip()}</root>"
            root = ET.fromstring(clean_xml)

            # æ£€æŸ¥å¹¶è¡Œæˆ–ä¸²è¡Œå—
            parallel_block = root.find('parallel')
            sequential_block = root.find('sequential')

            if parallel_block is not None:
                block_type = "parallel"
                service_nodes = list(parallel_block)
            elif sequential_block is not None:
                block_type = "sequential"
                service_nodes = list(sequential_block)
            else:
                # å•ä¸ªä»»åŠ¡
                service_nodes = [elem for elem in root if elem.tag not in ['think', 'answer', 'execute_tools']]

            for service_node in service_nodes:
                service_name = service_node.tag
                if len(service_node) > 0:
                    tool_node = service_node[0]
                    tool_name = tool_node.tag
                    tool_input = tool_node.text or ""
                    actions.append({
                        "service": service_name,
                        "tool": tool_name,
                        "input": tool_input.strip()
                    })
        except ET.ParseError as e:
            logger.error(f"XML Parse Error: {e}\nOriginal XML:\n{xml_string}")
            # å°è¯•XMLä¿®å¤å’Œå®¹é”™è§£æ
            try:
                fixed_actions = self._attempt_xml_repair(xml_string)
                if fixed_actions:
                    logger.info(f"âœ… XMLä¿®å¤æˆåŠŸï¼Œè§£æå‡º {len(fixed_actions)} ä¸ªåŠ¨ä½œ")
                    return {"type": block_type, "actions": fixed_actions}
            except Exception as repair_error:
                logger.warning(f"âš ï¸ XMLä¿®å¤å¤±è´¥: {repair_error}")
        
        return {"type": block_type, "actions": actions}

    def _attempt_xml_repair(self, xml_string: str) -> list:
        """
        å°è¯•ä¿®å¤å’Œè§£ææŸåçš„XMLï¼Œå¢å¼ºç³»ç»Ÿçš„å®¹é”™èƒ½åŠ›
        """
        import re
        from xml.etree import ElementTree as ET
        
        actions = []
        
        # æ–¹æ³•1: æ­£åˆ™è¡¨è¾¾å¼æå–å·¥å…·è°ƒç”¨
        try:
            # åŒ¹é…å•ä¸ªå·¥å…·è°ƒç”¨æ¨¡å¼
            tool_pattern = r'<(\w+)>\s*<(\w+)>(.*?)</\2>\s*</\1>'
            matches = re.findall(tool_pattern, xml_string, re.DOTALL)
            
            for service_name, tool_name, tool_input in matches:
                actions.append({
                    "service": service_name,
                    "tool": tool_name,
                    "input": tool_input.strip()
                })
            
            if actions:
                logger.info(f"ğŸ”§ æ­£åˆ™è¡¨è¾¾å¼ä¿®å¤ï¼šæå–åˆ° {len(actions)} ä¸ªå·¥å…·è°ƒç”¨")
                return actions
                
        except Exception as e:
            logger.debug(f"æ­£åˆ™è¡¨è¾¾å¼ä¿®å¤å¤±è´¥: {e}")
        
        # æ–¹æ³•2: å°è¯•è‡ªåŠ¨é—­åˆæ ‡ç­¾
        try:
            # ç®€å•çš„æ ‡ç­¾è‡ªåŠ¨é—­åˆ
            fixed_xml = xml_string
            
            # æŸ¥æ‰¾æœªé—­åˆçš„æ ‡ç­¾
            open_tags = re.findall(r'<([^/>\s]+)[^>]*>', fixed_xml)
            close_tags = re.findall(r'</([^>\s]+)>', fixed_xml)
            
            # ä¸ºæœªé—­åˆçš„æ ‡ç­¾æ·»åŠ é—­åˆæ ‡ç­¾
            for tag in open_tags:
                if tag not in close_tags:
                    fixed_xml += f'</{tag}>'
            
            # åŒ…è£…ä¸ºæ ¹å…ƒç´ å¹¶å°è¯•è§£æ
            clean_xml = f"<root>{fixed_xml.strip()}</root>"
            root = ET.fromstring(clean_xml)
            
            # é€’å½’æå–å·¥å…·è°ƒç”¨
            def extract_tools(element):
                tools = []
                for child in element:
                    if len(child) > 0:  # æœ‰å­å…ƒç´ 
                        for grandchild in child:
                            if grandchild.tag and grandchild.text:
                                tools.append({
                                    "service": child.tag,
                                    "tool": grandchild.tag,
                                    "input": grandchild.text.strip()
                                })
                    tools.extend(extract_tools(child))
                return tools
            
            extracted_tools = extract_tools(root)
            if extracted_tools:
                logger.info(f"ğŸ”§ æ ‡ç­¾é—­åˆä¿®å¤ï¼šæå–åˆ° {len(extracted_tools)} ä¸ªå·¥å…·è°ƒç”¨")
                return extracted_tools
                
        except Exception as e:
            logger.debug(f"æ ‡ç­¾é—­åˆä¿®å¤å¤±è´¥: {e}")
        
        # æ–¹æ³•3: åŸºäºå…³é”®è¯çš„å†…å®¹æå–
        try:
            # è¯†åˆ«å¸¸è§çš„æœåŠ¡åç§°å’Œå·¥å…·åç§°
            service_keywords = ['microsandbox', 'browser_use', 'search', 'deepsearch']
            tool_keywords = ['execute', 'search', 'navigate', 'click', 'type']
            
            # æŒ‰è¡Œåˆ†æï¼Œå¯»æ‰¾å¯èƒ½çš„å·¥å…·è°ƒç”¨
            lines = xml_string.split('\n')
            current_service = None
            current_tool = None
            current_input = []
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                    
                # æ£€æŸ¥æ˜¯å¦æ˜¯æœåŠ¡æ ‡ç­¾
                for service in service_keywords:
                    if f'<{service}>' in line.lower():
                        current_service = service
                        break
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å·¥å…·æ ‡ç­¾
                for tool in tool_keywords:
                    if f'<{tool}>' in line.lower():
                        current_tool = tool
                        current_input = []
                        continue
                
                # æ”¶é›†å·¥å…·è¾“å…¥
                if current_service and current_tool:
                    if f'</{current_tool}>' in line.lower():
                        # å·¥å…·è°ƒç”¨ç»“æŸ
                        if current_input:
                            actions.append({
                                "service": current_service,
                                "tool": current_tool,
                                "input": '\n'.join(current_input)
                            })
                        current_tool = None
                        current_input = []
                    else:
                        current_input.append(line)
            
            if actions:
                logger.info(f"ğŸ”§ å…³é”®è¯æå–ä¿®å¤ï¼šæå–åˆ° {len(actions)} ä¸ªå·¥å…·è°ƒç”¨")
                return actions
                
        except Exception as e:
            logger.debug(f"å…³é”®è¯æå–ä¿®å¤å¤±è´¥: {e}")
        
        return []

    def _attempt_answer_extraction(self, final_trajectory_str: str) -> str:
        """
        å°è¯•ä»æŸåçš„XMLä¸­æå–ç­”æ¡ˆå†…å®¹ï¼Œå¢å¼ºç­”æ¡ˆè§£æçš„å®¹é”™èƒ½åŠ›
        """
        import re
        
        # æ–¹æ³•1: éƒ¨åˆ†åŒ¹é…answeræ ‡ç­¾ï¼ˆå¤„ç†æœªé—­åˆçš„æƒ…å†µï¼‰
        try:
            # æŸ¥æ‰¾ç­”æ¡ˆå¼€å§‹æ ‡ç­¾
            answer_tag = TaskExecutionConstants.XML_TAGS['ANSWER']
            answer_start_pattern = f'<{answer_tag}>'
            
            if answer_start_pattern in final_trajectory_str:
                # æ‰¾åˆ°å¼€å§‹ä½ç½®
                start_pos = final_trajectory_str.find(answer_start_pattern)
                if start_pos != -1:
                    content_start = start_pos + len(answer_start_pattern)
                    
                    # æŸ¥æ‰¾ç»“æŸæ ‡ç­¾
                    answer_end_pattern = f'</{answer_tag}>'
                    end_pos = final_trajectory_str.find(answer_end_pattern, content_start)
                    
                    if end_pos != -1:
                        # æ ‡å‡†æƒ…å†µï¼šæœ‰å®Œæ•´çš„å¼€å§‹å’Œç»“æŸæ ‡ç­¾
                        answer_content = final_trajectory_str[content_start:end_pos].strip()
                        if answer_content:
                            return answer_content
                    else:
                        # å®¹é”™æƒ…å†µï¼šæ²¡æœ‰ç»“æŸæ ‡ç­¾ï¼Œå–åˆ°æ–‡æœ¬æœ«å°¾
                        remaining_text = final_trajectory_str[content_start:].strip()
                        if remaining_text:
                            # å¯»æ‰¾ä¸‹ä¸€ä¸ªXMLæ ‡ç­¾ä½œä¸ºç»“æŸ
                            next_tag_match = re.search(r'<[^>]+>', remaining_text)
                            if next_tag_match:
                                answer_content = remaining_text[:next_tag_match.start()].strip()
                            else:
                                answer_content = remaining_text
                            
                            if answer_content:
                                logger.info(f"ğŸ”§ éƒ¨åˆ†åŒ¹é…ä¿®å¤ï¼šæå–åˆ°æœªé—­åˆçš„answerå†…å®¹")
                                return answer_content
                                
        except Exception as e:
            logger.debug(f"éƒ¨åˆ†åŒ¹é…ä¿®å¤å¤±è´¥: {e}")
        
        # æ–¹æ³•2: åŸºäºå…³é”®è¯çš„æ™ºèƒ½è¯†åˆ«
        try:
            # æŸ¥æ‰¾æœ€åçš„æœ‰æ„ä¹‰æ®µè½
            paragraphs = final_trajectory_str.split('\n\n')
            
            # æŸ¥æ‰¾åŒ…å«ç­”æ¡ˆå…³é”®è¯çš„æ®µè½
            answer_keywords = ['ç­”æ¡ˆ', 'ç»“æœ', 'æœ€ç»ˆ', 'æ€»ç»“', 'ç»“è®º', 'answer', 'result', 'final', 'conclusion']
            
            for paragraph in reversed(paragraphs):
                paragraph = paragraph.strip()
                if len(paragraph) > 20:  # è¶³å¤Ÿé•¿çš„æ®µè½
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«ç­”æ¡ˆå…³é”®è¯
                    if any(keyword in paragraph.lower() for keyword in answer_keywords):
                        # ç§»é™¤XMLæ ‡ç­¾
                        clean_paragraph = re.sub(r'<[^>]*>', '', paragraph).strip()
                        if clean_paragraph:
                            logger.info(f"ğŸ”§ å…³é”®è¯è¯†åˆ«ä¿®å¤ï¼šæ‰¾åˆ°ç­”æ¡ˆæ®µè½")
                            return clean_paragraph[:500]  # é™åˆ¶é•¿åº¦
                            
        except Exception as e:
            logger.debug(f"å…³é”®è¯è¯†åˆ«ä¿®å¤å¤±è´¥: {e}")
        
        # æ–¹æ³•3: æå–æœ€åçš„æœ‰æ•ˆå†…å®¹
        try:
            # ç§»é™¤æ‰€æœ‰XMLæ ‡ç­¾ï¼Œè·å–çº¯æ–‡æœ¬
            clean_text = re.sub(r'<[^>]*>', '', final_trajectory_str).strip()
            
            if clean_text:
                # æŒ‰è¡Œåˆ†å‰²ï¼Œå¯»æ‰¾æœ€åå‡ è¡Œæœ‰æ„ä¹‰çš„å†…å®¹
                lines = [line.strip() for line in clean_text.split('\n') if line.strip()]
                
                if lines:
                    # ä»æœ€åå¼€å§‹å¯»æ‰¾æœ‰æ„ä¹‰çš„è¡Œ
                    meaningful_lines = []
                    for line in reversed(lines[-10:]):  # æ£€æŸ¥æœ€å10è¡Œ
                        if len(line) > 15 and not line.startswith('Step') and not line.startswith('Time'):
                            meaningful_lines.append(line)
                            if len(meaningful_lines) >= 3:  # æœ€å¤šå–3è¡Œ
                                break
                    
                    if meaningful_lines:
                        result = '\n'.join(reversed(meaningful_lines))
                        logger.info(f"ğŸ”§ æ–‡æœ¬æå–ä¿®å¤ï¼šä»çº¯æ–‡æœ¬ä¸­æå–ç­”æ¡ˆ")
                        return result
                        
        except Exception as e:
            logger.debug(f"æ–‡æœ¬æå–ä¿®å¤å¤±è´¥: {e}")
        
        return ""

    async def _execute_tool(self, action: dict, step_number: int = 0) -> str:
        """
        æ ¹æ®å•ä¸ªåŠ¨ä½œå­—å…¸ï¼Œé€šè¿‡toolscore_clientè°ƒç”¨å¯¹åº”çš„MCP Serverå¹¶è¿”å›ç»“æœã€‚
        ğŸ”§ å®Œæ•´ä¿®å¤ï¼šç»Ÿä¸€æ‰€æœ‰å·¥å…·çš„ç»“æœæ ¼å¼åŒ–ï¼Œä½¿ç»“æœæ¸…æ™°æ˜“è¯»
        ğŸ”„ Stage 4å¢å¼ºï¼šé›†æˆæŸ¥è¯¢ä¼˜åŒ–å’Œç»“æœå¢å¼º
        """
        service_name = action.get('service')
        tool_name = action.get('tool')
        tool_input = action.get('input')

        if not all([service_name, tool_name]):
            return "Error: Invalid action format. 'service' and 'tool' are required."

        # ğŸ”„ Stage 4: æŸ¥è¯¢ä¼˜åŒ–
        optimized_input = tool_input
        if service_name in ['deepsearch', 'browser_use'] and tool_input:
            try:
                # åˆ†æå’Œä¼˜åŒ–æŸ¥è¯¢
                query_analysis = self.query_optimizer.analyze_query(
                    tool_input, 
                    context=self.context_flow_manager.get_relevant_context(service_name, step_number)
                )
                
                if query_analysis.confidence < 0.5 and query_analysis.optimized_queries:
                    # ä½¿ç”¨ä¼˜åŒ–åçš„æŸ¥è¯¢
                    optimized_input = query_analysis.optimized_queries[0]
                    logger.info(f"ğŸ” æŸ¥è¯¢ä¼˜åŒ–: {tool_input[:50]}... -> {optimized_input[:50]}...")
                
                # æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯åˆ°æŸ¥è¯¢
                context_prompt = self.context_flow_manager.generate_context_prompt(
                    service_name, step_number, tool_input
                )
                if context_prompt:
                    optimized_input = f"{context_prompt}\n\nQuery: {optimized_input}"
                    
            except Exception as e:
                logger.warning(f"âš ï¸ æŸ¥è¯¢ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢: {e}")
                optimized_input = tool_input

        # ğŸ”§ P1 æ ¸å¿ƒä¿®å¤ï¼šä½¿ç”¨JSONå‚æ•°è§£æå™¨
        parser = JSONParameterParser(self.tool_manager)
        parse_result = parser.parse_tool_parameters(service_name, tool_name, optimized_input)

        if not parse_result.is_valid:
            # å¦‚æœè§£ææˆ–éªŒè¯å¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
            error_message = f"Tool execution failed: Invalid parameters for {service_name}/{tool_name}. "
            error_message += "; ".join(parse_result.errors)
            if parse_result.suggestions:
                error_message += f" Suggestions: {'; '.join(parse_result.suggestions)}"
            return error_message

        parameters = parse_result.parsed_params
        param_name = next(iter(parameters)) if parameters else '' # For logging

        logger.info(f"ğŸ”§ æ‰§è¡Œå·¥å…·: service='{service_name}', tool='{tool_name}', param_name='{param_name}', input_length={len(str(optimized_input))}")

        try:
            result = await self.toolscore_client.execute_tool(
                tool_id=service_name,
                action=tool_name,
                parameters=parameters
            )
            
            # ğŸ”„ Stage 4: ç»“æœå¢å¼º
            enhanced_result = None
            try:
                enhanced_result = self.result_enhancer.enhance_tool_result(
                    tool_name=service_name,
                    raw_result=result,
                    execution_context={
                        "step_number": step_number,
                        "original_query": tool_input,
                        "optimized_query": optimized_input
                    }
                )
                
                # æå–ä¸Šä¸‹æ–‡æ•°æ®
                self.context_flow_manager.extract_context_data(
                    str(result), service_name, step_number
                )
                
                # è®°å½•æŸ¥è¯¢ç»“æœç”¨äºå­¦ä¹ 
                success = enhanced_result.result_type.value in ['success', 'partial_success']
                query_type = self.query_optimizer._identify_query_type(tool_input)
                self.query_optimizer.record_query_result(
                    tool_input, query_type, success, str(result)
                )
                
            except Exception as e:
                logger.warning(f"âš ï¸ ç»“æœå¢å¼ºå¤±è´¥: {e}")
            
            if isinstance(result, dict):
                if result.get('success', True):
                    output = result.get('data', result.get('output', result.get('result', str(result))))
                    
                    # ğŸ”§ ä¿®å¤ï¼šç‰¹æ®Šå¤„ç† DeepSearch çš„ JSON å­—ç¬¦ä¸²è¾“å‡º
                    if service_name == 'deepsearch' and isinstance(output, str):
                        try:
                            # å°è¯•è§£æ JSON å­—ç¬¦ä¸²ï¼ˆDeepSearch çš„æˆåŠŸè¾“å‡ºæ ¼å¼ï¼‰
                            import json
                            parsed_output = json.loads(output)
                            if isinstance(parsed_output, dict):
                                output = parsed_output
                                logger.debug(f"Successfully parsed DeepSearch JSON string output")
                        except (json.JSONDecodeError, ValueError) as e:
                            # å¦‚æœä¸æ˜¯æœ‰æ•ˆçš„JSONï¼Œä¿æŒåŸå§‹å­—ç¬¦ä¸²
                            logger.debug(f"DeepSearch output is not JSON string, keeping as string: {e}")
                            pass
                    
                    # ğŸ”§ å®Œæ•´ä¿®å¤ï¼šä¸ºæ‰€æœ‰å·¥å…·ç»Ÿä¸€ç»“æœæ ¼å¼åŒ–
                    formatted_output = self._format_tool_output(service_name, tool_name, output)
                    
                    # ğŸ”„ Stage 4: å¦‚æœæœ‰å¢å¼ºç»“æœï¼Œæ·»åŠ é¢å¤–ä¿¡æ¯
                    if enhanced_result and enhanced_result.confidence_score < 0.5:
                        formatted_output += f"\n\nâš ï¸ ç»“æœç½®ä¿¡åº¦è¾ƒä½ ({enhanced_result.confidence_score:.2f})ï¼Œå»ºè®®éªŒè¯ä¿¡æ¯å‡†ç¡®æ€§ã€‚"
                    
                    return formatted_output
                else:
                    error_msg = result.get('error_message', result.get('error', 'Unknown error'))
                    return f"Tool execution failed: {error_msg}"
            else:
                return str(result)

        except Exception as e:
            logger.error(f"An unexpected error occurred while calling tool '{service_name}/{tool_name}': {e}", exc_info=True)
            return f"An unexpected error occurred while calling {service_name}: {e}"
    
    def _format_tool_output(self, service_name: str, tool_name: str, output) -> str:
        """
        ğŸ”§ å®Œæ•´ä¿®å¤ï¼šç»Ÿä¸€æ ¼å¼åŒ–æ‰€æœ‰å·¥å…·çš„è¾“å‡ºç»“æœï¼Œä½¿å…¶æ¸…æ™°æ˜“è¯»
        
        Args:
            service_name: æœåŠ¡åç§° (microsandbox, deepsearch, browser_useç­‰)
            tool_name: å·¥å…·åç§°
            output: åŸå§‹è¾“å‡ºç»“æœ
            
        Returns:
            str: æ ¼å¼åŒ–åçš„æ¸…æ™°ç»“æœ
        """
        # 1. MicroSandbox - æ™ºèƒ½æå–æ ¸å¿ƒæ‰§è¡Œç»“æœ
        if service_name == 'microsandbox':
            return self._format_microsandbox_output(output)
        
        # 2. DeepSearch - æ˜¾ç¤ºå®Œæ•´åŸå§‹JSONç»“æœ
        elif service_name == 'deepsearch':
            import json
            try:
                if isinstance(output, dict):
                    return json.dumps(output, ensure_ascii=False, indent=2)
                elif isinstance(output, list):
                    return json.dumps(output, ensure_ascii=False, indent=2)
                else:
                    return str(output)
            except Exception as e:
                logger.warning(f"Failed to format DeepSearch output: {e}")
                return str(output)
        
        # 3. Browser Use - æ ¼å¼åŒ–æµè§ˆå™¨æ“ä½œç»“æœ
        elif service_name == 'browser_use':
            if isinstance(output, dict):
                return self._format_browser_use_output(output)
            return str(output)
        
        # 4. Search Tool - æ ¼å¼åŒ–æœç´¢ç»“æœ
        elif service_name == 'search_tool':
            if isinstance(output, dict):
                return self._format_search_tool_output(output)
            return str(output)
        
        # 5. Memory Staging - æ ¼å¼åŒ–å†…å­˜æš‚å­˜ç»“æœ
        elif service_name == 'memory_staging':
            return self._format_memory_staging_output_generic(tool_name, output)
        
        # 6. å…¶ä»–å·¥å…· - é€šç”¨æ ¼å¼åŒ–
        else:
            return self._format_generic_output(output)
    
    def _format_deepsearch_output(self, output: dict) -> str:
        """ğŸ”§ ä¿®å¤ï¼šæ­£ç¡®å¤„ç†DeepSearchçš„å®é™…è¾“å‡ºæ ¼å¼ï¼Œæ”¯æŒJSONå­—ç¬¦ä¸²å’Œç»“æ„åŒ–æ•°æ®"""
        try:
            # ğŸ”§ ä¿®å¤ï¼šé¦–å…ˆå¤„ç† DeepSearch çš„å®é™…è¾“å‡ºæ ¼å¼
            # æ£€æŸ¥æ˜¯å¦æ˜¯åŒ…å«JSONå­—ç¬¦ä¸²çš„æ ¼å¼ï¼ˆæˆåŠŸæƒ…å†µï¼‰
            if 'query' in output and 'content' in output:
                query = output.get('query', '')
                content = output.get('content', '')
                
                formatted_lines = []
                
                # æ·»åŠ æŸ¥è¯¢ä¿¡æ¯
                if query:
                    formatted_lines.append(f"{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['SEARCH_QUERY']}: {query}")
                
                # æ·»åŠ å†…å®¹ï¼ˆè¿™æ˜¯ä¸»è¦çš„ç ”ç©¶ç»“æœï¼‰
                if content and content.strip():
                    formatted_lines.append(f"\n{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['SEARCH_SUMMARY']}:")
                    # é™åˆ¶å†…å®¹é•¿åº¦ï¼Œé¿å…è¿‡é•¿
                    max_content = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_CONTENT_LENGTH']
                    content_clean = content.strip()
                    if len(content_clean) > max_content:
                        content_clean = content_clean[:max_content] + "..."
                    formatted_lines.append(content_clean)
                
                # å¦‚æœæœ‰æ ¼å¼åŒ–å†…å®¹ï¼Œè¿”å›å®ƒ
                if formatted_lines:
                    return '\n'.join(formatted_lines)
            
            # ğŸ”§ å›é€€ï¼šå¤„ç†ä¼ ç»Ÿçš„ search_results æ ¼å¼
            search_results = output.get('search_results', [])
            query = output.get('query', '')
            summary = output.get('summary', '')
            answer = output.get('answer', '')  # æ·»åŠ å¯¹answerå­—æ®µçš„æ”¯æŒ
            
            formatted_lines = []
            
            # æ·»åŠ æŸ¥è¯¢ä¿¡æ¯
            if query:
                formatted_lines.append(f"{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['SEARCH_QUERY']}: {query}")
            
            # æ·»åŠ ç­”æ¡ˆæˆ–æ‘˜è¦
            if answer:
                formatted_lines.append(f"\n{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['SEARCH_SUMMARY']}:")
                max_content = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_CONTENT_LENGTH']
                answer_clean = answer.strip()
                if len(answer_clean) > max_content:
                    answer_clean = answer_clean[:max_content] + "..."
                formatted_lines.append(answer_clean)
            elif summary:
                formatted_lines.append(f"{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['SEARCH_SUMMARY']}: {summary}")
            
            # æ ¼å¼åŒ–æœç´¢ç»“æœ
            if search_results:
                max_results = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_SEARCH_RESULTS']
                results_text = TaskExecutionConstants.TOOL_FORMAT_PREFIXES['SEARCH_RESULTS'].format(len(search_results))
                formatted_lines.append(results_text)
                
                for i, result in enumerate(search_results[:max_results], 1):
                    if isinstance(result, dict):
                        title = result.get('title', 'æ— æ ‡é¢˜')
                        snippet = result.get('snippet', result.get('content', ''))
                        url = result.get('url', '')
                        
                        formatted_lines.append(f"{i}. {title}")
                        if snippet:
                            # ä½¿ç”¨å¸¸é‡é™åˆ¶snippeté•¿åº¦
                            max_length = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_SNIPPET_LENGTH']
                            snippet_clean = snippet.strip()[:max_length]
                            formatted_lines.append(f"   {snippet_clean}...")
                        if url:
                            formatted_lines.append(f"   æ¥æº: {url}")
                        formatted_lines.append("")  # ç©ºè¡Œåˆ†éš”
            
            result_text = '\n'.join(formatted_lines).strip()
            
            # ğŸ”§ ä¿®å¤ï¼šåªæœ‰åœ¨å®Œå…¨æ²¡æœ‰ä»»ä½•æœ‰ç”¨ä¿¡æ¯æ—¶æ‰è¿”å›"æœªæ‰¾åˆ°ç»“æœ"
            if not result_text:
                # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•å…¶ä»–æœ‰ç”¨çš„å­—æ®µ
                other_content = []
                for key, value in output.items():
                    if key not in ['query', 'content', 'search_results', 'summary', 'answer'] and value:
                        if isinstance(value, str) and value.strip():
                            other_content.append(f"{key}: {str(value)[:200]}...")
                        elif isinstance(value, (dict, list)) and value:
                            other_content.append(f"{key}: {str(value)[:200]}...")
                
                if other_content:
                    return "DeepSearchç»“æœ:\n" + "\n".join(other_content)
                else:
                    return "æœç´¢å®Œæˆï¼Œä½†æœªæ‰¾åˆ°ç›¸å…³ç»“æœ"
            
            return result_text
            
        except Exception as e:
            logger.warning(f"Failed to format DeepSearch output: {e}")
            max_content = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_CONTENT_LENGTH']
            return f"DeepSearchæœç´¢å®Œæˆï¼ŒåŸå§‹ç»“æœ: {str(output)[:max_content]}..."
    
    def _format_deepsearch_list_output(self, output: list) -> str:
        """ğŸ”§ ä¿®å¤ï¼šæ ¼å¼åŒ–DeepSearchåˆ—è¡¨ç»“æœï¼Œé¿å…é”™è¯¯çš„ç¡¬ç¼–ç æ¶ˆæ¯"""
        try:
            if not output:
                return "æœç´¢å®Œæˆï¼Œä½†æœªæ‰¾åˆ°ç›¸å…³ç»“æœ"
            
            results_text = TaskExecutionConstants.TOOL_FORMAT_PREFIXES['SEARCH_RESULTS'].format(len(output))
            formatted_lines = [results_text]
            
            max_results = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_SEARCH_RESULTS']
            for i, item in enumerate(output[:max_results], 1):
                if isinstance(item, dict):
                    title = item.get('title', f'ç»“æœ {i}')
                    content = item.get('content', item.get('snippet', ''))
                    
                    formatted_lines.append(f"{i}. {title}")
                    if content:
                        max_length = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_SNIPPET_LENGTH']
                        content_clean = str(content).strip()[:max_length]
                        formatted_lines.append(f"   {content_clean}...")
                    formatted_lines.append("")
                else:
                    formatted_lines.append(f"{i}. {str(item)[:100]}...")
            
            return '\n'.join(formatted_lines).strip()
            
        except Exception as e:
            logger.warning(f"Failed to format DeepSearch list output: {e}")
            return f"DeepSearchæœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(output)} ä¸ªç»“æœ"
    
    def _format_browser_use_output(self, output: dict) -> str:
        """ğŸ”§ å®Œæ•´ä¿®å¤ï¼šæ ¼å¼åŒ–Browser Useæ“ä½œç»“æœï¼Œç¡®ä¿æœç´¢ç»“æœä¸ä¸¢å¤±"""
        try:
            # ğŸ”§ ä¿®å¤ï¼šæ­£ç¡®æå–browser-useçš„å“åº”ç»“æ„
            # å®é™…ç»“æ„: {success: True, result: {...}, output: {...}, processing_time_ms: ...}
            result_data = output.get('result', {})
            output_data = output.get('output', {})
            
            # æå–å…³é”®ä¿¡æ¯ - ä¿®æ­£å­—æ®µè·¯å¾„
            status = output.get('success', result_data.get('success', True))
            
            # ğŸ”§ ä¿®å¤ï¼šä»resultå’Œoutputä¸­æå–å†…å®¹
            content = result_data.get('content', output_data.get('content', ''))
            
            # ğŸ”§ ä¿®å¤ï¼šæå–æœç´¢ç›¸å…³ä¿¡æ¯
            url = result_data.get('url', output_data.get('url', ''))
            query = result_data.get('query', output_data.get('query', ''))
            error = result_data.get('error', output_data.get('error', ''))
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ£€æŸ¥æ‰€æœ‰å¯èƒ½çš„æœç´¢ç»“æœå­—æ®µ
            search_results = (result_data.get('search_results') or 
                            result_data.get('results') or
                            output_data.get('search_results') or 
                            output_data.get('results') or [])
            
            formatted_lines = []
            
            # çŠ¶æ€ä¿¡æ¯
            status_text = "æˆåŠŸ" if status else "å¤±è´¥"
            formatted_lines.append(f"{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['BROWSER_ACTION']}: {action} - {status_text}")
            
            # æœç´¢æŸ¥è¯¢ä¿¡æ¯
            if query:
                formatted_lines.append(f"æœç´¢æŸ¥è¯¢: {query}")
            
            # URLä¿¡æ¯
            if url:
                formatted_lines.append(f"{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['PAGE_URL']}: {url}")
            
            # é”™è¯¯ä¿¡æ¯
            if error:
                formatted_lines.append(f"{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['ERROR_INFO']}: {error}")
            
            # ğŸ”§ ä¼˜å…ˆå¤„ç†æœç´¢ç»“æœ
            if search_results and isinstance(search_results, list):
                max_results = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_SEARCH_RESULTS']
                formatted_lines.append(f"æœç´¢ç»“æœ({len(search_results)}ä¸ª):")
                
                for i, result in enumerate(search_results[:max_results], 1):
                    if isinstance(result, dict):
                        title = result.get('title', result.get('name', f'ç»“æœ{i}'))
                        snippet = result.get('snippet', result.get('description', result.get('content', '')))
                        result_url = result.get('url', result.get('link', ''))
                        
                        formatted_lines.append(f"{i}. {title}")
                        if snippet:
                            max_snippet = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_SNIPPET_LENGTH']
                            clean_snippet = str(snippet).strip()[:max_snippet]
                            formatted_lines.append(f"   {clean_snippet}...")
                        if result_url:
                            formatted_lines.append(f"   é“¾æ¥: {result_url}")
                        formatted_lines.append("")
                    else:
                        formatted_lines.append(f"{i}. {str(result)[:100]}...")
            
            # ğŸ”§ å¢å¼ºï¼šå¤„ç†åŒ…å«æœç´¢ç»“æœçš„contentå­—æ®µ
            elif content and isinstance(content, str):
                max_content = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_CONTENT_LENGTH']
                
                # æ£€æŸ¥contentæ˜¯å¦åŒ…å«Googleæœç´¢ç»“æœæ ¼å¼
                if "Googleæœç´¢ç»“æœ" in content or "æ‰¾åˆ°" in content and "ä¸ªç›¸å…³ç»“æœ" in content:
                    # æˆªå–åˆç†é•¿åº¦çš„æœç´¢ç»“æœå†…å®¹
                    truncated_content = content[:max_content]
                    formatted_lines.append(f"æœç´¢å†…å®¹æ‘˜è¦: {truncated_content}...")
                    
                # å¦‚æœå†…å®¹æ˜¯HTMLï¼Œå°è¯•æå–æ–‡æœ¬
                elif '<html>' in content.lower() or '<div>' in content.lower():
                    import re
                    text_content = re.sub(r'<[^>]+>', '', content)
                    text_content = re.sub(r'\s+', ' ', text_content).strip()
                    if text_content:
                        formatted_lines.append(f"{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['PAGE_CONTENT']}: {text_content[:max_content]}...")
                else:
                    formatted_lines.append(f"{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['OPERATION_RESULT']}: {str(content)[:max_content]}...")
            
            # ğŸ”§ å¢å¼ºï¼šç¡®ä¿æ€»æ˜¯æœ‰å†…å®¹è¾“å‡ºï¼Œé¿å…è§¦å‘åŸå§‹æ•°æ®åå¤‡é€»è¾‘
            result_text = '\n'.join(formatted_lines).strip()
            if not result_text or len(result_text) < 20:
                # ğŸ”§ ä¿®å¤ï¼šæä¾›ç®€æ´çš„åå¤‡è¾“å‡ºï¼Œé¿å…å¤§é‡é‡å¤æ•°æ®
                logger.warning(f"Browser Use output seems incomplete. Raw keys: {list(output.keys())}")
                
                # å°è¯•ä»outputä¸­æå–åŸºæœ¬ä¿¡æ¯
                success_status = "æˆåŠŸ" if status else "å¤±è´¥"
                basic_info = f"æµè§ˆå™¨æ“ä½œæ‰§è¡Œ - {success_status}"
                
                if query:
                    basic_info += f"\næŸ¥è¯¢: {query}"
                if url:
                    basic_info += f"\nURL: {url}"
                if error:
                    basic_info += f"\né”™è¯¯: {error}"
                
                # ğŸ”§ å…³é”®ä¿®å¤ï¼šé¿å…è¾“å‡ºå¤§é‡åŸå§‹æ•°æ®ï¼Œåªè¾“å‡ºæ‘˜è¦
                return basic_info + "\n(è¯¦ç»†ç»“æœå¤„ç†ä¸­...)"
            
            return result_text
            
        except Exception as e:
            logger.error(f"Failed to format Browser Use output: {e}")
            max_content = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_CONTENT_LENGTH']
            return f"æµè§ˆå™¨æ“ä½œå®Œæˆï¼ŒåŸå§‹ç»“æœ: {str(output)[:max_content]}..."
    
    def _format_search_tool_output(self, output: dict) -> str:
        """ğŸ”§ æ ¼å¼åŒ–Search Toolæœç´¢ç»“æœ - ä½¿ç”¨å¸¸é‡é¿å…ç¡¬ç¼–ç """
        try:
            # æå–æœç´¢ç»“æœ
            results = output.get('results', output.get('files', []))
            query = output.get('query', '')
            count = output.get('count', len(results) if isinstance(results, list) else 0)
            
            formatted_lines = []
            
            # æœç´¢ä¿¡æ¯
            if query:
                formatted_lines.append(f"{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['FILE_SEARCH']}: {query}")
            
            file_results_text = TaskExecutionConstants.TOOL_FORMAT_PREFIXES['FILE_RESULTS'].format(count)
            formatted_lines.append(file_results_text)
            
            # æ ¼å¼åŒ–æ–‡ä»¶åˆ—è¡¨
            if isinstance(results, list):
                max_files = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_FILE_RESULTS']
                for i, result in enumerate(results[:max_files], 1):
                    if isinstance(result, dict):
                        file_path = result.get('path', result.get('file', ''))
                        matches = result.get('matches', result.get('content', ''))
                        
                        formatted_lines.append(f"{i}. {file_path}")
                        if matches:
                            formatted_lines.append(f"   åŒ¹é…å†…å®¹: {str(matches)[:100]}...")
                    else:
                        formatted_lines.append(f"{i}. {str(result)}")
            
            return '\n'.join(formatted_lines).strip()
            
        except Exception as e:
            logger.warning(f"Failed to format Search Tool output: {e}")
            return f"æ–‡ä»¶æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {count} ä¸ªç»“æœ"
    
    def _format_microsandbox_output(self, output) -> str:
        """ğŸ”§ ä¿®æ”¹ï¼šæ˜¾ç¤ºMicroSandboxçš„å®Œæ•´åŸå§‹JSONç»“æœ"""
        import json
        try:
            # ç›´æ¥è¿”å›å®Œæ•´çš„åŸå§‹JSONç»“æ„ï¼Œä¸è¿›è¡Œä»»ä½•ç®€åŒ–
            if isinstance(output, dict):
                return json.dumps(output, ensure_ascii=False, indent=2)
            else:
                return str(output)
        except Exception as e:
            logger.warning(f"Failed to format MicroSandbox output: {e}")
            return str(output)
    
    def _format_generic_output(self, output) -> str:
        """é€šç”¨å·¥å…·è¾“å‡ºæ ¼å¼åŒ–"""
        try:
            if isinstance(output, dict):
                # å°è¯•æå–æœ‰ç”¨ä¿¡æ¯
                if 'result' in output:
                    return str(output['result'])
                elif 'content' in output:
                    return str(output['content'])
                elif 'data' in output:
                    return str(output['data'])
                elif 'message' in output:
                    return str(output['message'])
                else:
                    # è¿‡æ»¤æ‰æŠ€æœ¯æ€§å­—æ®µï¼Œåªä¿ç•™æœ‰æ„ä¹‰çš„å†…å®¹
                    meaningful_fields = {}
                    skip_fields = {'success', 'status', 'code', 'timestamp', 'metadata', 'headers'}
                    
                    for key, value in output.items():
                        if key not in skip_fields and value:
                            meaningful_fields[key] = value
                    
                    if meaningful_fields:
                        return str(meaningful_fields)
            
            return str(output)
            
        except Exception as e:
            logger.warning(f"Failed to format generic output: {e}")
            return str(output)

    def _format_memory_staging_output(self, action: str, output: dict) -> str:
        """æ ¼å¼åŒ–å†…å­˜æš‚å­˜å·¥å…·è¾“å‡º - ä¸ºå·¥å…·æ‰§è¡Œæ–¹æ³•ä½¿ç”¨"""
        return self._format_memory_staging_output_generic(action, output)
    
    def _format_memory_staging_output_generic(self, action: str, output: dict) -> str:
        """æ ¼å¼åŒ–å†…å­˜æš‚å­˜å·¥å…·è¾“å‡º - é€šç”¨æ ¼å¼åŒ–æ–¹æ³•"""
        try:
            if not isinstance(output, dict):
                return str(output)
            
            success = output.get("success", False)
            
            if action == "memory_write":
                if success:
                    key = output.get("key", "unknown")
                    data_type = output.get("data_type", "unknown")
                    return f"âœ… æ•°æ®å·²ä¿å­˜åˆ°æš‚å­˜åŒº: {key} (ç±»å‹: {data_type})"
                else:
                    error = output.get("error", "Unknown error")
                    return f"âŒ ä¿å­˜æ•°æ®å¤±è´¥: {error}"
            
            elif action == "memory_read":
                if success:
                    key = output.get("key", "unknown")
                    value = output.get("value")
                    data_type = output.get("data_type", "unknown")
                    age = output.get("age_seconds", 0)
                    
                    # æ ¼å¼åŒ–å¹´é¾„
                    if age < 60:
                        age_str = f"{int(age)}ç§’å‰"
                    elif age < 3600:
                        age_str = f"{int(age/60)}åˆ†é’Ÿå‰"
                    else:
                        age_str = f"{int(age/3600)}å°æ—¶å‰"
                    
                    # æ ¼å¼åŒ–å€¼é¢„è§ˆ
                    if isinstance(value, (dict, list)):
                        value_preview = str(value)[:100] + "..." if len(str(value)) > 100 else str(value)
                    else:
                        value_preview = str(value)[:200] + "..." if len(str(value)) > 200 else str(value)
                    
                    return f"ğŸ“– ä»æš‚å­˜åŒºè¯»å–: {key}\nç±»å‹: {data_type} ({age_str})\nå†…å®¹: {value_preview}"
                else:
                    error = output.get("error", "Unknown error")
                    available_keys = output.get("available_keys", [])
                    if available_keys:
                        return f"âŒ è¯»å–å¤±è´¥: {error}\nå¯ç”¨é”®å: {', '.join(available_keys)}"
                    else:
                        return f"âŒ è¯»å–å¤±è´¥: {error}"
            
            elif action == "memory_list":
                if success:
                    entries = output.get("entries", [])
                    total_count = output.get("total_count", 0)
                    
                    if total_count == 0:
                        return "ğŸ“‹ æš‚å­˜åŒºä¸ºç©º"
                    
                    result_lines = [f"ğŸ“‹ æš‚å­˜åŒºå†…å®¹ ({total_count} é¡¹):"]
                    for entry in entries[:10]:  # åªæ˜¾ç¤ºå‰10é¡¹
                        key = entry.get("key", "unknown")
                        data_type = entry.get("data_type", "unknown")
                        age = entry.get("age_seconds", 0)
                        
                        if age < 60:
                            age_str = f"{int(age)}ç§’å‰"
                        elif age < 3600:
                            age_str = f"{int(age/60)}åˆ†é’Ÿå‰"
                        else:
                            age_str = f"{int(age/3600)}å°æ—¶å‰"
                        
                        result_lines.append(f"  - {key} ({data_type}) - {age_str}")
                    
                    if total_count > 10:
                        result_lines.append(f"  ... è¿˜æœ‰ {total_count - 10} é¡¹")
                    
                    return "\n".join(result_lines)
                else:
                    error = output.get("error", "Unknown error")
                    return f"âŒ åˆ—è¡¨è·å–å¤±è´¥: {error}"
            
            elif action == "memory_search":
                if success:
                    matches = output.get("matches", [])
                    total_matches = output.get("total_matches", 0)
                    query = output.get("query", "")
                    
                    if total_matches == 0:
                        return f"ğŸ” æœç´¢ '{query}' æ— ç»“æœ"
                    
                    result_lines = [f"ğŸ” æœç´¢ '{query}' æ‰¾åˆ° {total_matches} ä¸ªåŒ¹é…é¡¹:"]
                    for match in matches[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªåŒ¹é…
                        key = match.get("key", "unknown")
                        score = match.get("score", 0)
                        reasons = match.get("match_reasons", [])
                        value_preview = str(match.get("value", ""))[:100] + "..." if len(str(match.get("value", ""))) > 100 else str(match.get("value", ""))
                        
                        result_lines.append(f"  - {key} (åˆ†æ•°: {score}, åŒ¹é…: {', '.join(reasons)})")
                        result_lines.append(f"    å†…å®¹: {value_preview}")
                    
                    if total_matches > 5:
                        result_lines.append(f"  ... è¿˜æœ‰ {total_matches - 5} ä¸ªåŒ¹é…é¡¹")
                    
                    return "\n".join(result_lines)
                else:
                    error = output.get("error", "Unknown error")
                    return f"âŒ æœç´¢å¤±è´¥: {error}"
            
            elif action == "memory_clear":
                if success:
                    key = output.get("key")
                    if key:
                        return f"ğŸ—‘ï¸ å·²æ¸…é™¤æš‚å­˜æ•°æ®: {key}"
                    else:
                        cleared_count = output.get("cleared_count", 0)
                        return f"ğŸ—‘ï¸ å·²æ¸…ç©ºæ‰€æœ‰æš‚å­˜æ•°æ® ({cleared_count} é¡¹)"
                else:
                    error = output.get("error", "Unknown error")
                    return f"âŒ æ¸…é™¤å¤±è´¥: {error}"
            
            else:
                # æœªçŸ¥åŠ¨ä½œï¼Œä½¿ç”¨é€šç”¨æ ¼å¼åŒ–
                message = output.get("message", str(output))
                return f"ğŸ”„ å†…å­˜æš‚å­˜æ“ä½œ ({action}): {message}"
        
        except Exception as e:
            logger.warning(f"Failed to format memory staging output: {e}")
            return str(output)

    async def _execute_parallel(self, actions: list) -> list:
        """å¹¶å‘æ‰§è¡Œå¤šä¸ªåŠ¨ä½œã€‚"""
        import asyncio
        if not actions:
            return []
        
        tasks = [self._execute_tool(action) for action in actions]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¯èƒ½å‘ç”Ÿçš„å¼‚å¸¸ï¼Œç¡®ä¿è¿”å›å­—ç¬¦ä¸²åˆ—è¡¨
        return [str(res) if not isinstance(res, Exception) else f"Error: {res}" for res in results]
    
    @property
    def runtime_id(self) -> str:
        return self._runtime_id
    
    async def capabilities(self) -> List[str]:
        """è·å–è¿è¡Œæ—¶èƒ½åŠ›"""
        return ['llm_reasoning', 'tool_execution', 'xml_streaming', 'memory', 'trajectory_enhancement', 'error_recovery']
    
    async def health_check(self) -> bool:
        """å¥åº·æ£€æŸ¥"""
        try:
            if hasattr(self.toolscore_client, 'health_check'):
                return await self.toolscore_client.health_check()
            return True
        except Exception:
            return False
    
    async def initialize(self):
        """åˆå§‹åŒ–è¿è¡Œæ—¶"""
        logger.info("ğŸš€ åˆå§‹åŒ–Enhanced Reasoning Runtime")
        if not self.client:
            raise RuntimeError("LLMå®¢æˆ·ç«¯æœªé…ç½®")
        if not self.toolscore_client:
            raise RuntimeError("å·¥å…·å®¢æˆ·ç«¯æœªé…ç½®")
        
        # MicroSandboxè¿æ¥ç®¡ç†å™¨å·²ç§»é™¤ - ä½¿ç”¨æ ‡å‡†å·¥å…·æ‰§è¡Œæµç¨‹
            
        self.is_initialized = True
        logger.info("âœ… Enhanced Reasoning Runtime åˆå§‹åŒ–å®Œæˆ")
    
    async def execute(self, task: TaskSpec) -> TrajectoryResult:
        """æ‰§è¡Œä»»åŠ¡"""
        logger.info(f"ğŸ§  å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task.description}")
        if not self.is_initialized:
            await self.initialize()
        
        if self.xml_streaming_mode:
            return await self._execute_xml_streaming(task)
        else:
            # ä¿ç•™æ ‡å‡†æ¨¡å¼ä½œä¸ºå¤‡é€‰ï¼Œä½†ä¸»è¦æµç¨‹æ˜¯XMLæµ
            return await self._execute_standard(task)
    
    async def _execute_xml_streaming(self, task: TaskSpec) -> TrajectoryResult:
        """
        æ‰§è¡ŒåŸºäºXMLçš„ã€æ”¯æŒå•æ­¥ã€å¹¶è¡Œå’Œä¸²è¡Œå·¥å…·è°ƒç”¨çš„ä¸»æ§åˆ¶å¾ªç¯ã€‚
        """
        logger.info(f"ğŸ¯ Orchestrator starting task: {task.description}")
        start_time = time.time()
        
        # ğŸ” å¯åŠ¨æ­¥éª¤çº§æ—¥å¿—è®°å½•
        self.step_logger.start_task(task.task_id, task.description)
        
        # ğŸ†• Stage 3: æ™ºèƒ½ä»»åŠ¡åˆ†è§£
        decomposition_result = None
        if len(task.description) > 50:  # å¯¹è¾ƒå¤æ‚çš„ä»»åŠ¡è¿›è¡Œåˆ†è§£
            try:
                decomposition_result = self.task_decomposer.decompose_task(task.description)
                logger.info(f"ğŸ“‹ ä»»åŠ¡åˆ†è§£å®Œæˆ: {decomposition_result.complexity.value}, "
                          f"{len(decomposition_result.steps)} æ­¥éª¤, "
                          f"é¢„è®¡ {decomposition_result.estimated_total_duration:.1f}ç§’")
                
                # å¦‚æœæ˜¯æå¤æ‚ä»»åŠ¡ï¼Œè®°å½•åˆ†è§£ç»“æœ
                if decomposition_result.complexity in [TaskComplexity.COMPLEX, TaskComplexity.VERY_COMPLEX]:
                    logger.info(f"ğŸ¯ å¤æ‚ä»»åŠ¡æ‰§è¡Œç­–ç•¥: {decomposition_result.execution_strategy}")
                    for i, step in enumerate(decomposition_result.steps[:3]):  # åªæ˜¾ç¤ºå‰3æ­¥
                        logger.info(f"  æ­¥éª¤{i+1}: {step.description} ({step.action_type})")
                    if len(decomposition_result.steps) > 3:
                        logger.info(f"  ... è¿˜æœ‰ {len(decomposition_result.steps)-3} ä¸ªæ­¥éª¤")
                        
            except Exception as e:
                logger.warning(f"âš ï¸ ä»»åŠ¡åˆ†è§£å¤±è´¥ï¼Œç»§ç»­æ­£å¸¸æ‰§è¡Œ: {e}")
        
        # å‡†å¤‡å†å²è®°å½•
        available_tools = await self._get_available_tools()
        tool_descriptions = await self._get_tool_descriptions()
        history = self.prompt_builder.build_prompt(
            task_description=task.description,
            available_tools=available_tools,
            tool_descriptions=tool_descriptions,
            history=[]
        )
        
        full_trajectory = [] # è®°å½•å®Œæ•´çš„äº¤äº’è½¨è¿¹

        max_steps = task.max_steps or 20
        for step in range(max_steps):
            logger.info(f"--- Starting Step {step + 1}/{max_steps} ---")
            
            # ğŸ” å¼€å§‹æ­¥éª¤æ—¥å¿—è®°å½•
            self.step_logger.start_step(step)
            
            # 1. ğŸ†• Tokenä¼˜åŒ– - ä¼˜åŒ–æ¶ˆæ¯ä»¥å‡å°‘tokenæ¶ˆè€—
            original_history = history.copy()
            optimized_history = history
            optimization_info = {}
            
            if self.token_manager:
                try:
                    optimized_history, optimization_info = await self.token_manager.optimize_messages_with_cache(
                        history, 
                        model=getattr(self.client, 'model', 'gemini-2.5-flash'),
                        session_id=getattr(task, 'session_id', task.task_id)
                    )
                    if optimization_info.get('tokens_saved', 0) > 0:
                        logger.info(f"ğŸ’° Tokenä¼˜åŒ–: èŠ‚çœ {optimization_info['tokens_saved']} tokens "
                                  f"(${optimization_info['cost_saved']:.6f})")
                except Exception as e:
                    logger.warning(f"Tokenä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ¶ˆæ¯: {e}")
                    optimized_history = history
            
            # 2. ğŸ”§ è°ƒç”¨LLMï¼Œå¸¦å®Œæ•´å¼‚å¸¸å¤„ç†å’Œé‡è¯•æœºåˆ¶
            # ğŸ”§ ä¿®å¤ï¼šåœ¨execute_toolsæ ‡ç­¾ä¹‹ååœæ­¢ï¼Œè€Œä¸æ˜¯åœ¨æ ‡ç­¾æœ¬èº«åœæ­¢
            stop_sequences = ["\n<execute_tools />", "\n<execute_tools></execute_tools>", "</answer>"]
            llm_start_time = time.time()
            response_text = None
            llm_error = None
            token_usage = {}
            
            # ğŸ”¥ LLM APIè°ƒç”¨é‡è¯•æœºåˆ¶
            for attempt in range(3):  # æœ€å¤šé‡è¯•3æ¬¡
                try:
                    logger.debug(f"ğŸ”„ LLM APIè°ƒç”¨å°è¯• {attempt + 1}/3")
                    response_text = await self.client._call_api(optimized_history, stop_sequences=stop_sequences)
                    llm_end_time = time.time()
                    
                    logger.info(f"âœ… LLM APIè°ƒç”¨æˆåŠŸ (å°è¯• {attempt + 1})")
                    break  # æˆåŠŸåˆ™è·³å‡ºé‡è¯•å¾ªç¯
                    
                except Exception as e:
                    llm_end_time = time.time()
                    llm_error = e
                    wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿: 1, 2, 4 ç§’
                    
                    logger.error(f"âŒ LLM APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/3): {e}")
                    
                    # ç‰¹æ®Šå¤„ç†ä¸åŒç±»å‹çš„é”™è¯¯
                    error_type = type(e).__name__
                    if "RemoteProtocolError" in error_type:
                        logger.warning("ğŸš¨ æ£€æµ‹åˆ°RemoteProtocolError - æœåŠ¡å™¨è¿æ¥ä¸­æ–­")
                    elif "TimeoutError" in error_type or "timeout" in str(e).lower():
                        logger.warning("â° æ£€æµ‹åˆ°è¶…æ—¶é”™è¯¯")
                    elif "HTTPStatusError" in error_type:
                        logger.warning(f"ğŸŒ æ£€æµ‹åˆ°HTTPçŠ¶æ€é”™è¯¯: {getattr(e, 'response', {}).get('status_code', 'unknown')}")
                    
                    if attempt < 2:  # ä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•
                        logger.info(f"ğŸ”„ {wait_time}ç§’åè¿›è¡Œç¬¬ {attempt + 2} æ¬¡é‡è¯•...")
                        await asyncio.sleep(wait_time)
                    else:
                        logger.error("âŒ æ‰€æœ‰LLM APIè°ƒç”¨å°è¯•éƒ½å¤±è´¥äº†")
            
            # 3. ğŸ†• Tokenä½¿ç”¨ç»Ÿè®¡å’Œè®°å½•ï¼ˆæ— è®ºæˆåŠŸå¤±è´¥éƒ½å°è¯•ï¼‰
            if response_text and self.token_manager:
                try:
                    # è®¡ç®—å®é™…tokenä½¿ç”¨
                    prompt_text = " ".join([msg.get('content', '') for msg in optimized_history if isinstance(msg, dict)])
                    prompt_tokens = await self.token_manager.count_tokens_accurately(prompt_text)
                    completion_tokens = await self.token_manager.count_tokens_accurately(response_text)
                    
                    # è®°å½•tokenä½¿ç”¨
                    await self.token_manager.record_token_usage(
                        prompt_tokens=prompt_tokens,
                        completion_tokens=completion_tokens,
                        model=getattr(self.client, 'model', 'gemini-2.5-flash'),
                        task_id=task.task_id,
                        session_id=getattr(task, 'session_id', None),
                        cached_tokens=optimization_info.get('tokens_saved', 0)
                    )
                    
                    token_usage = {
                        'prompt_tokens': prompt_tokens,
                        'completion_tokens': completion_tokens,
                        'total_tokens': prompt_tokens + completion_tokens,
                        'cached_tokens': optimization_info.get('tokens_saved', 0),
                        'model': getattr(self.client, 'model', 'gemini-2.5-flash'),
                        'data_source': 'api_provided'
                    }
                except Exception as e:
                    logger.warning(f"Tokenç»Ÿè®¡å¤±è´¥: {e}")
            
            # 4. ğŸ” è®°å½•LLMè°ƒç”¨ï¼ˆåŒ…å«é”™è¯¯ä¿¡æ¯å’Œtokenä¿¡æ¯ï¼‰
            if response_text:
                triggered_stop = self._detect_triggered_stop_sequence(response_text, stop_sequences)
            else:
                triggered_stop = None
                # ğŸ”§ å³ä½¿LLMè°ƒç”¨å¤±è´¥ä¹Ÿè®°å½•è½¨è¿¹
                response_text = f"LLM APIè°ƒç”¨å¤±è´¥: {llm_error}" if llm_error else "LLM APIè°ƒç”¨å¤±è´¥: æœªçŸ¥åŸå› "
            
            self.step_logger.log_llm_call(
                prompt=original_history,  # ä½¿ç”¨åŸå§‹æ¶ˆæ¯è®°å½•å®Œæ•´å†…å®¹
                raw_response=response_text,
                stop_sequence=triggered_stop,
                start_time=llm_start_time,
                end_time=llm_end_time,
                token_usage=token_usage  # ğŸ†• ä¼ é€’è¯¦ç»†çš„tokenä½¿ç”¨ä¿¡æ¯
            )
            
            # 5. ğŸš¨ å¦‚æœLLMè°ƒç”¨å½»åº•å¤±è´¥ï¼Œç”Ÿæˆé”™è¯¯å“åº”ä½†ç»§ç»­è®°å½•è½¨è¿¹
            if llm_error:
                error_response = self._generate_llm_failure_response(llm_error, task)
                
                # è®°å½•é”™è¯¯æ­¥éª¤
                self.step_logger.log_step_error(
                    step_index=len(full_trajectory),
                    error_type="LLM_API_FAILURE",
                    error_message=str(llm_error),
                    recovery_attempted=True
                )
                
                # ä»ç„¶æ·»åŠ åˆ°å†å²ä¸­ä»¥ä¿æŒè½¨è¿¹å®Œæ•´æ€§
                history.append({"role": "assistant", "content": error_response})
                full_trajectory.append({"role": "assistant", "content": error_response})
                
                # è®¾ç½®ä»»åŠ¡å¤±è´¥ä½†ä¸ç«‹å³é€€å‡ºï¼Œç¡®ä¿è½¨è¿¹è¢«ä¿å­˜
                success = False
                final_result = f"ä»»åŠ¡å› LLM APIè¿æ¥é—®é¢˜å¤±è´¥: {llm_error}"
                
                # è·³åˆ°è½¨è¿¹ä¿å­˜å’Œè¿”å›
                break
            
            # ğŸ”§ ä¿®å¤ï¼šè‡ªåŠ¨æ³¨å…¥ç¼ºå¤±çš„<execute_tools />æ ‡ç­¾
            response_text = self._auto_inject_execute_tools(response_text)
            
            history.append({"role": "assistant", "content": response_text})
            full_trajectory.append({"role": "assistant", "content": response_text})

            # ğŸ†• æ–°å¢ï¼šå¤„ç† <tool_param> æŸ¥è¯¢
            if "<tool_param>" in response_text:
                tool_param_result = await self._handle_tool_param_query(response_text)
                history.append({"role": "assistant", "content": tool_param_result})
                full_trajectory.append({"role": "assistant", "content": tool_param_result})
                self.step_logger.finish_step("tool_param_query_handled")
                continue

            # ğŸ”§ ä¿®å¤ï¼šæ›´æ™ºèƒ½çš„ç­”æ¡ˆæ£€æµ‹é€»è¾‘
            answer_tag = TaskExecutionConstants.XML_TAGS['ANSWER']
            answer_start_tag = f"<{answer_tag}>"
            answer_end_tag = f"</{answer_tag}>"
            
            # æ£€æµ‹ç­”æ¡ˆæ ‡ç­¾ï¼ˆå¼€å§‹æ ‡ç­¾æˆ–ç»“æŸæ ‡ç­¾ï¼‰
            has_answer_start = answer_start_tag in response_text
            has_answer_end = answer_end_tag in response_text
            has_boxed_content = "\\boxed{" in response_text
            
            if has_answer_end or (has_answer_start and has_boxed_content):
                logger.info("âœ… Final Answer detected. Task complete.")
                # ğŸ” è®°å½•è§£æç»“æœï¼ˆåŒ…å«ç­”æ¡ˆçš„æƒ…å†µï¼‰
                parsing_start_time = time.time()
                think_content = self.step_logger._extract_think_content(response_text)
                answer_content = self.step_logger._extract_answer_content(response_text)
                parsing_end_time = time.time()
                
                self.step_logger.log_parsing_result(
                    think_content=think_content,
                    execution_block=None,
                    answer_content=answer_content,
                    actions=[],
                    parsing_errors=[],
                    start_time=parsing_start_time,
                    end_time=parsing_end_time
                )
                self.step_logger.finish_step("task_completed_with_answer")
                break

            # ğŸ” Stage 3å¢å¼ºï¼šä½¿ç”¨å¢å¼ºXMLè§£æå™¨
            parsing_start_time = time.time()
            
            # ä½¿ç”¨å¢å¼ºXMLè§£æå™¨
            parse_result = self.xml_parser.parse_xml_response(response_text)
            actions = parse_result.actions
            
            # è®°å½•è§£æè¯¦æƒ…
            think_content = self.step_logger._extract_think_content(response_text)
            execution_block_text = self.step_logger._extract_execution_block(response_text)
            parsing_end_time = time.time()
            
            # æ„å»ºè§£æé”™è¯¯ä¿¡æ¯
            parsing_errors = []
            if not parse_result.success:
                parsing_errors.extend(parse_result.errors)
            if parse_result.warnings:
                parsing_errors.extend([f"è­¦å‘Š: {w}" for w in parse_result.warnings])
            
            # è®°å½•è§£æç»“æœï¼ˆåŒ…å«å¢å¼ºè§£æä¿¡æ¯ï¼‰
            self.step_logger.log_parsing_result(
                think_content=think_content,
                execution_block=execution_block_text,
                answer_content=None,
                actions=actions,
                parsing_errors=parsing_errors,
                start_time=parsing_start_time,
                end_time=parsing_end_time
            )
            
            # è®°å½•è§£æç½®ä¿¡åº¦å’Œä¿®å¤æ“ä½œ
            if parse_result.repaired_xml:
                logger.info(f"ğŸ”§ XMLè‡ªåŠ¨ä¿®å¤æˆåŠŸï¼Œç½®ä¿¡åº¦: {parse_result.confidence_score:.2f}")
            if not parse_result.success and len(actions) > 0:
                logger.warning(f"âš ï¸ éƒ¨åˆ†è§£ææˆåŠŸï¼Œæå–åˆ° {len(actions)} ä¸ªåŠ¨ä½œ")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æœ€ç»ˆç­”æ¡ˆæ ‡ç­¾ - å¦‚æœæœ‰åˆ™ç›´æ¥ç»“æŸ
            think_tag = TaskExecutionConstants.XML_TAGS['THINK']
            answer_tag = TaskExecutionConstants.XML_TAGS['ANSWER']
            execute_tools_tag = TaskExecutionConstants.XML_TAGS['EXECUTE_TOOLS']
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ£€æµ‹åˆ°answeræ ‡ç­¾æ—¶ç›´æ¥ç»“æŸä»»åŠ¡
            if f"<{answer_tag}>" in response_text:
                logger.info("âœ… æ£€æµ‹åˆ°<answer>æ ‡ç­¾ï¼Œä»»åŠ¡å®Œæˆ")
                history.append({"role": "assistant", "content": response_text})
                full_trajectory.append({"role": "assistant", "content": response_text})
                self.step_logger.finish_step("answer_tag_detected")
                break
            
            # ğŸ”§ ä¿®å¤ï¼šåˆ é™¤é”™è¯¯çš„thought-only final answeré€»è¾‘
            # ä¸åº”è¯¥å°†çº¯æ€è€ƒå†…å®¹å½“ä½œæœ€ç»ˆç­”æ¡ˆï¼Œæ¨¡å‹å¯èƒ½åªæ˜¯åœ¨ç¬¬ä¸€æ­¥æ€è€ƒ
            # è®©æ‰§è¡Œæµç¨‹ç»§ç»­ï¼Œå¦‚æœç¡®å®éœ€è¦å·¥å…·æ‰§è¡Œï¼Œåç»­çš„é€»è¾‘ä¼šå¤„ç†

            # ğŸ”§ Stage 2 å¢å¼ºï¼šå¤æ‚ä»»åŠ¡æ£€æµ‹ä¸å¼ºåˆ¶æ‰§è¡Œæœºåˆ¶
            if not actions:
                # ğŸš¨ æ–°å¢ï¼šå¤æ‚ä»»åŠ¡æ£€æµ‹ä¸å¼ºåˆ¶æ‰§è¡Œ
                if self._is_complex_task_response(response_text):
                    logger.warning("ğŸš¨ æ£€æµ‹åˆ°å¤æ‚ä»»åŠ¡ä½†æ— å·¥å…·æ‰§è¡Œ - å¼ºåˆ¶æ‰§è¡Œç¬¬ä¸€æ­¥")
                    
                    # å°è¯•å¼ºåˆ¶æ‰§è¡Œç¬¬ä¸€æ­¥
                    force_execution_result = await self._force_first_step_execution(response_text, task)
                    if force_execution_result:
                        result_xml = force_execution_result
                        history.append({"role": "assistant", "content": result_xml})
                        full_trajectory.append({"role": "assistant", "content": result_xml})
                        # ğŸ” å®Œæˆæ­¥éª¤è®°å½•
                        self.step_logger.finish_step("complex_task_forced_execution")
                        continue
                
                # ğŸ”§ åŸæœ‰çš„è®¡åˆ’-æ‰§è¡Œæ¡¥æ¢æœºåˆ¶ï¼ˆä½œä¸ºå¤‡é€‰æ–¹æ¡ˆï¼‰
                plan_content = self._extract_detailed_plan(response_text)
                if plan_content and self._has_executable_plan(plan_content):
                    logger.info("ğŸ¯ æ£€æµ‹åˆ°è¯¦ç»†è®¡åˆ’ä½†ç¼ºå°‘æ‰§è¡ŒåŠ¨ä½œï¼Œå¼•å¯¼LLMå¼€å§‹æ‰§è¡Œ")
                    
                    # ğŸ”§ æ–°å¢ï¼šåˆ†æè®¡åˆ’ä¸­çš„ç¬¬ä¸€æ­¥å…·ä½“åŠ¨ä½œ
                    first_action = self._extract_first_executable_action(plan_content)
                    if first_action:
                        execution_guidance = (
                            f"You have created a detailed plan. Now please start executing the first step: {first_action}. "
                            "Use the appropriate tool call with the exact XML format and end with <execute_tools />. "
                            "Remember: plans are not answers - execution is required."
                        )
                    else:
                        execution_guidance = (
                            "You have created a detailed plan. Now please start executing the first step of your plan. "
                            "Use the appropriate tool call with the exact XML format and end with <execute_tools />. "
                            "Remember: plans are not answers - execution is required."
                        )
                    
                    result_xml = self._format_result(execution_guidance)
                    history.append({"role": "assistant", "content": result_xml})
                    full_trajectory.append({"role": "assistant", "content": result_xml})
                    # ğŸ” å®Œæˆæ­¥éª¤è®°å½•
                    self.step_logger.finish_step("plan_execution_guidance_injected")
                    continue
                
                # ğŸ”§ ä¿®å¤ï¼šå¯¹äºåªæœ‰æ€è€ƒå†…å®¹çš„æƒ…å†µï¼Œæä¾›å¼•å¯¼è€Œä¸æ˜¯ç›´æ¥ç»ˆæ­¢
                if f"<{think_tag}>" in response_text:
                    logger.info("ğŸ’­ æ£€æµ‹åˆ°çº¯æ€è€ƒå†…å®¹ï¼Œæä¾›æ‰§è¡Œå¼•å¯¼")
                    
                    # æä¾›æ‰§è¡Œå¼•å¯¼
                    guidance = (
                        "You have shared your thinking process. Now please proceed to execute the necessary steps. "
                        "Use the appropriate tool calls with the exact XML format and end with <execute_tools />. "
                        "Remember: thinking is just the first step - execution is required to complete the task."
                    )
                    
                    result_xml = self._format_result(guidance)
                    history.append({"role": "assistant", "content": result_xml})
                    full_trajectory.append({"role": "assistant", "content": result_xml})
                    # ğŸ” å®Œæˆæ­¥éª¤è®°å½•
                    self.step_logger.finish_step("thinking_execution_guidance")
                    continue
                
                # å…¶ä»–æƒ…å†µï¼šæ­£å¸¸çš„æ— åŠ¨ä½œå“åº”
                logger.info("âœ… Detected response without tool execution - continuing to next step")
                # ğŸ” å®Œæˆæ­¥éª¤è®°å½•
                self.step_logger.finish_step("no_action_continue")
                continue

            # 4. æ ¹æ®ç±»å‹åˆ†å‘æ‰§è¡Œ
            results = []
            block_type = parse_result.execution_type or "single"

            # ğŸ”§ ä¿®å¤ï¼šæ·»åŠ å·¥å…·æ‰§è¡Œå¼‚å¸¸å¤„ç†ï¼Œç¡®ä¿è½¨è¿¹è®°å½•å®Œæ•´æ€§
            try:
                # å¯¹äºä¸²è¡Œå—ï¼Œæˆ‘ä»¬åªæ‰§è¡Œç¬¬ä¸€ä¸ªåŠ¨ä½œã€‚LLMå°†åœ¨ä¸‹ä¸€è½®æ ¹æ®ç»“æœå†³å®šåç»­æ­¥éª¤ã€‚
                if block_type == "sequential":
                    logger.info(f"Executing first action of sequential block.")
                    if actions:
                        result_data = await self._execute_tool_with_logging(actions[0], 0)
                        results = [result_data["formatted_result"]]
                elif block_type == "parallel":
                    logger.info(f"Executing parallel block with {len(actions)} actions.")
                    results = await self._execute_parallel_with_logging(actions)
                else: # single
                    if actions:
                        logger.info(f"Executing single action.")
                        result_data = await self._execute_tool_with_logging(actions[0], 0)
                        results = [result_data["formatted_result"]]
                        
            except Exception as tool_exec_error:
                # ğŸ”§ å…³é”®ä¿®å¤ï¼šå·¥å…·æ‰§è¡Œå¤±è´¥æ—¶ï¼Œè®°å½•å®Œæ•´çš„æ¨ç†è¿‡ç¨‹å’Œé”™è¯¯ä¿¡æ¯
                logger.error(f"å·¥å…·æ‰§è¡Œå¤±è´¥: {tool_exec_error}")
                error_type = self._analyze_error_type(str(tool_exec_error))
                
                # åˆ›å»ºè¯¦ç»†çš„é”™è¯¯ç»“æœï¼ŒåŒ…å«æ¨ç†è¿‡ç¨‹
                error_result = f"å·¥å…·æ‰§è¡Œå¤±è´¥: {str(tool_exec_error)}"
                
                # ğŸ”§ ç‰¹æ®Šå¤„ç†å‚æ•°éªŒè¯å¤±è´¥çš„æƒ…å†µ
                if "Parameter validation failed" in str(tool_exec_error):
                    # æå–æ¨¡å‹åŸæœ¬æƒ³è¦æ‰§è¡Œçš„åŠ¨ä½œ
                    original_action = actions[0] if actions else {}
                    service_name = original_action.get('service', 'unknown')
                    tool_name = original_action.get('tool', 'unknown')
                    tool_input = original_action.get('input', '')
                    
                    error_result = f"""å‚æ•°éªŒè¯å¤±è´¥ï¼Œä½†æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹å·²è®°å½•ï¼š

æ¨¡å‹å°è¯•æ‰§è¡Œï¼š{service_name}.{tool_name}
æ¨¡å‹æä¾›çš„è¾“å…¥ï¼š{tool_input}

é”™è¯¯è¯¦æƒ…ï¼š{str(tool_exec_error)}

å»ºè®®ï¼šè¯·æ£€æŸ¥å‚æ•°æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼Œç¡®ä¿ä¼ å…¥äº†å·¥å…·æ‰€éœ€çš„å¿…éœ€å‚æ•°ã€‚"""
                
                results = [error_result]
                
                # ğŸ”§ è®°å½•é”™è¯¯æ­¥éª¤åˆ°è½¨è¿¹ä¸­
                self.step_logger.log_step_error(
                    step_index=len(full_trajectory),
                    error_type=error_type,
                    error_message=str(tool_exec_error),
                    recovery_attempted=True
                )

            # 5. æ ¼å¼åŒ–å¹¶ä¸ºæ¯ä¸ªç»“æœæ³¨å…¥å•ç‹¬çš„<result>æ ‡ç­¾
            for res in results:
                result_xml = self._format_result(res)
                history.append({"role": "assistant", "content": result_xml})
                full_trajectory.append({"role": "assistant", "content": result_xml})
                
            # ğŸ” å®Œæˆæ­¥éª¤è®°å½•
            self.step_logger.finish_step()

        else:
            logger.warning(f"Max steps ({max_steps}) reached. Terminating task.")
            # ğŸ” å®Œæˆæœ€åä¸€ä¸ªæ­¥éª¤è®°å½•
            if self.step_logger.current_step_data:
                self.step_logger.finish_step("max_steps_reached")

        # ä»»åŠ¡ç»“æŸï¼Œå¤„ç†æœ€ç»ˆç»“æœ
        final_trajectory_str = "\n".join(item["content"] for item in full_trajectory)
        total_duration = time.time() - start_time
        
        # ğŸ”§ æ ¹æœ¬ä¿®å¤ï¼šåŒºåˆ†æ­¥æ•°é™åˆ¶å’ŒçœŸæ­£å¤±è´¥
        max_steps_reached = len(full_trajectory) >= max_steps
        
        # ğŸ§  æ–°æ™ºèƒ½è¯„ä¼°ï¼šä½¿ç”¨è¯­ä¹‰ç†è§£å’Œç»“æœé©±åŠ¨çš„åˆ¤å®šé€»è¾‘
        final_result = self._extract_final_result(final_trajectory_str)
        
        try:
            success, confidence_score, evaluation_reasoning = await self._intelligent_task_success_evaluation(
                task_input=task.description,
                final_trajectory_str=final_trajectory_str,
                full_trajectory=full_trajectory,
                final_output=final_result
            )
            logger.info(f"ğŸ§  æ™ºèƒ½è¯„ä¼°: æˆåŠŸ={success}, ç½®ä¿¡åº¦={confidence_score:.2f}, ç†ç”±={evaluation_reasoning}")
        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•: {e}")
            success = self._determine_task_success(final_trajectory_str, full_trajectory)
            confidence_score = 0.5
            evaluation_reasoning = "ä½¿ç”¨ä¼ ç»Ÿè¯„ä¼°æ–¹æ³•"
        
        # ğŸ”§ æ–°å¢ï¼šå¦‚æœè¾¾åˆ°æœ€å¤§æ­¥æ•°ä½†æ²¡æœ‰æ˜ç¡®çš„ç­”æ¡ˆï¼Œé™ä½æˆåŠŸåˆ¤å®šæ ‡å‡†
        if max_steps_reached:
            answer_tag = TaskExecutionConstants.XML_TAGS['ANSWER']
            has_explicit_answer = f"<{answer_tag}>" in final_trajectory_str
            has_boxed_content = "\\boxed{" in final_trajectory_str
            
            if not has_explicit_answer and not has_boxed_content:
                # è¾¾åˆ°æœ€å¤§æ­¥æ•°ä¸”æ²¡æœ‰æ˜ç¡®ç­”æ¡ˆï¼Œæ ‡è®°ä¸ºéƒ¨åˆ†æˆåŠŸä½†éœ€è¦è¯´æ˜
                logger.warning(f"ä»»åŠ¡è¾¾åˆ°æœ€å¤§æ­¥æ•°({max_steps})ä½†æ²¡æœ‰æ˜ç¡®ç­”æ¡ˆæ ‡è®°")
                # æ ¹æ®æ˜¯å¦æœ‰å·¥å…·æ‰§è¡Œç»“æœæ¥åˆ¤å®š
                tool_success_rate = self._calculate_tool_success_rate()
                success = tool_success_rate > 0.5  # è‡³å°‘50%çš„å·¥å…·æ‰§è¡ŒæˆåŠŸæ‰è®¤ä¸ºéƒ¨åˆ†æˆåŠŸ
        
        # ğŸ”§ æ ¹æœ¬ä¿®å¤ï¼šåŠ¨æ€æå–çœŸå®çš„æœ€ç»ˆç»“æœï¼Œè€ƒè™‘æ­¥æ•°é™åˆ¶æƒ…å†µ
        if max_steps_reached:
            final_result = f"å·²è¾¾æœ€å¤§æ­¥éª¤({max_steps})ï¼Œä»»åŠ¡è¢«ä¸­æ­¢ã€‚å½“å‰è¿›å±•ï¼š{self._extract_final_result(final_trajectory_str)}"
        else:
            final_result = self._extract_final_result(final_trajectory_str)

        # ğŸ” å®Œæˆä»»åŠ¡æ­¥éª¤æ—¥å¿—è®°å½•
        final_status = "success" if success else "failure"
        await self.step_logger.finalize_task(final_status, final_result)

        xml_output = {
            "timestamp": datetime.now().isoformat(),
            "task_id": task.task_id,
            "task_description": task.description,
            "duration": total_duration,
            "success": success,
            "final_result": final_result,
            "raw_response": final_trajectory_str,
        }
        
        await self._save_xml_output(xml_output)

        # ğŸ”§ ä¿®å¤ï¼šä»step_loggerè·å–å®é™…çš„æ‰§è¡Œæ­¥éª¤
        actual_steps = await self.step_logger.get_execution_steps()
        
        # ğŸ§  æ„å»ºæ™ºèƒ½è¯„ä¼°å…ƒæ•°æ®
        intelligent_evaluation = {
            'confidence_score': confidence_score,
            'evaluation_reasoning': evaluation_reasoning,
            'evaluation_method': 'intelligent_semantic' if 'evaluation_reasoning' in locals() and 'LLM' in evaluation_reasoning else 'traditional_rule_based',
            'max_steps_reached': max_steps_reached,
            'trajectory_length': len(full_trajectory)
        }
        
        return TrajectoryResult(
            task_name=task.task_id,
            task_id=task.task_id, 
            task_description=task.description,
            runtime_id=self._runtime_id,
            steps=actual_steps,  # ğŸ”§ ä½¿ç”¨å®é™…æ­¥éª¤è€Œä¸æ˜¯ç©ºæ•°ç»„
            success=success,
            final_result=final_result,  # ğŸ”§ ä½¿ç”¨åŠ¨æ€æå–çš„ç»“æœ
            total_duration=total_duration,
            metadata={
                'full_trajectory': full_trajectory,
                'intelligent_evaluation': intelligent_evaluation  # ğŸ§  æ–°å¢æ™ºèƒ½è¯„ä¼°ä¿¡æ¯
            }
        )

    def _format_result(self, result: str) -> str:
        """ğŸ”§ æ ¹æœ¬ä¿®å¤ï¼šæ ¼å¼åŒ–å·¥å…·ç»“æœï¼Œä½¿ç”¨å¸¸é‡æ›¿ä»£ç¡¬ç¼–ç """
        if not result:
            no_action_msg = TaskExecutionConstants.NO_ACTION_PERFORMED
            return f"<{TaskExecutionConstants.XML_TAGS['RESULT']}>{no_action_msg}</{TaskExecutionConstants.XML_TAGS['RESULT']}>"
        return f"<{TaskExecutionConstants.XML_TAGS['RESULT']}>{result}</{TaskExecutionConstants.XML_TAGS['RESULT']}>"
    
    async def _execute_standard(self, task: TaskSpec) -> TrajectoryResult:
        """æ ‡å‡†æ‰§è¡Œæ¨¡å¼ (ä½œä¸ºå¤‡ç”¨) - ğŸ”§ å·²ä¿®å¤ç¡¬ç¼–ç é—®é¢˜"""
        logger.warning("æ‰§è¡Œæ ‡å‡†ï¼ˆReActï¼‰æ¨¡å¼ï¼Œæ­¤æ¨¡å¼åŠŸèƒ½æœ‰é™ã€‚")
        # ç®€å•å®ç°æ ‡å‡†æ¨¡å¼
        start_time = time.time()
        response = ""
        try:
            # ç®€å•çš„LLMè°ƒç”¨
            messages = self.prompt_builder.build_prompt(
                task_description=task.description,
                available_tools=[],
                tool_descriptions="",
                streaming_mode=False
            )
            response = await self.client._call_api(messages)
            
            # ğŸ§  æ ‡å‡†æ¨¡å¼ä¹Ÿä½¿ç”¨æ™ºèƒ½è¯„ä¼°ï¼ˆç®€åŒ–ç‰ˆï¼‰
            final_result = self._extract_final_result(response)
            
            try:
                success, confidence_score, evaluation_reasoning = await self._intelligent_task_success_evaluation(
                    task_input=task.description,
                    final_trajectory_str=response,
                    full_trajectory=[{'content': response, 'timestamp': time.time()}],
                    final_output=final_result
                )
                logger.info(f"ğŸ§  æ ‡å‡†æ¨¡å¼æ™ºèƒ½è¯„ä¼°: æˆåŠŸ={success}, ç½®ä¿¡åº¦={confidence_score:.2f}")
            except Exception as eval_e:
                logger.error(f"âŒ æ ‡å‡†æ¨¡å¼æ™ºèƒ½è¯„ä¼°å¤±è´¥: {eval_e}")
                success = self._determine_task_success(response, [])
                confidence_score = 0.5
                evaluation_reasoning = "é™çº§åˆ°ä¼ ç»Ÿè¯„ä¼°"
            
        except Exception as e:
            logger.error(f"æ ‡å‡†æ¨¡å¼æ‰§è¡Œå¤±è´¥: {e}")
            success = False
            final_result = f"æ‰§è¡Œå¤±è´¥: {str(e)}"
            response = f"Error: {str(e)}"
            confidence_score = 0.0
            evaluation_reasoning = f"æ‰§è¡Œå¼‚å¸¸: {str(e)}"
        
        total_duration = time.time() - start_time
        
        # ğŸ§  æ„å»ºæ ‡å‡†æ¨¡å¼çš„æ™ºèƒ½è¯„ä¼°å…ƒæ•°æ®
        intelligent_evaluation = {
            'confidence_score': confidence_score,
            'evaluation_reasoning': evaluation_reasoning,
            'evaluation_method': 'intelligent_semantic_standard_mode',
            'max_steps_reached': False,
            'trajectory_length': 1
        }
        
        # æ„å»ºè¿”å›å¯¹è±¡
        from core.interfaces import TrajectoryResult
        trajectory = TrajectoryResult(
            task_name=task.task_id,
            task_id=task.task_id,
            task_description=task.description,
            runtime_id=self._runtime_id,
            steps=[],
            success=success,
            final_result=final_result,  # ğŸ”§ ä½¿ç”¨åŠ¨æ€æå–çš„ç»“æœ
            total_duration=total_duration,
            metadata={
                'mode': 'standard', 
                'raw_response': response,
                'intelligent_evaluation': intelligent_evaluation  # ğŸ§  æ–°å¢æ™ºèƒ½è¯„ä¼°ä¿¡æ¯
            }
        )
        
        return trajectory

    async def _get_available_tools(self) -> List[str]:
        """è·å–å¯ç”¨å·¥å…·åˆ—è¡¨"""
        try:
            # æ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼Œé¿å…å¼‚æ­¥å–æ¶ˆå¯¼è‡´çš„é—®é¢˜
            tools = await asyncio.wait_for(
                self.toolscore_client.get_available_tools(), 
                timeout=5.0
            )
            return [str(tool) for tool in tools] if isinstance(tools, list) else []
        except asyncio.TimeoutError:
            logger.warning(f"è·å–å·¥å…·åˆ—è¡¨è¶…æ—¶ï¼Œä½¿ç”¨é»˜è®¤å·¥å…·åˆ—è¡¨")
            return ["microsandbox", "browser_use", "deepsearch", "search_tool"]
        except (asyncio.CancelledError, GeneratorExit):
            logger.info("å·¥å…·åˆ—è¡¨è·å–è¢«å–æ¶ˆ")
            raise
        except Exception as e:
            logger.warning(f"è·å–å·¥å…·åˆ—è¡¨å¤±è´¥: {e}")
            return ["microsandbox", "browser_use", "deepsearch", "search_tool"]
    
    async def _get_tool_descriptions(self) -> str:
        """è·å–å·¥å…·æè¿°"""
        try:
            # æ·»åŠ è¶…æ—¶ä¿æŠ¤
            descriptions = await asyncio.wait_for(
                self.toolscore_client.get_tool_descriptions(),
                timeout=5.0
            )
            return descriptions if descriptions else "å·¥å…·æè¿°è·å–å¤±è´¥"
        except asyncio.TimeoutError:
            logger.warning(f"è·å–å·¥å…·æè¿°è¶…æ—¶ï¼Œä½¿ç”¨é»˜è®¤æè¿°")
            return "åŸºç¡€å·¥å…·ï¼šä»£ç æ‰§è¡Œã€æµè§ˆå™¨æ“ä½œã€æœç´¢åŠŸèƒ½"
        except (asyncio.CancelledError, GeneratorExit):
            logger.info("å·¥å…·æè¿°è·å–è¢«å–æ¶ˆ")
            raise
        except Exception as e:
            logger.warning(f"è·å–å·¥å…·æè¿°å¤±è´¥: {e}")
            return "å·¥å…·æè¿°è·å–å¤±è´¥"

    async def _intelligent_task_success_evaluation(
        self, 
        task_input: str, 
        final_trajectory_str: str, 
        full_trajectory: List, 
        final_output: str
    ) -> Tuple[bool, float, str]:
        """
        ğŸ§  æ™ºèƒ½ä»»åŠ¡æˆåŠŸè¯„ä¼° - æ–°çš„ä¸»è¦çŠ¶æ€åˆ¤å®šæ–¹æ³•
        
        ä½¿ç”¨è¯­ä¹‰ç†è§£å’Œç»“æœé©±åŠ¨çš„åˆ¤å®šé€»è¾‘ï¼Œæ›¿ä»£ä¼ ç»Ÿçš„æ ¼å¼é©±åŠ¨æ–¹æ³•
        
        Args:
            task_input: åŸå§‹ä»»åŠ¡è¾“å…¥
            final_trajectory_str: å®Œæ•´è½¨è¿¹å­—ç¬¦ä¸²
            full_trajectory: è½¨è¿¹æ­¥éª¤åˆ—è¡¨
            final_output: æœ€ç»ˆè¾“å‡ºå†…å®¹
            
        Returns:
            Tuple[is_success, confidence_score, reasoning]
        """
        try:
            # æå–å·¥å…·æ‰§è¡Œç»“æœ
            tool_results = []
            for step in full_trajectory:
                if isinstance(step, dict) and 'tool_execution' in step:
                    tool_results.append(step['tool_execution'])
            
            # è°ƒç”¨æ™ºèƒ½è¯„ä¼°å™¨
            is_success, confidence, reasoning = await intelligent_task_evaluation(
                llm_client=self.client,
                task_input=task_input,
                trajectory=full_trajectory,
                final_output=final_output,
                tool_results=tool_results
            )
            
            logger.info(f"ğŸ§  æ™ºèƒ½çŠ¶æ€è¯„ä¼°ç»“æœ: æˆåŠŸ={is_success}, ç½®ä¿¡åº¦={confidence:.2f}, ç†ç”±={reasoning}")
            
            return is_success, confidence, reasoning
            
        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½çŠ¶æ€è¯„ä¼°å¤±è´¥: {e}")
            # é™çº§åˆ°ä¼ ç»Ÿæ–¹æ³•
            traditional_success = self._determine_task_success(final_trajectory_str, full_trajectory)
            return traditional_success, 0.5, f"é™çº§è¯„ä¼°: {traditional_success}"

    def _determine_task_success(self, final_trajectory_str: str, full_trajectory: List) -> bool:
        """ğŸ”§ Priority 1 ä¿®å¤ï¼šå½»åº•è§£å†³"è§„åˆ’å³æˆåŠŸ"ç³»ç»Ÿæ€§æ¼æ´
        
        æ ¸å¿ƒåŸåˆ™ï¼šå¿…é¡»æœ‰å®é™…å·¥å…·æ‰§è¡Œæˆ–æ˜ç¡®ç­”æ¡ˆæ ‡ç­¾ï¼Œä»…æœ‰è§„åˆ’/æ€è€ƒå†…å®¹ä¸èƒ½åˆ¤å®šä¸ºæˆåŠŸ
        
        Args:
            final_trajectory_str: å®Œæ•´è½¨è¿¹å­—ç¬¦ä¸²
            full_trajectory: è½¨è¿¹æ­¥éª¤åˆ—è¡¨
        
        Returns:
            bool: ä»»åŠ¡æ˜¯å¦æˆåŠŸå®Œæˆ
        """
        # ğŸ”§ æœ€é«˜ä¼˜å…ˆçº§ï¼šæ£€æŸ¥å®é™…å·¥å…·æ‰§è¡ŒçŠ¶æ€
        tool_success_rate = self._calculate_tool_success_rate()
        has_successful_tools = tool_success_rate > 0.0
        
        # 1. æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„ç­”æ¡ˆæ ‡ç­¾ï¼ˆå¿…é¡»æœ‰ç»“æŸæ ‡ç­¾ï¼‰
        answer_tag = TaskExecutionConstants.XML_TAGS['ANSWER']
        has_complete_answer = f'</{answer_tag}>' in final_trajectory_str
        has_boxed_answer = "\\boxed{" in final_trajectory_str  # æ•°å­¦ç­”æ¡ˆæ ¼å¼
        
        # 2. æ£€æŸ¥æ˜¯å¦æœ‰æœªå¤„ç†çš„å…³é”®é”™è¯¯æŒ‡ç¤ºå™¨
        has_critical_errors = any(
            indicator in final_trajectory_str.lower() 
            for indicator in TaskExecutionConstants.FAILURE_INDICATORS
        )
        
        # 3. æ£€æŸ¥æ˜¯å¦æœ‰å®é™…çš„å·¥å…·æ‰§è¡Œæˆæœ
        result_tag = TaskExecutionConstants.XML_TAGS['RESULT']
        has_tool_results = f'<{result_tag}>' in final_trajectory_str and TaskExecutionConstants.NO_ACTION_PERFORMED not in final_trajectory_str
        
        # 4. ğŸ”§ æ–°å¢ï¼šæ£€æŸ¥æ˜¯å¦åªæœ‰æ€è€ƒå†…å®¹ï¼ˆ"è§„åˆ’å³æˆåŠŸ"æ£€æµ‹ï¼‰
        think_tag = TaskExecutionConstants.XML_TAGS['THINK']
        execute_tools_tag = TaskExecutionConstants.XML_TAGS['EXECUTE_TOOLS']
        
        has_only_thinking = (f'<{think_tag}>' in final_trajectory_str and 
                           not has_tool_results and 
                           not has_complete_answer and
                           not has_boxed_answer and
                           f'<{execute_tools_tag}>' not in final_trajectory_str)
        
        # ğŸ”§ Priority 4 æ–°å¢ï¼šå¤šå·¥å…·ååŒè´¨é‡è¯„ä¼°
        multi_tool_quality = self._evaluate_multi_tool_coordination_quality(final_trajectory_str)
        
        # ğŸ”§ Priority 1 æ ¸å¿ƒä¿®å¤ï¼šä¸¥æ ¼çš„æˆåŠŸåˆ¤å®šé€»è¾‘
        success = False
        
        # åœºæ™¯1ï¼šæœ‰å®é™…å·¥å…·æ‰§è¡ŒæˆåŠŸ + æœ‰å®Œæ•´ç­”æ¡ˆ + æœ‰æ„ä¹‰ç»“æœ = æ˜ç¡®æˆåŠŸ
        if has_successful_tools and (has_complete_answer or has_boxed_answer) and not has_critical_errors and self._has_meaningful_tool_results(final_trajectory_str):
            success = True
            logger.info("ğŸ¯ åˆ¤å®šæˆåŠŸï¼šå·¥å…·æ‰§è¡ŒæˆåŠŸ + å®Œæ•´ç­”æ¡ˆ + æœ‰æ„ä¹‰ç»“æœ")
        
        # åœºæ™¯2ï¼šæœ‰å®é™…å·¥å…·æ‰§è¡ŒæˆåŠŸ + æœ‰å®é™…ç»“æœè¾“å‡º = æ½œåœ¨æˆåŠŸ
        elif has_successful_tools and has_tool_results and not has_critical_errors:
            success = True
            logger.info("ğŸ¯ åˆ¤å®šæˆåŠŸï¼šå·¥å…·æ‰§è¡ŒæˆåŠŸ + æœ‰å®é™…ç»“æœ")
        
        # åœºæ™¯3ï¼šğŸ”§ Priority 4 æ–°å¢ï¼šå¤šå·¥å…·ååŒæˆåŠŸåœºæ™¯
        elif multi_tool_quality['is_coordinated'] and multi_tool_quality['quality_score'] > TaskExecutionConstants.MULTI_TOOL_COORDINATION['RESULT_INTEGRATION']['quality_threshold']:
            success = True
            logger.info(f"ğŸ¯ åˆ¤å®šæˆåŠŸï¼šå¤šå·¥å…·ååŒå®Œæˆï¼Œè´¨é‡åˆ†æ•°={multi_tool_quality['quality_score']:.2f}")
        
        # åœºæ™¯4ï¼šçº¯æ¨ç†ä»»åŠ¡ï¼šæœ‰å®Œæ•´ç­”æ¡ˆæ ‡ç­¾ï¼ˆå¿…é¡»æœ‰ç»“æŸæ ‡ç­¾æˆ–boxedæ ¼å¼ï¼‰
        elif (has_complete_answer or has_boxed_answer) and not has_critical_errors:
            success = True
            logger.info("ğŸ¯ åˆ¤å®šæˆåŠŸï¼šçº¯æ¨ç†ä»»åŠ¡ï¼Œæœ‰å®Œæ•´ç­”æ¡ˆæ ‡ç­¾")
        
        # åœºæ™¯5ï¼šğŸ”§ "è§„åˆ’å³æˆåŠŸ"æ¼æ´é˜²æŠ¤ - åªæœ‰æ€è€ƒå†…å®¹æ—¶æ˜ç¡®æ‹’ç»
        elif has_only_thinking:
            success = False
            logger.warning('ğŸš¨ "è§„åˆ’å³æˆåŠŸ"æ¼æ´é˜²æŠ¤ï¼šä»…æœ‰æ€è€ƒå†…å®¹ï¼Œä¸è®¤å®šä¸ºæˆåŠŸ')
        
        # åœºæ™¯6ï¼šä»»ä½•å…³é”®é”™è¯¯éƒ½å¯¼è‡´å¤±è´¥
        elif has_critical_errors:
            success = False
            logger.info("ğŸ¯ åˆ¤å®šå¤±è´¥ï¼šæ£€æµ‹åˆ°å…³é”®é”™è¯¯")
        
        # åœºæ™¯7ï¼šå…¶ä»–æƒ…å†µé»˜è®¤å¤±è´¥
        else:
            success = False
            logger.info("ğŸ¯ åˆ¤å®šå¤±è´¥ï¼šæœªæ»¡è¶³æˆåŠŸæ¡ä»¶")
        
        logger.info(f"ğŸ¯ Successåˆ¤å®šè¯¦æƒ…: tool_success_rate={tool_success_rate:.2f}, "
                   f"has_complete_answer={has_complete_answer}, has_boxed_answer={has_boxed_answer}, "
                   f"has_tool_results={has_tool_results}, has_only_thinking={has_only_thinking}, "
                   f"has_critical_errors={has_critical_errors}, final_success={success}")
        
        return success
    
    def _calculate_tool_success_rate(self) -> float:
        """è®¡ç®—å½“å‰ä»»åŠ¡ä¸­å·¥å…·æ‰§è¡Œçš„æˆåŠŸç‡"""
        if not hasattr(self, 'step_logger') or not self.step_logger.current_task_data:
            return 0.0
        
        total_executions = 0
        successful_executions = 0
        
        for step in self.step_logger.current_task_data.get('steps', []):
            for tool_exec in step.get('tool_executions', []):
                total_executions += 1
                if tool_exec.get('execution_status') == 'success':
                    successful_executions += 1
        
        return successful_executions / total_executions if total_executions > 0 else 0.0
    
    def _analyze_error_type(self, error_message: str) -> str:
        """ğŸ”§ å¢å¼ºçš„æ™ºèƒ½é”™è¯¯ç±»å‹åˆ†æ - æ£€æµ‹æ›´å¤šç‰¹å®šé”™è¯¯åœºæ™¯"""
        error_msg_lower = error_message.lower()
        
        # ğŸ” ç©ºç»“æœ/æ— æ•°æ®é”™è¯¯ï¼ˆé«˜ä¼˜å…ˆçº§æ£€æµ‹ï¼‰
        if any(indicator in error_msg_lower for indicator in ['no results', 'empty result', 'no data found', 'æ²¡æœ‰ç»“æœ', 'ç©ºç»“æœ', 'æœªæ‰¾åˆ°æ•°æ®', 'empty response']):
            return "empty_results"
        
        # â±ï¸ è¶…æ—¶é”™è¯¯
        if any(indicator in error_msg_lower for indicator in ['timeout', 'time out', 'timed out', 'è¶…æ—¶', 'æ‰§è¡Œè¶…æ—¶']):
            return "timeout_error"
        
        # ğŸš« æœåŠ¡ä¸å¯ç”¨é”™è¯¯ï¼ˆéœ€è¦åœ¨æ•°æ®ä¸å¯ç”¨ä¹‹å‰æ£€æµ‹ï¼‰
        if any(indicator in error_msg_lower for indicator in ['service unavailable', 'server error', '503', '502', '500', 'æœåŠ¡ä¸å¯ç”¨', 'service down']):
            return "service_unavailable"
        
        # ğŸ“Š æ•°æ®ä¸å¯ç”¨é”™è¯¯  
        if any(indicator in error_msg_lower for indicator in ['data not available', 'unavailable', 'æ•°æ®ä¸å¯ç”¨', 'ä¸å¯ç”¨', 'data unavailable']):
            return "data_not_available"
        
        # å‚æ•°é”™è¯¯
        if any(indicator in error_msg_lower for indicator in ['parameter', 'param', 'å‚æ•°', 'æ— æ•ˆå‚æ•°']):
            return "parameter_error"
        
        # å·¥å…·ä¸å­˜åœ¨é”™è¯¯
        if any(indicator in error_msg_lower for indicator in ['ä¸æ”¯æŒ', 'not support', 'ä¸å­˜åœ¨', 'not found']):
            return "tool_not_found"
        
        # ç½‘ç»œ/è¿æ¥é”™è¯¯
        if any(indicator in error_msg_lower for indicator in ['connection', 'network', 'connect', 'connection refused', 'ç½‘ç»œ']):
            return "network_error"
        
        # éªŒè¯é”™è¯¯
        if any(indicator in error_msg_lower for indicator in ['validation', 'validate', 'éªŒè¯å¤±è´¥']):
            return "validation_error"
        
        # æƒé™é”™è¯¯
        if any(indicator in error_msg_lower for indicator in ['permission', 'access', 'æƒé™', 'forbidden']):
            return "permission_error"
        
        return "unknown_error"
    
    def _format_error_with_recovery_suggestion(self, error_message: str, error_type: str, service_name: str, tool_name: str) -> str:
        """ğŸ”§ å¢å¼ºçš„é”™è¯¯æ ¼å¼åŒ–å’Œæ¢å¤å»ºè®® - é’ˆå¯¹å…·ä½“é”™è¯¯ç±»å‹æä¾›è¯¦ç»†æŒ‡å¯¼"""
        base_error = f"Tool execution failed: {error_message}"
        
        recovery_suggestions = {
            "parameter_error": f"ğŸ’¡ å»ºè®®: æ£€æŸ¥ {service_name} çš„ {tool_name} å·¥å…·å‚æ•°æ ¼å¼ã€‚å‚è€ƒå·¥å…·å®šä¹‰ä¸­çš„æ­£ç¡®å‚æ•°åç§°ã€‚",
            "tool_not_found": f"ğŸ’¡ å»ºè®®: å·¥å…· {tool_name} åœ¨ {service_name} ä¸­ä¸å­˜åœ¨ã€‚æ£€æŸ¥å·¥å…·åç§°æ˜¯å¦æ­£ç¡®ï¼Œæˆ–å°è¯•ä½¿ç”¨å…¶ä»–å·¥å…·ã€‚",
            "network_error": f"ğŸ’¡ å»ºè®®: ç½‘ç»œè¿æ¥é—®é¢˜ã€‚ç­‰å¾…å‡ ç§’åé‡è¯•ï¼Œæˆ–å°è¯•ä½¿ç”¨æ›¿ä»£å·¥å…·ã€‚",
            "validation_error": f"ğŸ’¡ å»ºè®®: è¾“å…¥æ•°æ®éªŒè¯å¤±è´¥ã€‚æ£€æŸ¥è¾“å…¥æ ¼å¼å’Œå†…å®¹æ˜¯å¦ç¬¦åˆè¦æ±‚ã€‚",
            "permission_error": f"ğŸ’¡ å»ºè®®: æƒé™ä¸è¶³ã€‚æ£€æŸ¥æœåŠ¡é…ç½®æˆ–å°è¯•å…¶ä»–æ–¹æ³•ã€‚",
            "empty_results": f"ğŸ” å»ºè®®: æœç´¢æœªæ‰¾åˆ°ç»“æœã€‚å°è¯•:\n  â€¢ ä½¿ç”¨ä¸åŒçš„å…³é”®è¯æˆ–æ›´ç®€å•çš„æŸ¥è¯¢\n  â€¢ åˆ‡æ¢åˆ°å…¶ä»–æœç´¢å·¥å…· (å¦‚ deepsearch â†’ browser_use)\n  â€¢ æ£€æŸ¥æ•°æ®æ˜¯å¦å·²ä¿å­˜åœ¨å†…å­˜æš‚å­˜åŒº: <memory_staging><memory_list></memory_list></memory_staging>",
            "data_not_available": f"ğŸ“Š å»ºè®®: æ•°æ®ä¸å¯ç”¨ã€‚å°è¯•:\n  â€¢ ä½¿ç”¨æ›´å¹¿æ³›çš„æœç´¢è¯\n  â€¢ æ£€æŸ¥å†…å­˜æš‚å­˜åŒºæ˜¯å¦æœ‰ç›¸å…³æ•°æ®: <memory_staging><memory_search>å…³é”®è¯</memory_search></memory_staging>\n  â€¢ è€ƒè™‘ä½¿ç”¨ç¤ºä¾‹æ•°æ®ï¼ˆæ˜ç¡®æ ‡è®°ä¸ºæ¨¡æ‹Ÿæ•°æ®ï¼‰",
            "timeout_error": f"â±ï¸ å»ºè®®: å·¥å…·æ‰§è¡Œè¶…æ—¶ã€‚å°è¯•:\n  â€¢ ç®€åŒ–æŸ¥è¯¢æˆ–æ“ä½œ\n  â€¢ åˆ†æ­¥éª¤æ‰§è¡Œå¤æ‚ä»»åŠ¡\n  â€¢ ç¨åé‡è¯•",
            "service_unavailable": f"ğŸš« å»ºè®®: æœåŠ¡ä¸å¯ç”¨ã€‚å°è¯•:\n  â€¢ ä½¿ç”¨æ›¿ä»£å·¥å…·è¾¾åˆ°ç›¸åŒç›®æ ‡\n  â€¢ ç¨åé‡è¯•\n  â€¢ ä½¿ç”¨ç¼“å­˜æˆ–å†…å­˜ä¸­çš„æ•°æ®",
            "unknown_error": f"ğŸ’¡ å»ºè®®: æœªçŸ¥é”™è¯¯ã€‚å°è¯•ç®€åŒ–è¾“å…¥æˆ–ä½¿ç”¨å…¶ä»–å·¥å…·æ›¿ä»£ã€‚"
        }
        
        suggestion = recovery_suggestions.get(error_type, recovery_suggestions["unknown_error"])
        return f"{base_error}\n{suggestion}"
    
    def _extract_final_result(self, final_trajectory_str: str) -> str:
        """ğŸ”§ å®Œæ•´ä¿®å¤ï¼šä¼˜åŒ–æœ€ç»ˆç»“æœæå–ä¼˜å…ˆçº§ï¼Œç¡®ä¿å®é™…ç»“æœä¼˜äºæ€è€ƒè¿‡ç¨‹
        
        Args:
            final_trajectory_str: å®Œæ•´è½¨è¿¹å­—ç¬¦ä¸²
        
        Returns:
            str: æå–çš„æœ€ç»ˆç»“æœ
        """
        import re
        
        # ğŸ”§ ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šæå–answeræ ‡ç­¾å†…å®¹ï¼Œä¼˜å…ˆæå–\boxed{}æ ¼å¼
        answer_tag = TaskExecutionConstants.XML_TAGS['ANSWER']
        answer_pattern = f'<{answer_tag}>(.*?)</{answer_tag}>'
        answer_match = re.search(answer_pattern, final_trajectory_str, re.DOTALL)
        if answer_match:
            answer_content = answer_match.group(1).strip()
            if answer_content and len(answer_content) > 0:
                # ğŸ”§ æ–°å¢ï¼šä¼˜å…ˆæå–\boxed{}å†…çš„æ¸…æ´å†…å®¹
                boxed_pattern = r'\\boxed\{(.*?)\}'
                boxed_match = re.search(boxed_pattern, answer_content, re.DOTALL)
                if boxed_match:
                    clean_answer = boxed_match.group(1).strip()
                    logger.info(f" ä»\\boxed{{}}æå–æ¸…æ´æœ€ç»ˆç»“æœ: {clean_answer}...")
                    return clean_answer
                else:
                    # å¦‚æœæ²¡æœ‰\boxed{}æ ¼å¼ï¼Œè¿”å›åŸå§‹answerå†…å®¹
                    logger.info(f"ä»<answer>æ ‡ç­¾æå–æœ€ç»ˆç»“æœ: {answer_content}...")
                    return answer_content
        else:
            # ğŸ”§ å®¹é”™æœºåˆ¶ï¼šå¦‚æœæ ‡å‡†ç­”æ¡ˆæ ‡ç­¾è§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤
            answer_content = self._attempt_answer_extraction(final_trajectory_str)
            if answer_content:
                logger.info(f"ğŸ”§ å®¹é”™æå–ç­”æ¡ˆæˆåŠŸ: {answer_content}...")
                return answer_content
        
        # ğŸ”§ ç¬¬äºŒä¼˜å…ˆçº§ï¼šæå–æœ€åçš„æœ‰æ•ˆå·¥å…·æ‰§è¡Œç»“æœï¼ˆé"No action"ï¼‰
        result_tag = TaskExecutionConstants.XML_TAGS['RESULT']
        result_pattern = f'<{result_tag}>(.*?)</{result_tag}>'
        result_matches = re.findall(result_pattern, final_trajectory_str, re.DOTALL)
        
        # è¿‡æ»¤å‡ºæœ‰æ•ˆçš„å·¥å…·æ‰§è¡Œç»“æœ
        valid_results = []
        for result in result_matches:
            result_clean = result.strip()
            # æ’é™¤æ— æ„ä¹‰çš„ç»“æœ
            if (result_clean and 
                TaskExecutionConstants.NO_ACTION_PERFORMED not in result_clean and
                "No executable action detected" not in result_clean and
                len(result_clean) > 10):
                valid_results.append(result_clean)
        
        if valid_results:
            # ğŸ”§ ä¼˜åŒ–ï¼šé€‰æ‹©æœ€æœ‰ä»·å€¼çš„ç»“æœ
            best_result = self._select_best_tool_result(valid_results)
            logger.info(f"ğŸ”§ ä»å·¥å…·æ‰§è¡Œç»“æœæå–æœ€ç»ˆç­”æ¡ˆ: {best_result[:100]}...")
            return best_result
        
        # ğŸ”§ ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼šæå–æ•°å€¼è®¡ç®—ç»“æœï¼ˆé’ˆå¯¹æ•°å­¦é—®é¢˜ï¼‰
        # æŸ¥æ‰¾æ•°å€¼ç»“æœæ¨¡å¼
        calculation_patterns = [
            r'ç»“æœ[ï¼š:]\s*([0-9.e-]+\s*[A-Za-z]*)',  # "ç»“æœ: 9.43e-07 A"
            r'ç­”æ¡ˆ[ï¼š:]\s*([0-9.e-]+\s*[A-Za-z]*)',  # "ç­”æ¡ˆ: 42"
            r'photocurrent[ï¼š:]\s*([0-9.e-]+\s*[A-Za-z]*)',  # "photocurrent: 9.43e-07 A"
            r'([0-9.e-]+\s*[A-Za-z]*)\s*(?:å®‰åŸ¹|A|ç“¦ç‰¹|W|ç±³|m)',  # å•ä½æ¨¡å¼
        ]
        
        for pattern in calculation_patterns:
            matches = re.findall(pattern, final_trajectory_str, re.IGNORECASE)
            if matches:
                # ğŸ”§ æ·»åŠ ä¸Šä¸‹æ–‡éªŒè¯ - ç¡®ä¿ç»“æœæ¥è‡ªå®é™…çš„å·¥å…·æ‰§è¡Œ
                calculation_result = matches[-1].strip()
                if self._validate_calculation_context(final_trajectory_str, calculation_result):
                    logger.info(f"ğŸ§® ä»è®¡ç®—ç»“æœæå–æœ€ç»ˆç­”æ¡ˆ: {calculation_result}")
                    return f"è®¡ç®—ç»“æœ: {calculation_result}"
                else:
                    logger.warning(f"âš ï¸ è®¡ç®—ç»“æœ {calculation_result} æœªé€šè¿‡ä¸Šä¸‹æ–‡éªŒè¯ï¼Œè·³è¿‡")
        
        # ğŸ”§ ç¬¬å››ä¼˜å…ˆçº§ï¼šæå–æœç´¢ç­”æ¡ˆï¼ˆé’ˆå¯¹é—®ç­”ç±»ä»»åŠ¡ï¼‰
        # æŸ¥æ‰¾IORAç­‰ä¸“æœ‰åè¯çš„è§£é‡Š
        info_patterns = [
            r'IORA[æ˜¯ä¸º].*?[ã€‚.]',  # IORAç›¸å…³è§£é‡Š
            r'æ–°åŠ å¡å›½ç«‹å¤§å­¦.*?[ã€‚.]',  # å¤§å­¦ç›¸å…³ä¿¡æ¯
            r'([A-Z]{3,}\s*(?:æ˜¯|ä¸º|æŒ‡).*?[ã€‚.])',  # ç¼©å†™è§£é‡Šæ¨¡å¼
        ]
        
        for pattern in info_patterns:
            matches = re.findall(pattern, final_trajectory_str, re.DOTALL)
            if matches:
                info_result = matches[-1].strip()
                logger.info(f"ğŸ“– ä»ä¿¡æ¯æ£€ç´¢æå–æœ€ç»ˆç­”æ¡ˆ: {info_result[:100]}...")
                return info_result
        
        # ğŸ”§ ç¬¬äº”ä¼˜å…ˆçº§ï¼šæ™ºèƒ½æå–æœ€åçš„thinkå†…å®¹ï¼ˆé™ä½ä¼˜å…ˆçº§ï¼‰
        think_tag = TaskExecutionConstants.XML_TAGS['THINK']
        think_pattern = f'<{think_tag}>(.*?)</{think_tag}>'
        think_matches = re.findall(think_pattern, final_trajectory_str, re.DOTALL)
        if think_matches:
            last_think = think_matches[-1].strip()
            # åªæœ‰åœ¨æ²¡æœ‰å…¶ä»–ç»“æœæ—¶æ‰ä½¿ç”¨æ€è€ƒå†…å®¹ï¼Œä¸”éœ€è¦è¶³å¤Ÿé•¿
            if last_think and len(last_think) > 50:
                logger.info(f"ğŸ“ ä»æ€è€ƒè¿‡ç¨‹æå–ç»“æœ: {last_think[:100]}...")
                return f"åˆ†æè¿‡ç¨‹: {last_think[:200]}..."
        
        # ğŸ”§ ç¬¬å…­ä¼˜å…ˆçº§ï¼šæå–å¯è§çš„æœ‰æ„ä¹‰æ–‡æœ¬
        visible_content = re.sub(r'<[^>]+>', '', final_trajectory_str).strip()
        if visible_content and len(visible_content) > 20:
            # å¯»æ‰¾æœ€åçš„æœ‰æ„ä¹‰å†…å®¹
            lines = [line.strip() for line in visible_content.split('\n') if line.strip()]
            meaningful_lines = []
            
            for line in lines[-10:]:  # æ£€æŸ¥æœ€å10è¡Œ
                # è¿‡æ»¤æ‰æ— æ„ä¹‰çš„è¡Œ
                if (len(line) > 10 and 
                    not line.startswith('---') and
                    'Starting Step' not in line and
                    'executable action' not in line):
                    meaningful_lines.append(line)
            
            if meaningful_lines:
                final_content = ' '.join(meaningful_lines[-3:])  # å–æœ€å3è¡Œæœ‰æ„ä¹‰å†…å®¹
                logger.info(f"ğŸ“„ ä»å¯è§æ–‡æœ¬æå–ç»“æœ: {final_content[:100]}...")
                return final_content
        
        # æœ€åå¤‡é€‰ï¼šè¿”å›ä»»åŠ¡å®ŒæˆçŠ¶æ€  
        logger.warning("âš ï¸ æ— æ³•æå–å…·ä½“çš„æœ€ç»ˆç»“æœï¼Œè¿”å›é»˜è®¤å®Œæˆæ¶ˆæ¯")
        return TaskExecutionConstants.TASK_COMPLETED_NO_ANSWER
    
    def _select_best_tool_result(self, valid_results: list) -> str:
        """é€‰æ‹©æœ€æœ‰ä»·å€¼çš„å·¥å…·æ‰§è¡Œç»“æœ"""
        if not valid_results:
            return ""
        
        import re
        
        # ä¼˜å…ˆçº§è¯„åˆ†
        scored_results = []
        for result in valid_results:
            score = 0
            result_lower = result.lower()
            
            # åŒ…å«æ•°å€¼è®¡ç®—çš„ç»“æœå¾—åˆ†æ›´é«˜
            if re.search(r'[0-9.e-]+', result):
                score += 10
            
            # åŒ…å«ä¸“ä¸šæœ¯è¯­çš„ç»“æœå¾—åˆ†æ›´é«˜
            if any(term in result_lower for term in ['iora', 'university', 'å¤§å­¦', 'ç»“æœ', 'ç­”æ¡ˆ']):
                score += 8
            
            # é•¿åº¦é€‚ä¸­çš„ç»“æœå¾—åˆ†æ›´é«˜
            if 20 <= len(result) <= 300:
                score += 5
            
            # åŒ…å«æœç´¢ç»“æœçš„å¾—åˆ†æ›´é«˜
            if 'æœç´¢ç»“æœ' in result or 'search' in result_lower:
                score += 7
            
            scored_results.append((score, result))
        
        # è¿”å›å¾—åˆ†æœ€é«˜çš„ç»“æœ
        scored_results.sort(key=lambda x: x[0], reverse=True)
        return scored_results[0][1]
    
    def _should_inject_no_action_message(self, response_text: str) -> bool:
        """ğŸ”§ å®Œæ•´ä¿®å¤ï¼šä¸¥æ ¼æ§åˆ¶æ— åŠ¨ä½œæ¶ˆæ¯æ³¨å…¥ï¼Œå½»åº•æ¶ˆé™¤å†—ä½™æ¶ˆæ¯
        
        Args:
            response_text: LLMå“åº”æ–‡æœ¬
        
        Returns:
            bool: æ˜¯å¦éœ€è¦æ³¨å…¥æ— åŠ¨ä½œæ¶ˆæ¯
        """
        import re
        
        # ğŸ”§ å¢å¼ºæ£€æµ‹ï¼šå¦‚æœæœ‰ä»»ä½•XMLæ ‡ç­¾ï¼Œéƒ½è®¤ä¸ºæœ‰å†…å®¹
        xml_tags = TaskExecutionConstants.XML_TAGS
        all_possible_tags = [
            f"<{xml_tags['THINK']}>", f"</{xml_tags['THINK']}>",
            f"<{xml_tags['ANSWER']}>", f"</{xml_tags['ANSWER']}>", 
            f"<{xml_tags['RESULT']}>", f"</{xml_tags['RESULT']}>",
            f"<{xml_tags['OBSERVATION']}>", f"</{xml_tags['OBSERVATION']}>",
            f"<{xml_tags['CONCLUSION']}>", f"</{xml_tags['CONCLUSION']}>",
            "<execute_tools/>", "<execute_tools></execute_tools>"
        ]
        
        # 1. æ£€æµ‹ä»»ä½•XMLç»“æ„åŒ–å†…å®¹
        for tag in all_possible_tags:
            if tag in response_text:
                logger.info(f"ğŸ’­ æ£€æµ‹åˆ°XMLæ ‡ç­¾ {tag}ï¼Œæ— éœ€æ³¨å…¥æ— åŠ¨ä½œæ¶ˆæ¯")
                return False
        
        # 2. æ£€æµ‹ä»»ä½•å·¥å…·æœåŠ¡å™¨æ ‡ç­¾
        server_tags = ["<microsandbox>", "<deepsearch>", "<browser_use>", "<search_tool>"]
        for tag in server_tags:
            if tag in response_text:
                logger.info(f"ğŸ”§ æ£€æµ‹åˆ°å·¥å…·æ ‡ç­¾ {tag}ï¼Œæ— éœ€æ³¨å…¥æ— åŠ¨ä½œæ¶ˆæ¯")
                return False
        
        # 3. æ£€æµ‹æœ‰æ„ä¹‰çš„æ–‡æœ¬å†…å®¹ï¼ˆæ›´ä¸¥æ ¼çš„æ ‡å‡†ï¼‰
        clean_text = re.sub(r'<[^>]+>', '', response_text).strip()
        
        # å¦‚æœæœ‰è¶³å¤Ÿçš„æœ‰æ„ä¹‰æ–‡æœ¬å†…å®¹
        if len(clean_text) > 20:  # é™ä½é˜ˆå€¼ï¼Œæ›´å®½æ¾
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ„ä¹‰çš„å†…å®¹ï¼ˆéç©ºç™½ã€éé‡å¤å­—ç¬¦ï¼‰
            meaningful_chars = len(re.sub(r'\s+', '', clean_text))
            if meaningful_chars > 10:
                logger.info(f"ğŸ“ æ£€æµ‹åˆ°æœ‰æ„ä¹‰æ–‡æœ¬å†…å®¹({meaningful_chars}å­—ç¬¦)ï¼Œæ— éœ€æ³¨å…¥æ— åŠ¨ä½œæ¶ˆæ¯")
                return False
        
        # 4. ğŸ”§ æ–°å¢ï¼šæ£€æµ‹ä»»åŠ¡å®Œæˆçš„ç‰¹æ®Šæƒ…å†µ
        completion_indicators = [
            "ä»»åŠ¡å®Œæˆ", "execution completed", "calculation complete",
            "æœç´¢å®Œæˆ", "æ“ä½œå®Œæˆ", "å¤„ç†å®Œæˆ", "åˆ†æå®Œæˆ"
        ]
        
        response_lower = response_text.lower()
        for indicator in completion_indicators:
            if indicator.lower() in response_lower:
                logger.info(f"âœ… æ£€æµ‹åˆ°å®ŒæˆæŒ‡ç¤ºè¯ '{indicator}'ï¼Œæ— éœ€æ³¨å…¥æ— åŠ¨ä½œæ¶ˆæ¯")
                return False
        
        # 5. ğŸ”§ æ–°å¢ï¼šå¦‚æœå“åº”åŒ…å«ä»»ä½•æ•°å­—ã€å­—æ¯æˆ–ä¸­æ–‡å­—ç¬¦çš„æœ‰æ„ä¹‰ç»„åˆ
        if re.search(r'[a-zA-Z\u4e00-\u9fff]{3,}', response_text):
            logger.info("ğŸ“„ æ£€æµ‹åˆ°æœ‰æ„ä¹‰çš„æ–‡æœ¬ç»„åˆï¼Œæ— éœ€æ³¨å…¥æ— åŠ¨ä½œæ¶ˆæ¯")
            return False
        
        # 6. ğŸ”§ ç‰¹æ®Šæƒ…å†µï¼šå¦‚æœå“åº”æ˜¯ç©ºçš„æˆ–è€…åªæœ‰ç©ºç™½ç¬¦
        if not response_text or response_text.isspace():
            logger.warning("âš ï¸ æ£€æµ‹åˆ°å®Œå…¨ç©ºçš„å“åº”ï¼Œéœ€è¦æ³¨å…¥æŒ‡å¯¼æ¶ˆæ¯")
            return True
        
        # 7. ğŸ”§ æœ€ä¸¥æ ¼çš„åˆ¤æ–­ï¼šåªæœ‰åœ¨å“åº”çœŸçš„æ²¡æœ‰ä»»ä½•æœ‰ç”¨ä¿¡æ¯æ—¶æ‰æ³¨å…¥
        # æ£€æŸ¥æ˜¯å¦åªåŒ…å«æ— æ„ä¹‰çš„é‡å¤å­—ç¬¦æˆ–ç¬¦å·
        if len(set(response_text.replace(' ', '').replace('\n', ''))) < 3:
            logger.warning(f"âš ï¸ æ£€æµ‹åˆ°æ— æ„ä¹‰çš„é‡å¤å†…å®¹ï¼Œéœ€è¦æ³¨å…¥æŒ‡å¯¼æ¶ˆæ¯")
            return True
        
        # é»˜è®¤æƒ…å†µï¼šä¸æ³¨å…¥æ— åŠ¨ä½œæ¶ˆæ¯ï¼ˆæ›´ä¿å®ˆçš„ç­–ç•¥ï¼‰
        logger.info("ğŸ¯ å“åº”åŒ…å«å†…å®¹ï¼Œæ— éœ€æ³¨å…¥æ— åŠ¨ä½œæ¶ˆæ¯")
        return False
    
    def _extract_detailed_plan(self, response_text: str) -> Optional[str]:
        """ğŸ”§ æ–°å¢ï¼šä»å“åº”ä¸­æå–è¯¦ç»†è®¡åˆ’å†…å®¹"""
        import re
        
        # æ£€æŸ¥thinkæ ‡ç­¾ä¸­çš„å†…å®¹
        think_tag = TaskExecutionConstants.XML_TAGS['THINK']
        think_pattern = f'<{think_tag}>(.*?)</{think_tag}>'
        think_match = re.search(think_pattern, response_text, re.DOTALL)
        
        if think_match:
            think_content = think_match.group(1).strip()
            return think_content
        
        # å¦‚æœæ²¡æœ‰thinkæ ‡ç­¾ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–å½¢å¼çš„è®¡åˆ’å†…å®¹
        # å¯»æ‰¾åŒ…å«æ­¥éª¤ã€è®¡åˆ’å…³é”®è¯çš„å†…å®¹
        plan_indicators = [
            'step', 'phase', 'first', 'next', 'then', 'need to', 'will',
            'æ­¥éª¤', 'é˜¶æ®µ', 'é¦–å…ˆ', 'ç„¶å', 'æ¥ä¸‹æ¥', 'éœ€è¦', 'å°†ä¼š'
        ]
        
        lines = response_text.split('\n')
        plan_lines = []
        
        for line in lines:
            line_lower = line.lower()
            if any(indicator in line_lower for indicator in plan_indicators):
                plan_lines.append(line.strip())
        
        if plan_lines and len('\n'.join(plan_lines)) > 50:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„è®¡åˆ’å†…å®¹
            return '\n'.join(plan_lines)
        
        return None
    
    def _has_executable_plan(self, plan_content: str) -> bool:
        """ğŸ”§ æ–°å¢ï¼šåˆ¤æ–­è®¡åˆ’å†…å®¹æ˜¯å¦åŒ…å«å¯æ‰§è¡Œçš„å…·ä½“æ­¥éª¤"""
        if not plan_content or len(plan_content) < 30:
            return False
        
        plan_lower = plan_content.lower()
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å·¥å…·ç›¸å…³çš„æ‰§è¡Œæ„å›¾
        tool_indicators = [
            'search', 'execute', 'run', 'call', 'use', 'browser', 'python', 'code',
            'æœç´¢', 'æ‰§è¡Œ', 'è¿è¡Œ', 'è°ƒç”¨', 'ä½¿ç”¨', 'æµè§ˆå™¨', 'ä»£ç ', 'å·¥å…·'
        ]
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ˜ç¡®çš„æ‰§è¡Œæ­¥éª¤
        execution_indicators = [
            'step 1', 'first step', 'start by', 'begin with', 'initially',
            'ç¬¬ä¸€æ­¥', 'é¦–å…ˆ', 'å¼€å§‹', 'å…ˆ', 'ç¬¬1æ­¥'
        ]
        
        # æ£€æŸ¥å·¥å…·æœåŠ¡å™¨åç§°
        service_indicators = [
            'microsandbox', 'deepsearch', 'browser_use', 'search_tool'
        ]
        
        has_tools = any(indicator in plan_lower for indicator in tool_indicators)
        has_execution_steps = any(indicator in plan_lower for indicator in execution_indicators)
        has_services = any(indicator in plan_lower for indicator in service_indicators)
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤šä¸ªæ­¥éª¤ï¼ˆè¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªè¯¦ç»†è®¡åˆ’ï¼‰
        step_count = (
            plan_lower.count('step') + plan_lower.count('æ­¥éª¤') + 
            plan_lower.count('first') + plan_lower.count('then') + 
            plan_lower.count('next') + plan_lower.count('é¦–å…ˆ') + 
            plan_lower.count('ç„¶å') + plan_lower.count('æ¥ä¸‹æ¥')
        )
        
        has_multiple_steps = step_count >= 2
        
        # å¦‚æœæœ‰å·¥å…·æ„å›¾ã€æ‰§è¡Œæ­¥éª¤ã€æˆ–å¤šæ­¥è®¡åˆ’ï¼Œè®¤ä¸ºè¿™æ˜¯å¯æ‰§è¡Œè®¡åˆ’
        is_executable = (has_tools and has_execution_steps) or has_services or has_multiple_steps
        
        logger.debug(f"ğŸ” è®¡åˆ’åˆ†æ: å·¥å…·={has_tools}, æ‰§è¡Œæ­¥éª¤={has_execution_steps}, "
                    f"æœåŠ¡={has_services}, å¤šæ­¥éª¤={has_multiple_steps}, å¯æ‰§è¡Œ={is_executable}")
        
        return is_executable
    
    def _extract_first_executable_action(self, plan_content: str) -> Optional[str]:
        """ğŸ”§ Priority 3 æ–°å¢ï¼šä»è®¡åˆ’ä¸­æå–ç¬¬ä¸€ä¸ªå¯æ‰§è¡Œçš„å…·ä½“åŠ¨ä½œ"""
        import re
        
        plan_lower = plan_content.lower()
        lines = plan_content.split('\n')
        
        # å¯»æ‰¾æ˜ç¡®çš„ç¬¬ä¸€æ­¥éª¤
        first_step_patterns = [
            r'(?:step\s*1|first\s*step|ç¬¬ä¸€æ­¥|é¦–å…ˆ)[:\s]*(.*?)(?:\n|$)',
            r'(?:1\.|â‘ |å¼€å§‹|start)[:\s]*(.*?)(?:\n|$)',
            r'(?:éœ€è¦|need\s*to|will|åº”è¯¥)[:\s]*(.*?)(?:\n|$)'
        ]
        
        for pattern in first_step_patterns:
            match = re.search(pattern, plan_lower, re.IGNORECASE | re.DOTALL)
            if match:
                action = match.group(1).strip()
                # æ¸…ç†å¹¶ç®€åŒ–åŠ¨ä½œæè¿°
                if len(action) > 10 and len(action) < 200:
                    return action
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ç¡®çš„ç¬¬ä¸€æ­¥ï¼Œå°è¯•ä»è®¡åˆ’ä¸­æå–å·¥å…·ç›¸å…³çš„åŠ¨ä½œ
        tool_action_patterns = [
            r'(search\s+for\s+[^.\n]+)',
            r'(execute\s+[^.\n]+)',
            r'(run\s+[^.\n]+)',
            r'(use\s+[^.\n]+)',
            r'(æœç´¢[^ã€‚\n]+)',
            r'(æ‰§è¡Œ[^ã€‚\n]+)',
            r'(è¿è¡Œ[^ã€‚\n]+)',
            r'(ä½¿ç”¨[^ã€‚\n]+)'
        ]
        
        for pattern in tool_action_patterns:
            match = re.search(pattern, plan_lower)
            if match:
                action = match.group(1).strip()
                if len(action) > 5 and len(action) < 150:
                    return action
        
        return None
    
    def _validate_calculation_context(self, trajectory_str: str, calculation_result: str) -> bool:
        """ğŸ”§ æ–°å¢ï¼šéªŒè¯è®¡ç®—ç»“æœæ˜¯å¦æ¥è‡ªçœŸå®çš„å·¥å…·æ‰§è¡Œä¸Šä¸‹æ–‡"""
        import re
        
        # 1. æ£€æŸ¥ç»“æœæ˜¯å¦å‡ºç°åœ¨å·¥å…·æ‰§è¡Œç»“æœæ ‡ç­¾å†…
        result_tag = TaskExecutionConstants.XML_TAGS['RESULT']
        result_pattern = f'<{result_tag}>(.*?)</{result_tag}>'
        result_blocks = re.findall(result_pattern, trajectory_str, re.DOTALL)
        
        # æ£€æŸ¥è®¡ç®—ç»“æœæ˜¯å¦åœ¨ä»»ä½•resultå—ä¸­
        for result_block in result_blocks:
            if calculation_result in result_block:
                logger.debug("âœ… è®¡ç®—ç»“æœåœ¨å·¥å…·æ‰§è¡Œç»“æœä¸­æ‰¾åˆ°")
                return True
        
        # 2. æ£€æŸ¥ç»“æœæ˜¯å¦åœ¨å·¥å…·æ‰§è¡Œçš„ä¸Šä¸‹æ–‡ä¸­ï¼ˆé™„è¿‘æœ‰å·¥å…·è°ƒç”¨ï¼‰
        # æŸ¥æ‰¾ç»“æœåœ¨è½¨è¿¹ä¸­çš„ä½ç½®
        result_index = trajectory_str.find(calculation_result)
        if result_index == -1:
            logger.debug("âŒ æœªæ‰¾åˆ°è®¡ç®—ç»“æœåœ¨è½¨è¿¹ä¸­çš„ä½ç½®")
            return False
        
        # æ£€æŸ¥ç»“æœå‰å500å­—ç¬¦å†…æ˜¯å¦æœ‰å·¥å…·æ‰§è¡Œæ ‡è®°
        context_start = max(0, result_index - 500)
        context_end = min(len(trajectory_str), result_index + len(calculation_result) + 500)
        context = trajectory_str[context_start:context_end]
        
        tool_execution_indicators = [
            '<execute_tools', '</execute_tools>', '<result>', '</result>',
            'microsandbox', 'deepsearch', 'browser_use', 'search_tool',
            'ä»£ç æ‰§è¡Œ', 'æ‰§è¡Œç»“æœ', 'å·¥å…·æ‰§è¡Œ', 'è®¡ç®—å®Œæˆ'
        ]
        
        has_tool_context = any(indicator in context for indicator in tool_execution_indicators)
        if has_tool_context:
            logger.debug("âœ… è®¡ç®—ç»“æœåœ¨å·¥å…·æ‰§è¡Œä¸Šä¸‹æ–‡ä¸­")
            return True
        
        # 3. æ£€æŸ¥æ˜¯å¦æ˜¯çº¯æ€è€ƒè¿‡ç¨‹ä¸­çš„è™šå‡è®¡ç®—
        think_tag = TaskExecutionConstants.XML_TAGS['THINK']
        think_pattern = f'<{think_tag}>(.*?)</{think_tag}>'
        think_blocks = re.findall(think_pattern, trajectory_str, re.DOTALL)
        
        for think_block in think_blocks:
            if calculation_result in think_block:
                # å¦‚æœç»“æœåªåœ¨æ€è€ƒè¿‡ç¨‹ä¸­ï¼Œä¸”æ²¡æœ‰å¯¹åº”çš„å·¥å…·æ‰§è¡Œï¼Œåˆ™è®¤ä¸ºæ˜¯è™šå‡çš„
                logger.debug("âš ï¸ è®¡ç®—ç»“æœåªåœ¨æ€è€ƒè¿‡ç¨‹ä¸­å‘ç°ï¼Œå¯èƒ½æ˜¯è™šå‡ç»“æœ")
                return False
        
        # 4. æ£€æŸ¥ç»“æœæ˜¯å¦æœ‰åˆç†çš„æ•°å€¼æ ¼å¼å’Œå•ä½
        # å¦‚æœæ˜¯çº¯å­—æ¯ï¼ˆå¦‚"e"ï¼‰ï¼Œå¾ˆå¯èƒ½æ˜¯è™šå‡ç»“æœ
        if re.match(r'^[a-zA-Z]$', calculation_result.strip()):
            logger.debug("âŒ è®¡ç®—ç»“æœæ˜¯å•ä¸ªå­—æ¯ï¼Œå¯èƒ½æ˜¯è™šå‡ç»“æœ")
            return False
        
        # 5. é»˜è®¤æƒ…å†µï¼šå¦‚æœç»“æœçœ‹èµ·æ¥åˆç†ä¸”æ²¡æœ‰æ˜æ˜¾é—®é¢˜ï¼Œå…è®¸é€šè¿‡
        logger.debug("ğŸ”§ è®¡ç®—ç»“æœé€šè¿‡åŸºæœ¬éªŒè¯")
        return True
    
    def _has_meaningful_tool_results(self, trajectory_str: str) -> bool:
        """ğŸ”§ Priority 2 å¢å¼ºï¼šå·¥å…·ç»“æœè§£æèƒ½åŠ›ï¼Œæ”¯æŒå¤æ‚JSONç»“æ„"""
        import re
        import json
        
        result_tag = TaskExecutionConstants.XML_TAGS['RESULT']
        result_pattern = f'<{result_tag}>(.*?)</{result_tag}>'
        result_blocks = re.findall(result_pattern, trajectory_str, re.DOTALL)
        
        meaningful_results = 0
        for result_block in result_blocks:
            result_clean = result_block.strip()
            
            # æ’é™¤æ— æ„ä¹‰çš„ç»“æœ
            if (len(result_clean) > 20 and  # æœ‰è¶³å¤Ÿçš„å†…å®¹
                TaskExecutionConstants.NO_ACTION_PERFORMED not in result_clean and
                "No executable action detected" not in result_clean and
                "Error:" not in result_clean and
                "failed" not in result_clean.lower()):
                
                # ğŸ”§ Priority 2 æ–°å¢ï¼šå¤æ‚JSONç»“æ„è§£æ
                is_meaningful = self._analyze_complex_result_content(result_clean)
                
                if is_meaningful:
                    meaningful_results += 1
        
        # å¦‚æœæœ‰è‡³å°‘ä¸€ä¸ªæœ‰æ„ä¹‰çš„å·¥å…·ç»“æœï¼Œè®¤ä¸ºå·¥å…·æ‰§è¡Œæœ‰æ„ä¹‰
        has_meaningful = meaningful_results > 0
        logger.debug(f"ğŸ” å·¥å…·ç»“æœåˆ†æ: æ€»ç»“æœå—={len(result_blocks)}, æœ‰æ„ä¹‰ç»“æœ={meaningful_results}, åˆ¤å®š={has_meaningful}")
        
        return has_meaningful
    
    def _analyze_complex_result_content(self, result_content: str) -> bool:
        """ğŸ”§ Priority 2 æ–°å¢ï¼šåˆ†æå¤æ‚ç»“æœå†…å®¹ï¼Œæ”¯æŒJSONã€ä»£ç ã€æœç´¢ç»“æœç­‰"""
        import re
        import json
        
        # 1. æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰ä»·å€¼çš„ä¿¡æ¯æŒ‡ç¤ºè¯
        has_data = any(indicator in result_content.lower() for indicator in [
            'result', 'found', 'success', 'completed', 'ç»“æœ', 'æˆåŠŸ', 'å®Œæˆ',
            'http', 'www', 'search', 'execute', 'calculation', 'answer'
        ])
        
        # 2. æ£€æŸ¥æ˜¯å¦åŒ…å«æ•°å€¼ã€ä»£ç æ‰§è¡Œç»“æœæˆ–æœç´¢ç»“æœ
        has_numerical = re.search(r'\d+', result_content)
        has_technical_content = any(keyword in result_content.lower() for keyword in [
            'python', 'code', 'execute', 'import', 'def', 'return',
            'search results', 'æœç´¢ç»“æœ', 'photocurrent', 'iora'
        ])
        
        # 3. ğŸ”§ æ–°å¢ï¼šJSONç»“æ„è§£æ
        has_structured_data = self._has_structured_json_data(result_content)
        
        # 4. ğŸ”§ æ–°å¢ï¼šç½‘é¡µå†…å®¹è§£æ
        has_web_content = self._has_meaningful_web_content(result_content)
        
        # 5. ğŸ”§ æ–°å¢ï¼šæ–‡ä»¶æœç´¢ç»“æœè§£æ
        has_file_results = self._has_meaningful_file_results(result_content)
        
        # 6. ğŸ”§ æ–°å¢ï¼šè®¡ç®—ç»“æœè§£æ
        has_calculation_results = self._has_calculation_results(result_content)
        
        return (has_data or has_numerical or has_technical_content or 
                has_structured_data or has_web_content or has_file_results or 
                has_calculation_results)
    
    def _has_structured_json_data(self, content: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰æ„ä¹‰çš„JSONç»“æ„æ•°æ®"""
        import json
        import re
        
        # å°è¯•æå–JSONå¯¹è±¡
        json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
        json_matches = re.findall(json_pattern, content, re.DOTALL)
        
        for json_str in json_matches:
            try:
                data = json.loads(json_str)
                if isinstance(data, dict) and len(data) > 0:
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰æ„ä¹‰çš„é”®å€¼å¯¹
                    meaningful_keys = ['result', 'data', 'response', 'output', 'value', 'content']
                    if any(key in data for key in meaningful_keys):
                        return True
            except json.JSONDecodeError:
                continue
        
        return False
    
    def _has_meaningful_web_content(self, content: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰æ„ä¹‰çš„ç½‘é¡µå†…å®¹"""
        import re
        
        # æ£€æŸ¥URLæ¨¡å¼
        url_pattern = r'https?://[^\s<>"\']+|www\.[^\s<>"\']+\.[^\s<>"\']+' 
        has_urls = re.search(url_pattern, content)
        
        # æ£€æŸ¥HTMLæ ‡ç­¾
        html_pattern = r'<[^>]+>'
        has_html = re.search(html_pattern, content)
        
        # æ£€æŸ¥ç½‘é¡µç‰¹æœ‰å†…å®¹
        web_indicators = ['page title', 'page content', 'browser', 'navigation', 'click', 'scroll']
        has_web_terms = any(indicator in content.lower() for indicator in web_indicators)
        
        return has_urls or has_html or has_web_terms
    
    def _has_meaningful_file_results(self, content: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰æ„ä¹‰çš„æ–‡ä»¶æœç´¢ç»“æœ"""
        import re
        
        # æ–‡ä»¶è·¯å¾„æ¨¡å¼
        file_pattern = r'[^\s<>"\']+\.[a-zA-Z0-9]+'
        has_files = re.search(file_pattern, content)
        
        # æ–‡ä»¶æ“ä½œæŒ‡ç¤ºè¯
        file_indicators = ['file', 'directory', 'folder', 'path', 'æ–‡ä»¶', 'ç›®å½•', 'è·¯å¾„']
        has_file_terms = any(indicator in content.lower() for indicator in file_indicators)
        
        # æœç´¢ç»“æœæ•°é‡
        count_pattern = r'found\s+(\d+)|(\d+)\s+results|(\d+)\s+files'
        has_counts = re.search(count_pattern, content.lower())
        
        return has_files or (has_file_terms and has_counts)
    
    def _has_calculation_results(self, content: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«è®¡ç®—ç»“æœ"""
        import re
        
        # æ•°å­¦è¡¨è¾¾å¼å’Œç»“æœ
        math_pattern = r'=\s*[-+]?\d*\.?\d+|result:\s*[-+]?\d*\.?\d+|answer:\s*[-+]?\d*\.?\d+'
        has_math = re.search(math_pattern, content.lower())
        
        # è®¡ç®—ç›¸å…³æœ¯è¯­
        calc_indicators = ['calculation', 'computed', 'evaluated', 'è®¡ç®—', 'ç»“æœ', 'output']
        has_calc_terms = any(indicator in content.lower() for indicator in calc_indicators)
        
        # å¤æ‚æ•°å€¼ï¼ˆç§‘å­¦è®¡æ•°æ³•ã€å°æ•°ç­‰ï¼‰
        complex_num_pattern = r'[-+]?\d*\.?\d+[eE][-+]?\d+|[-+]?\d+\.\d{2,}'
        has_complex_nums = re.search(complex_num_pattern, content)
        
        return has_math or (has_calc_terms and has_complex_nums)
    
    def _evaluate_multi_tool_coordination_quality(self, trajectory_str: str) -> Dict[str, Any]:
        """ğŸ”§ Priority 4 æ–°å¢ï¼šè¯„ä¼°å¤šå·¥å…·ååŒçš„è´¨é‡å’Œæ•ˆæœ"""
        import re
        
        # ç»Ÿè®¡ä½¿ç”¨çš„å·¥å…·ç±»å‹
        used_tools = set()
        result_tag = TaskExecutionConstants.XML_TAGS['RESULT']
        result_pattern = f'<{result_tag}>(.*?)</{result_tag}>'
        result_blocks = re.findall(result_pattern, trajectory_str, re.DOTALL)
        
        # è¯†åˆ«ä½¿ç”¨çš„å·¥å…·æœåŠ¡
        tool_services = ['microsandbox', 'deepsearch', 'browser_use', 'search_tool']
        for service in tool_services:
            if service in trajectory_str.lower():
                used_tools.add(service)
        
        tools_count = len(used_tools)
        is_multi_tool = tools_count >= TaskExecutionConstants.MULTI_TOOL_COORDINATION['RESULT_INTEGRATION']['min_meaningful_tools']
        
        # è¯„ä¼°å·¥å…·ååŒè´¨é‡
        quality_score = 0.0
        coordination_indicators = []
        
        if is_multi_tool:
            # æ£€æŸ¥å·¥å…·é—´çš„æ•°æ®æµè½¬
            data_flow_quality = self._assess_tool_data_flow(trajectory_str, used_tools)
            quality_score += data_flow_quality * 0.4
            coordination_indicators.append(f"æ•°æ®æµè½¬è´¨é‡: {data_flow_quality:.2f}")
            
            # æ£€æŸ¥ç»“æœæ•´åˆè´¨é‡
            integration_quality = self._assess_result_integration(result_blocks)
            quality_score += integration_quality * 0.3
            coordination_indicators.append(f"ç»“æœæ•´åˆè´¨é‡: {integration_quality:.2f}")
            
            # æ£€æŸ¥ä»»åŠ¡å®Œæˆåº¦
            completion_quality = self._assess_task_completion_via_coordination(trajectory_str)
            quality_score += completion_quality * 0.3
            coordination_indicators.append(f"ä»»åŠ¡å®Œæˆåº¦: {completion_quality:.2f}")
        
        return {
            'is_coordinated': is_multi_tool,
            'tools_used': list(used_tools),
            'tools_count': tools_count,
            'quality_score': quality_score,
            'coordination_indicators': coordination_indicators
        }
    
    def _assess_tool_data_flow(self, trajectory_str: str, used_tools: set) -> float:
        """è¯„ä¼°å·¥å…·é—´çš„æ•°æ®æµè½¬è´¨é‡"""
        # æ£€æŸ¥å‰ä¸€ä¸ªå·¥å…·çš„è¾“å‡ºæ˜¯å¦è¢«åç»­å·¥å…·ä½¿ç”¨
        data_flow_score = 0.0
        
        # ç®€åŒ–ç‰ˆï¼šæ£€æŸ¥æ˜¯å¦æœ‰æ˜æ˜¾çš„æ•°æ®ä¼ é€’æ¨¡å¼
        if 'microsandbox' in used_tools and 'deepsearch' in used_tools:
            # æœç´¢ååˆ†ææ¨¡å¼
            if 'search' in trajectory_str.lower() and 'code' in trajectory_str.lower():
                data_flow_score += 0.5
        
        if 'browser_use' in used_tools and 'search_tool' in used_tools:
            # æµè§ˆåæœç´¢æ¨¡å¼
            if 'browse' in trajectory_str.lower() and 'file' in trajectory_str.lower():
                data_flow_score += 0.5
        
        return min(1.0, data_flow_score)
    
    def _assess_result_integration(self, result_blocks: list) -> float:
        """è¯„ä¼°ç»“æœæ•´åˆè´¨é‡"""
        if len(result_blocks) < 2:
            return 0.0
        
        # æ£€æŸ¥ç»“æœé—´çš„å…³è”æ€§
        integration_score = 0.0
        
        # ç®€åŒ–ç‰ˆï¼šæ£€æŸ¥ç»“æœæ˜¯å¦åŒ…å«ç›¸äº’å¼•ç”¨æˆ–è¡¥å……ä¿¡æ¯
        combined_results = ' '.join(result_blocks).lower()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®å¼•ç”¨
        if any(indicator in combined_results for indicator in ['based on', 'according to', 'using the', 'åŸºäº', 'æ ¹æ®']):
            integration_score += 0.4
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç»¼åˆåˆ†æ
        if any(indicator in combined_results for indicator in ['combined', 'integrated', 'overall', 'ç»¼åˆ', 'æ•´åˆ']):
            integration_score += 0.3
        
        # æ£€æŸ¥ç»“æœçš„äº’è¡¥æ€§
        if len(set(result_blocks)) == len(result_blocks):  # æ— é‡å¤ç»“æœ
            integration_score += 0.3
        
        return min(1.0, integration_score)
    
    def _assess_task_completion_via_coordination(self, trajectory_str: str) -> float:
        """è¯„ä¼°é€šè¿‡å·¥å…·ååŒå®Œæˆä»»åŠ¡çš„ç¨‹åº¦"""
        completion_score = 0.0
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ˜ç¡®çš„ä»»åŠ¡å®ŒæˆæŒ‡ç¤º
        completion_indicators = [
            'task completed', 'finished', 'done', 'result', 'conclusion',
            'ä»»åŠ¡å®Œæˆ', 'å®Œæˆ', 'ç»“æœ', 'ç»“è®º', 'ç­”æ¡ˆ'
        ]
        
        trajectory_lower = trajectory_str.lower()
        for indicator in completion_indicators:
            if indicator in trajectory_lower:
                completion_score += 0.2
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°å€¼æˆ–å…·ä½“ç»“æœ
        import re
        if re.search(r'\d+\.?\d*', trajectory_str):
            completion_score += 0.3
        
        return min(1.0, completion_score)
        
    def _detect_success(self, response: str) -> bool:
        """æ£€æµ‹XMLå“åº”æ˜¯å¦æˆåŠŸ - ä¿ç•™å‘åå…¼å®¹æ€§"""
        response_lower = response.lower()
        return ('<answer>' in response_lower) and ('error>' not in response_lower)
    
    def _get_trajectory_file_path(self, task_id: str, is_raw: bool = False) -> str:
        """æ ¹æ®å­˜å‚¨æ¨¡å¼è·å–è½¨è¿¹æ–‡ä»¶è·¯å¾„"""
        out_dir = get_trajectories_dir()
        date_str = datetime.now().strftime("%Y-%m-%d")
        group_dir = os.path.join(out_dir, "grouped", date_str)
        if is_raw:
            return os.path.join(group_dir, f"raw_trajectories_{date_str}.jsonl")
        else:
            return os.path.join(group_dir, f"trajectories_{date_str}.jsonl")
    
    async def _save_xml_output(self, xml_output):
        """ä¿å­˜XMLè¾“å‡ºæ•°æ®åˆ°JSONLæ–‡ä»¶"""
        file_path = self._get_trajectory_file_path(xml_output['task_id'])
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        
        with open(file_path, 'a', encoding='utf-8') as f:
            f.write(json.dumps(xml_output, ensure_ascii=False) + '\n')
        
        logger.info(f"ä¿å­˜XMLæ•°æ®åˆ°: {file_path}")
    
    def _detect_triggered_stop_sequence(self, response_text: str, stop_sequences: list) -> str:
        """æ£€æµ‹è§¦å‘çš„åœæ­¢åºåˆ—"""
        for stop_seq in stop_sequences:
            if stop_seq in response_text:
                return stop_seq
        return "unknown"
    
    async def _execute_tool_with_logging(self, action: dict, execution_index: int) -> dict:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨å¹¶è®°å½•è¯¦ç»†æ—¥å¿—"""
        tool_start_time = time.time()
        
        # æ„å»ºå·¥å…·æ‰§è¡Œå‚æ•°
        service_name = action.get('service')
        tool_name = action.get('tool')
        tool_input = action.get('input')
        
        # ğŸ†• æ£€æŸ¥æ˜¯å¦ä¸ºå†…å­˜æš‚å­˜å·¥å…·
        if self.tool_manager.is_memory_staging_tool(service_name):
            logger.info(f"ğŸ”„ æ‰§è¡Œå†…å­˜æš‚å­˜å·¥å…·: {service_name}.{tool_name}")
            
            # è§£æå·¥å…·è¾“å…¥å‚æ•°
            try:
                # å¯¹äºå†…å­˜æš‚å­˜å·¥å…·ï¼Œtool_inputå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å­—å…¸
                if isinstance(tool_input, str):
                    # å°è¯•è§£æä¸ºJSON
                    try:
                        import json
                        parameters = json.loads(tool_input)
                    except:
                        # å¦‚æœè§£æå¤±è´¥ï¼Œæ ¹æ®åŠ¨ä½œç±»å‹æ„å»ºå‚æ•°
                        if tool_name in ["memory_write"]:
                            # å¯¹äºå†™å…¥æ“ä½œï¼Œå‡è®¾è¾“å…¥æ˜¯è¦ä¿å­˜çš„å€¼
                            parameters = {"key": f"auto_key_{int(time.time())}", "value": tool_input}
                        elif tool_name in ["memory_read", "memory_clear"]:
                            parameters = {"key": tool_input}
                        elif tool_name in ["memory_search"]:
                            parameters = {"query": tool_input}
                        else:
                            parameters = {}
                else:
                    parameters = tool_input or {}
                
                # è®¾ç½®æ‰§è¡Œä¸Šä¸‹æ–‡
                parameters["_current_step"] = getattr(self, "_current_step_id", None)
                parameters["_current_tool"] = service_name
                
                # ç›´æ¥æ‰§è¡Œå†…å­˜æš‚å­˜å·¥å…·
                raw_result = self.tool_manager.execute_memory_staging_action(tool_name, parameters)
                
                formatted_result = self._format_memory_staging_output(tool_name, raw_result)
                execution_status = "success" if raw_result.get("success", False) else "failure"
                error_details = raw_result.get("error") if not raw_result.get("success", False) else None
                
            except Exception as e:
                error_str = str(e)
                raw_result = {"error": error_str, "success": False}
                formatted_result = f"Memory staging tool execution failed: {error_str}"
                execution_status = "failure"
                error_details = error_str
                
            # è®°å½•å†…å­˜æš‚å­˜å·¥å…·è°ƒç”¨ï¼ˆæ— éœ€HTTPè¯·æ±‚ï¼‰
            toolscore_request = {
                "tool_type": "memory_staging",
                "tool_id": service_name,
                "action": tool_name,
                "parameters": parameters if 'parameters' in locals() else {}
            }
            
        else:
            # åŸæœ‰çš„å¤–éƒ¨å·¥å…·æ‰§è¡Œé€»è¾‘
            param_mapping = {
                "browser_use": "query",
                "microsandbox": "code",
                "deepsearch": "question"
            }
            param_name = param_mapping.get(service_name, "input")
            
            # ğŸ”§ Fix JSON parameter parsing issue - ä½¿ç”¨å·²æœ‰çš„JSONParameterParser
            # Parse tool_input if it contains JSON data mixed with XML tags
            parsed_parameters = self._parse_tool_input_parameters(tool_input, service_name, tool_name, param_name)
            
            # ğŸ”§ ä¿®å¤ï¼šæ£€æŸ¥å‚æ•°éªŒè¯é”™è¯¯å¹¶ä½œä¸ºå·¥å…·ç»“æœè¿”å›ï¼Œè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
            if "_validation_error" in parsed_parameters:
                validation_error = parsed_parameters["_validation_error"]
                logger.warning(f"Parameter validation failed, returning error to model for correction: {validation_error}")
                
                # ğŸ”§ å…³é”®ä¿®å¤ï¼šå°†å‚æ•°éªŒè¯é”™è¯¯ä½œä¸ºå·¥å…·æ‰§è¡Œç»“æœè¿”å›ç»™æ¨¡å‹
                # è¿™æ ·æ¨¡å‹å¯ä»¥çœ‹åˆ°é”™è¯¯ä¿¡æ¯ï¼Œå¹¶åŸºäºæ­¤é‡æ–°æ€è€ƒå’Œä¿®æ­£å‚æ•°
                error_result = {
                    "error": validation_error,
                    "success": False,
                    "error_type": "parameter_validation_error",
                    "suggestions": [
                        f"è¯·æ£€æŸ¥å·¥å…· {service_name}.{tool_name} çš„å‚æ•°æ ¼å¼",
                        "ç¡®ä¿æ‰€æœ‰å¿…éœ€å‚æ•°éƒ½å·²æä¾›",
                        "å‚è€ƒå·¥å…·æ–‡æ¡£ç¡®è®¤æ­£ç¡®çš„å‚æ•°åç§°å’Œç±»å‹"
                    ]
                }
                
                # æ ¼å¼åŒ–é”™è¯¯ä¿¡æ¯ï¼Œè®©æ¨¡å‹èƒ½å¤Ÿç†è§£å¹¶ä¿®æ­£
                formatted_error = self._format_parameter_validation_error(
                    service_name, tool_name, validation_error, parsed_parameters.get(param_name, tool_input)
                )
                
                tool_end_time = time.time()
                
                # è®°å½•å‚æ•°éªŒè¯å¤±è´¥çš„æ—¥å¿—ï¼Œä½†ä¸æ ‡è®°ä¸ºæ‰§è¡Œå¤±è´¥
                self.step_logger.log_tool_execution(
                    execution_index=execution_index,
                    action=action,
                    toolscore_request={
                        "tool_type": "external",
                        "tool_id": service_name,
                        "action": tool_name,
                        "parameters": parsed_parameters,
                        "validation_status": "failed"
                    },
                    raw_response=error_result,
                    formatted_result=formatted_error,
                    start_time=tool_start_time,
                    end_time=tool_end_time,
                    execution_status="parameter_validation_failed",  # æ–°çš„çŠ¶æ€ï¼Œä¸æ˜¯failure
                    error_details=validation_error
                )
                
                return {
                    "formatted_result": formatted_error,
                    "raw_result": error_result,
                    "execution_status": "parameter_validation_failed"
                }
            
            # æ¸…ç†_validation_errorå‚æ•°ï¼Œç¡®ä¿å®ƒä¸ä¼šä¼ é€’ç»™å®é™…çš„å·¥å…·
            clean_parameters = {k: v for k, v in parsed_parameters.items() if k != "_validation_error"}
            
            toolscore_request = {
                "endpoint": f"http://127.0.0.1:{self._get_service_port(service_name)}/execute_tool",
                "method": "POST",
                "payload": {
                    "tool_id": service_name,
                    "action": tool_name,
                    "parameters": clean_parameters
                }
            }
            
            # ğŸ”§ æ™ºèƒ½å·¥å…·æ‰§è¡Œä¸é”™è¯¯åˆ†æ
            try:
                raw_result = await self.toolscore_client.execute_tool(
                    tool_id=service_name,
                    action=tool_name,
                    parameters=clean_parameters
                )
                
                formatted_result = self._format_tool_output(service_name, tool_name, raw_result)
                execution_status = "success"
                error_details = None
                
                # ğŸ§  æ£€æµ‹å·¥å…·ç»“æœä¸­çš„æ½œåœ¨é—®é¢˜å¹¶æä¾›æ™ºèƒ½æŒ‡å¯¼
                smart_guidance = self._provide_smart_recovery_guidance(raw_result, service_name, tool_name)
                if smart_guidance:
                    formatted_result += f"\n\n{smart_guidance}"
                
            except Exception as e:
                error_str = str(e)
                error_type = self._analyze_error_type(error_str)
                
                raw_result = {"error": error_str, "success": False, "error_type": error_type}
                formatted_result = self._format_error_with_recovery_suggestion(error_str, error_type, service_name, tool_name)
                execution_status = "failure"
                error_details = error_str
        
        tool_end_time = time.time()
        
        # ğŸ” è®°å½•å·¥å…·æ‰§è¡Œæ—¥å¿—
        self.step_logger.log_tool_execution(
            execution_index=execution_index,
            action=action,
            toolscore_request=toolscore_request,
            raw_response=raw_result,
            formatted_result=formatted_result,
            start_time=tool_start_time,
            end_time=tool_end_time,
            execution_status=execution_status,
            error_details=error_details
        )
        
        return {
            "formatted_result": formatted_result,
            "raw_result": raw_result,
            "execution_status": execution_status
        }
    
    async def _execute_parallel_with_logging(self, actions: list) -> list:
        """å¹¶å‘æ‰§è¡Œå¤šä¸ªå·¥å…·è°ƒç”¨å¹¶è®°å½•æ—¥å¿—"""
        import asyncio
        
        if not actions:
            return []
        
        # åˆ›å»ºå¹¶å‘ä»»åŠ¡
        tasks = [
            self._execute_tool_with_logging(action, i) 
            for i, action in enumerate(actions)
        ]
        
        # å¹¶å‘æ‰§è¡Œ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # æå–æ ¼å¼åŒ–ç»“æœ
        formatted_results = []
        for result in results:
            if isinstance(result, Exception):
                formatted_results.append(f"Error: {result}")
            else:
                formatted_results.append(result["formatted_result"])
        
        return formatted_results
    
    def _get_service_port(self, service_name: str) -> int:
        """è·å–æœåŠ¡ç«¯å£å·"""
        port_mapping = {
            "microsandbox": 8090,
            "deepsearch": 8086,
            "browser_use": 8082,
            "search_tool": 8080
        }
        return port_mapping.get(service_name, 8080)

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        logger.info("ğŸ§¹ æ¸…ç†Enhanced Reasoning Runtimeèµ„æº")
        if self.toolscore_client and hasattr(self.toolscore_client, 'close'):
            await self.toolscore_client.close()
        self.is_initialized = False
        logger.info("âœ… èµ„æºæ¸…ç†å®Œæˆ")
    
    # ğŸš¨ é˜¶æ®µ2æ–°å¢ï¼šå¤æ‚ä»»åŠ¡æ£€æµ‹å’Œå¼ºåˆ¶æ‰§è¡Œæœºåˆ¶
    
    def _is_complex_task_response(self, response_text: str) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºå¤æ‚ä»»åŠ¡å“åº”ï¼ˆå¯èƒ½å¯¼è‡´è§„åˆ’-æ‰§è¡Œè„±èŠ‚ï¼‰"""
        complex_indicators = [
            # ä¸­æ–‡æŒ‡ç¤ºç¬¦
            'å¤šæ­¥', 'åˆ†æ', 'ç ”ç©¶', 'ç»¼åˆ', 'è¯¦ç»†', 
            'ç¬¬ä¸€æ­¥', 'ç¬¬äºŒæ­¥', 'ç¬¬ä¸‰æ­¥',
            'ç„¶å', 'æ¥ä¸‹æ¥', 'æœ€å',
            'éœ€è¦', 'åŒ…å«', 'æ¶‰åŠ',
            'æ–¹æ³•è®º', 'æ–¹æ³•', 'ç­–ç•¥',
            # è‹±æ–‡æŒ‡ç¤ºç¬¦
            'step 1', 'step 2', 'step 3', 'first', 'then', 'next', 'finally',
            'comprehensive', 'detailed', 'analysis', 'research', 'methodology',
            'approach', 'strategy', 'multiple', 'several', 'various',
            'I need to', 'I will', 'let me', 'plan', 'outline'
        ]
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤æ‚ä»»åŠ¡æŒ‡ç¤ºç¬¦
        text_lower = response_text.lower()
        indicator_count = sum(1 for indicator in complex_indicators if indicator in text_lower)
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤šæ­¥éª¤ç¼–å·
        import re
        step_patterns = [
            r'\d+[.)]â€ˆ*[^\n]*',  # 1. æˆ– 1)
            r'step\s*\d+',  # step 1, step 2
            r'ç¬¬[\u4e00äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]*æ­¥',  # ç¬¬ä¸€æ­¥, ç¬¬äºŒæ­¥
        ]
        
        has_step_numbering = any(re.search(pattern, text_lower) for pattern in step_patterns)
        
        # æ£€æŸ¥å“åº”é•¿åº¦ï¼ˆè¿‡é•¿çš„è§„åˆ’æ€§å“åº”ï¼‰
        is_long_response = len(response_text) > 1000
        
        # ç»¼åˆåˆ¤æ–­
        is_complex = (
            indicator_count >= 3 or  # å¤šä¸ªå¤æ‚æŒ‡ç¤ºç¬¦
            has_step_numbering or    # åŒ…å«æ­¥éª¤ç¼–å·
            (indicator_count >= 2 and is_long_response)  # æŒ‡ç¤ºç¬¦+é•¿å“åº”
        )
        
        if is_complex:
            logger.debug(f"ğŸš¨ æ£€æµ‹åˆ°å¤æ‚ä»»åŠ¡å“åº”: indicators={indicator_count}, steps={has_step_numbering}, long={is_long_response}")
        
        return is_complex
    
    async def _force_first_step_execution(self, response_text: str, task: 'TaskSpec') -> Optional[str]:
        """å¼ºåˆ¶æ‰§è¡Œç¬¬ä¸€æ­¥æœºåˆ¶"""
        try:
            # åˆ†æå“åº”ä¸­çš„å¯æ‰§è¡Œå†…å®¹
            executable_action = self._extract_actionable_content(response_text)
            
            if executable_action:
                logger.info(f"ğŸ”¥ å¼ºåˆ¶æ‰§è¡Œç¬¬ä¸€æ­¥: {executable_action}")
                
                # ç”Ÿæˆå¼ºåˆ¶æ‰§è¡ŒæŒ‡ä»¤
                force_execution_prompt = (
                    f"ğŸš¨ EXECUTION ENFORCEMENT: You provided planning but no tool execution. "
                    f"This will cause task failure. You MUST execute the first step immediately.\n\n"
                    f"Based on your plan, the first action should be: {executable_action}\n\n"
                    f"Please execute this action now using the proper tool format and end with <execute_tools />. "
                    f"Remember: Every complex task requires immediate execution after planning!"
                )
                
                return self._format_result(force_execution_prompt)
                
            else:
                # é€šç”¨å¼ºåˆ¶æŒ‡ä»¤
                generic_force_prompt = (
                    f"ğŸš¨ CRITICAL EXECUTION FAILURE: Complex task detected but no tool execution found. "
                    f"This pattern causes complete task failure.\n\n"
                    f"You MUST start executing immediately. Choose ONE concrete action you can take right now "
                    f"and execute it using proper XML tool format. End with <execute_tools />.\n\n"
                    f"Example actions you could take:\n"
                    f"- Search for information: <deepsearch><research>topic</research></deepsearch>\n"
                    f"- Browse for data: <browser_use><browser_search_google>query</browser_search_google></browser_use>\n"
                    f"- Analyze data: <microsandbox><microsandbox_execute>code</microsandbox_execute></microsandbox>\n\n"
                    f"Act NOW to prevent task failure!"
                )
                
                return self._format_result(generic_force_prompt)
                
        except Exception as e:
            logger.error(f"âš ï¸ å¼ºåˆ¶æ‰§è¡Œæœºåˆ¶å¤±è´¥: {e}")
            return None
    
    def _extract_actionable_content(self, response_text: str) -> Optional[str]:
        """ä»å“åº”ä¸­æå–å¯æ‰§è¡Œçš„å†…å®¹"""
        import re
        
        # å¸¸è§çš„å¯æ‰§è¡ŒåŠ¨ä½œæ¨¡å¼
        action_patterns = [
            # ä¸­æ–‡æ¨¡å¼ - æ”¹è¿›çš„æ¨¡å¼åŒ¹é…
            r'æœç´¢(.+?)(?:\n|$)',
            r'æŸ¥æ‰¾(.+?)(?:\n|$)',
            r'ç ”ç©¶(.+?)(?:\n|$)',
            r'åˆ†æ(.+?)(?:\n|$)',
            r'è°ƒç ”(.+?)(?:\n|$)',
            # è‹±æ–‡æ¨¡å¼ - æ”¹è¿›çš„æ¨¡å¼åŒ¹é…
            r'search for (.+?)(?:\n|$)',
            r'research (.+?)(?:\n|$)',
            r'analyze (.+?)(?:\n|$)',
            r'look up (.+?)(?:\n|$)',
            r'find (.+?)(?:\n|$)',
            r'investigate (.+?)(?:\n|$)',
            # ç¬¬ä¸€æ­¥æ¨¡å¼ - æ›´ç²¾ç¡®çš„åŒ¹é…
            r'ç¬¬ä¸€æ­¥[:\uff1a]?\s*(.+?)(?:\n|$)',
            r'é¦–å…ˆ(.+?)(?:\n|$)',
            r'step 1[:\uff1a]?\s*(.+?)(?:\n|$)',
            r'first[,\uff0c]?\s*(.+?)(?:\n|$)',
            # é€šç”¨åŠ¨ä½œæ¨¡å¼
            r'æˆ‘éœ€è¦(.+?)(?:\n|$)',
            r'i need to (.+?)(?:\n|$)',
        ]
        
        for pattern in action_patterns:
            match = re.search(pattern, response_text, re.IGNORECASE)
            if match:
                action = match.group(1).strip()
                # æ¸…ç†åŠ¨ä½œå†…å®¹
                action = re.sub(r'^[:\uff1a\s]+', '', action)  # ç§»é™¤å¼€å¤´çš„å†’å·å’Œç©ºæ ¼
                action = re.sub(r'[ã€‚\.\n]+$', '', action)  # ç§»é™¤ç»“å°¾çš„å¥å·å’Œæ¢è¡Œ
                
                if len(action) > 5:  # ç¡®ä¿åŠ¨ä½œæœ‰æ„ä¹‰
                    return action[:100]  # é™åˆ¶é•¿åº¦
        
        return None
    
    def _enhance_no_action_guidance(self, response_text: str) -> str:
        """å¢å¼ºçš„æ— åŠ¨ä½œæŒ‡å¯¼"""
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¤æ‚ä»»åŠ¡
        if self._is_complex_task_response(response_text):
            return (
                "ğŸš¨ CRITICAL: Complex task detected with no execution. This causes task failure!\n\n"
                "You MUST execute tools immediately. Choose ONE action and do it now:\n"
                "- ğŸ” Search: <deepsearch><research>topic</research></deepsearch>\n"
                "- ğŸŒ Browse: <browser_use><browser_search_google>query</browser_search_google></browser_use>\n"
                "- ğŸ“Š Analyze: <microsandbox><microsandbox_execute>code</microsandbox_execute></microsandbox>\n"
                "- ğŸ”„ Check Memory: <memory_staging><memory_list></memory_list></memory_staging>\n\n"
                "End with <execute_tools /> or the task will fail completely!"
            )
        else:
            return "No executable action detected in this step. Please provide a tool call with proper XML format."
    
    def _detect_tool_result_issues(self, raw_result: Any, service_name: str, tool_name: str) -> tuple[bool, str]:
        """ğŸ”§ æ£€æµ‹å·¥å…·æ‰§è¡Œç»“æœä¸­çš„å¸¸è§é—®é¢˜ï¼Œæä¾›æ™ºèƒ½æŒ‡å¯¼"""
        
        # ğŸ”§ ä¿®å¤ï¼šå¯¹äº microsandboxï¼Œæ­£ç¡®æå–å®é™…è¾“å‡ºå†…å®¹è€Œéæ•´ä¸ªå­—å…¸ç»“æ„
        if service_name == "microsandbox":
            # æ­£ç¡®æå– microsandbox çš„å®é™…è¾“å‡ºå†…å®¹
            if isinstance(raw_result, dict):
                # è·å– data å­—æ®µä¸­çš„å†…å®¹
                data = raw_result.get('data', raw_result)
                if isinstance(data, dict):
                    # æå– stdout ä½œä¸ºä¸»è¦è¾“å‡ºå†…å®¹
                    stdout_content = data.get('stdout', '')
                    stderr_content = data.get('stderr', '')
                    result_str = str(stdout_content).lower()
                    
                    # å¦‚æœ stdout ä¸ºç©ºä½†æœ‰ stderrï¼Œåˆ†æ stderrï¼ˆä½†ä¸ç›´æ¥åˆ¤æ–­ä¸ºé”™è¯¯ï¼‰
                    if not stdout_content and stderr_content:
                        result_str = str(stderr_content).lower()
                else:
                    result_str = str(data).lower()
            else:
                result_str = str(raw_result).lower()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ•°å€¼è¾“å‡ºï¼ˆç§‘å­¦è®°æ•°æ³•ã€å°æ•°ã€è®¡ç®—ç»“æœç­‰ï¼‰
            has_numeric_output = bool(re.search(r'\d+\.?\d*e?[+-]?\d*', result_str))
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å…¸å‹çš„æˆåŠŸè¾“å‡ºæ¨¡å¼
            success_output_patterns = [
                'watts:', 'photocurrent:', 'frequency:', 'result:', 'output:', 'print',
                'ç“¦ç‰¹', 'å…‰ç”µæµ', 'é¢‘ç‡', 'ç»“æœ', 'è¾“å‡º', 'completed', 'finished',
                ':', 'hz', 'ampere', 'volt', 'calculation'
            ]
            has_success_output = any(indicator in result_str for indicator in success_output_patterns)
            
            # æ£€æŸ¥æ˜¯å¦æ²¡æœ‰æ˜æ˜¾çš„é”™è¯¯æŒ‡æ ‡
            error_patterns = ['traceback', 'exception:', 'error:', 'failed to', 'cannot', 'unable to']
            has_obvious_error = any(pattern in result_str for pattern in error_patterns)
            
            # å¦‚æœæœ‰æ•°å€¼è¾“å‡ºæˆ–æˆåŠŸæ¨¡å¼ï¼Œä¸”æ²¡æœ‰æ˜æ˜¾é”™è¯¯ï¼Œè¯´æ˜æ‰§è¡ŒæˆåŠŸ
            if (has_numeric_output or has_success_output) and not has_obvious_error:
                logger.debug(f"âœ… {service_name} æ£€æµ‹åˆ°æˆåŠŸè¾“å‡ºï¼Œè·³è¿‡é—®é¢˜æ£€æµ‹")
                return False, ""
        # ğŸ”§ ä¿®å¤ï¼šä¸º deepsearch æ­£ç¡®æå–å®é™…è¾“å‡ºå†…å®¹  
        elif service_name == "deepsearch":
            try:
                if isinstance(raw_result, dict):
                    # ğŸ”§ å¢å¼ºçš„å†…å®¹æå–é€»è¾‘ - æ”¯æŒå¤šå±‚åµŒå¥—ç»“æ„
                    report_content = None
                    
                    # æ–¹æ¡ˆ1ï¼šç›´æ¥ä»æ ¹çº§åˆ«æŸ¥æ‰¾
                    content_fields = ['answer', 'final_report', 'report', 'summary', 'content', 'result', 'response']
                    for field in content_fields:
                        if field in raw_result and raw_result[field]:
                            report_content = raw_result[field]
                            break
                    
                    # æ–¹æ¡ˆ2ï¼šä» data å­—æ®µä¸­æŸ¥æ‰¾
                    if not report_content:
                        data = raw_result.get('data', {})
                        if isinstance(data, dict):
                            for field in content_fields:
                                if field in data and data[field]:
                                    report_content = data[field]
                                    break
                    
                    # æ–¹æ¡ˆ3ï¼šä» result å­—æ®µä¸­æŸ¥æ‰¾ï¼ˆé’ˆå¯¹ step_logs ä¸­çš„ç‰¹å®šç»“æ„ï¼‰
                    if not report_content:
                        result_data = raw_result.get('result', {})
                        if isinstance(result_data, dict):
                            for field in content_fields:
                                if field in result_data and result_data[field]:
                                    report_content = result_data[field]
                                    break
                    
                    # æ–¹æ¡ˆ4ï¼šé€’å½’æŸ¥æ‰¾ä»»ä½•åŒ…å«å®è´¨æ€§å†…å®¹çš„å­—æ®µ
                    if not report_content:
                        report_content = self._extract_deepsearch_content_recursive(raw_result)
                    
                    # ğŸ”§ æ›´å®½æ¾çš„æˆåŠŸæ£€æµ‹æ ‡å‡†
                    if report_content:
                        content_str = str(report_content).strip()
                        # é™ä½é•¿åº¦è¦æ±‚ï¼Œå¢åŠ å†…å®¹è´¨é‡æ£€æµ‹
                        if (len(content_str) >= 50 and  # é™ä½åˆ°50å­—ç¬¦
                            self._is_meaningful_research_content(content_str)):
                            logger.debug(f"âœ… {service_name} æ£€æµ‹åˆ°æœ‰æ•ˆç ”ç©¶æŠ¥å‘Šå†…å®¹ï¼Œè·³è¿‡é—®é¢˜æ£€æµ‹")
                            return False, ""
                        
                        result_str = content_str.lower()
                    else:
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç‰¹å®šå­—æ®µï¼Œæ£€æŸ¥æ•´ä½“ç»“æ„
                        full_content = str(raw_result)
                        if (len(full_content) >= 200 and  # å®Œæ•´ç»“æ„çš„æœ€ä½è¦æ±‚
                            self._is_meaningful_research_content(full_content)):
                            logger.debug(f"âœ… {service_name} ä»å®Œæ•´ç»“æ„æ£€æµ‹åˆ°ç ”ç©¶å†…å®¹ï¼Œè·³è¿‡é—®é¢˜æ£€æµ‹")
                            return False, ""
                        result_str = full_content.lower()
                else:
                    result_str = str(raw_result).lower()
                    # å¯¹äºéå­—å…¸ç»“æ„ï¼Œä¹Ÿè¦æ£€æŸ¥æ˜¯å¦åŒ…å«ç ”ç©¶å†…å®¹
                    if (len(result_str) >= 100 and 
                        self._is_meaningful_research_content(result_str)):
                        logger.debug(f"âœ… {service_name} ä»å­—ç¬¦ä¸²ç»“æ„æ£€æµ‹åˆ°ç ”ç©¶å†…å®¹ï¼Œè·³è¿‡é—®é¢˜æ£€æµ‹")
                        return False, ""
                        
            except Exception as e:
                logger.warning(f"æ£€æŸ¥deepsearchå†…å®¹æ—¶å‡ºé”™: {e}")
                result_str = str(raw_result).lower()
                # å³ä½¿å‡ºç°å¼‚å¸¸ï¼Œä¹Ÿè¦å°è¯•åŸºæœ¬çš„å†…å®¹æ£€æµ‹
                if len(result_str) >= 100:
                    logger.debug(f"âš ï¸ {service_name} å¼‚å¸¸å¤„ç†ä¸­æ£€æµ‹åˆ°è¶³å¤Ÿå†…å®¹ï¼Œè·³è¿‡é—®é¢˜æ£€æµ‹")
                    return False, ""
        
        # ğŸ”§ ä¿®å¤ï¼šä¸ºå…¶ä»–å·¥å…·æ­£ç¡®æå–å†…å®¹
        else:
            # å¯¹äºå…¶ä»–æœåŠ¡ï¼Œå°è¯•æ™ºèƒ½æå–å†…å®¹
            try:
                if isinstance(raw_result, dict):
                    # ä¼˜å…ˆæŸ¥æ‰¾å¸¸è§çš„å†…å®¹å­—æ®µ
                    content_fields = ['content', 'result', 'output', 'data', 'message']
                    extracted_content = None
                    
                    for field in content_fields:
                        if field in raw_result and raw_result[field]:
                            extracted_content = raw_result[field]
                            break
                    
                    if extracted_content:
                        result_str = str(extracted_content).lower()
                    else:
                        result_str = str(raw_result).lower()
                else:
                    result_str = str(raw_result).lower()
            except Exception as e:
                logger.warning(f"æå–{service_name}å†…å®¹æ—¶å‡ºé”™: {e}")
                result_str = str(raw_result).lower()
        
        # ğŸš€ å¯¹äºå…¶ä»–å·¥å…·ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ˜æ˜¾çš„æˆåŠŸæ ‡å¿—
        success_patterns = [
            r'success["\']?\s*:\s*true',  # "success": true
            r'completed successfully',     # æˆåŠŸå®Œæˆ
            r'executed successfully',      # æˆåŠŸæ‰§è¡Œ
            r'operation completed',        # æ“ä½œå®Œæˆ
        ]
        if any(re.search(pattern, result_str) for pattern in success_patterns):
            return False, ""
        
        # ğŸ”§ å¢å¼ºçš„æœç´¢ç»“æœæ£€æµ‹ - åŒºåˆ†æ‰§è¡Œå¤±è´¥å’Œå†…å®¹ä¸ºç©º
        empty_result_indicators = [
            'no results', 'empty', 'not found', 'æ²¡æœ‰ç»“æœ', 'æœªæ‰¾åˆ°', 
            'no data', 'no information', 'æ— æ•°æ®', 'æ— ä¿¡æ¯'
        ]
        
        # ğŸ”§ ç‰¹æ®Šå¤„ç†ï¼šæˆåŠŸå®Œæˆä½†æ— å†…å®¹çš„æƒ…å†µ
        successful_empty_indicators = [
            'æœç´¢å®Œæˆï¼Œä½†æœªæ‰¾åˆ°ç›¸å…³ç»“æœ',  # deepsearch çš„æ ‡å‡†ç©ºç»“æœæ¶ˆæ¯
            'æœç´¢å®Œæˆï¼Œæ²¡æœ‰æ‰¾åˆ°', 
            'search completed, no results',
            'search finished, no content found'
        ]
        
        # å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯æˆåŠŸçš„ç©ºç»“æœ
        for indicator in successful_empty_indicators:
            if indicator in result_str:
                logger.debug(f"âœ… {service_name} æœç´¢æˆåŠŸæ‰§è¡Œä½†æœªæ‰¾åˆ°å†…å®¹ï¼Œè¿™æ˜¯æ­£å¸¸æƒ…å†µ")
                # ä¸è¿”å›é”™è¯¯ï¼Œè€Œæ˜¯è®©å®ƒè¢«æ ‡è®°ä¸ºæˆåŠŸä½†æä¾›ä½¿ç”¨å»ºè®®
                return False, ""  # ä¸æ ‡è®°ä¸ºé—®é¢˜
        
        # å†æ£€æŸ¥ä¸€èˆ¬çš„ç©ºç»“æœï¼ˆå¯èƒ½æ˜¯çœŸæ­£çš„é”™è¯¯ï¼‰
        if any(indicator in result_str for indicator in empty_result_indicators):
            guidance = (
                f"ğŸ” {service_name} æœç´¢æœªæ‰¾åˆ°ç»“æœã€‚å»ºè®®å°è¯•:\n"
                f"â€¢ ä½¿ç”¨æ›´ç®€å•æˆ–ä¸åŒçš„å…³é”®è¯\n"
                f"â€¢ åˆ‡æ¢åˆ°å…¶ä»–æœç´¢å·¥å…· (deepsearch â†” browser_use)\n"
                f"â€¢ æ£€æŸ¥å†…å­˜æš‚å­˜åŒºä¸­çš„ç›¸å…³æ•°æ®: <memory_staging><memory_search>ç›¸å…³è¯</memory_search></memory_staging>\n"
                f"â€¢ å¦‚æœç¡®å®æ— æ³•æ‰¾åˆ°ï¼Œè€ƒè™‘ä½¿ç”¨ç¤ºä¾‹æ•°æ®å¹¶æ˜ç¡®è¯´æ˜"
            )
            return True, guidance
        
        # æ£€æµ‹è¶…æ—¶æˆ–è¿æ¥é—®é¢˜ï¼ˆæ›´ç²¾ç¡®çš„åŒ¹é…ï¼Œé¿å…è¯¯åˆ¤ï¼‰
        # ğŸ”§ ä¿®å¤ï¼šå¯¹äºmicrosandboxï¼Œå¦‚æœå·²ç»é€šè¿‡äº†æˆåŠŸæ£€æµ‹ï¼Œä¸è¦å†æ£€æŸ¥è¶…æ—¶
        if service_name != "microsandbox":
            timeout_indicators = [
                'timeout', 'timed out', 'connection failed', 'connection error',
                'network error', 'connection refused', 'connection reset',
                'è¶…æ—¶', 'è¿æ¥å¤±è´¥', 'è¿æ¥é”™è¯¯', 'ç½‘ç»œé”™è¯¯', 'è¿æ¥è¢«æ‹’ç»'
            ]
            if any(indicator in result_str.lower() for indicator in timeout_indicators):
                guidance = (
                    f"â±ï¸ {service_name} è¿æ¥æˆ–è¶…æ—¶é—®é¢˜ã€‚å»ºè®®:\n"
                    f"â€¢ ç¨ç­‰ç‰‡åˆ»åé‡è¯•\n"
                    f"â€¢ å°è¯•ä½¿ç”¨å…¶ä»–å·¥å…·è¾¾åˆ°ç›¸åŒç›®æ ‡\n"
                    f"â€¢ ç®€åŒ–æŸ¥è¯¢æˆ–æ“ä½œ"
                )
                return True, guidance
        
        # æ£€æµ‹æƒé™æˆ–è®¿é—®é—®é¢˜
        if any(indicator in result_str for indicator in [
            'forbidden', 'unauthorized', 'access denied', 'æ‹’ç»è®¿é—®', 'æƒé™'
        ]):
            guidance = (
                f"ğŸš« {service_name} è®¿é—®å—é™ã€‚å»ºè®®:\n"
                f"â€¢ å°è¯•ä½¿ç”¨å…¶ä»–å…¬å¼€æ•°æ®æº\n"
                f"â€¢ ä½¿ç”¨ä¸åŒçš„æœç´¢ç­–ç•¥\n"
                f"â€¢ è€ƒè™‘ä½¿ç”¨å†…å­˜ä¸­å·²æœ‰çš„æ•°æ®"
            )
            return True, guidance
        
        # æ£€æµ‹æœåŠ¡é”™è¯¯ï¼ˆæ›´ç²¾ç¡®çš„åŒ¹é…ï¼Œé¿å…è¯¯åˆ¤æˆåŠŸçš„è¾“å‡ºï¼‰
        error_indicators = [
            'error:', 'failed:', 'exception:', 'traceback:', 'fatal error',
            'execution failed', 'command failed', 'operation failed',
            'æ‰§è¡Œå¤±è´¥', 'å‘½ä»¤å¤±è´¥', 'æ“ä½œå¤±è´¥', 'å‘ç”Ÿé”™è¯¯', 'å¼‚å¸¸:'
        ]
        # æ’é™¤åŒ…å«æˆåŠŸæŒ‡æ ‡çš„æƒ…å†µ
        success_indicators = ['success', 'completed', 'finished', 'æˆåŠŸ', 'å®Œæˆ', 'ç»“æœ:']
        has_success = any(indicator in result_str.lower() for indicator in success_indicators)
        
        if not has_success and any(indicator in result_str.lower() for indicator in error_indicators):
            guidance = (
                f"ğŸ”§ {service_name} æ‰§è¡Œå‡ºé”™ã€‚å»ºè®®:\n"
                f"â€¢ æ£€æŸ¥å‚æ•°æ ¼å¼æ˜¯å¦æ­£ç¡®\n"
                f"â€¢ å°è¯•ç®€åŒ–æ“ä½œ\n"
                f"â€¢ ä½¿ç”¨æ›¿ä»£æ–¹æ³•æˆ–å·¥å…·"
            )
            return True, guidance
        
        return False, ""
    
    def _provide_smart_recovery_guidance(self, raw_result: Any, service_name: str, tool_name: str) -> str:
        """ğŸ§  ä¸ºå·¥å…·æ‰§è¡Œç»“æœæä¾›æ™ºèƒ½æ¢å¤æŒ‡å¯¼"""
        has_issue, guidance = self._detect_tool_result_issues(raw_result, service_name, tool_name)
        
        if has_issue:
            return f"{guidance}\n\nğŸ’¡ ä½ å¯ä»¥åœ¨ä¸‹ä¸€æ­¥å°è¯•å»ºè®®çš„æ–¹æ³•ï¼Œæˆ–ç»§ç»­ä½¿ç”¨ç°æœ‰ä¿¡æ¯ã€‚"
        
        return ""
    
    def _generate_llm_failure_response(self, error: Exception, task) -> str:
        """
        ğŸ”§ ç”ŸæˆLLMè°ƒç”¨å¤±è´¥æ—¶çš„é”™è¯¯å“åº”
        ç¡®ä¿å³ä½¿APIå¤±è´¥ä¹Ÿèƒ½ç”Ÿæˆæœ‰æ„ä¹‰çš„å›å¤
        """
        error_type = type(error).__name__
        error_message = str(error)
        
        # åŸºäºé”™è¯¯ç±»å‹ç”Ÿæˆä¸åŒçš„å“åº”
        if "RemoteProtocolError" in error_type:
            response = f"""<think>
Gemini APIè¿æ¥åè®®é”™è¯¯ï¼š{error_message}
è¿™é€šå¸¸æ˜¯ç”±äºç½‘ç»œä¸ç¨³å®šæˆ–æœåŠ¡å™¨è´Ÿè½½è¿‡é«˜å¯¼è‡´çš„ã€‚
è™½ç„¶æ— æ³•å®ŒæˆLLMæ¨ç†ï¼Œä½†æˆ‘å·²ç»è®°å½•äº†è¿™ä¸ªé”™è¯¯ã€‚
</think>

<answer>
æŠ±æ­‰ï¼Œç”±äºGemini APIè¿æ¥åè®®é”™è¯¯ï¼Œæ— æ³•å®Œæˆæ­¤æ¬¡ä»»åŠ¡æ¨ç†ã€‚

é”™è¯¯è¯¦æƒ…ï¼š{error_type} - {error_message}

å»ºè®®ï¼š
1. æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦ç¨³å®š
2. ç¨åé‡è¯•ä»»åŠ¡
3. å¦‚æœé—®é¢˜æŒç»­ï¼Œå¯èƒ½éœ€è¦æ£€æŸ¥APIæœåŠ¡çŠ¶æ€

ä»»åŠ¡ID: {task.task_id}
</answer>"""
        elif "TimeoutError" in error_type or "timeout" in error_message.lower():
            response = f"""<think>
LLM APIè°ƒç”¨è¶…æ—¶ï¼š{error_message}
è¿™å¯èƒ½æ˜¯ç”±äºç½‘ç»œå»¶è¿Ÿæˆ–æœåŠ¡å™¨å“åº”ç¼“æ…¢å¯¼è‡´çš„ã€‚
</think>

<answer>
æŠ±æ­‰ï¼ŒLLM APIè°ƒç”¨è¶…æ—¶ï¼Œæ— æ³•å®Œæˆæ­¤æ¬¡æ¨ç†ä»»åŠ¡ã€‚

é”™è¯¯è¯¦æƒ…ï¼š{error_type} - {error_message}

å»ºè®®ï¼š
1. æ£€æŸ¥ç½‘ç»œè¿æ¥é€Ÿåº¦
2. ç¨åé‡è¯•ä»»åŠ¡
3. è€ƒè™‘ç®€åŒ–ä»»åŠ¡å¤æ‚åº¦

ä»»åŠ¡ID: {task.task_id}
</answer>"""
        elif "HTTPStatusError" in error_type:
            response = f"""<think>
LLM API HTTPçŠ¶æ€é”™è¯¯ï¼š{error_message}
è¿™å¯èƒ½æ˜¯APIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨æˆ–è¾¾åˆ°äº†ä½¿ç”¨é™åˆ¶ã€‚
</think>

<answer>
æŠ±æ­‰ï¼ŒLLM APIæœåŠ¡è¿”å›é”™è¯¯çŠ¶æ€ï¼Œæ— æ³•å®Œæˆæ­¤æ¬¡ä»»åŠ¡ã€‚

é”™è¯¯è¯¦æƒ…ï¼š{error_type} - {error_message}

å»ºè®®ï¼š
1. æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ
2. éªŒè¯APIæœåŠ¡çŠ¶æ€
3. ç¨åé‡è¯•ä»»åŠ¡

ä»»åŠ¡ID: {task.task_id}
</answer>"""
        else:
            response = f"""<think>
LLM APIè°ƒç”¨é‡åˆ°æœªçŸ¥é”™è¯¯ï¼š{error_message}
è¿™æ˜¯ä¸€ä¸ªæ„å¤–çš„é”™è¯¯æƒ…å†µï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒæŸ¥ã€‚
</think>

<answer>
æŠ±æ­‰ï¼ŒLLM APIè°ƒç”¨é‡åˆ°æœªçŸ¥é”™è¯¯ï¼Œæ— æ³•å®Œæˆæ­¤æ¬¡æ¨ç†ä»»åŠ¡ã€‚

é”™è¯¯è¯¦æƒ…ï¼š{error_type} - {error_message}

å»ºè®®ï¼š
1. æ£€æŸ¥ç³»ç»Ÿæ—¥å¿—è·å–æ›´å¤šä¿¡æ¯
2. éªŒè¯ç³»ç»Ÿé…ç½®
3. å¦‚æœé—®é¢˜æŒç»­ï¼Œè¯·è”ç³»æŠ€æœ¯æ”¯æŒ

ä»»åŠ¡ID: {task.task_id}
</answer>"""
        
        return response

    async def cleanup(self):
        """æ¸…ç†è¿è¡Œæ—¶èµ„æº"""
        logger.info("ğŸ§¹ æ¸…ç†Enhanced Reasoning Runtimeèµ„æº...")
        
        try:
            # MicroSandboxè¿æ¥ç®¡ç†å™¨å·²ç§»é™¤ - æ— éœ€æ¸…ç†
            
            # æ¸…ç†å…¶ä»–èµ„æº
            if hasattr(self, 'memory_manager') and self.memory_manager:
                # å‡è®¾MemoryManageræœ‰cleanupæ–¹æ³•
                if hasattr(self.memory_manager, 'cleanup'):
                    await self.memory_manager.cleanup()
                    
            logger.info("âœ… Enhanced Reasoning Runtimeæ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†Enhanced Reasoning Runtimeæ—¶å‡ºé”™: {e}")
    
    def get_connection_stats(self) -> Dict[str, Any]:
        """è·å–è¿æ¥ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        
        # MicroSandboxè¿æ¥ç®¡ç†å™¨å·²ç§»é™¤ - æ— ç»Ÿè®¡ä¿¡æ¯
        
        return stats
    
    def _extract_deepsearch_content_recursive(self, data: Any, max_depth: int = 3) -> str:
        """ğŸ”§ é€’å½’æå– deepsearch ç»“æœä¸­çš„å®è´¨æ€§å†…å®¹"""
        if max_depth <= 0:
            return ""
        
        if isinstance(data, dict):
            # ä¼˜å…ˆæŸ¥æ‰¾åŒ…å«å®è´¨æ€§å†…å®¹çš„å­—æ®µ
            priority_fields = ['answer', 'final_report', 'report', 'summary', 'content', 'result']
            for field in priority_fields:
                if field in data:
                    value = data[field]
                    if isinstance(value, str) and len(value.strip()) >= 50:
                        return value.strip()
                    elif isinstance(value, (dict, list)):
                        recursive_result = self._extract_deepsearch_content_recursive(value, max_depth - 1)
                        if recursive_result:
                            return recursive_result
            
            # å¦‚æœä¼˜å…ˆå­—æ®µæ²¡æœ‰å†…å®¹ï¼Œéå†æ‰€æœ‰å­—æ®µ
            for key, value in data.items():
                if isinstance(value, str) and len(value.strip()) >= 100:
                    return value.strip()
                elif isinstance(value, (dict, list)):
                    recursive_result = self._extract_deepsearch_content_recursive(value, max_depth - 1)
                    if recursive_result:
                        return recursive_result
        
        elif isinstance(data, list):
            for item in data:
                recursive_result = self._extract_deepsearch_content_recursive(item, max_depth - 1)
                if recursive_result:
                    return recursive_result
        
        elif isinstance(data, str) and len(data.strip()) >= 50:
            return data.strip()
        
        return ""
    
    def _is_meaningful_research_content(self, content: str) -> bool:
        """ğŸ”§ æ£€æµ‹å†…å®¹æ˜¯å¦ä¸ºæœ‰æ„ä¹‰çš„ç ”ç©¶æŠ¥å‘Š"""
        if not content or len(content.strip()) < 30:
            return False
        
        content_lower = content.lower()
        
        # æ£€æŸ¥ç ”ç©¶ç›¸å…³å…³é”®è¯
        research_indicators = [
            # ä¸­æ–‡ç ”ç©¶æŒ‡æ ‡
            'ç ”ç©¶', 'åˆ†æ', 'åº”ç”¨', 'æŠ€æœ¯', 'æ–¹æ³•', 'å‘å±•', 'è¶‹åŠ¿', 'æŒ‘æˆ˜', 'æœºé‡', 
            'ç®—æ³•', 'æ¨¡å‹', 'ç³»ç»Ÿ', 'æ¡†æ¶', 'å®éªŒ', 'ç»“æœ', 'ç»“è®º', 'æ€»ç»“',
            'é‡å­', 'æœºå™¨å­¦ä¹ ', 'äººå·¥æ™ºèƒ½', 'æ·±åº¦å­¦ä¹ ', 'ç¥ç»ç½‘ç»œ',
            # è‹±æ–‡ç ”ç©¶æŒ‡æ ‡
            'research', 'analysis', 'application', 'technology', 'method', 'development',
            'trend', 'challenge', 'opportunity', 'algorithm', 'model', 'system', 
            'framework', 'experiment', 'result', 'conclusion', 'summary',
            'quantum', 'machine learning', 'artificial intelligence', 'deep learning',
            'neural network', 'computing', 'optimization'
        ]
        
        # è®¡ç®—ç ”ç©¶ç›¸å…³è¯æ±‡çš„å‡ºç°æ¬¡æ•°
        research_score = sum(1 for indicator in research_indicators if indicator in content_lower)
        
        # æ£€æŸ¥ç»“æ„åŒ–å†…å®¹æŒ‡æ ‡
        structure_indicators = [
            '1.', '2.', '3.', 'ä¸€ã€', 'äºŒã€', 'ä¸‰ã€', 'é¦–å…ˆ', 'å…¶æ¬¡', 'æœ€å',
            'introduction', 'background', 'methodology', 'approach', 'conclusion',
            'èƒŒæ™¯', 'æ–¹æ³•', 'ç»“è®º', 'æ€»ç»“'
        ]
        has_structure = any(indicator in content_lower for indicator in structure_indicators)
        
        # æ£€æŸ¥æŠ€æœ¯æ·±åº¦æŒ‡æ ‡
        technical_indicators = [
            'algorithm', 'implementation', 'performance', 'accuracy', 'efficiency',
            'optimization', 'parameter', 'dataset', 'training', 'testing',
            'ç®—æ³•', 'å®ç°', 'æ€§èƒ½', 'å‡†ç¡®ç‡', 'æ•ˆç‡', 'ä¼˜åŒ–', 'å‚æ•°', 'æ•°æ®é›†', 'è®­ç»ƒ', 'æµ‹è¯•'
        ]
        technical_score = sum(1 for indicator in technical_indicators if indicator in content_lower)
        
        # ç»¼åˆè¯„åˆ†åˆ¤æ–­
        is_meaningful = (
            research_score >= 3 or  # è‡³å°‘3ä¸ªç ”ç©¶ç›¸å…³è¯æ±‡
            (research_score >= 2 and has_structure) or  # 2ä¸ªç ”ç©¶è¯æ±‡+ç»“æ„åŒ–
            (research_score >= 2 and technical_score >= 2) or  # ç ”ç©¶è¯æ±‡+æŠ€æœ¯è¯æ±‡
            (len(content) >= 200 and research_score >= 1)  # é•¿å†…å®¹+åŸºæœ¬ç ”ç©¶è¯æ±‡
        )
        
        logger.debug(f"å†…å®¹è´¨é‡è¯„ä¼°: é•¿åº¦={len(content)}, ç ”ç©¶åˆ†æ•°={research_score}, "
                    f"æŠ€æœ¯åˆ†æ•°={technical_score}, æœ‰ç»“æ„={has_structure}, æœ‰æ„ä¹‰={is_meaningful}")
        
        return is_meaningful

    def _parse_tool_input_parameters(self, tool_input: str, service_name: str, tool_name: str, default_param_name: str) -> dict:
        """
        ä½¿ç”¨å·²æœ‰çš„JSONParameterParserè§£æå·¥å…·è¾“å…¥å‚æ•°
        
        Args:
            tool_input: ä»XMLè§£æå¾—åˆ°çš„åŸå§‹è¾“å…¥ï¼ˆå¯èƒ½åŒ…å«JSON+XMLæ··åˆå†…å®¹ï¼‰
            service_name: æœåŠ¡åç§°ï¼ˆå¦‚ 'browser_use'ï¼‰
            tool_name: å·¥å…·åç§°ï¼ˆå¦‚ 'browser_search_google'ï¼‰
            default_param_name: é»˜è®¤å‚æ•°åç§°
            
        Returns:
            dict: è§£æåçš„å‚æ•°å­—å…¸
        """
        try:
            # ä½¿ç”¨å·²æœ‰çš„JSONParameterParser
            parse_result = self.json_parameter_parser.parse_tool_parameters(
                tool_id=service_name,
                action=tool_name,
                raw_input=tool_input
            )
            
            if parse_result.is_valid:
                logger.debug(f"âœ… JSONå‚æ•°è§£ææˆåŠŸ: {parse_result.parsed_params}")
                return parse_result.parsed_params
            else:
                logger.warning(f"âš ï¸ JSONå‚æ•°è§£æå¤±è´¥: {parse_result.errors}")
                
                # ğŸ”§ ä¿®å¤ï¼šå°†å‚æ•°éªŒè¯é”™è¯¯æ³¨å…¥ç»“æœæµï¼Œè®©æ¨¡å‹çœ‹åˆ°é”™è¯¯ä¿¡æ¯
                error_message = f"Parameter validation failed for {service_name}.{tool_name}: {parse_result.errors}"
                
                # å°†é”™è¯¯ä¿¡æ¯ä½œä¸ºç‰¹æ®Šå‚æ•°è¿”å›ï¼Œè¿™æ ·å·¥å…·æ‰§è¡Œä¼šåŒ…å«é”™è¯¯åé¦ˆ
                return {
                    "_validation_error": error_message,
                    default_param_name: tool_input
                }
                
        except Exception as e:
            logger.error(f"âŒ JSONå‚æ•°è§£æå¼‚å¸¸: {e}")
            # å‡ºé”™æ—¶å›é€€åˆ°ç®€å•å‚æ•°æ˜ å°„
            return {default_param_name: tool_input}

    async def _handle_tool_param_query(self, xml_string: str) -> str:
        """
        å¤„ç† <tool_param> æŸ¥è¯¢ï¼Œè¿”å›å·¥å…·çš„å‚æ•°å®šä¹‰ã€‚
        """
        try:
            tool_id_match = re.search(r"<tool_id>(.*?)</tool_id>", xml_string)
            action_match = re.search(r"<action>(.*?)</action>", xml_string)

            if not tool_id_match or not action_match:
                error_msg = "Invalid <tool_param> format. Missing <tool_id> or <action> tag."
                logger.warning(error_msg)
                return self._format_result(f"Error: {error_msg}")

            tool_id = tool_id_match.group(1).strip()
            action = action_match.group(1).strip()

            logger.info(f"ğŸ” Handling <tool_param> query for {tool_id}/{action}")

            # è·å–å‚æ•°å®šä¹‰
            param_definitions = self.tool_manager.get_action_parameters(tool_id, action)

            response_data = {
                "status": "success",
                "tool_id": tool_id,
                "action": action,
                "parameters": param_definitions
            }

            # æ ¼å¼åŒ–ä¸ºJSONå­—ç¬¦ä¸²ä»¥ä¾¿åœ¨<result>ä¸­è¿”å›
            response_json = json.dumps(response_data, ensure_ascii=False, indent=2)
            return self._format_result(response_json)

        except ValueError as e:
            logger.error(f"Error handling <tool_param> query: {e}")
            return self._format_result(f"Error: {str(e)}")
        except Exception as e:
            logger.error(f"An unexpected error occurred in _handle_tool_param_query: {e}", exc_info=True)
            return self._format_result("An internal error occurred while fetching tool parameters.")
    
    def _auto_inject_execute_tools(self, response_text: str) -> str:
        """
        ğŸ”§ è‡ªåŠ¨æ³¨å…¥ç¼ºå¤±çš„<execute_tools />æ ‡ç­¾
        
        æ£€æµ‹å·¥å…·è°ƒç”¨ä½†ç¼ºå°‘<execute_tools />çš„æƒ…å†µï¼Œè‡ªåŠ¨æ·»åŠ è¯¥æ ‡ç­¾ä»¥ç¡®ä¿å·¥å…·èƒ½å¤Ÿæ‰§è¡Œã€‚
        
        Args:
            response_text: LLMçš„åŸå§‹å“åº”
            
        Returns:
            å¯èƒ½æ·»åŠ äº†<execute_tools />çš„å“åº”æ–‡æœ¬
        """
        import re
        
        # å¦‚æœå·²ç»æœ‰<execute_tools />ï¼Œä¸éœ€è¦å¤„ç†
        if '<execute_tools />' in response_text or '<execute_tools></execute_tools>' in response_text:
            return response_text
        
        # æ£€æµ‹å·¥å…·è°ƒç”¨æ¨¡å¼ï¼š<service_name><tool_name>...</tool_name></service_name>
        tool_call_patterns = [
            r'<(microsandbox|deepsearch|browser_use|search_tool|memory_staging)>\s*<[^>]+>.*?</[^>]+>\s*</(microsandbox|deepsearch|browser_use|search_tool|memory_staging)>',
            r'<browser>\s*<[^>]+>.*?</[^>]+>\s*</browser>'  # å…¼å®¹browseråˆ«å
        ]
        
        has_tool_calls = False
        for pattern in tool_call_patterns:
            if re.search(pattern, response_text, re.DOTALL | re.IGNORECASE):
                has_tool_calls = True
                break
        
        # å¦‚æœæ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ä½†æ²¡æœ‰execute_toolsæ ‡ç­¾ï¼Œè‡ªåŠ¨æ·»åŠ 
        if has_tool_calls:
            # æ‰¾åˆ°æœ€åä¸€ä¸ªå·¥å…·è°ƒç”¨çš„ç»“æŸä½ç½®
            last_tool_end = -1
            for pattern in tool_call_patterns:
                matches = list(re.finditer(pattern, response_text, re.DOTALL | re.IGNORECASE))
                if matches:
                    last_match_end = matches[-1].end()
                    if last_match_end > last_tool_end:
                        last_tool_end = last_match_end
            
            if last_tool_end > -1:
                # åœ¨æœ€åä¸€ä¸ªå·¥å…·è°ƒç”¨åæ·»åŠ <execute_tools />
                before = response_text[:last_tool_end]
                after = response_text[last_tool_end:]
                
                # ç¡®ä¿æœ‰é€‚å½“çš„æ¢è¡Œ
                if not before.endswith('\n'):
                    before += '\n'
                
                injected_response = before + '<execute_tools />' + after
                
                logger.info("ğŸ”§ è‡ªåŠ¨æ³¨å…¥<execute_tools />æ ‡ç­¾ä»¥ç¡®ä¿å·¥å…·æ‰§è¡Œ")
                logger.debug(f"æ³¨å…¥ä½ç½®: å­—ç¬¦ä½ç½® {last_tool_end}")
                
                return injected_response
        
        # æ²¡æœ‰æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨æˆ–å·²æœ‰execute_toolsæ ‡ç­¾ï¼Œè¿”å›åŸæ–‡
        return response_text
    
    def _format_parameter_validation_error(self, service_name: str, tool_name: str, validation_error: str, original_input: str) -> str:
        """
        ğŸ”§ æ ¼å¼åŒ–å‚æ•°éªŒè¯é”™è¯¯ï¼Œè®©æ¨¡å‹èƒ½å¤Ÿç†è§£å¹¶ä¿®æ­£å‚æ•°
        
        Args:
            service_name: æœåŠ¡åç§°
            tool_name: å·¥å…·åç§°
            validation_error: éªŒè¯é”™è¯¯ä¿¡æ¯
            original_input: åŸå§‹è¾“å…¥å‚æ•°
            
        Returns:
            æ ¼å¼åŒ–åçš„é”™è¯¯ä¿¡æ¯
        """
        error_message = f"""
Parameter Validation Failed 

Tool Call: {service_name}.{tool_name}
Error Details: {validation_error}

Your Input: {original_input}

Correction Suggestions: Use <tool_param><tool_id>{service_name}</tool_id><action>{tool_name}</action></tool_param> to get the correct parameters

Please retry the tool call with correct parameters based on the error information above.
"""
        return error_message.strip()

    def _format_error_with_recovery_suggestion(self, error_message: str, error_type: str, service_name: str, tool_name: str) -> str:
        """ğŸ”§ å¢å¼ºçš„é”™è¯¯æ ¼å¼åŒ–å’Œæ¢å¤å»ºè®® - é’ˆå¯¹å…·ä½“é”™è¯¯ç±»å‹æä¾›è¯¦ç»†æŒ‡å¯¼"""
        base_error = f"Tool execution failed: {error_message}"
        
        recovery_suggestions = {
            "parameter_error": f"ğŸ’¡ å»ºè®®: æ£€æŸ¥ {service_name} çš„ {tool_name} å·¥å…·å‚æ•°æ ¼å¼ã€‚å‚è€ƒå·¥å…·å®šä¹‰ä¸­çš„æ­£ç¡®å‚æ•°åç§°ã€‚",
            "tool_not_found": f"ğŸ’¡ å»ºè®®: å·¥å…· {tool_name} åœ¨ {service_name} ä¸­ä¸å­˜åœ¨ã€‚æ£€æŸ¥å·¥å…·åç§°æ˜¯å¦æ­£ç¡®ï¼Œæˆ–å°è¯•ä½¿ç”¨å…¶ä»–å·¥å…·ã€‚",
            "network_error": f"ğŸ’¡ å»ºè®®: ç½‘ç»œè¿æ¥é—®é¢˜ã€‚ç­‰å¾…å‡ ç§’åé‡è¯•ï¼Œæˆ–å°è¯•ä½¿ç”¨æ›¿ä»£å·¥å…·ã€‚",
            "validation_error": f"ğŸ’¡ å»ºè®®: è¾“å…¥æ•°æ®éªŒè¯å¤±è´¥ã€‚æ£€æŸ¥è¾“å…¥æ ¼å¼å’Œå†…å®¹æ˜¯å¦ç¬¦åˆè¦æ±‚ã€‚",
            "permission_error": f"ğŸ’¡ å»ºè®®: æƒé™ä¸è¶³ã€‚æ£€æŸ¥æœåŠ¡é…ç½®æˆ–å°è¯•å…¶ä»–æ–¹æ³•ã€‚",
            "empty_results": f"ğŸ” å»ºè®®: æœç´¢æœªæ‰¾åˆ°ç»“æœã€‚å°è¯•:\n  â€¢ ä½¿ç”¨ä¸åŒçš„å…³é”®è¯æˆ–æ›´ç®€å•çš„æŸ¥è¯¢\n  â€¢ åˆ‡æ¢åˆ°å…¶ä»–æœç´¢å·¥å…· (å¦‚ deepsearch â†’ browser_use)\n  â€¢ æ£€æŸ¥æ•°æ®æ˜¯å¦å·²ä¿å­˜åœ¨å†…å­˜æš‚å­˜åŒº: <memory_staging><memory_list></memory_list></memory_staging>",
            "data_not_available": f"ğŸ“Š å»ºè®®: æ•°æ®ä¸å¯ç”¨ã€‚å°è¯•:\n  â€¢ ä½¿ç”¨æ›´å¹¿æ³›çš„æœç´¢è¯\n  â€¢ æ£€æŸ¥å†…å­˜æš‚å­˜åŒºæ˜¯å¦æœ‰ç›¸å…³æ•°æ®: <memory_staging><memory_search>å…³é”®è¯</memory_search></memory_staging>\n  â€¢ è€ƒè™‘ä½¿ç”¨ç¤ºä¾‹æ•°æ®ï¼ˆæ˜ç¡®æ ‡è®°ä¸ºæ¨¡æ‹Ÿæ•°æ®ï¼‰",
            "timeout_error": f"â±ï¸ å»ºè®®: å·¥å…·æ‰§è¡Œè¶…æ—¶ã€‚å°è¯•:\n  â€¢ ç®€åŒ–æŸ¥è¯¢æˆ–æ“ä½œ\n  â€¢ åˆ†æ­¥éª¤æ‰§è¡Œå¤æ‚ä»»åŠ¡\n  â€¢ ç¨åé‡è¯•",
            "service_unavailable": f"ğŸš« å»ºè®®: æœåŠ¡ä¸å¯ç”¨ã€‚å°è¯•:\n  â€¢ ä½¿ç”¨æ›¿ä»£å·¥å…·è¾¾åˆ°ç›¸åŒç›®æ ‡\n  â€¢ ç¨åé‡è¯•\n  â€¢ ä½¿ç”¨ç¼“å­˜æˆ–å†…å­˜ä¸­çš„æ•°æ®",
            "unknown_error": f"ğŸ’¡ å»ºè®®: æœªçŸ¥é”™è¯¯ã€‚å°è¯•ç®€åŒ–è¾“å…¥æˆ–ä½¿ç”¨å…¶ä»–å·¥å…·æ›¿ä»£ã€‚"
        }
        
        suggestion = recovery_suggestions.get(error_type, recovery_suggestions["unknown_error"])
        return f"{base_error}\n{suggestion}"

