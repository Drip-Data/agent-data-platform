"""
å¢å¼ºçš„æ¨ç†è¿è¡Œæ—¶ - ç®€åŒ–ç‰ˆæœ¬
ä¸“æ³¨äºæ ¸å¿ƒåŠŸèƒ½ï¼šLLMæ¨ç†ã€å·¥å…·æ‰§è¡Œã€ä»»åŠ¡å¤„ç†ã€XMLæµå¼è¾“å‡º
"""

import json
import logging
import os
import time
import uuid
from datetime import datetime
from typing import List, Optional
from enum import Enum

from core.interfaces import RuntimeInterface, TaskSpec, TrajectoryResult, TaskExecutionConstants, ErrorMessageConstants
from core.llm.prompt_builders.reasoning_prompt_builder import ReasoningPromptBuilder
from core.utils.path_utils import get_trajectories_dir
from core.streaming.sequential_executor import SequentialStreamingExecutor
from core.memory_manager import MemoryManager
from core.trajectory_enhancer import TrajectoryEnhancer
from core.step_logger import StepDiagnosticLogger


logger = logging.getLogger(__name__)


class TrajectoryStorageMode(Enum):
    """è½¨è¿¹å­˜å‚¨æ¨¡å¼"""
    INDIVIDUAL_FILES = "individual"
    DAILY_GROUPED = "daily_grouped"
    WEEKLY_GROUPED = "weekly_grouped"
    MONTHLY_GROUPED = "monthly_grouped"


from core.unified_tool_manager import UnifiedToolManager

from core.unified_tool_manager import UnifiedToolManager

class EnhancedReasoningRuntime(RuntimeInterface):
    """
    å¢å¼ºçš„æ¨ç†è¿è¡Œæ—¶ - ä¸“æ³¨æ ¸å¿ƒåŠŸèƒ½, å¹¶é›†æˆé«˜çº§æ¨¡å—
    """
    
    def __init__(self, config_manager, llm_client, toolscore_client, tool_manager: UnifiedToolManager, redis_manager=None, 
                 toolscore_websocket_endpoint=None, xml_streaming_mode: bool = False, 
                 trajectory_storage_mode: str = "daily_grouped"):
        self._runtime_id = f"enhanced-reasoning-{uuid.uuid4()}"
        self.config_manager = config_manager
        self.client = llm_client
        self.toolscore_client = toolscore_client
        self.tool_manager = tool_manager
        self.xml_streaming_mode = xml_streaming_mode
        self.trajectory_storage_mode = TrajectoryStorageMode(trajectory_storage_mode)
        self.prompt_builder = ReasoningPromptBuilder(tool_manager=self.tool_manager, streaming_mode=xml_streaming_mode)
        self.is_initialized = False

        # åˆå§‹åŒ–é«˜çº§æ¨¡å—
        self.memory_manager = MemoryManager(redis_manager=redis_manager)
        self.trajectory_enhancer = TrajectoryEnhancer()
        self.sequential_executor = SequentialStreamingExecutor(
            llm_client=self.client, 
            tool_executor=self.toolscore_client,
            memory_manager=self.memory_manager
        )
        self.step_logger = StepDiagnosticLogger()
        self.mcp_servers = self._load_mcp_config("config/mcp_servers.json")
    
    def _load_mcp_config(self, config_path: str) -> dict:
        """ä»JSONæ–‡ä»¶åŠ è½½å¹¶æ ¼å¼åŒ–MCPæœåŠ¡å™¨é…ç½®ã€‚"""
        config = {}
        try:
            with open(config_path, 'r') as f:
                mcp_config = json.load(f)
                for service_name, details in mcp_config.items():
                    # æ ‡å‡†åŒ–æœåŠ¡åç§°ï¼šå»æ‰ "_server" åç¼€ï¼Œä¸ä»£ç æœŸæœ›ä¸€è‡´
                    clean_name = service_name.replace("_server", "")
                    config[clean_name] = f"http://127.0.0.1:{details['port']}"
            logger.info(f"Loaded and formatted MCP server configs: {config}")
            return config
        except FileNotFoundError:
            logger.error(f"Error: MCP config file not found at {config_path}")
            return {}
        except json.JSONDecodeError:
            logger.error(f"Error: Could not decode JSON from {config_path}")
            return {}

    def _parse_execution_block(self, xml_string: str) -> dict:
        """
        ä»LLMç”Ÿæˆçš„XMLæ–‡æœ¬ä¸­è§£æå‡ºæ‰§è¡Œå—ã€‚
        è¿”å›ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«ç±»å‹ï¼ˆsingle, parallel, sequentialï¼‰å’ŒåŠ¨ä½œåˆ—è¡¨ã€‚
        """
        from xml.etree import ElementTree as ET

        actions = []
        block_type = "single" # é»˜è®¤
        try:
            # æ¸…ç†å¹¶åŒ…è£¹XMLï¼Œä»¥ä¾¿å®‰å…¨è§£æ
            clean_xml = f"<root>{xml_string.strip()}</root>"
            root = ET.fromstring(clean_xml)

            # æ£€æŸ¥å¹¶è¡Œæˆ–ä¸²è¡Œå—
            parallel_block = root.find('parallel')
            sequential_block = root.find('sequential')

            if parallel_block is not None:
                block_type = "parallel"
                service_nodes = list(parallel_block)
            elif sequential_block is not None:
                block_type = "sequential"
                service_nodes = list(sequential_block)
            else:
                # å•ä¸ªä»»åŠ¡
                service_nodes = [elem for elem in root if elem.tag not in ['think', 'answer', 'execute_tools']]

            for service_node in service_nodes:
                service_name = service_node.tag
                if len(service_node) > 0:
                    tool_node = service_node[0]
                    tool_name = tool_node.tag
                    tool_input = tool_node.text or ""
                    actions.append({
                        "service": service_name,
                        "tool": tool_name,
                        "input": tool_input.strip()
                    })
        except ET.ParseError as e:
            logger.error(f"XML Parse Error: {e}\nOriginal XML:\n{xml_string}")
        
        return {"type": block_type, "actions": actions}

    async def _execute_tool(self, action: dict) -> str:
        """
        æ ¹æ®å•ä¸ªåŠ¨ä½œå­—å…¸ï¼Œé€šè¿‡toolscore_clientè°ƒç”¨å¯¹åº”çš„MCP Serverå¹¶è¿”å›ç»“æœã€‚
        ğŸ”§ å®Œæ•´ä¿®å¤ï¼šç»Ÿä¸€æ‰€æœ‰å·¥å…·çš„ç»“æœæ ¼å¼åŒ–ï¼Œä½¿ç»“æœæ¸…æ™°æ˜“è¯»
        """
        service_name = action.get('service')
        tool_name = action.get('tool')
        tool_input = action.get('input')

        if not all([service_name, tool_name]):
            return "Error: Invalid action format. 'service' and 'tool' are required."

        # æ˜ å°„æœåŠ¡åˆ°å…¶æœŸæœ›çš„ä¸»è¦å‚æ•°å
        param_mapping = {
            "browser_use": "query",
            "microsandbox": "code",
            "deepsearch": "question"
        }
        # é»˜è®¤å‚æ•°åä¸º 'input'
        param_name = param_mapping.get(service_name, "input")
        parameters = {param_name: tool_input}

        logger.info(f"Executing via toolscore_client: service='{service_name}', tool='{tool_name}', params='{param_name}'")

        try:
            result = await self.toolscore_client.execute_tool(
                tool_id=service_name,
                action=tool_name,
                parameters=parameters
            )
            
            if isinstance(result, dict):
                if result.get('success', True):
                    output = result.get('data', result.get('output', result.get('result', str(result))))
                    
                    # ğŸ”§ å®Œæ•´ä¿®å¤ï¼šä¸ºæ‰€æœ‰å·¥å…·ç»Ÿä¸€ç»“æœæ ¼å¼åŒ–
                    formatted_output = self._format_tool_output(service_name, tool_name, output)
                    return formatted_output
                else:
                    error_msg = result.get('error_message', result.get('error', 'Unknown error'))
                    return f"Tool execution failed: {error_msg}"
            else:
                return str(result)

        except Exception as e:
            logger.error(f"An unexpected error occurred while calling tool '{service_name}/{tool_name}': {e}", exc_info=True)
            return f"An unexpected error occurred while calling {service_name}: {e}"
    
    def _format_tool_output(self, service_name: str, tool_name: str, output) -> str:
        """
        ğŸ”§ å®Œæ•´ä¿®å¤ï¼šç»Ÿä¸€æ ¼å¼åŒ–æ‰€æœ‰å·¥å…·çš„è¾“å‡ºç»“æœï¼Œä½¿å…¶æ¸…æ™°æ˜“è¯»
        
        Args:
            service_name: æœåŠ¡åç§° (microsandbox, deepsearch, browser_useç­‰)
            tool_name: å·¥å…·åç§°
            output: åŸå§‹è¾“å‡ºç»“æœ
            
        Returns:
            str: æ ¼å¼åŒ–åçš„æ¸…æ™°ç»“æœ
        """
        # 1. MicroSandbox - æ™ºèƒ½æå–æ ¸å¿ƒæ‰§è¡Œç»“æœ
        if service_name == 'microsandbox':
            return self._format_microsandbox_output(output)
        
        # 2. DeepSearch - æ ¼å¼åŒ–æœç´¢ç»“æœ
        elif service_name == 'deepsearch':
            if isinstance(output, dict):
                return self._format_deepsearch_output(output)
            elif isinstance(output, list):
                return self._format_deepsearch_list_output(output)
            return str(output)
        
        # 3. Browser Use - æ ¼å¼åŒ–æµè§ˆå™¨æ“ä½œç»“æœ
        elif service_name == 'browser_use':
            if isinstance(output, dict):
                return self._format_browser_use_output(output)
            return str(output)
        
        # 4. Search Tool - æ ¼å¼åŒ–æœç´¢ç»“æœ
        elif service_name == 'search_tool':
            if isinstance(output, dict):
                return self._format_search_tool_output(output)
            return str(output)
        
        # 5. å…¶ä»–å·¥å…· - é€šç”¨æ ¼å¼åŒ–
        else:
            return self._format_generic_output(output)
    
    def _format_deepsearch_output(self, output: dict) -> str:
        """ğŸ”§ æ ¼å¼åŒ–DeepSearchæœç´¢ç»“æœ - ä½¿ç”¨å¸¸é‡é¿å…ç¡¬ç¼–ç """
        try:
            # æå–å…³é”®ä¿¡æ¯
            search_results = output.get('search_results', [])
            query = output.get('query', '')
            summary = output.get('summary', '')
            
            formatted_lines = []
            
            # æ·»åŠ æŸ¥è¯¢ä¿¡æ¯
            if query:
                formatted_lines.append(f"{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['SEARCH_QUERY']}: {query}")
            
            # æ·»åŠ æ‘˜è¦
            if summary:
                formatted_lines.append(f"{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['SEARCH_SUMMARY']}: {summary}")
            
            # æ ¼å¼åŒ–æœç´¢ç»“æœ
            if search_results:
                max_results = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_SEARCH_RESULTS']
                results_text = TaskExecutionConstants.TOOL_FORMAT_PREFIXES['SEARCH_RESULTS'].format(len(search_results))
                formatted_lines.append(results_text)
                
                for i, result in enumerate(search_results[:max_results], 1):
                    if isinstance(result, dict):
                        title = result.get('title', 'æ— æ ‡é¢˜')
                        snippet = result.get('snippet', result.get('content', ''))
                        url = result.get('url', '')
                        
                        formatted_lines.append(f"{i}. {title}")
                        if snippet:
                            # ä½¿ç”¨å¸¸é‡é™åˆ¶snippeté•¿åº¦
                            max_length = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_SNIPPET_LENGTH']
                            snippet_clean = snippet.strip()[:max_length]
                            formatted_lines.append(f"   {snippet_clean}...")
                        if url:
                            formatted_lines.append(f"   æ¥æº: {url}")
                        formatted_lines.append("")  # ç©ºè¡Œåˆ†éš”
            
            result_text = '\n'.join(formatted_lines).strip()
            return result_text if result_text else "æœç´¢å®Œæˆï¼Œä½†æœªæ‰¾åˆ°ç›¸å…³ç»“æœ"
            
        except Exception as e:
            logger.warning(f"Failed to format DeepSearch output: {e}")
            max_content = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_CONTENT_LENGTH']
            return f"DeepSearchæœç´¢å®Œæˆï¼ŒåŸå§‹ç»“æœ: {str(output)[:max_content]}..."
    
    def _format_deepsearch_list_output(self, output: list) -> str:
        """ğŸ”§ æ ¼å¼åŒ–DeepSearchåˆ—è¡¨ç»“æœ - ä½¿ç”¨å¸¸é‡é¿å…ç¡¬ç¼–ç """
        try:
            if not output:
                return "æœç´¢å®Œæˆï¼Œä½†æœªæ‰¾åˆ°ç›¸å…³ç»“æœ"
            
            results_text = TaskExecutionConstants.TOOL_FORMAT_PREFIXES['SEARCH_RESULTS'].format(len(output))
            formatted_lines = [results_text]
            
            max_results = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_SEARCH_RESULTS']
            for i, item in enumerate(output[:max_results], 1):
                if isinstance(item, dict):
                    title = item.get('title', f'ç»“æœ {i}')
                    content = item.get('content', item.get('snippet', ''))
                    
                    formatted_lines.append(f"{i}. {title}")
                    if content:
                        max_length = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_SNIPPET_LENGTH']
                        content_clean = str(content).strip()[:max_length]
                        formatted_lines.append(f"   {content_clean}...")
                    formatted_lines.append("")
                else:
                    formatted_lines.append(f"{i}. {str(item)[:100]}...")
            
            return '\n'.join(formatted_lines).strip()
            
        except Exception as e:
            logger.warning(f"Failed to format DeepSearch list output: {e}")
            return f"DeepSearchæœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(output)} ä¸ªç»“æœ"
    
    def _format_browser_use_output(self, output: dict) -> str:
        """ğŸ”§ å®Œæ•´ä¿®å¤ï¼šæ ¼å¼åŒ–Browser Useæ“ä½œç»“æœï¼Œç¡®ä¿æœç´¢ç»“æœä¸ä¸¢å¤±"""
        try:
            # æå–å…³é”®ä¿¡æ¯ - å¢å¼ºå­—æ®µæå–
            action = output.get('action', output.get('operation', TaskExecutionConstants.TOOL_FORMAT_PREFIXES['BROWSER_ACTION']))
            status = output.get('status', output.get('success', output.get('result', True)))
            content = output.get('content', output.get('data', output.get('text', '')))
            url = output.get('url', output.get('current_url', ''))
            error = output.get('error', output.get('error_message', ''))
            
            # ğŸ”§ æ–°å¢ï¼šä¸“é—¨å¤„ç†æœç´¢ç»“æœ
            search_results = output.get('search_results', output.get('results', []))
            query = output.get('query', output.get('search_query', ''))
            
            formatted_lines = []
            
            # çŠ¶æ€ä¿¡æ¯
            status_text = "æˆåŠŸ" if status else "å¤±è´¥"
            formatted_lines.append(f"{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['BROWSER_ACTION']}: {action} - {status_text}")
            
            # æœç´¢æŸ¥è¯¢ä¿¡æ¯
            if query:
                formatted_lines.append(f"æœç´¢æŸ¥è¯¢: {query}")
            
            # URLä¿¡æ¯
            if url:
                formatted_lines.append(f"{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['PAGE_URL']}: {url}")
            
            # é”™è¯¯ä¿¡æ¯
            if error:
                formatted_lines.append(f"{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['ERROR_INFO']}: {error}")
            
            # ğŸ”§ ä¼˜å…ˆå¤„ç†æœç´¢ç»“æœ
            if search_results and isinstance(search_results, list):
                max_results = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_SEARCH_RESULTS']
                formatted_lines.append(f"æœç´¢ç»“æœ({len(search_results)}ä¸ª):")
                
                for i, result in enumerate(search_results[:max_results], 1):
                    if isinstance(result, dict):
                        title = result.get('title', result.get('name', f'ç»“æœ{i}'))
                        snippet = result.get('snippet', result.get('description', result.get('content', '')))
                        result_url = result.get('url', result.get('link', ''))
                        
                        formatted_lines.append(f"{i}. {title}")
                        if snippet:
                            max_snippet = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_SNIPPET_LENGTH']
                            clean_snippet = str(snippet).strip()[:max_snippet]
                            formatted_lines.append(f"   {clean_snippet}...")
                        if result_url:
                            formatted_lines.append(f"   é“¾æ¥: {result_url}")
                        formatted_lines.append("")
                    else:
                        formatted_lines.append(f"{i}. {str(result)[:100]}...")
            
            # å¤„ç†æ™®é€šå†…å®¹ä¿¡æ¯
            elif content:
                max_content = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_CONTENT_LENGTH']
                # å¦‚æœå†…å®¹æ˜¯HTMLï¼Œå°è¯•æå–æ–‡æœ¬
                if isinstance(content, str) and ('<html>' in content.lower() or '<div>' in content.lower()):
                    # ç®€å•çš„HTMLæ–‡æœ¬æå–
                    import re
                    text_content = re.sub(r'<[^>]+>', '', content)
                    text_content = re.sub(r'\s+', ' ', text_content).strip()
                    if text_content:
                        formatted_lines.append(f"{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['PAGE_CONTENT']}: {text_content[:max_content]}...")
                else:
                    formatted_lines.append(f"{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['OPERATION_RESULT']}: {str(content)[:max_content]}...")
            
            # ğŸ”§ å¢å¼ºï¼šå¦‚æœæ²¡æœ‰æœ‰ç”¨å†…å®¹ï¼Œæä¾›æ›´è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
            result_text = '\n'.join(formatted_lines).strip()
            if not result_text or len(result_text) < 20:
                # å¦‚æœæ ¼å¼åŒ–ç»“æœå¤ªçŸ­ï¼Œè¯´æ˜å¯èƒ½æœ‰é—®é¢˜ï¼Œæä¾›åŸå§‹æ•°æ®çš„æ‘˜è¦
                logger.warning(f"Browser Use output seems incomplete. Raw keys: {list(output.keys())}")
                if output:
                    return f"æµè§ˆå™¨æ“ä½œæ‰§è¡Œï¼Œè¿”å›æ•°æ®å­—æ®µ: {', '.join(output.keys())}\nåŸå§‹æ•°æ®: {str(output)[:300]}..."
                else:
                    return "æµè§ˆå™¨æ“ä½œæ‰§è¡Œå®Œæˆï¼Œä½†æœªè¿”å›æ•°æ®"
            
            return result_text
            
        except Exception as e:
            logger.error(f"Failed to format Browser Use output: {e}")
            max_content = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_CONTENT_LENGTH']
            return f"æµè§ˆå™¨æ“ä½œå®Œæˆï¼ŒåŸå§‹ç»“æœ: {str(output)[:max_content]}..."
    
    def _format_search_tool_output(self, output: dict) -> str:
        """ğŸ”§ æ ¼å¼åŒ–Search Toolæœç´¢ç»“æœ - ä½¿ç”¨å¸¸é‡é¿å…ç¡¬ç¼–ç """
        try:
            # æå–æœç´¢ç»“æœ
            results = output.get('results', output.get('files', []))
            query = output.get('query', '')
            count = output.get('count', len(results) if isinstance(results, list) else 0)
            
            formatted_lines = []
            
            # æœç´¢ä¿¡æ¯
            if query:
                formatted_lines.append(f"{TaskExecutionConstants.TOOL_FORMAT_PREFIXES['FILE_SEARCH']}: {query}")
            
            file_results_text = TaskExecutionConstants.TOOL_FORMAT_PREFIXES['FILE_RESULTS'].format(count)
            formatted_lines.append(file_results_text)
            
            # æ ¼å¼åŒ–æ–‡ä»¶åˆ—è¡¨
            if isinstance(results, list):
                max_files = TaskExecutionConstants.TOOL_RESULT_LIMITS['MAX_FILE_RESULTS']
                for i, result in enumerate(results[:max_files], 1):
                    if isinstance(result, dict):
                        file_path = result.get('path', result.get('file', ''))
                        matches = result.get('matches', result.get('content', ''))
                        
                        formatted_lines.append(f"{i}. {file_path}")
                        if matches:
                            formatted_lines.append(f"   åŒ¹é…å†…å®¹: {str(matches)[:100]}...")
                    else:
                        formatted_lines.append(f"{i}. {str(result)}")
            
            return '\n'.join(formatted_lines).strip()
            
        except Exception as e:
            logger.warning(f"Failed to format Search Tool output: {e}")
            return f"æ–‡ä»¶æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {count} ä¸ªç»“æœ"
    
    def _format_microsandbox_output(self, output) -> str:
        """ğŸ”§ ä¸“ç”¨MicroSandboxç»“æœæ ¼å¼åŒ– - æå–æ ¸å¿ƒæ‰§è¡Œå†…å®¹"""
        try:
            if isinstance(output, dict):
                # ä¼˜å…ˆæå–stdoutï¼ˆä¸»è¦è¾“å‡ºï¼‰
                if 'stdout' in output:
                    stdout_content = str(output['stdout']).strip()
                    if stdout_content:
                        return stdout_content
                
                # å¦‚æœæ²¡æœ‰stdoutï¼Œæ£€æŸ¥åµŒå¥—ç»“æ„
                if 'result' in output and isinstance(output['result'], dict):
                    nested_result = output['result']
                    if 'stdout' in nested_result:
                        stdout_content = str(nested_result['stdout']).strip()
                        if stdout_content:
                            return stdout_content
                
                # æ£€æŸ¥stderré”™è¯¯ä¿¡æ¯
                stderr_content = ""
                if 'stderr' in output:
                    stderr_content = str(output['stderr']).strip()
                elif 'result' in output and isinstance(output['result'], dict) and 'stderr' in output['result']:
                    stderr_content = str(output['result']['stderr']).strip()
                
                if stderr_content:
                    return f"æ‰§è¡Œé”™è¯¯: {stderr_content}"
                
                # æ£€æŸ¥è¿”å›ä»£ç 
                return_code = output.get('return_code') or (output.get('result', {}).get('return_code') if isinstance(output.get('result'), dict) else None)
                if return_code == 0:
                    return "ä»£ç æ‰§è¡ŒæˆåŠŸï¼Œä½†æ— è¾“å‡ºå†…å®¹"
                elif return_code is not None:
                    return f"ä»£ç æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ä»£ç : {return_code}"
            
            # å…¶ä»–æƒ…å†µè¿”å›ç®€åŒ–çš„å­—ç¬¦ä¸²
            output_str = str(output).strip()
            if len(output_str) > 200:
                return f"æ‰§è¡Œå®Œæˆ: {output_str[:200]}..."
            return output_str if output_str else "ä»£ç æ‰§è¡Œå®Œæˆ"
            
        except Exception as e:
            logger.warning(f"Failed to format MicroSandbox output: {e}")
            return f"ä»£ç æ‰§è¡Œå®Œæˆ: {str(output)[:100]}..."
    
    def _format_generic_output(self, output) -> str:
        """é€šç”¨å·¥å…·è¾“å‡ºæ ¼å¼åŒ–"""
        try:
            if isinstance(output, dict):
                # å°è¯•æå–æœ‰ç”¨ä¿¡æ¯
                if 'result' in output:
                    return str(output['result'])
                elif 'content' in output:
                    return str(output['content'])
                elif 'data' in output:
                    return str(output['data'])
                elif 'message' in output:
                    return str(output['message'])
                else:
                    # è¿‡æ»¤æ‰æŠ€æœ¯æ€§å­—æ®µï¼Œåªä¿ç•™æœ‰æ„ä¹‰çš„å†…å®¹
                    meaningful_fields = {}
                    skip_fields = {'success', 'status', 'code', 'timestamp', 'metadata', 'headers'}
                    
                    for key, value in output.items():
                        if key not in skip_fields and value:
                            meaningful_fields[key] = value
                    
                    if meaningful_fields:
                        return str(meaningful_fields)
            
            return str(output)
            
        except Exception as e:
            logger.warning(f"Failed to format generic output: {e}")
            return str(output)

    async def _execute_parallel(self, actions: list) -> list:
        """å¹¶å‘æ‰§è¡Œå¤šä¸ªåŠ¨ä½œã€‚"""
        import asyncio
        if not actions:
            return []
        
        tasks = [self._execute_tool(action) for action in actions]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¯èƒ½å‘ç”Ÿçš„å¼‚å¸¸ï¼Œç¡®ä¿è¿”å›å­—ç¬¦ä¸²åˆ—è¡¨
        return [str(res) if not isinstance(res, Exception) else f"Error: {res}" for res in results]
    
    @property
    def runtime_id(self) -> str:
        return self._runtime_id
    
    async def capabilities(self) -> List[str]:
        """è·å–è¿è¡Œæ—¶èƒ½åŠ›"""
        return ['llm_reasoning', 'tool_execution', 'xml_streaming', 'memory', 'trajectory_enhancement', 'error_recovery']
    
    async def health_check(self) -> bool:
        """å¥åº·æ£€æŸ¥"""
        try:
            if hasattr(self.toolscore_client, 'health_check'):
                return await self.toolscore_client.health_check()
            return True
        except Exception:
            return False
    
    async def initialize(self):
        """åˆå§‹åŒ–è¿è¡Œæ—¶"""
        logger.info("ğŸš€ åˆå§‹åŒ–Enhanced Reasoning Runtime")
        if not self.client:
            raise RuntimeError("LLMå®¢æˆ·ç«¯æœªé…ç½®")
        if not self.toolscore_client:
            raise RuntimeError("å·¥å…·å®¢æˆ·ç«¯æœªé…ç½®")
        self.is_initialized = True
        logger.info("âœ… Enhanced Reasoning Runtime åˆå§‹åŒ–å®Œæˆ")
    
    async def execute(self, task: TaskSpec) -> TrajectoryResult:
        """æ‰§è¡Œä»»åŠ¡"""
        logger.info(f"ğŸ§  å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task.description}")
        if not self.is_initialized:
            await self.initialize()
        
        if self.xml_streaming_mode:
            return await self._execute_xml_streaming(task)
        else:
            # ä¿ç•™æ ‡å‡†æ¨¡å¼ä½œä¸ºå¤‡é€‰ï¼Œä½†ä¸»è¦æµç¨‹æ˜¯XMLæµ
            return await self._execute_standard(task)
    
    async def _execute_xml_streaming(self, task: TaskSpec) -> TrajectoryResult:
        """
        æ‰§è¡ŒåŸºäºXMLçš„ã€æ”¯æŒå•æ­¥ã€å¹¶è¡Œå’Œä¸²è¡Œå·¥å…·è°ƒç”¨çš„ä¸»æ§åˆ¶å¾ªç¯ã€‚
        """
        logger.info(f"ğŸ¯ Orchestrator starting task: {task.description}")
        start_time = time.time()
        
        # ğŸ” å¯åŠ¨æ­¥éª¤çº§æ—¥å¿—è®°å½•
        self.step_logger.start_task(task.task_id, task.description)
        
        # å‡†å¤‡å†å²è®°å½•
        available_tools = await self._get_available_tools()
        tool_descriptions = await self._get_tool_descriptions()
        history = self.prompt_builder.build_prompt(
            task_description=task.description,
            available_tools=available_tools,
            tool_descriptions=tool_descriptions,
            history=[]
        )
        
        full_trajectory = [] # è®°å½•å®Œæ•´çš„äº¤äº’è½¨è¿¹

        max_steps = task.max_steps or 20
        for step in range(max_steps):
            logger.info(f"--- Starting Step {step + 1}/{max_steps} ---")
            
            # ğŸ” å¼€å§‹æ­¥éª¤æ—¥å¿—è®°å½•
            self.step_logger.start_step(step)
            
            # 1. è°ƒç”¨LLMï¼Œè®¾ç½®åŠ¨æ€åœæ­¢åºåˆ—
            stop_sequences = ["<execute_tools />", "<execute_tools></execute_tools>", "</answer>"]
            llm_start_time = time.time()
            response_text = await self.client._call_api(history, stop_sequences=stop_sequences)
            llm_end_time = time.time()
            
            # ğŸ” è®°å½•LLMè°ƒç”¨
            triggered_stop = self._detect_triggered_stop_sequence(response_text, stop_sequences)
            self.step_logger.log_llm_call(
                prompt=history,
                raw_response=response_text,
                stop_sequence=triggered_stop,
                start_time=llm_start_time,
                end_time=llm_end_time
            )
            
            history.append({"role": "assistant", "content": response_text})
            full_trajectory.append({"role": "assistant", "content": response_text})

            # ğŸ”§ ä¿®å¤ï¼šæ›´æ™ºèƒ½çš„ç­”æ¡ˆæ£€æµ‹é€»è¾‘
            answer_tag = TaskExecutionConstants.XML_TAGS['ANSWER']
            answer_start_tag = f"<{answer_tag}>"
            answer_end_tag = f"</{answer_tag}>"
            
            # æ£€æµ‹ç­”æ¡ˆæ ‡ç­¾ï¼ˆå¼€å§‹æ ‡ç­¾æˆ–ç»“æŸæ ‡ç­¾ï¼‰
            has_answer_start = answer_start_tag in response_text
            has_answer_end = answer_end_tag in response_text
            has_boxed_content = "\\boxed{" in response_text
            
            if has_answer_end or (has_answer_start and has_boxed_content):
                logger.info("âœ… Final Answer detected. Task complete.")
                # ğŸ” è®°å½•è§£æç»“æœï¼ˆåŒ…å«ç­”æ¡ˆçš„æƒ…å†µï¼‰
                parsing_start_time = time.time()
                think_content = self.step_logger._extract_think_content(response_text)
                answer_content = self.step_logger._extract_answer_content(response_text)
                parsing_end_time = time.time()
                
                self.step_logger.log_parsing_result(
                    think_content=think_content,
                    execution_block=None,
                    answer_content=answer_content,
                    actions=[],
                    parsing_errors=[],
                    start_time=parsing_start_time,
                    end_time=parsing_end_time
                )
                self.step_logger.finish_step("task_completed_with_answer")
                break

            # ğŸ” è®°å½•è§£æé˜¶æ®µ
            parsing_start_time = time.time()
            execution_block = self._parse_execution_block(response_text)
            actions = execution_block.get("actions", [])
            think_content = self.step_logger._extract_think_content(response_text)
            execution_block_text = self.step_logger._extract_execution_block(response_text)
            parsing_end_time = time.time()
            
            self.step_logger.log_parsing_result(
                think_content=think_content,
                execution_block=execution_block_text,
                answer_content=None,
                actions=actions,
                parsing_errors=[],
                start_time=parsing_start_time,
                end_time=parsing_end_time
            )
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ä»…åŒ…å«æ€è€ƒçš„æœ€ç»ˆç­”æ¡ˆ
            think_tag = TaskExecutionConstants.XML_TAGS['THINK']
            answer_tag = TaskExecutionConstants.XML_TAGS['ANSWER']
            execute_tools_tag = TaskExecutionConstants.XML_TAGS['EXECUTE_TOOLS']
            
            if not actions and f"<{think_tag}>" in response_text and f"<{execute_tools_tag} />" not in response_text:
                logger.info("âœ… Detected a thought-only response, considering it the final answer.")
                # æå–æ€è€ƒå†…å®¹ä½œä¸ºæœ€ç»ˆç­”æ¡ˆ
                try:
                    import re
                    match = re.search(f"<{think_tag}>(.*)</{think_tag}>", response_text, re.DOTALL)
                    if match:
                        final_thought = match.group(1).strip()
                        answer_content = f"<{answer_tag}>{final_thought}</{answer_tag}>"
                        history.append({"role": "assistant", "content": answer_content})
                        full_trajectory.append({"role": "assistant", "content": answer_content})
                except Exception:
                    pass # å¦‚æœè§£æå¤±è´¥ï¼Œåˆ™æ­£å¸¸ç»§ç»­
                # ğŸ” å®Œæˆæ­¥éª¤è®°å½•
                self.step_logger.finish_step("thought_only_final_answer")
                break

            # ğŸ”§ æ ¹æœ¬ä¿®å¤ï¼šæ™ºèƒ½åˆ¤æ–­æ˜¯å¦éœ€è¦æ³¨å…¥"æ— åŠ¨ä½œ"æ¶ˆæ¯
            if not actions:
                # ğŸ”§ æ–°å¢ï¼šè®¡åˆ’æ£€æµ‹é€»è¾‘ - è§£å†³è®¡åˆ’-æ‰§è¡Œè„±èŠ‚é—®é¢˜
                plan_content = self._extract_detailed_plan(response_text)
                if plan_content and self._has_executable_plan(plan_content):
                    logger.info("ğŸ¯ æ£€æµ‹åˆ°è¯¦ç»†è®¡åˆ’ä½†ç¼ºå°‘æ‰§è¡ŒåŠ¨ä½œï¼Œå¼•å¯¼LLMå¼€å§‹æ‰§è¡Œ")
                    execution_guidance = (
                        "You have created a detailed plan. Now please start executing the first step of your plan. "
                        "Use the appropriate tool call with the exact XML format and end with <execute_tools />. "
                        "Remember: plans are not answers - execution is required."
                    )
                    result_xml = self._format_result(execution_guidance)
                    history.append({"role": "assistant", "content": result_xml})
                    full_trajectory.append({"role": "assistant", "content": result_xml})
                    # ğŸ” å®Œæˆæ­¥éª¤è®°å½•
                    self.step_logger.finish_step("plan_execution_guidance_injected")
                    continue
                
                elif self._should_inject_no_action_message(response_text):
                    logger.warning("No executable actions found in LLM response. Injecting guidance.")
                    result_xml = self._format_result("No executable action detected in this step.")
                    history.append({"role": "assistant", "content": result_xml})
                    full_trajectory.append({"role": "assistant", "content": result_xml})
                    # ğŸ” å®Œæˆæ­¥éª¤è®°å½•
                    self.step_logger.finish_step("no_action_injected")
                else:
                    logger.info("âœ… Detected thought-only response without tool execution - this is normal.")
                    # ğŸ” å®Œæˆæ­¥éª¤è®°å½•
                    self.step_logger.finish_step("thought_only_normal")
                continue

            # 4. æ ¹æ®ç±»å‹åˆ†å‘æ‰§è¡Œ
            results = []
            block_type = execution_block.get("type")

            # å¯¹äºä¸²è¡Œå—ï¼Œæˆ‘ä»¬åªæ‰§è¡Œç¬¬ä¸€ä¸ªåŠ¨ä½œã€‚LLMå°†åœ¨ä¸‹ä¸€è½®æ ¹æ®ç»“æœå†³å®šåç»­æ­¥éª¤ã€‚
            if block_type == "sequential":
                logger.info(f"Executing first action of sequential block.")
                if actions:
                    result_data = await self._execute_tool_with_logging(actions[0], 0)
                    results = [result_data["formatted_result"]]
            elif block_type == "parallel":
                logger.info(f"Executing parallel block with {len(actions)} actions.")
                results = await self._execute_parallel_with_logging(actions)
            else: # single
                if actions:
                    logger.info(f"Executing single action.")
                    result_data = await self._execute_tool_with_logging(actions[0], 0)
                    results = [result_data["formatted_result"]]

            # 5. æ ¼å¼åŒ–å¹¶ä¸ºæ¯ä¸ªç»“æœæ³¨å…¥å•ç‹¬çš„<result>æ ‡ç­¾
            for res in results:
                result_xml = self._format_result(res)
                history.append({"role": "assistant", "content": result_xml})
                full_trajectory.append({"role": "assistant", "content": result_xml})
                
            # ğŸ” å®Œæˆæ­¥éª¤è®°å½•
            self.step_logger.finish_step()

        else:
            logger.warning(f"Max steps ({max_steps}) reached. Terminating task.")
            # ğŸ” å®Œæˆæœ€åä¸€ä¸ªæ­¥éª¤è®°å½•
            if self.step_logger.current_step_data:
                self.step_logger.finish_step("max_steps_reached")

        # ä»»åŠ¡ç»“æŸï¼Œå¤„ç†æœ€ç»ˆç»“æœ
        final_trajectory_str = "\n".join(item["content"] for item in full_trajectory)
        total_duration = time.time() - start_time
        
        # ğŸ”§ æ ¹æœ¬ä¿®å¤ï¼šåŒºåˆ†æ­¥æ•°é™åˆ¶å’ŒçœŸæ­£å¤±è´¥
        max_steps_reached = len(full_trajectory) >= max_steps
        
        # ğŸ”§ æ ¹æœ¬ä¿®å¤ï¼šæ™ºèƒ½åˆ¤å®šä»»åŠ¡æˆåŠŸçŠ¶æ€ï¼Œè€ƒè™‘æ­¥æ•°é™åˆ¶å› ç´ 
        success = self._determine_task_success(final_trajectory_str, full_trajectory)
        
        # ğŸ”§ æ–°å¢ï¼šå¦‚æœè¾¾åˆ°æœ€å¤§æ­¥æ•°ä½†æ²¡æœ‰æ˜ç¡®çš„ç­”æ¡ˆï¼Œé™ä½æˆåŠŸåˆ¤å®šæ ‡å‡†
        if max_steps_reached:
            answer_tag = TaskExecutionConstants.XML_TAGS['ANSWER']
            has_explicit_answer = f"<{answer_tag}>" in final_trajectory_str
            has_boxed_content = "\\boxed{" in final_trajectory_str
            
            if not has_explicit_answer and not has_boxed_content:
                # è¾¾åˆ°æœ€å¤§æ­¥æ•°ä¸”æ²¡æœ‰æ˜ç¡®ç­”æ¡ˆï¼Œæ ‡è®°ä¸ºéƒ¨åˆ†æˆåŠŸä½†éœ€è¦è¯´æ˜
                logger.warning(f"ä»»åŠ¡è¾¾åˆ°æœ€å¤§æ­¥æ•°({max_steps})ä½†æ²¡æœ‰æ˜ç¡®ç­”æ¡ˆæ ‡è®°")
                # æ ¹æ®æ˜¯å¦æœ‰å·¥å…·æ‰§è¡Œç»“æœæ¥åˆ¤å®š
                tool_success_rate = self._calculate_tool_success_rate()
                success = tool_success_rate > 0.5  # è‡³å°‘50%çš„å·¥å…·æ‰§è¡ŒæˆåŠŸæ‰è®¤ä¸ºéƒ¨åˆ†æˆåŠŸ
        
        # ğŸ”§ æ ¹æœ¬ä¿®å¤ï¼šåŠ¨æ€æå–çœŸå®çš„æœ€ç»ˆç»“æœï¼Œè€ƒè™‘æ­¥æ•°é™åˆ¶æƒ…å†µ
        if max_steps_reached:
            final_result = f"å·²è¾¾æœ€å¤§æ­¥éª¤({max_steps})ï¼Œä»»åŠ¡è¢«ä¸­æ­¢ã€‚å½“å‰è¿›å±•ï¼š{self._extract_final_result(final_trajectory_str)}"
        else:
            final_result = self._extract_final_result(final_trajectory_str)

        # ğŸ” å®Œæˆä»»åŠ¡æ­¥éª¤æ—¥å¿—è®°å½•
        final_status = "success" if success else "failure"
        await self.step_logger.finalize_task(final_status, final_result)

        xml_output = {
            "timestamp": datetime.now().isoformat(),
            "task_id": task.task_id,
            "task_description": task.description,
            "duration": total_duration,
            "success": success,
            "final_result": final_result,
            "raw_response": final_trajectory_str,
        }
        
        await self._save_xml_output(xml_output)

        # ğŸ”§ ä¿®å¤ï¼šä»step_loggerè·å–å®é™…çš„æ‰§è¡Œæ­¥éª¤
        actual_steps = await self.step_logger.get_execution_steps()
        
        return TrajectoryResult(
            task_name=task.task_id,
            task_id=task.task_id, 
            task_description=task.description,
            runtime_id=self._runtime_id,
            steps=actual_steps,  # ğŸ”§ ä½¿ç”¨å®é™…æ­¥éª¤è€Œä¸æ˜¯ç©ºæ•°ç»„
            success=success,
            final_result=final_result,  # ğŸ”§ ä½¿ç”¨åŠ¨æ€æå–çš„ç»“æœ
            total_duration=total_duration,
            metadata={'full_trajectory': full_trajectory}
        )

    def _format_result(self, result: str) -> str:
        """ğŸ”§ æ ¹æœ¬ä¿®å¤ï¼šæ ¼å¼åŒ–å·¥å…·ç»“æœï¼Œä½¿ç”¨å¸¸é‡æ›¿ä»£ç¡¬ç¼–ç """
        if not result:
            no_action_msg = TaskExecutionConstants.NO_ACTION_PERFORMED
            return f"<{TaskExecutionConstants.XML_TAGS['RESULT']}>{no_action_msg}</{TaskExecutionConstants.XML_TAGS['RESULT']}>"
        return f"<{TaskExecutionConstants.XML_TAGS['RESULT']}>{result}</{TaskExecutionConstants.XML_TAGS['RESULT']}>"
    
    async def _execute_standard(self, task: TaskSpec) -> TrajectoryResult:
        """æ ‡å‡†æ‰§è¡Œæ¨¡å¼ (ä½œä¸ºå¤‡ç”¨) - ğŸ”§ å·²ä¿®å¤ç¡¬ç¼–ç é—®é¢˜"""
        logger.warning("æ‰§è¡Œæ ‡å‡†ï¼ˆReActï¼‰æ¨¡å¼ï¼Œæ­¤æ¨¡å¼åŠŸèƒ½æœ‰é™ã€‚")
        # ç®€å•å®ç°æ ‡å‡†æ¨¡å¼
        start_time = time.time()
        response = ""
        try:
            # ç®€å•çš„LLMè°ƒç”¨
            messages = self.prompt_builder.build_prompt(
                task_description=task.description,
                available_tools=[],
                tool_descriptions="",
                streaming_mode=False
            )
            response = await self.client._call_api(messages)
            
            # ğŸ”§ æ ¹æœ¬ä¿®å¤ï¼šä½¿ç”¨ç›¸åŒçš„æ™ºèƒ½åˆ¤å®šé€»è¾‘
            success = self._determine_task_success(response, [])
            final_result = self._extract_final_result(response)
            
        except Exception as e:
            logger.error(f"æ ‡å‡†æ¨¡å¼æ‰§è¡Œå¤±è´¥: {e}")
            success = False
            final_result = f"æ‰§è¡Œå¤±è´¥: {str(e)}"
            response = f"Error: {str(e)}"
        
        total_duration = time.time() - start_time
        
        # æ„å»ºè¿”å›å¯¹è±¡
        from core.interfaces import TrajectoryResult
        trajectory = TrajectoryResult(
            task_name=task.task_id,
            task_id=task.task_id,
            task_description=task.description,
            runtime_id=self._runtime_id,
            steps=[],
            success=success,
            final_result=final_result,  # ğŸ”§ ä½¿ç”¨åŠ¨æ€æå–çš„ç»“æœ
            total_duration=total_duration,
            metadata={'mode': 'standard', 'raw_response': response}
        )
        
        return trajectory

    async def _get_available_tools(self) -> List[str]:
        """è·å–å¯ç”¨å·¥å…·åˆ—è¡¨"""
        try:
            tools = await self.toolscore_client.get_available_tools()
            return [str(tool) for tool in tools] if isinstance(tools, list) else []
        except Exception as e:
            logger.warning(f"è·å–å·¥å…·åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    async def _get_tool_descriptions(self) -> str:
        """è·å–å·¥å…·æè¿°"""
        try:
            descriptions = await self.toolscore_client.get_tool_descriptions()
            return descriptions if descriptions else "å·¥å…·æè¿°è·å–å¤±è´¥"
        except Exception as e:
            logger.warning(f"è·å–å·¥å…·æè¿°å¤±è´¥: {e}")
            return "å·¥å…·æè¿°è·å–å¤±è´¥"

    def _determine_task_success(self, final_trajectory_str: str, full_trajectory: List) -> bool:
        """ğŸ”§ æ ¹æœ¬æ€§é‡æ„ï¼šåŸºäºå®é™…æ‰§è¡Œæƒ…å†µæ™ºèƒ½åˆ¤å®šæˆåŠŸçŠ¶æ€
        
        ä¼˜å…ˆçº§ï¼šå®é™…å·¥å…·æ‰§è¡ŒçŠ¶æ€ > ç­”æ¡ˆå®Œæ•´æ€§ > å†…å®¹è´¨é‡ > é”™è¯¯æ£€æŸ¥
        
        Args:
            final_trajectory_str: å®Œæ•´è½¨è¿¹å­—ç¬¦ä¸²
            full_trajectory: è½¨è¿¹æ­¥éª¤åˆ—è¡¨
        
        Returns:
            bool: ä»»åŠ¡æ˜¯å¦æˆåŠŸå®Œæˆ
        """
        # ğŸ”§ æœ€é«˜ä¼˜å…ˆçº§ï¼šæ£€æŸ¥å®é™…å·¥å…·æ‰§è¡ŒçŠ¶æ€
        tool_success_rate = self._calculate_tool_success_rate()
        has_successful_tools = tool_success_rate > 0.0
        
        # 1. æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„ç­”æ¡ˆæ ‡ç­¾
        answer_tag = TaskExecutionConstants.XML_TAGS['ANSWER']
        has_answer = f'</{answer_tag}>' in final_trajectory_str or f'<{answer_tag}>' in final_trajectory_str
        
        # 2. æ£€æŸ¥æ˜¯å¦æœ‰æœªå¤„ç†çš„å…³é”®é”™è¯¯æŒ‡ç¤ºå™¨
        has_critical_errors = any(
            indicator in final_trajectory_str.lower() 
            for indicator in TaskExecutionConstants.FAILURE_INDICATORS
        )
        
        # 3. æ£€æŸ¥æ˜¯å¦æœ‰å®é™…çš„å·¥å…·æ‰§è¡Œæˆæœ
        result_tag = TaskExecutionConstants.XML_TAGS['RESULT']
        has_tool_results = f'<{result_tag}>' in final_trajectory_str and TaskExecutionConstants.NO_ACTION_PERFORMED not in final_trajectory_str
        
        # 4. æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ„ä¹‰çš„æ€è€ƒå†…å®¹
        think_tag = TaskExecutionConstants.XML_TAGS['THINK']
        has_meaningful_thinking = f'<{think_tag}>' in final_trajectory_str and len(final_trajectory_str.strip()) > 50
        
        # ğŸ”§ æ™ºèƒ½ç»¼åˆåˆ¤å®šé€»è¾‘ï¼šåŸºäºå¤šç»´åº¦è¯„ä¼°
        success = False
        
        # åœºæ™¯1ï¼šæœ‰å·¥å…·æ‰§è¡Œä¸”æˆåŠŸ + æœ‰ç­”æ¡ˆ + æœ‰æ„ä¹‰ç»“æœ = æ˜ç¡®æˆåŠŸ
        if has_successful_tools and has_answer and not has_critical_errors and self._has_meaningful_tool_results(final_trajectory_str):
            success = True
            logger.info("ğŸ¯ åˆ¤å®šæˆåŠŸï¼šå·¥å…·æ‰§è¡ŒæˆåŠŸ + å®Œæ•´ç­”æ¡ˆ + æœ‰æ„ä¹‰ç»“æœ")
        
        # åœºæ™¯2ï¼šæœ‰å·¥å…·æ‰§è¡Œä¸”æˆåŠŸ + æœ‰ç»“æœè¾“å‡º = æ½œåœ¨æˆåŠŸ
        elif has_successful_tools and has_tool_results and not has_critical_errors:
            success = True
            logger.info("ğŸ¯ åˆ¤å®šæˆåŠŸï¼šå·¥å…·æ‰§è¡ŒæˆåŠŸ + æœ‰å®é™…ç»“æœ")
        
        # åœºæ™¯3ï¼šçº¯æ¨ç†ä»»åŠ¡ï¼šæœ‰ç­”æ¡ˆä½†æ— éœ€å·¥å…·
        elif has_answer and not has_tool_results and has_meaningful_thinking and not has_critical_errors:
            success = True
            logger.info("ğŸ¯ åˆ¤å®šæˆåŠŸï¼šçº¯æ¨ç†ä»»åŠ¡ï¼Œæœ‰å®Œæ•´ç­”æ¡ˆ")
        
        # åœºæ™¯4ï¼šä»»ä½•å…³é”®é”™è¯¯éƒ½å¯¼è‡´å¤±è´¥
        elif has_critical_errors:
            success = False
            logger.info("ğŸ¯ åˆ¤å®šå¤±è´¥ï¼šæ£€æµ‹åˆ°å…³é”®é”™è¯¯")
        
        # åœºæ™¯5ï¼šå…¶ä»–æƒ…å†µé»˜è®¤å¤±è´¥
        else:
            success = False
            logger.info("ğŸ¯ åˆ¤å®šå¤±è´¥ï¼šæœªæ»¡è¶³æˆåŠŸæ¡ä»¶")
        
        logger.info(f"ğŸ¯ Successåˆ¤å®šè¯¦æƒ…: tool_success_rate={tool_success_rate:.2f}, has_answer={has_answer}, "
                   f"has_tool_results={has_tool_results}, has_meaningful_thinking={has_meaningful_thinking}, "
                   f"has_critical_errors={has_critical_errors}, final_success={success}")
        
        return success
    
    def _calculate_tool_success_rate(self) -> float:
        """è®¡ç®—å½“å‰ä»»åŠ¡ä¸­å·¥å…·æ‰§è¡Œçš„æˆåŠŸç‡"""
        if not hasattr(self, 'step_logger') or not self.step_logger.current_task_data:
            return 0.0
        
        total_executions = 0
        successful_executions = 0
        
        for step in self.step_logger.current_task_data.get('steps', []):
            for tool_exec in step.get('tool_executions', []):
                total_executions += 1
                if tool_exec.get('execution_status') == 'success':
                    successful_executions += 1
        
        return successful_executions / total_executions if total_executions > 0 else 0.0
    
    def _analyze_error_type(self, error_message: str) -> str:
        """ğŸ”§ æ™ºèƒ½é”™è¯¯ç±»å‹åˆ†æ"""
        error_msg_lower = error_message.lower()
        
        # å‚æ•°é”™è¯¯
        if any(indicator in error_msg_lower for indicator in ['parameter', 'param', 'å‚æ•°', 'æ— æ•ˆå‚æ•°']):
            return "parameter_error"
        
        # å·¥å…·ä¸å­˜åœ¨é”™è¯¯
        if any(indicator in error_msg_lower for indicator in ['ä¸æ”¯æŒ', 'not support', 'ä¸å­˜åœ¨', 'not found']):
            return "tool_not_found"
        
        # ç½‘ç»œ/è¿æ¥é”™è¯¯
        if any(indicator in error_msg_lower for indicator in ['timeout', 'connection', 'network', 'connect', 'è¶…æ—¶']):
            return "network_error"
        
        # éªŒè¯é”™è¯¯
        if any(indicator in error_msg_lower for indicator in ['validation', 'validate', 'éªŒè¯å¤±è´¥']):
            return "validation_error"
        
        # æƒé™é”™è¯¯
        if any(indicator in error_msg_lower for indicator in ['permission', 'access', 'æƒé™', 'forbidden']):
            return "permission_error"
        
        return "unknown_error"
    
    def _format_error_with_recovery_suggestion(self, error_message: str, error_type: str, service_name: str, tool_name: str) -> str:
        """ğŸ”§ æ ¼å¼åŒ–é”™è¯¯ä¿¡æ¯å¹¶æä¾›æ¢å¤å»ºè®®"""
        base_error = f"Tool execution failed: {error_message}"
        
        recovery_suggestions = {
            "parameter_error": f"ğŸ’¡ å»ºè®®: æ£€æŸ¥ {service_name} çš„ {tool_name} å·¥å…·å‚æ•°æ ¼å¼ã€‚å‚è€ƒå·¥å…·å®šä¹‰ä¸­çš„æ­£ç¡®å‚æ•°åç§°ã€‚",
            "tool_not_found": f"ğŸ’¡ å»ºè®®: å·¥å…· {tool_name} åœ¨ {service_name} ä¸­ä¸å­˜åœ¨ã€‚æ£€æŸ¥å·¥å…·åç§°æ˜¯å¦æ­£ç¡®ï¼Œæˆ–å°è¯•ä½¿ç”¨å…¶ä»–å·¥å…·ã€‚",
            "network_error": f"ğŸ’¡ å»ºè®®: ç½‘ç»œè¿æ¥é—®é¢˜ã€‚ç­‰å¾…å‡ ç§’åé‡è¯•ï¼Œæˆ–å°è¯•ä½¿ç”¨æ›¿ä»£å·¥å…·ã€‚",
            "validation_error": f"ğŸ’¡ å»ºè®®: è¾“å…¥æ•°æ®éªŒè¯å¤±è´¥ã€‚æ£€æŸ¥è¾“å…¥æ ¼å¼å’Œå†…å®¹æ˜¯å¦ç¬¦åˆè¦æ±‚ã€‚",
            "permission_error": f"ğŸ’¡ å»ºè®®: æƒé™ä¸è¶³ã€‚æ£€æŸ¥æœåŠ¡é…ç½®æˆ–å°è¯•å…¶ä»–æ–¹æ³•ã€‚",
            "unknown_error": f"ğŸ’¡ å»ºè®®: æœªçŸ¥é”™è¯¯ã€‚å°è¯•ç®€åŒ–è¾“å…¥æˆ–ä½¿ç”¨å…¶ä»–å·¥å…·æ›¿ä»£ã€‚"
        }
        
        suggestion = recovery_suggestions.get(error_type, recovery_suggestions["unknown_error"])
        return f"{base_error}\n{suggestion}"
    
    def _extract_final_result(self, final_trajectory_str: str) -> str:
        """ğŸ”§ å®Œæ•´ä¿®å¤ï¼šä¼˜åŒ–æœ€ç»ˆç»“æœæå–ä¼˜å…ˆçº§ï¼Œç¡®ä¿å®é™…ç»“æœä¼˜äºæ€è€ƒè¿‡ç¨‹
        
        Args:
            final_trajectory_str: å®Œæ•´è½¨è¿¹å­—ç¬¦ä¸²
        
        Returns:
            str: æå–çš„æœ€ç»ˆç»“æœ
        """
        import re
        
        # ğŸ”§ ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šæå–answeræ ‡ç­¾å†…å®¹ï¼Œä¼˜å…ˆæå–\boxed{}æ ¼å¼
        answer_tag = TaskExecutionConstants.XML_TAGS['ANSWER']
        answer_pattern = f'<{answer_tag}>(.*?)</{answer_tag}>'
        answer_match = re.search(answer_pattern, final_trajectory_str, re.DOTALL)
        if answer_match:
            answer_content = answer_match.group(1).strip()
            if answer_content and len(answer_content) > 0:
                # ğŸ”§ æ–°å¢ï¼šä¼˜å…ˆæå–\boxed{}å†…çš„æ¸…æ´å†…å®¹
                boxed_pattern = r'\\boxed\{(.*?)\}'
                boxed_match = re.search(boxed_pattern, answer_content, re.DOTALL)
                if boxed_match:
                    clean_answer = boxed_match.group(1).strip()
                    logger.info(f"âœ… ä»\\boxed{{}}æå–æ¸…æ´æœ€ç»ˆç»“æœ: {clean_answer[:100]}...")
                    return clean_answer
                else:
                    # å¦‚æœæ²¡æœ‰\boxed{}æ ¼å¼ï¼Œè¿”å›åŸå§‹answerå†…å®¹
                    logger.info(f"âœ… ä»<answer>æ ‡ç­¾æå–æœ€ç»ˆç»“æœ: {answer_content[:100]}...")
                    return answer_content
        
        # ğŸ”§ ç¬¬äºŒä¼˜å…ˆçº§ï¼šæå–æœ€åçš„æœ‰æ•ˆå·¥å…·æ‰§è¡Œç»“æœï¼ˆé"No action"ï¼‰
        result_tag = TaskExecutionConstants.XML_TAGS['RESULT']
        result_pattern = f'<{result_tag}>(.*?)</{result_tag}>'
        result_matches = re.findall(result_pattern, final_trajectory_str, re.DOTALL)
        
        # è¿‡æ»¤å‡ºæœ‰æ•ˆçš„å·¥å…·æ‰§è¡Œç»“æœ
        valid_results = []
        for result in result_matches:
            result_clean = result.strip()
            # æ’é™¤æ— æ„ä¹‰çš„ç»“æœ
            if (result_clean and 
                TaskExecutionConstants.NO_ACTION_PERFORMED not in result_clean and
                "No executable action detected" not in result_clean and
                len(result_clean) > 10):
                valid_results.append(result_clean)
        
        if valid_results:
            # ğŸ”§ ä¼˜åŒ–ï¼šé€‰æ‹©æœ€æœ‰ä»·å€¼çš„ç»“æœ
            best_result = self._select_best_tool_result(valid_results)
            logger.info(f"ğŸ”§ ä»å·¥å…·æ‰§è¡Œç»“æœæå–æœ€ç»ˆç­”æ¡ˆ: {best_result[:100]}...")
            return best_result
        
        # ğŸ”§ ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼šæå–æ•°å€¼è®¡ç®—ç»“æœï¼ˆé’ˆå¯¹æ•°å­¦é—®é¢˜ï¼‰
        # æŸ¥æ‰¾æ•°å€¼ç»“æœæ¨¡å¼
        calculation_patterns = [
            r'ç»“æœ[ï¼š:]\s*([0-9.e-]+\s*[A-Za-z]*)',  # "ç»“æœ: 9.43e-07 A"
            r'ç­”æ¡ˆ[ï¼š:]\s*([0-9.e-]+\s*[A-Za-z]*)',  # "ç­”æ¡ˆ: 42"
            r'photocurrent[ï¼š:]\s*([0-9.e-]+\s*[A-Za-z]*)',  # "photocurrent: 9.43e-07 A"
            r'([0-9.e-]+\s*[A-Za-z]*)\s*(?:å®‰åŸ¹|A|ç“¦ç‰¹|W|ç±³|m)',  # å•ä½æ¨¡å¼
        ]
        
        for pattern in calculation_patterns:
            matches = re.findall(pattern, final_trajectory_str, re.IGNORECASE)
            if matches:
                # ğŸ”§ æ·»åŠ ä¸Šä¸‹æ–‡éªŒè¯ - ç¡®ä¿ç»“æœæ¥è‡ªå®é™…çš„å·¥å…·æ‰§è¡Œ
                calculation_result = matches[-1].strip()
                if self._validate_calculation_context(final_trajectory_str, calculation_result):
                    logger.info(f"ğŸ§® ä»è®¡ç®—ç»“æœæå–æœ€ç»ˆç­”æ¡ˆ: {calculation_result}")
                    return f"è®¡ç®—ç»“æœ: {calculation_result}"
                else:
                    logger.warning(f"âš ï¸ è®¡ç®—ç»“æœ {calculation_result} æœªé€šè¿‡ä¸Šä¸‹æ–‡éªŒè¯ï¼Œè·³è¿‡")
        
        # ğŸ”§ ç¬¬å››ä¼˜å…ˆçº§ï¼šæå–æœç´¢ç­”æ¡ˆï¼ˆé’ˆå¯¹é—®ç­”ç±»ä»»åŠ¡ï¼‰
        # æŸ¥æ‰¾IORAç­‰ä¸“æœ‰åè¯çš„è§£é‡Š
        info_patterns = [
            r'IORA[æ˜¯ä¸º].*?[ã€‚.]',  # IORAç›¸å…³è§£é‡Š
            r'æ–°åŠ å¡å›½ç«‹å¤§å­¦.*?[ã€‚.]',  # å¤§å­¦ç›¸å…³ä¿¡æ¯
            r'([A-Z]{3,}\s*(?:æ˜¯|ä¸º|æŒ‡).*?[ã€‚.])',  # ç¼©å†™è§£é‡Šæ¨¡å¼
        ]
        
        for pattern in info_patterns:
            matches = re.findall(pattern, final_trajectory_str, re.DOTALL)
            if matches:
                info_result = matches[-1].strip()
                logger.info(f"ğŸ“– ä»ä¿¡æ¯æ£€ç´¢æå–æœ€ç»ˆç­”æ¡ˆ: {info_result[:100]}...")
                return info_result
        
        # ğŸ”§ ç¬¬äº”ä¼˜å…ˆçº§ï¼šæ™ºèƒ½æå–æœ€åçš„thinkå†…å®¹ï¼ˆé™ä½ä¼˜å…ˆçº§ï¼‰
        think_tag = TaskExecutionConstants.XML_TAGS['THINK']
        think_pattern = f'<{think_tag}>(.*?)</{think_tag}>'
        think_matches = re.findall(think_pattern, final_trajectory_str, re.DOTALL)
        if think_matches:
            last_think = think_matches[-1].strip()
            # åªæœ‰åœ¨æ²¡æœ‰å…¶ä»–ç»“æœæ—¶æ‰ä½¿ç”¨æ€è€ƒå†…å®¹ï¼Œä¸”éœ€è¦è¶³å¤Ÿé•¿
            if last_think and len(last_think) > 50:
                logger.info(f"ğŸ“ ä»æ€è€ƒè¿‡ç¨‹æå–ç»“æœ: {last_think[:100]}...")
                return f"åˆ†æè¿‡ç¨‹: {last_think[:200]}..."
        
        # ğŸ”§ ç¬¬å…­ä¼˜å…ˆçº§ï¼šæå–å¯è§çš„æœ‰æ„ä¹‰æ–‡æœ¬
        visible_content = re.sub(r'<[^>]+>', '', final_trajectory_str).strip()
        if visible_content and len(visible_content) > 20:
            # å¯»æ‰¾æœ€åçš„æœ‰æ„ä¹‰å†…å®¹
            lines = [line.strip() for line in visible_content.split('\n') if line.strip()]
            meaningful_lines = []
            
            for line in lines[-10:]:  # æ£€æŸ¥æœ€å10è¡Œ
                # è¿‡æ»¤æ‰æ— æ„ä¹‰çš„è¡Œ
                if (len(line) > 10 and 
                    not line.startswith('---') and
                    'Starting Step' not in line and
                    'executable action' not in line):
                    meaningful_lines.append(line)
            
            if meaningful_lines:
                final_content = ' '.join(meaningful_lines[-3:])  # å–æœ€å3è¡Œæœ‰æ„ä¹‰å†…å®¹
                logger.info(f"ğŸ“„ ä»å¯è§æ–‡æœ¬æå–ç»“æœ: {final_content[:100]}...")
                return final_content
        
        # æœ€åå¤‡é€‰ï¼šè¿”å›ä»»åŠ¡å®ŒæˆçŠ¶æ€  
        logger.warning("âš ï¸ æ— æ³•æå–å…·ä½“çš„æœ€ç»ˆç»“æœï¼Œè¿”å›é»˜è®¤å®Œæˆæ¶ˆæ¯")
        return TaskExecutionConstants.TASK_COMPLETED_NO_ANSWER
    
    def _select_best_tool_result(self, valid_results: list) -> str:
        """é€‰æ‹©æœ€æœ‰ä»·å€¼çš„å·¥å…·æ‰§è¡Œç»“æœ"""
        if not valid_results:
            return ""
        
        import re
        
        # ä¼˜å…ˆçº§è¯„åˆ†
        scored_results = []
        for result in valid_results:
            score = 0
            result_lower = result.lower()
            
            # åŒ…å«æ•°å€¼è®¡ç®—çš„ç»“æœå¾—åˆ†æ›´é«˜
            if re.search(r'[0-9.e-]+', result):
                score += 10
            
            # åŒ…å«ä¸“ä¸šæœ¯è¯­çš„ç»“æœå¾—åˆ†æ›´é«˜
            if any(term in result_lower for term in ['iora', 'university', 'å¤§å­¦', 'ç»“æœ', 'ç­”æ¡ˆ']):
                score += 8
            
            # é•¿åº¦é€‚ä¸­çš„ç»“æœå¾—åˆ†æ›´é«˜
            if 20 <= len(result) <= 300:
                score += 5
            
            # åŒ…å«æœç´¢ç»“æœçš„å¾—åˆ†æ›´é«˜
            if 'æœç´¢ç»“æœ' in result or 'search' in result_lower:
                score += 7
            
            scored_results.append((score, result))
        
        # è¿”å›å¾—åˆ†æœ€é«˜çš„ç»“æœ
        scored_results.sort(key=lambda x: x[0], reverse=True)
        return scored_results[0][1]
    
    def _should_inject_no_action_message(self, response_text: str) -> bool:
        """ğŸ”§ å®Œæ•´ä¿®å¤ï¼šä¸¥æ ¼æ§åˆ¶æ— åŠ¨ä½œæ¶ˆæ¯æ³¨å…¥ï¼Œå½»åº•æ¶ˆé™¤å†—ä½™æ¶ˆæ¯
        
        Args:
            response_text: LLMå“åº”æ–‡æœ¬
        
        Returns:
            bool: æ˜¯å¦éœ€è¦æ³¨å…¥æ— åŠ¨ä½œæ¶ˆæ¯
        """
        import re
        
        # ğŸ”§ å¢å¼ºæ£€æµ‹ï¼šå¦‚æœæœ‰ä»»ä½•XMLæ ‡ç­¾ï¼Œéƒ½è®¤ä¸ºæœ‰å†…å®¹
        xml_tags = TaskExecutionConstants.XML_TAGS
        all_possible_tags = [
            f"<{xml_tags['THINK']}>", f"</{xml_tags['THINK']}>",
            f"<{xml_tags['ANSWER']}>", f"</{xml_tags['ANSWER']}>", 
            f"<{xml_tags['RESULT']}>", f"</{xml_tags['RESULT']}>",
            f"<{xml_tags['OBSERVATION']}>", f"</{xml_tags['OBSERVATION']}>",
            f"<{xml_tags['CONCLUSION']}>", f"</{xml_tags['CONCLUSION']}>",
            "<execute_tools/>", "<execute_tools></execute_tools>"
        ]
        
        # 1. æ£€æµ‹ä»»ä½•XMLç»“æ„åŒ–å†…å®¹
        for tag in all_possible_tags:
            if tag in response_text:
                logger.info(f"ğŸ’­ æ£€æµ‹åˆ°XMLæ ‡ç­¾ {tag}ï¼Œæ— éœ€æ³¨å…¥æ— åŠ¨ä½œæ¶ˆæ¯")
                return False
        
        # 2. æ£€æµ‹ä»»ä½•å·¥å…·æœåŠ¡å™¨æ ‡ç­¾
        server_tags = ["<microsandbox>", "<deepsearch>", "<browser_use>", "<search_tool>"]
        for tag in server_tags:
            if tag in response_text:
                logger.info(f"ğŸ”§ æ£€æµ‹åˆ°å·¥å…·æ ‡ç­¾ {tag}ï¼Œæ— éœ€æ³¨å…¥æ— åŠ¨ä½œæ¶ˆæ¯")
                return False
        
        # 3. æ£€æµ‹æœ‰æ„ä¹‰çš„æ–‡æœ¬å†…å®¹ï¼ˆæ›´ä¸¥æ ¼çš„æ ‡å‡†ï¼‰
        clean_text = re.sub(r'<[^>]+>', '', response_text).strip()
        
        # å¦‚æœæœ‰è¶³å¤Ÿçš„æœ‰æ„ä¹‰æ–‡æœ¬å†…å®¹
        if len(clean_text) > 20:  # é™ä½é˜ˆå€¼ï¼Œæ›´å®½æ¾
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ„ä¹‰çš„å†…å®¹ï¼ˆéç©ºç™½ã€éé‡å¤å­—ç¬¦ï¼‰
            meaningful_chars = len(re.sub(r'\s+', '', clean_text))
            if meaningful_chars > 10:
                logger.info(f"ğŸ“ æ£€æµ‹åˆ°æœ‰æ„ä¹‰æ–‡æœ¬å†…å®¹({meaningful_chars}å­—ç¬¦)ï¼Œæ— éœ€æ³¨å…¥æ— åŠ¨ä½œæ¶ˆæ¯")
                return False
        
        # 4. ğŸ”§ æ–°å¢ï¼šæ£€æµ‹ä»»åŠ¡å®Œæˆçš„ç‰¹æ®Šæƒ…å†µ
        completion_indicators = [
            "ä»»åŠ¡å®Œæˆ", "execution completed", "calculation complete",
            "æœç´¢å®Œæˆ", "æ“ä½œå®Œæˆ", "å¤„ç†å®Œæˆ", "åˆ†æå®Œæˆ"
        ]
        
        response_lower = response_text.lower()
        for indicator in completion_indicators:
            if indicator.lower() in response_lower:
                logger.info(f"âœ… æ£€æµ‹åˆ°å®ŒæˆæŒ‡ç¤ºè¯ '{indicator}'ï¼Œæ— éœ€æ³¨å…¥æ— åŠ¨ä½œæ¶ˆæ¯")
                return False
        
        # 5. ğŸ”§ æ–°å¢ï¼šå¦‚æœå“åº”åŒ…å«ä»»ä½•æ•°å­—ã€å­—æ¯æˆ–ä¸­æ–‡å­—ç¬¦çš„æœ‰æ„ä¹‰ç»„åˆ
        if re.search(r'[a-zA-Z\u4e00-\u9fff]{3,}', response_text):
            logger.info("ğŸ“„ æ£€æµ‹åˆ°æœ‰æ„ä¹‰çš„æ–‡æœ¬ç»„åˆï¼Œæ— éœ€æ³¨å…¥æ— åŠ¨ä½œæ¶ˆæ¯")
            return False
        
        # 6. ğŸ”§ ç‰¹æ®Šæƒ…å†µï¼šå¦‚æœå“åº”æ˜¯ç©ºçš„æˆ–è€…åªæœ‰ç©ºç™½ç¬¦
        if not response_text or response_text.isspace():
            logger.warning("âš ï¸ æ£€æµ‹åˆ°å®Œå…¨ç©ºçš„å“åº”ï¼Œéœ€è¦æ³¨å…¥æŒ‡å¯¼æ¶ˆæ¯")
            return True
        
        # 7. ğŸ”§ æœ€ä¸¥æ ¼çš„åˆ¤æ–­ï¼šåªæœ‰åœ¨å“åº”çœŸçš„æ²¡æœ‰ä»»ä½•æœ‰ç”¨ä¿¡æ¯æ—¶æ‰æ³¨å…¥
        # æ£€æŸ¥æ˜¯å¦åªåŒ…å«æ— æ„ä¹‰çš„é‡å¤å­—ç¬¦æˆ–ç¬¦å·
        if len(set(response_text.replace(' ', '').replace('\n', ''))) < 3:
            logger.warning(f"âš ï¸ æ£€æµ‹åˆ°æ— æ„ä¹‰çš„é‡å¤å†…å®¹ï¼Œéœ€è¦æ³¨å…¥æŒ‡å¯¼æ¶ˆæ¯")
            return True
        
        # é»˜è®¤æƒ…å†µï¼šä¸æ³¨å…¥æ— åŠ¨ä½œæ¶ˆæ¯ï¼ˆæ›´ä¿å®ˆçš„ç­–ç•¥ï¼‰
        logger.info("ğŸ¯ å“åº”åŒ…å«å†…å®¹ï¼Œæ— éœ€æ³¨å…¥æ— åŠ¨ä½œæ¶ˆæ¯")
        return False
    
    def _extract_detailed_plan(self, response_text: str) -> Optional[str]:
        """ğŸ”§ æ–°å¢ï¼šä»å“åº”ä¸­æå–è¯¦ç»†è®¡åˆ’å†…å®¹"""
        import re
        
        # æ£€æŸ¥thinkæ ‡ç­¾ä¸­çš„å†…å®¹
        think_tag = TaskExecutionConstants.XML_TAGS['THINK']
        think_pattern = f'<{think_tag}>(.*?)</{think_tag}>'
        think_match = re.search(think_pattern, response_text, re.DOTALL)
        
        if think_match:
            think_content = think_match.group(1).strip()
            return think_content
        
        # å¦‚æœæ²¡æœ‰thinkæ ‡ç­¾ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–å½¢å¼çš„è®¡åˆ’å†…å®¹
        # å¯»æ‰¾åŒ…å«æ­¥éª¤ã€è®¡åˆ’å…³é”®è¯çš„å†…å®¹
        plan_indicators = [
            'step', 'phase', 'first', 'next', 'then', 'need to', 'will',
            'æ­¥éª¤', 'é˜¶æ®µ', 'é¦–å…ˆ', 'ç„¶å', 'æ¥ä¸‹æ¥', 'éœ€è¦', 'å°†ä¼š'
        ]
        
        lines = response_text.split('\n')
        plan_lines = []
        
        for line in lines:
            line_lower = line.lower()
            if any(indicator in line_lower for indicator in plan_indicators):
                plan_lines.append(line.strip())
        
        if plan_lines and len('\n'.join(plan_lines)) > 50:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„è®¡åˆ’å†…å®¹
            return '\n'.join(plan_lines)
        
        return None
    
    def _has_executable_plan(self, plan_content: str) -> bool:
        """ğŸ”§ æ–°å¢ï¼šåˆ¤æ–­è®¡åˆ’å†…å®¹æ˜¯å¦åŒ…å«å¯æ‰§è¡Œçš„å…·ä½“æ­¥éª¤"""
        if not plan_content or len(plan_content) < 30:
            return False
        
        plan_lower = plan_content.lower()
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å·¥å…·ç›¸å…³çš„æ‰§è¡Œæ„å›¾
        tool_indicators = [
            'search', 'execute', 'run', 'call', 'use', 'browser', 'python', 'code',
            'æœç´¢', 'æ‰§è¡Œ', 'è¿è¡Œ', 'è°ƒç”¨', 'ä½¿ç”¨', 'æµè§ˆå™¨', 'ä»£ç ', 'å·¥å…·'
        ]
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ˜ç¡®çš„æ‰§è¡Œæ­¥éª¤
        execution_indicators = [
            'step 1', 'first step', 'start by', 'begin with', 'initially',
            'ç¬¬ä¸€æ­¥', 'é¦–å…ˆ', 'å¼€å§‹', 'å…ˆ', 'ç¬¬1æ­¥'
        ]
        
        # æ£€æŸ¥å·¥å…·æœåŠ¡å™¨åç§°
        service_indicators = [
            'microsandbox', 'deepsearch', 'browser_use', 'search_tool'
        ]
        
        has_tools = any(indicator in plan_lower for indicator in tool_indicators)
        has_execution_steps = any(indicator in plan_lower for indicator in execution_indicators)
        has_services = any(indicator in plan_lower for indicator in service_indicators)
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤šä¸ªæ­¥éª¤ï¼ˆè¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªè¯¦ç»†è®¡åˆ’ï¼‰
        step_count = (
            plan_lower.count('step') + plan_lower.count('æ­¥éª¤') + 
            plan_lower.count('first') + plan_lower.count('then') + 
            plan_lower.count('next') + plan_lower.count('é¦–å…ˆ') + 
            plan_lower.count('ç„¶å') + plan_lower.count('æ¥ä¸‹æ¥')
        )
        
        has_multiple_steps = step_count >= 2
        
        # å¦‚æœæœ‰å·¥å…·æ„å›¾ã€æ‰§è¡Œæ­¥éª¤ã€æˆ–å¤šæ­¥è®¡åˆ’ï¼Œè®¤ä¸ºè¿™æ˜¯å¯æ‰§è¡Œè®¡åˆ’
        is_executable = (has_tools and has_execution_steps) or has_services or has_multiple_steps
        
        logger.debug(f"ğŸ” è®¡åˆ’åˆ†æ: å·¥å…·={has_tools}, æ‰§è¡Œæ­¥éª¤={has_execution_steps}, "
                    f"æœåŠ¡={has_services}, å¤šæ­¥éª¤={has_multiple_steps}, å¯æ‰§è¡Œ={is_executable}")
        
        return is_executable
    
    def _validate_calculation_context(self, trajectory_str: str, calculation_result: str) -> bool:
        """ğŸ”§ æ–°å¢ï¼šéªŒè¯è®¡ç®—ç»“æœæ˜¯å¦æ¥è‡ªçœŸå®çš„å·¥å…·æ‰§è¡Œä¸Šä¸‹æ–‡"""
        import re
        
        # 1. æ£€æŸ¥ç»“æœæ˜¯å¦å‡ºç°åœ¨å·¥å…·æ‰§è¡Œç»“æœæ ‡ç­¾å†…
        result_tag = TaskExecutionConstants.XML_TAGS['RESULT']
        result_pattern = f'<{result_tag}>(.*?)</{result_tag}>'
        result_blocks = re.findall(result_pattern, trajectory_str, re.DOTALL)
        
        # æ£€æŸ¥è®¡ç®—ç»“æœæ˜¯å¦åœ¨ä»»ä½•resultå—ä¸­
        for result_block in result_blocks:
            if calculation_result in result_block:
                logger.debug("âœ… è®¡ç®—ç»“æœåœ¨å·¥å…·æ‰§è¡Œç»“æœä¸­æ‰¾åˆ°")
                return True
        
        # 2. æ£€æŸ¥ç»“æœæ˜¯å¦åœ¨å·¥å…·æ‰§è¡Œçš„ä¸Šä¸‹æ–‡ä¸­ï¼ˆé™„è¿‘æœ‰å·¥å…·è°ƒç”¨ï¼‰
        # æŸ¥æ‰¾ç»“æœåœ¨è½¨è¿¹ä¸­çš„ä½ç½®
        result_index = trajectory_str.find(calculation_result)
        if result_index == -1:
            logger.debug("âŒ æœªæ‰¾åˆ°è®¡ç®—ç»“æœåœ¨è½¨è¿¹ä¸­çš„ä½ç½®")
            return False
        
        # æ£€æŸ¥ç»“æœå‰å500å­—ç¬¦å†…æ˜¯å¦æœ‰å·¥å…·æ‰§è¡Œæ ‡è®°
        context_start = max(0, result_index - 500)
        context_end = min(len(trajectory_str), result_index + len(calculation_result) + 500)
        context = trajectory_str[context_start:context_end]
        
        tool_execution_indicators = [
            '<execute_tools', '</execute_tools>', '<result>', '</result>',
            'microsandbox', 'deepsearch', 'browser_use', 'search_tool',
            'ä»£ç æ‰§è¡Œ', 'æ‰§è¡Œç»“æœ', 'å·¥å…·æ‰§è¡Œ', 'è®¡ç®—å®Œæˆ'
        ]
        
        has_tool_context = any(indicator in context for indicator in tool_execution_indicators)
        if has_tool_context:
            logger.debug("âœ… è®¡ç®—ç»“æœåœ¨å·¥å…·æ‰§è¡Œä¸Šä¸‹æ–‡ä¸­")
            return True
        
        # 3. æ£€æŸ¥æ˜¯å¦æ˜¯çº¯æ€è€ƒè¿‡ç¨‹ä¸­çš„è™šå‡è®¡ç®—
        think_tag = TaskExecutionConstants.XML_TAGS['THINK']
        think_pattern = f'<{think_tag}>(.*?)</{think_tag}>'
        think_blocks = re.findall(think_pattern, trajectory_str, re.DOTALL)
        
        for think_block in think_blocks:
            if calculation_result in think_block:
                # å¦‚æœç»“æœåªåœ¨æ€è€ƒè¿‡ç¨‹ä¸­ï¼Œä¸”æ²¡æœ‰å¯¹åº”çš„å·¥å…·æ‰§è¡Œï¼Œåˆ™è®¤ä¸ºæ˜¯è™šå‡çš„
                logger.debug("âš ï¸ è®¡ç®—ç»“æœåªåœ¨æ€è€ƒè¿‡ç¨‹ä¸­å‘ç°ï¼Œå¯èƒ½æ˜¯è™šå‡ç»“æœ")
                return False
        
        # 4. æ£€æŸ¥ç»“æœæ˜¯å¦æœ‰åˆç†çš„æ•°å€¼æ ¼å¼å’Œå•ä½
        # å¦‚æœæ˜¯çº¯å­—æ¯ï¼ˆå¦‚"e"ï¼‰ï¼Œå¾ˆå¯èƒ½æ˜¯è™šå‡ç»“æœ
        if re.match(r'^[a-zA-Z]$', calculation_result.strip()):
            logger.debug("âŒ è®¡ç®—ç»“æœæ˜¯å•ä¸ªå­—æ¯ï¼Œå¯èƒ½æ˜¯è™šå‡ç»“æœ")
            return False
        
        # 5. é»˜è®¤æƒ…å†µï¼šå¦‚æœç»“æœçœ‹èµ·æ¥åˆç†ä¸”æ²¡æœ‰æ˜æ˜¾é—®é¢˜ï¼Œå…è®¸é€šè¿‡
        logger.debug("ğŸ”§ è®¡ç®—ç»“æœé€šè¿‡åŸºæœ¬éªŒè¯")
        return True
    
    def _has_meaningful_tool_results(self, trajectory_str: str) -> bool:
        """ğŸ”§ æ–°å¢ï¼šæ£€æŸ¥å·¥å…·æ‰§è¡Œæ˜¯å¦äº§ç”Ÿäº†æœ‰æ„ä¹‰çš„ç»“æœ"""
        import re
        
        result_tag = TaskExecutionConstants.XML_TAGS['RESULT']
        result_pattern = f'<{result_tag}>(.*?)</{result_tag}>'
        result_blocks = re.findall(result_pattern, trajectory_str, re.DOTALL)
        
        meaningful_results = 0
        for result_block in result_blocks:
            result_clean = result_block.strip()
            
            # æ’é™¤æ— æ„ä¹‰çš„ç»“æœ
            if (len(result_clean) > 20 and  # æœ‰è¶³å¤Ÿçš„å†…å®¹
                TaskExecutionConstants.NO_ACTION_PERFORMED not in result_clean and
                "No executable action detected" not in result_clean and
                "Error:" not in result_clean and
                "failed" not in result_clean.lower()):
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰ä»·å€¼çš„ä¿¡æ¯
                has_data = any(indicator in result_clean.lower() for indicator in [
                    'result', 'found', 'success', 'completed', 'ç»“æœ', 'æˆåŠŸ', 'å®Œæˆ',
                    'http', 'www', 'search', 'execute', 'calculation', 'answer'
                ])
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«æ•°å€¼ã€ä»£ç æ‰§è¡Œç»“æœæˆ–æœç´¢ç»“æœ
                has_numerical = re.search(r'\d+', result_clean)
                has_technical_content = any(keyword in result_clean.lower() for keyword in [
                    'python', 'code', 'execute', 'import', 'def', 'return',
                    'search results', 'æœç´¢ç»“æœ', 'photocurrent', 'iora'
                ])
                
                if has_data or has_numerical or has_technical_content:
                    meaningful_results += 1
        
        # å¦‚æœæœ‰è‡³å°‘ä¸€ä¸ªæœ‰æ„ä¹‰çš„å·¥å…·ç»“æœï¼Œè®¤ä¸ºå·¥å…·æ‰§è¡Œæœ‰æ„ä¹‰
        has_meaningful = meaningful_results > 0
        logger.debug(f"ğŸ” å·¥å…·ç»“æœåˆ†æ: æ€»ç»“æœå—={len(result_blocks)}, æœ‰æ„ä¹‰ç»“æœ={meaningful_results}, åˆ¤å®š={has_meaningful}")
        
        return has_meaningful
        
    def _detect_success(self, response: str) -> bool:
        """æ£€æµ‹XMLå“åº”æ˜¯å¦æˆåŠŸ - ä¿ç•™å‘åå…¼å®¹æ€§"""
        response_lower = response.lower()
        return ('<answer>' in response_lower) and ('error>' not in response_lower)
    
    def _get_trajectory_file_path(self, task_id: str, is_raw: bool = False) -> str:
        """æ ¹æ®å­˜å‚¨æ¨¡å¼è·å–è½¨è¿¹æ–‡ä»¶è·¯å¾„"""
        out_dir = get_trajectories_dir()
        date_str = datetime.now().strftime("%Y-%m-%d")
        group_dir = os.path.join(out_dir, "grouped", date_str)
        if is_raw:
            return os.path.join(group_dir, f"raw_trajectories_{date_str}.jsonl")
        else:
            return os.path.join(group_dir, f"trajectories_{date_str}.jsonl")
    
    async def _save_xml_output(self, xml_output):
        """ä¿å­˜XMLè¾“å‡ºæ•°æ®åˆ°JSONLæ–‡ä»¶"""
        file_path = self._get_trajectory_file_path(xml_output['task_id'])
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        
        with open(file_path, 'a', encoding='utf-8') as f:
            f.write(json.dumps(xml_output, ensure_ascii=False) + '\n')
        
        logger.info(f"ä¿å­˜XMLæ•°æ®åˆ°: {file_path}")
    
    def _detect_triggered_stop_sequence(self, response_text: str, stop_sequences: list) -> str:
        """æ£€æµ‹è§¦å‘çš„åœæ­¢åºåˆ—"""
        for stop_seq in stop_sequences:
            if stop_seq in response_text:
                return stop_seq
        return "unknown"
    
    async def _execute_tool_with_logging(self, action: dict, execution_index: int) -> dict:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨å¹¶è®°å½•è¯¦ç»†æ—¥å¿—"""
        tool_start_time = time.time()
        
        # æ„å»ºtoolscoreè¯·æ±‚
        service_name = action.get('service')
        tool_name = action.get('tool')
        tool_input = action.get('input')
        
        param_mapping = {
            "browser_use": "query",
            "microsandbox": "code",
            "deepsearch": "question"
        }
        param_name = param_mapping.get(service_name, "input")
        
        toolscore_request = {
            "endpoint": f"http://127.0.0.1:{self._get_service_port(service_name)}/execute_tool",
            "method": "POST",
            "payload": {
                "tool_id": service_name,
                "action": tool_name,
                "parameters": {param_name: tool_input}
            }
        }
        
        # ğŸ”§ æ™ºèƒ½å·¥å…·æ‰§è¡Œä¸é”™è¯¯åˆ†æ
        try:
            raw_result = await self.toolscore_client.execute_tool(
                tool_id=service_name,
                action=tool_name,
                parameters={param_name: tool_input}
            )
            
            formatted_result = self._format_tool_output(service_name, tool_name, raw_result)
            execution_status = "success"
            error_details = None
            
        except Exception as e:
            error_str = str(e)
            error_type = self._analyze_error_type(error_str)
            
            raw_result = {"error": error_str, "success": False, "error_type": error_type}
            formatted_result = self._format_error_with_recovery_suggestion(error_str, error_type, service_name, tool_name)
            execution_status = "failure"
            error_details = error_str
        
        tool_end_time = time.time()
        
        # ğŸ” è®°å½•å·¥å…·æ‰§è¡Œæ—¥å¿—
        self.step_logger.log_tool_execution(
            execution_index=execution_index,
            action=action,
            toolscore_request=toolscore_request,
            raw_response=raw_result,
            formatted_result=formatted_result,
            start_time=tool_start_time,
            end_time=tool_end_time,
            execution_status=execution_status,
            error_details=error_details
        )
        
        return {
            "formatted_result": formatted_result,
            "raw_result": raw_result,
            "execution_status": execution_status
        }
    
    async def _execute_parallel_with_logging(self, actions: list) -> list:
        """å¹¶å‘æ‰§è¡Œå¤šä¸ªå·¥å…·è°ƒç”¨å¹¶è®°å½•æ—¥å¿—"""
        import asyncio
        
        if not actions:
            return []
        
        # åˆ›å»ºå¹¶å‘ä»»åŠ¡
        tasks = [
            self._execute_tool_with_logging(action, i) 
            for i, action in enumerate(actions)
        ]
        
        # å¹¶å‘æ‰§è¡Œ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # æå–æ ¼å¼åŒ–ç»“æœ
        formatted_results = []
        for result in results:
            if isinstance(result, Exception):
                formatted_results.append(f"Error: {result}")
            else:
                formatted_results.append(result["formatted_result"])
        
        return formatted_results
    
    def _get_service_port(self, service_name: str) -> int:
        """è·å–æœåŠ¡ç«¯å£å·"""
        port_mapping = {
            "microsandbox": 8090,
            "deepsearch": 8086,
            "browser_use": 8082,
            "search_tool": 8080
        }
        return port_mapping.get(service_name, 8080)

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        logger.info("ğŸ§¹ æ¸…ç†Enhanced Reasoning Runtimeèµ„æº")
        if self.toolscore_client and hasattr(self.toolscore_client, 'close'):
            await self.toolscore_client.close()
        self.is_initialized = False
        logger.info("âœ… èµ„æºæ¸…ç†å®Œæˆ")
    
