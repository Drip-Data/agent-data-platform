"""
å¢å¼ºæ¨ç†è¿è¡Œæ—¶ - ç®€åŒ–ç‰ˆæœ¬ï¼Œä¸“æ³¨LLMæ¨ç†å’Œæ‰§è¡Œ
ä½¿ç”¨ToolScore APIè¿›è¡Œå·¥å…·ç®¡ç†ï¼Œç§»é™¤å¤æ‚çš„æœ¬åœ°å·¥å…·ç®¡ç†é€»è¾‘
"""

import asyncio
import json
import logging
import os
import time
import uuid
from typing import Dict, Any, Optional, List
from core.interfaces import RuntimeInterface, TaskSpec, TrajectoryResult, ExecutionStep, ErrorType, ActionType
from core.llm_client import LLMClient
from core.metrics import EnhancedMetrics
from core.toolscore.mcp_client import MCPToolClient
from runtimes.reasoning.toolscore_client import ToolScoreClient
from runtimes.reasoning.real_time_tool_client import RealTimeToolClient

logger = logging.getLogger(__name__)

class EnhancedReasoningRuntime(RuntimeInterface):
    """å¢å¼ºæ¨ç†è¿è¡Œæ—¶ - ç®€åŒ–ç‰ˆæœ¬ï¼Œä¸“æ³¨LLMæ¨ç†å’Œæ‰§è¡Œ"""
    
    def __init__(self):
        self._runtime_id = f"enhanced-reasoning-{uuid.uuid4()}"
        self.config = {
            'vllm_url': os.getenv('VLLM_URL', 'http://vllm:8000'),
            'gemini_api_key': os.getenv('GEMINI_API_KEY', ''),
            'gemini_api_url': os.getenv('GEMINI_API_URL', ''),
            'provider': 'gemini',
            'save_individual_trajectories': os.getenv("SAVE_INDIVIDUAL_TRAJECTORIES", "").lower() in ("1", "true", "yes")
        }
        self.client = LLMClient(self.config)
        self.metrics = EnhancedMetrics(port=8003)
        
        # ç®€åŒ–çš„å·¥å…·ç®¡ç†æ¶æ„
        self.toolscore_endpoint = os.getenv('TOOLSCORE_HTTP_URL', 'http://localhost:8082')
        self.toolscore_websocket_endpoint = os.getenv('TOOLSCORE_WS_URL', 'ws://localhost:8082')
        
        # è½»é‡çº§å®¢æˆ·ç«¯
        self.toolscore_client = ToolScoreClient(self.toolscore_endpoint)
        self.real_time_client = RealTimeToolClient(self.toolscore_websocket_endpoint)
        
        # ä¿ç•™MCPå®¢æˆ·ç«¯ç”¨äºç›´æ¥å·¥å…·è°ƒç”¨
        toolscore_url = os.getenv('TOOLSCORE_URL', 'ws://toolscore:8080/websocket')
        self.mcp_client = MCPToolClient(toolscore_url)
        
        # ç­‰å¾…å·¥å…·å®‰è£…çš„ä»»åŠ¡
        self.pending_tool_requests = {}
        # ğŸ“Œ ç¼“å­˜å®æ—¶å·¥å…·äº‹ä»¶ï¼Œä¾¿äºå†™å…¥è½¨è¿¹
        self._tool_event_buffer = []
        
    async def initialize(self):
        """åˆå§‹åŒ–è¿è¡Œæ—¶ - ç®€åŒ–ä¸ºçº¯å·¥å…·æ¶ˆè´¹è€…"""
        logger.info("ğŸš€ åˆå§‹åŒ–Enhanced Reasoning Runtime - ç®€åŒ–ç‰ˆæœ¬")
        
        # ç­‰å¾…ToolScoreæœåŠ¡å°±ç»ª
        logger.info("â³ ç­‰å¾…ToolScoreæœåŠ¡å°±ç»ª...")
        toolscore_ready = await self.toolscore_client.wait_for_ready()
        if not toolscore_ready:
            logger.error("âŒ ToolScoreæœåŠ¡æœªå°±ç»ªï¼Œå°†ä½¿ç”¨é™çº§æ¨¡å¼")
        else:
            logger.info("âœ… ToolScore HTTPæœåŠ¡å·²å°±ç»ª")
        
        # è¿æ¥å®æ—¶æ›´æ–°
        logger.info(f"ğŸ”Œ æ­£åœ¨è¿æ¥WebSocketç«¯ç‚¹: {self.toolscore_websocket_endpoint}")
        try:
            await self.real_time_client.connect_real_time_updates()
            logger.info("âœ… WebSocketå®æ—¶æ›´æ–°è¿æ¥æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ WebSocketè¿æ¥å¤±è´¥ï¼Œå°†ç»§ç»­è¿è¡Œä½†ä¸ä¼šæ¥æ”¶å®æ—¶æ›´æ–°: {e}")
            # ä¸é˜»æ­¢åˆå§‹åŒ–ç»§ç»­è¿›è¡Œ
        
        # æ³¨å†Œå·¥å…·æ›´æ–°å›è°ƒ
        await self.real_time_client.register_tool_update_callback(
            self._on_new_tool_available
        )
        
        # å¯åŠ¨å®šæœŸæ¸…ç†ä»»åŠ¡
        asyncio.create_task(self._periodic_cleanup())
        
        logger.info("âœ… Enhanced Reasoning Runtime å·²æˆåŠŸåˆå§‹åŒ–ä¸ºçº¯æ¨ç†å¼•æ“")
        
    async def _on_new_tool_available(self, tool_event: Dict[str, Any]):
        """æ–°å·¥å…·å¯ç”¨æ—¶çš„å›è°ƒ"""
        tool_id = tool_event.get("tool_id")
        tool_name = tool_event.get("name", tool_id)
        
        logger.info(f"ğŸ‰ æ£€æµ‹åˆ°æ–°å·¥å…·: {tool_name} ({tool_id})")
        
        # å†™å…¥äº‹ä»¶ç¼“å†²åŒºï¼Œä¾›å½“å‰æ‰§è¡Œä¸­çš„ä»»åŠ¡è®°å½•
        self._tool_event_buffer.append({
            "tool_id": tool_id,
            "name": tool_name,
            "event": tool_event,
            "timestamp": time.time()
        })
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç­‰å¾…è¿™ä¸ªå·¥å…·çš„ä»»åŠ¡
        completed_requests = []
        for task_id, request_info in list(self.pending_tool_requests.items()):
            if self._tool_matches_requirement(tool_event, request_info.get("required_capabilities", [])):
                logger.info(f"ğŸš€ æ¢å¤ç­‰å¾…ä»»åŠ¡: {task_id} (æ–°å·¥å…·: {tool_id})")
                
                # æ‰§è¡Œæ¢å¤å›è°ƒ
                callback = request_info.get("resume_callback")
                if callback:
                    try:
                        await callback(tool_event)
                    except Exception as e:
                        logger.error(f"ä»»åŠ¡æ¢å¤å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")
                
                completed_requests.append(task_id)
        
        # æ¸…ç†å·²å®Œæˆçš„è¯·æ±‚
        for task_id in completed_requests:
            self.pending_tool_requests.pop(task_id, None)
    
    def _tool_matches_requirement(self, tool_event: Dict[str, Any], 
                                required_capabilities: List[str]) -> bool:
        """æ£€æŸ¥å·¥å…·æ˜¯å¦æ»¡è¶³éœ€æ±‚"""
        if not required_capabilities:
            return True
        
        tool_capabilities = tool_event.get("capabilities", [])
        tool_capability_names = []
        
        # æå–èƒ½åŠ›åç§°
        for cap in tool_capabilities:
            if isinstance(cap, dict):
                tool_capability_names.append(cap.get("name", ""))
            elif isinstance(cap, str):
                tool_capability_names.append(cap)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…çš„èƒ½åŠ›
        for required_cap in required_capabilities:
            for tool_cap in tool_capability_names:
                if required_cap.lower() in tool_cap.lower() or tool_cap.lower() in required_cap.lower():
                    return True
        
            return False
            
    async def _periodic_cleanup(self):
        """å®šæœŸæ¸…ç†è¿‡æœŸè¯·æ±‚"""
        while True:
            try:
                await asyncio.sleep(60)  # æ¯åˆ†é’Ÿæ¸…ç†ä¸€æ¬¡
                await self.real_time_client.cleanup_expired_requests()

                # æ¸…ç†æœ¬åœ°çš„è¿‡æœŸè¯·æ±‚
                current_time = time.time()
                expired_requests = []
                for task_id, request_info in self.pending_tool_requests.items():
                    if current_time - request_info.get("timestamp", 0) > 300:  # 5åˆ†é’Ÿè¿‡æœŸ
                        expired_requests.append(task_id)

                for task_id in expired_requests:
                    self.pending_tool_requests.pop(task_id, None)
                    logger.info(f"æ¸…ç†è¿‡æœŸä»»åŠ¡è¯·æ±‚: {task_id}")
                
            except Exception as e:
                    logger.error(f"å®šæœŸæ¸…ç†ä»»åŠ¡å¼‚å¸¸: {e}")

    @property
    def runtime_id(self) -> str:
        return self._runtime_id

    async def capabilities(self) -> list:
        """è·å–è¿è¡Œæ—¶èƒ½åŠ›"""
        return ['llm_reasoning', 'tool_execution', 'dynamic_tool_request']

    async def health_check(self) -> bool:
        """å¥åº·æ£€æŸ¥"""
        try:
            # æ£€æŸ¥LLMå®¢æˆ·ç«¯
            await self.client.generate_reasoning("health check", [], [])
            
            # æ£€æŸ¥ToolScoreè¿æ¥
            toolscore_healthy = await self.toolscore_client.health_check()
            
            return toolscore_healthy
        except:
            return False

    async def execute(self, task: TaskSpec) -> TrajectoryResult:
        """æ‰§è¡Œä»»åŠ¡"""
        logger.info(f"ğŸ§  å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task.description}")
        start_time = time.time()
        trajectory_id = task.task_id
        success = False
        final_trajectory_error_type = None
        final_trajectory_error_message = None
        
        steps: List[ExecutionStep] = []
        max_steps = 10
        max_retries = 1
        retry_delay_seconds = 2
        current_outputs = []  # ç”¨äºå­˜å‚¨æ¯æ­¥çš„è¾“å‡º
        
        # ğŸ” æ–°å¢ï¼šæ”¶é›†LLMäº¤äº’ä¿¡æ¯
        current_step_llm_interactions = []
        
        # è·å–å¯ç”¨å·¥å…·æè¿°
        logger.info("ğŸ“‹ ä»ToolScoreè·å–å¯ç”¨å·¥å…·...")
        available_tools_description = await self.real_time_client.get_fresh_tools_for_llm(
            fallback_client=self.toolscore_client
        )
        logger.info(f"ğŸ“‹ è·å–åˆ°å·¥å…·æè¿°é•¿åº¦: {len(available_tools_description)} å­—ç¬¦")

        # === è®°å½•é¦–æ¬¡æš´éœ²ç»™ LLM çš„å·¥å…·é›†åˆ ===
        expose_step = ExecutionStep(
            step_id=len(steps)+1,
            action_type=ActionType.TOOL_CALL,
            action_params={"tools_snapshot": available_tools_description},
            observation="Tools exposed to LLM for planning",
            success=True
        )
        steps.append(expose_step)

        # æ™ºèƒ½ä»»åŠ¡éœ€æ±‚åˆ†æ
        logger.info("ğŸ§  å¼€å§‹æ™ºèƒ½ä»»åŠ¡éœ€æ±‚åˆ†æ...")
                
        # ğŸ” æ–°å¢ï¼šè®°å½•ä»»åŠ¡éœ€æ±‚åˆ†æçš„LLMäº¤äº’
        task_analysis_interactions = []
        original_call_api = self.client._call_api
        async def wrapped_call_api_for_analysis(prompt: str) -> str:
            interaction_start = time.time()
            response = await original_call_api(prompt)
            
            from core.interfaces import LLMInteraction
            interaction = LLMInteraction(
                provider=self.client.provider.value if hasattr(self.client.provider, 'value') else str(self.client.provider),
                model=getattr(self.client, 'model', 'unknown'),
                context="task_requirements_analysis",
                prompt=prompt,
                prompt_length=len(prompt),
                prompt_type="task_analysis",
                response=response,
                response_length=len(response),
                response_time=time.time() - interaction_start
            )
            task_analysis_interactions.append(interaction)
            return response
        
        # ä¸´æ—¶æ›¿æ¢æ–¹æ³•è¿›è¡Œä»»åŠ¡åˆ†æ
        self.client._call_api = wrapped_call_api_for_analysis
        try:
            task_requirements = await self.client.analyze_task_requirements(task.description)
        finally:
            self.client._call_api = original_call_api
        
        logger.info("âœ… ä»»åŠ¡éœ€æ±‚åˆ†æå®Œæˆ:")
        logger.info(f"   ä»»åŠ¡ç±»å‹: {task_requirements.get('task_type')}")
        logger.info(f"   æ‰€éœ€èƒ½åŠ›: {task_requirements.get('required_capabilities', [])}")
        logger.info(f"   æ¨èå·¥å…·ç±»å‹: {task_requirements.get('tools_needed', [])}")
        logger.info(f"   ç½®ä¿¡åº¦: {task_requirements.get('confidence')}")
        
        # ä¿å­˜ä»»åŠ¡åˆ†æçš„LLMäº¤äº’åˆ°ç¬¬ä¸€æ­¥çš„é¢„å¤‡é˜¶æ®µ
        current_step_llm_interactions.extend(task_analysis_interactions)

        """### è‡ªåŠ¨ç¼ºå£æ£€æµ‹ & ä¿®å¤ ###"""
        try:
            # æ‹‰å–å½“å‰å·²æ³¨å†Œå·¥å…·ï¼ˆå­—å…¸åˆ—è¡¨å½¢å¼ï¼‰
            tools_resp = await self.toolscore_client.get_available_tools()
            current_tools_meta = tools_resp.get("available_tools", [])

            gap_result = await self.toolscore_client.analyze_tool_gap(
                task_description=task.description,
                current_tools=current_tools_meta
            )

            if gap_result and not gap_result.get("has_sufficient_tools", True):
                missing_caps = gap_result.get("gap_analysis", {}).get("missing_capabilities", [])

                logger.info(
                    f"âš  æ£€æµ‹åˆ°èƒ½åŠ›ç¼ºå£ï¼Œç¼ºå°‘: {missing_caps or 'æœªçŸ¥'}. æ­£åœ¨è¯·æ±‚ ToolScore è‡ªåŠ¨å®‰è£…â€¦")

                cap_req_res = await self.toolscore_client.request_tool_capability(
                    task_description=task.description,
                    required_capabilities=missing_caps,
                    auto_install=True
                )

                if cap_req_res.get("success") and cap_req_res.get("installed_tools"):
                    logger.info(
                        f"ğŸ›  å·²è§¦å‘å®‰è£… {len(cap_req_res['installed_tools'])} ä¸ªå·¥å…·ï¼Œæ³¨å†Œç­‰å¾…äº‹ä»¶â€¦")

                    # é€šè¿‡ RealTimeToolClient ç­‰å¾…æ–°å·¥å…·ï¼›æ³¨å†Œå›è°ƒä½†åŒæ—¶è½®è¯¢ï¼Œæœ€å¤š 60s
                    await self.real_time_client.register_pending_request(
                        request_id=f"{task.task_id}-auto-gap-fix", 
                        required_capabilities=missing_caps
                    )

                    wait_start = time.time()
                    WAIT_TIMEOUT = 60
                    while time.time() - wait_start < WAIT_TIMEOUT:
                        # åˆ¤æ–­æ˜¯å¦å·²æ»¡è¶³èƒ½åŠ›
                        fresh_tools = await self.toolscore_client.get_available_tools()
                        fresh_caps_ok = False
                        for tool in fresh_tools.get("available_tools", []):
                            caps = [c.get("name") if isinstance(c, dict) else c for c in tool.get("capabilities", [])]
                            if any(any(mc.lower() in (cap or "").lower() for cap in caps) for mc in missing_caps):
                                fresh_caps_ok = True
                                break
                        if fresh_caps_ok:
                            logger.info("âœ… ç¼ºå£å·¥å…·å·²å°±ä½ï¼Œç»§ç»­ä»»åŠ¡æ‰§è¡Œ")
                            break
                        await asyncio.sleep(2)
                else:
                    logger.warning("ToolScore æœªèƒ½è‡ªåŠ¨å®‰è£…æ‰€éœ€å·¥å…·ï¼Œåç»­å¯èƒ½ä¾èµ– LLM è‡ªè¡Œæ£€ç´¢ã€‚")
        except Exception as auto_gap_err:
            logger.error(f"è‡ªåŠ¨ç¼ºå£æ£€æµ‹/ä¿®å¤è¿‡ç¨‹å¼‚å¸¸: {auto_gap_err}")

        for step_id in range(1, max_steps + 1):
            # ğŸ” é‡ç½®å½“å‰æ­¥éª¤çš„LLMäº¤äº’è®°å½•
            current_step_llm_interactions = []
            
            logger.info(f"ğŸ”„ æ‰§è¡Œæ­¥éª¤ {step_id}/{max_steps}")
            
            tool_start = time.time()
            observation = ""
            current_attempt_err_type = None
            current_attempt_err_msg = None
            tool_success = False
            action_type = ActionType.TOOL_CALL
            thinking = ""
            execution_code = ""
            
            # ğŸ” æ–°å¢ï¼šåŒ…è£…LLMå®¢æˆ·ç«¯ä»¥æ”¶é›†äº¤äº’ä¿¡æ¯
            original_call_api = self.client._call_api
            async def wrapped_call_api(prompt: str) -> str:
                # è®°å½•LLMäº¤äº’å¼€å§‹
                interaction_start = time.time()
                
                # è°ƒç”¨åŸå§‹æ–¹æ³•
                response = await original_call_api(prompt)
                
                # è®°å½•LLMäº¤äº’
                from core.interfaces import LLMInteraction
                interaction = LLMInteraction(
                    provider=self.client.provider.value if hasattr(self.client.provider, 'value') else str(self.client.provider),
                    model=getattr(self.client, 'model', 'unknown'),
                    context=f"step_{step_id}_reasoning",
                    prompt=prompt,
                    prompt_length=len(prompt),
                    prompt_type="task_execution",
                    response=response,
                    response_length=len(response),
                    response_time=time.time() - interaction_start
                )
                current_step_llm_interactions.append(interaction)
                return response
            
            # ä¸´æ—¶æ›¿æ¢æ–¹æ³•
            self.client._call_api = wrapped_call_api
            
            try:
                # è·å–ä¸‹ä¸€ä¸ªåŠ¨ä½œ
                serializable_steps = [s.to_dict() if hasattr(s, 'to_dict') else s.__dict__ for s in steps]
                
                # è·å–å·²æ³¨å†Œå·¥å…·IDåˆ—è¡¨å’Œæè¿°
                registered_tools = await self.toolscore_client.get_available_tools()
                available_tool_ids = [tool.get('tool_id') for tool in registered_tools.get('available_tools', [])]
                available_tools_description = await self.real_time_client.get_fresh_tools_for_llm(
                    fallback_client=self.toolscore_client
                )
                
                action_result = await self.client.generate_enhanced_reasoning(
                    task_description=task.description,
                    available_tools=available_tool_ids,  # æ·»åŠ å·²æ³¨å†Œå·¥å…·IDåˆ—è¡¨
                    tool_descriptions=available_tools_description,  # è¯¦ç»†å·¥å…·æè¿°
                    previous_steps=serializable_steps,
                    execution_context={}
                )
                
                thinking = action_result.get('thinking', f"Step {step_id}: Analyzing task and deciding next action")
                action = action_result.get('action')
                tool_id = action_result.get('tool_id') or action_result.get('tool')
                params = action_result.get('parameters', {})
                
                # æ·»åŠ actionå’Œtool_idåˆ°paramsä¸­ä»¥ä¿æŒå…¼å®¹æ€§
                if action:
                    params['action'] = action
                if tool_id:
                    params['tool_id'] = tool_id

                execution_code = json.dumps({
                    'action': action,
                    'tool_id': tool_id,
                    'parameters': params
                }, ensure_ascii=False)
            finally:
                # æ¢å¤åŸå§‹æ–¹æ³•
                self.client._call_api = original_call_api

            # å°è¯•æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼ŒåŒ…å«é‡è¯•æœºåˆ¶
            for attempt in range(max_retries + 1):
                
                # ç‰¹æ®Šå¤„ç†ï¼šæ£€æŸ¥æ˜¯å¦å®Œæˆä»»åŠ¡
                if action == 'complete_task':
                    logger.info("ğŸ¯ LLMè®¤ä¸ºä»»åŠ¡å·²å®Œæˆ")
                    
                    # ğŸ” æ–°å¢ï¼šè®°å½•å®Œæˆä»»åŠ¡çš„æ€»ç»“ç”ŸæˆLLMäº¤äº’
                    complete_summary_interactions = []
                    original_call_api_complete = self.client._call_api
                    async def wrapped_call_api_for_complete_summary(prompt: str) -> str:
                        interaction_start = time.time()
                        response = await original_call_api_complete(prompt)
                        
                        from core.interfaces import LLMInteraction
                        interaction = LLMInteraction(
                            provider=self.client.provider.value if hasattr(self.client.provider, 'value') else str(self.client.provider),
                            model=getattr(self.client, 'model', 'unknown'),
                            context=f"step_{step_id}_complete_task_summary",
                            prompt=prompt,
                            prompt_length=len(prompt),
                            prompt_type="complete_task_summary",
                            response=response,
                            response_length=len(response),
                            response_time=time.time() - interaction_start
                        )
                        complete_summary_interactions.append(interaction)
                        return response
                    
                    self.client._call_api = wrapped_call_api_for_complete_summary
                    try:
                        summary = await self.client.generate_task_summary(
                            task.description, [s.__dict__ for s in steps], current_outputs
                        )
                    finally:
                        self.client._call_api = original_call_api_complete
                    
                    # å°†å®Œæˆä»»åŠ¡çš„æ€»ç»“LLMäº¤äº’æ·»åŠ åˆ°å½“å‰æ­¥éª¤
                    current_step_llm_interactions.extend(complete_summary_interactions)
                    success = True
                    observation = summary
                    tool_success = True
                    action_type = ActionType.TOOL_CALL
                    
                    duration = time.time() - tool_start
                    steps.append(ExecutionStep(
                        step_id=step_id,
                        action_type=action_type,
                        action_params=params,
                        observation=observation,
                        success=True,
                        thinking=thinking,
                        execution_code=execution_code,
                        error_type=None,
                        error_message=None,
                        timestamp=time.time(),
                        duration=duration,
                        llm_interactions=current_step_llm_interactions  # ğŸ” æ–°å¢
                    ))
                    break
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å·¥å…·èƒ½åŠ›è¯·æ±‚
                elif action == 'request_tool_capability' or (tool_id and 'search' in tool_id.lower()):
                    logger.info("ğŸ” æ£€æµ‹åˆ°å·¥å…·èƒ½åŠ›è¯·æ±‚ï¼Œå‘èµ·ToolScore APIè°ƒç”¨")
                    
                    # ä»å‚æ•°ä¸­æå–ä»»åŠ¡æè¿°å’Œèƒ½åŠ›éœ€æ±‚
                    task_desc = params.get('task_description', task.description)
                    required_caps = params.get('required_capabilities', [])
                    reason = params.get('reason', '')
                    
                    # å¦‚æœæœ‰ç†ç”±ï¼Œæå–å¯èƒ½çš„èƒ½åŠ›éœ€æ±‚
                    if reason and not required_caps:
                        # ç®€å•çš„å…³é”®è¯æå–
                        if 'image' in reason.lower() or 'picture' in reason.lower():
                            required_caps = ['image_generation']
                        elif 'file' in reason.lower() or 'document' in reason.lower():
                            required_caps = ['file_processing']
                        elif 'web' in reason.lower() or 'scraping' in reason.lower():
                            required_caps = ['web_scraping']
                    
                    # è°ƒç”¨ToolScore API
                    capability_result = await self.toolscore_client.request_tool_capability(
                        task_description=task_desc,
                        required_capabilities=required_caps,
                        auto_install=True
                    )
                    
                    if capability_result.get("success"):
                        # å·¥å…·å®‰è£…æˆåŠŸ
                        installed_tools = capability_result.get("installed_tools", [])
                        processing_time = capability_result.get("processing_time_ms", 0)
                        
                        if installed_tools:
                            tool_names = [tool.get("name", tool.get("tool_id", "unknown")) for tool in installed_tools]
                            observation = f"æˆåŠŸå®‰è£…äº† {len(installed_tools)} ä¸ªæ–°å·¥å…·: {', '.join(tool_names)}ã€‚å¤„ç†æ—¶é—´: {processing_time}msã€‚æ–°å·¥å…·ç°åœ¨å¯ä»¥ä½¿ç”¨ã€‚"
                            
                            # æ³¨å†Œç­‰å¾…æ–°å·¥å…·çš„å›è°ƒ
                            await self.real_time_client.register_pending_request(
                                request_id=f"{trajectory_id}-step-{step_id}",
                                required_capabilities=required_caps,
                                callback=self._create_tool_available_callback(trajectory_id, step_id)
                            )
                            
                            # æ›´æ–°å·¥å…·åˆ—è¡¨
                            registered_tools = await self.toolscore_client.get_available_tools()
                            available_tool_ids = [tool.get('tool_id') for tool in registered_tools.get('available_tools', [])]
                            available_tools_description = await self.real_time_client.get_fresh_tools_for_llm(
                                fallback_client=self.toolscore_client
                            )
                        else:
                            observation = "å·¥å…·å®‰è£…è¯·æ±‚å·²å¤„ç†ï¼Œä½†æœªå®‰è£…æ–°å·¥å…·ã€‚ç°æœ‰å·¥å…·å¯èƒ½å·²æ»¡è¶³éœ€æ±‚ã€‚"
                        
                        tool_success = True
                    else:
                        # å·¥å…·å®‰è£…å¤±è´¥
                        error_msg = capability_result.get("message", "æœªçŸ¥é”™è¯¯")
                        observation = f"å·¥å…·èƒ½åŠ›è¯·æ±‚å¤±è´¥: {error_msg}"
                        tool_success = False
                        current_attempt_err_type = ErrorType.TOOL_ERROR
                        current_attempt_err_msg = error_msg
                
                # ğŸ” æ–°å¢ï¼šå¤„ç†mcp-search-toolçš„è°ƒç”¨
                elif tool_id == 'mcp-search-tool' or action in ['search_and_install_tools', 'analyze_tool_needs']:
                    logger.info(f"ğŸ› ï¸ æ£€æµ‹åˆ°mcp-search-toolè°ƒç”¨: action={action}")
                    
                    try:
                        # ğŸ” é€šè¿‡ToolScore APIè°ƒç”¨mcp-search-tool
                        if action == 'analyze_tool_needs':
                            # åˆ†æå·¥å…·éœ€æ±‚
                            task_desc = params.get('task_description', task.description)
                            
                            # è°ƒç”¨ToolScoreçš„å·¥å…·åˆ†æAPI
                            analysis_result = await self.toolscore_client.analyze_tool_needs(
                                task_description=task_desc
                            )
                            
                            if analysis_result.get("success"):
                                analysis = analysis_result.get("analysis", {})
                                needed_tools = analysis.get("needed_tools", [])
                                recommendations = analysis.get("recommendations", "")
                                
                                observation = f"å·¥å…·éœ€æ±‚åˆ†æå®Œæˆã€‚éœ€è¦çš„å·¥å…·ç±»å‹: {', '.join(needed_tools)}ã€‚å»ºè®®: {recommendations}"
                                tool_success = True
                            else:
                                error_msg = analysis_result.get("message", "åˆ†æå¤±è´¥")
                                observation = f"å·¥å…·éœ€æ±‚åˆ†æå¤±è´¥: {error_msg}"
                                tool_success = False
                                
                        elif action == 'search_and_install_tools':
                            # æœç´¢å¹¶å®‰è£…å·¥å…·
                            task_desc = params.get('task_description', task.description)
                            reason = params.get('reason', '')
                            
                            # è°ƒç”¨ToolScoreçš„å·¥å…·æœç´¢å’Œå®‰è£…API
                            search_result = await self.toolscore_client.search_and_install_tools(
                                task_description=task_desc,
                                reason=reason
                            )
                            
                            if search_result.get("success"):
                                installed_tools = search_result.get("installed_tools", [])
                                
                                if installed_tools:
                                    tool_names = [tool.get("name", tool.get("tool_id", "unknown")) for tool in installed_tools]
                                    observation = f"æˆåŠŸæœç´¢å¹¶å®‰è£…äº† {len(installed_tools)} ä¸ªæ–°å·¥å…·: {', '.join(tool_names)}ã€‚"
                                    
                                    # æ›´æ–°å¯ç”¨å·¥å…·æè¿°
                                    try:
                                        available_tools_description = await self.real_time_client.get_fresh_tools_for_llm(
                                            fallback_client=self.toolscore_client
                                        )
                                        logger.info("âœ… å·²æ›´æ–°å¯ç”¨å·¥å…·åˆ—è¡¨")
                                    except Exception as e:
                                        logger.warning(f"æ›´æ–°å·¥å…·åˆ—è¡¨å¤±è´¥: {e}")
                                else:
                                    observation = "æœç´¢å®Œæˆï¼Œä½†æœªæ‰¾åˆ°åˆé€‚çš„æ–°å·¥å…·ã€‚"
                                
                                tool_success = True
                            else:
                                error_msg = search_result.get("message", "æœç´¢å¤±è´¥")
                                observation = f"å·¥å…·æœç´¢å¤±è´¥: {error_msg}"
                                tool_success = False
                        else:
                            # æœªçŸ¥çš„mcp-search-toolåŠ¨ä½œ
                            observation = f"ä¸æ”¯æŒçš„mcp-search-toolåŠ¨ä½œ: {action}"
                            tool_success = False
                            
                    except Exception as e:
                        logger.error(f"mcp-search-toolè°ƒç”¨å¼‚å¸¸: {e}")
                        observation = f"mcp-search-toolè°ƒç”¨å¤±è´¥: {str(e)}"
                        tool_success = False
                        current_attempt_err_type = ErrorType.TOOL_ERROR
                        current_attempt_err_msg = str(e)

                # å¸¸è§„å·¥å…·è°ƒç”¨
                elif tool_id and action:
                    logger.info(f"ğŸ”§ æ‰§è¡Œå·¥å…·è°ƒç”¨: tool_id={tool_id}, action={action}")
                    logger.debug(f"Attempt {attempt + 1}: Executing action '{action}' with tool_id '{tool_id}'")
                    
                    # ğŸ” é¦–å…ˆå°è¯•é€šè¿‡ToolScore APIæ‰§è¡Œå·¥å…·
                    try:
                        # æ¸…ç†å‚æ•°
                        cleaned_params = {k: v for k, v in params.items() 
                                        if k not in ['action', 'tool_id', 'tool']}
                        
                        logger.info(f"ğŸŒ é€šè¿‡ToolScore APIæ‰§è¡Œå·¥å…·: {tool_id}/{action}")
                        
                        # è°ƒç”¨ToolScoreçš„å·¥å…·æ‰§è¡ŒAPI
                        execution_result = await self.toolscore_client.execute_tool(
                            tool_id=tool_id,
                            action=action,
                            parameters=cleaned_params
                        )
                        
                        if execution_result.get("success"):
                            tool_success = True
                            result_data = execution_result.get("result", {})
                            
                            # å¤„ç†æ‰§è¡Œç»“æœ
                            if isinstance(result_data, dict):
                                if result_data.get("stdout"):
                                    output = result_data["stdout"].strip()
                                    observation = f"å·¥å…· '{tool_id}/{action}' æ‰§è¡ŒæˆåŠŸã€‚è¾“å‡º: {output[:300]}{'...' if len(output) > 300 else ''}"
                                    current_outputs.append(output)
                                else:
                                    observation = f"å·¥å…· '{tool_id}/{action}' æ‰§è¡ŒæˆåŠŸã€‚"
                            else:
                                output_str = str(result_data)
                                observation = f"å·¥å…· '{tool_id}/{action}' æ‰§è¡ŒæˆåŠŸã€‚ç»“æœ: {output_str[:300]}{'...' if len(output_str) > 300 else ''}"
                                current_outputs.append(output_str)
                                
                            logger.info(f"âœ… å·¥å…·æ‰§è¡ŒæˆåŠŸ: {tool_id}")
                            
                        else:
                            # ToolScoreæ‰§è¡Œå¤±è´¥ï¼Œå°è¯•ç›´æ¥MCPè°ƒç”¨
                            error_msg = execution_result.get("message", "æ‰§è¡Œå¤±è´¥")
                            logger.warning(f"ToolScoreæ‰§è¡Œå¤±è´¥: {error_msg}ï¼Œå°è¯•ç›´æ¥MCPè°ƒç”¨")
                            
                            # æ˜ å°„å·¥å…·IDåˆ°å®é™…çš„MCPæœåŠ¡å™¨ID
                            actual_server_id = self._map_tool_id_to_server(tool_id)
                            
                            logger.info(f"ğŸ”§ ç›´æ¥è°ƒç”¨MCPæœåŠ¡å™¨: {actual_server_id}, åŠ¨ä½œ: {action}")
                            
                            # è°ƒç”¨MCPå®¢æˆ·ç«¯
                            result = await self.mcp_client.execute_tool(actual_server_id, action, cleaned_params)
                            tool_success = result.success
                            
                            # å¤„ç†ç»“æœ - ä¿®å¤æ•°æ®æˆªæ–­é—®é¢˜
                            if tool_success and result.data:
                                # å®‰å…¨å¤„ç†å“åº”æ•°æ®ï¼Œé¿å…æˆªæ–­
                                try:
                                    if isinstance(result.data, dict):
                                        # å¯¹äºå­—å…¸ç±»å‹ï¼Œç”Ÿæˆç®€åŒ–ä½†å®Œæ•´çš„è§‚å¯Ÿç»“æœ
                                        data_summary = {}
                                        for key, value in result.data.items():
                                            if isinstance(value, (str, int, float, bool)):
                                                data_summary[key] = value
                                            elif isinstance(value, dict):
                                                # åµŒå¥—å­—å…¸ï¼Œåªä¿ç•™å…³é”®å­—æ®µ
                                                data_summary[key] = {k: v for k, v in list(value.items())[:3]}
                                            elif isinstance(value, list):
                                                # åˆ—è¡¨ï¼Œåªä¿ç•™é•¿åº¦ä¿¡æ¯
                                                data_summary[key] = f"List[{len(value)} items]"
                                            else:
                                                data_summary[key] = str(type(value).__name__)
                                        
                                        observation = f"Tool '{tool_id}/{action}' executed successfully. Summary: {json.dumps(data_summary, ensure_ascii=False)}"
                                    else:
                                        # å¯¹äºéå­—å…¸ç±»å‹ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶é™åˆ¶é•¿åº¦
                                        data_str = str(result.data)
                                        if len(data_str) > 500:
                                            data_str = data_str[:500] + "...[truncated]"
                                        observation = f"Tool '{tool_id}/{action}' executed successfully. Data: {data_str}"
                                    
                                except Exception as e:
                                    logger.warning(f"Error processing tool result: {e}")
                                    observation = f"Tool '{tool_id}/{action}' executed successfully, but response processing failed: {str(e)}"
                                
                                # æ ¹æ®å·¥å…·ç±»å‹ç”Ÿæˆç‰¹å®šçš„è§‚å¯Ÿç»“æœ
                                if 'python' in actual_server_id.lower():
                                    if isinstance(result.data, dict):
                                        stdout = result.data.get('stdout', '').strip()
                                        if stdout:
                                            observation = f"Pythonä»£ç æ‰§è¡ŒæˆåŠŸã€‚è¾“å‡º:\n{stdout[:200]}{'...' if len(stdout) > 200 else ''}"
                                            current_outputs.append(stdout)
                                        else:
                                            observation = "Pythonä»£ç æ‰§è¡ŒæˆåŠŸï¼Œæ— è¾“å‡ºã€‚"
                                    elif 'browser' in actual_server_id.lower():
                                        if isinstance(result.data, dict):
                                            url = result.data.get('url', 'N/A')
                                            title = result.data.get('title', 'N/A')
                                            observation = f"æµè§ˆå™¨æ“ä½œæˆåŠŸã€‚å½“å‰é¡µé¢: {url}, æ ‡é¢˜: {title}"
                                            
                                            if action == 'browser_get_text':
                                                text = result.data.get('text', '')
                                                if text:
                                                    preview = text[:300] + ('...' if len(text) > 300 else '')
                                                    observation += f"\né¡µé¢å†…å®¹é¢„è§ˆ:\n{preview}"
                            else:
                                if tool_success:
                                    observation = f"Tool '{tool_id}/{action}' executed successfully."
                                else:
                                    observation = f"Tool '{tool_id}/{action}' execution failed: {result.error_message or 'Unknown error'}"

                    except Exception as e:
                        logger.error(f"å·¥å…·æ‰§è¡Œå¼‚å¸¸: {e}")
                        tool_success = False
                        current_attempt_err_type = ErrorType.TOOL_ERROR
                        current_attempt_err_msg = str(e)
                        observation = f"å·¥å…· '{tool_id}' æ‰§è¡Œå¤±è´¥: {str(e)}"

                else:
                    # æ— æ•ˆçš„å·¥å…·è°ƒç”¨
                    tool_success = False
                    current_attempt_err_type = ErrorType.SYSTEM_ERROR
                    if not tool_id:
                        current_attempt_err_msg = f"LLMæœªæŒ‡å®štool_idã€‚å°è¯•çš„åŠ¨ä½œ: '{action}'"
                    elif not action:
                        current_attempt_err_msg = f"LLMæœªæŒ‡å®šåŠ¨ä½œã€‚å·¥å…·: '{tool_id}'"
                    else:
                        current_attempt_err_msg = f"LLMå°è¯•è°ƒç”¨å·¥å…· '{tool_id}' æ‰§è¡ŒåŠ¨ä½œ '{action}'ï¼Œä½†å½“å‰ä¸æ”¯æŒæˆ–æ— æ•ˆã€‚"
                    observation = current_attempt_err_msg
                    action_type = ActionType.TOOL_CALL

                # é”™è¯¯å¤„ç†å’Œé‡è¯•é€»è¾‘
                if not tool_success:
                    logger.warning(
                        f"Step {step_id}, Action {action}, Attempt {attempt + 1}/{max_retries + 1} failed. "
                        f"ErrorType: {current_attempt_err_type}, ErrorMsg: {current_attempt_err_msg}"
                    )

                    # é‡è¯•é€»è¾‘
                    is_retryable = False
                    if current_attempt_err_type in [ErrorType.NETWORK_ERROR, ErrorType.TIMEOUT, ErrorType.RATE_LIMIT]:
                        is_retryable = True

                    if is_retryable and attempt < max_retries:
                        logger.info(f"Retrying action {action} after {retry_delay_seconds}s delay...")
                        await asyncio.sleep(retry_delay_seconds)
                    else:
                        break
            
            # å®Œæˆä»»åŠ¡æ£€æŸ¥
            exec_code_dict = {}
            if execution_code:
                try:
                    exec_code_dict = json.loads(execution_code)
                except json.JSONDecodeError:
                    pass
            
            if exec_code_dict.get('action') == 'complete_task' and success:
                break

            duration = time.time() - tool_start

            steps.append(ExecutionStep(
                step_id=step_id,
                action_type=action_type,
                action_params=params,
                observation=observation,
                success=tool_success,
                error_type=current_attempt_err_type,
                error_message=current_attempt_err_msg,
                thinking=thinking,
                execution_code=execution_code,
                timestamp=time.time(),
                duration=duration,
                llm_interactions=current_step_llm_interactions  # ğŸ” æ–°å¢
            ))

            # æ£€æŸ¥æ˜¯å¦å®Œæˆ - ä¹Ÿéœ€è¦è®°å½•LLMäº¤äº’
            completion_interactions = []
            original_call_api = self.client._call_api
            async def wrapped_call_api_for_completion(prompt: str) -> str:
                interaction_start = time.time()
                response = await original_call_api(prompt)
                
                from core.interfaces import LLMInteraction
                interaction = LLMInteraction(
                    provider=self.client.provider.value if hasattr(self.client.provider, 'value') else str(self.client.provider),
                    model=getattr(self.client, 'model', 'unknown'),
                    context=f"step_{step_id}_completion_check",
                    prompt=prompt,
                    prompt_length=len(prompt),
                    prompt_type="completion_check",
                    response=response,
                    response_length=len(response),
                    response_time=time.time() - interaction_start
                )
                completion_interactions.append(interaction)
                return response
            
            self.client._call_api = wrapped_call_api_for_completion
            try:
                completion = await self.client.check_task_completion(
                    task.description,
                    [s.__dict__ for s in steps],
                    current_outputs
                )
            finally:
                self.client._call_api = original_call_api
            
            # å°†å®Œæˆæ£€æŸ¥çš„LLMäº¤äº’æ·»åŠ åˆ°å½“å‰æ­¥éª¤
            if completion_interactions:
                steps[-1].llm_interactions.extend(completion_interactions)
            
            if completion.get('completed'):
                success = True
                break
        
        # å¦‚æœå¾ªç¯ç»“æŸä½†ä»»åŠ¡æ²¡æœ‰æˆåŠŸå®Œæˆï¼Œè®¾ç½®é”™è¯¯çŠ¶æ€
        if not success and steps:
            final_trajectory_error_type = steps[-1].error_type or ErrorType.EXECUTION_FAILED
            final_trajectory_error_message = steps[-1].error_message or f"Task failed after {len(steps)} steps"
            logger.warning(f"Task execution completed without success: {final_trajectory_error_message}")

        total_duration = time.time() - start_time
        
        # ç”Ÿæˆæœ€ç»ˆç»“æœ
        if success and steps:
            last_step_exec_code = {}
            if steps[-1].execution_code:
                try:
                    last_step_exec_code = json.loads(steps[-1].execution_code)
                except json.JSONDecodeError:
                    pass

            if last_step_exec_code.get('action') == 'complete_task':
                final_result = steps[-1].observation
            else:
                # æ™ºèƒ½ç”Ÿæˆæœ€ç»ˆç»“æœ
                browser_content = None
                python_output = None
                
                for step in reversed(steps[-3:]):
                    if not browser_content and 'Successfully retrieved page text' in step.observation:
                        if 'Preview:' in step.observation:
                            preview_start = step.observation.find('Preview:') + len('Preview:')
                            preview_end = step.observation.find('---', preview_start + 10)
                            if preview_end > preview_start:
                                browser_content = step.observation[preview_start:preview_end].strip()
                    
                    if not python_output and 'Python code executed' in step.observation and 'Output' in step.observation:
                        python_output = step.observation
                
                if browser_content:
                    final_result = f"ä»»åŠ¡å®Œæˆã€‚æˆåŠŸè®¿é—®äº†ç½‘ç«™å¹¶è·å–äº†é¡µé¢å†…å®¹ï¼š\n\n{browser_content[:800]}{'...' if len(browser_content) > 800 else ''}"
                elif python_output:
                    final_result = f"ä»»åŠ¡å®Œæˆã€‚{python_output}"
                elif current_outputs:
                    final_result = f"ä»»åŠ¡å®Œæˆã€‚ç”Ÿæˆç»“æœï¼š\n{chr(10).join(current_outputs[-2:])}"
                else:
                    # ğŸ” æ–°å¢ï¼šè®°å½•ä»»åŠ¡æ€»ç»“ç”Ÿæˆçš„LLMäº¤äº’
                    summary_interactions = []
                    original_call_api = self.client._call_api
                    async def wrapped_call_api_for_summary(prompt: str) -> str:
                        interaction_start = time.time()
                        response = await original_call_api(prompt)
                        
                        from core.interfaces import LLMInteraction
                        interaction = LLMInteraction(
                            provider=self.client.provider.value if hasattr(self.client.provider, 'value') else str(self.client.provider),
                            model=getattr(self.client, 'model', 'unknown'),
                            context="final_task_summary",
                            prompt=prompt,
                            prompt_length=len(prompt),
                            prompt_type="task_summary",
                            response=response,
                            response_length=len(response),
                            response_time=time.time() - interaction_start
                        )
                        summary_interactions.append(interaction)
                        return response
                    
                    self.client._call_api = wrapped_call_api_for_summary
                    try:
                        final_result = await self.client.generate_task_summary(
                            task.description, [s.__dict__ for s in steps], current_outputs
                        )
                    finally:
                        self.client._call_api = original_call_api
                    
                    # å°†æ€»ç»“ç”Ÿæˆçš„LLMäº¤äº’æ·»åŠ åˆ°æœ€åä¸€æ­¥
                    if summary_interactions and steps:
                        steps[-1].llm_interactions.extend(summary_interactions)
        else:
            final_result = final_trajectory_error_message or "Task execution failed"

        # åˆ›å»ºè½¨è¿¹ç»“æœ
        trajectory = TrajectoryResult(
            task_name=task.task_id,  # ä½¿ç”¨task_idä½œä¸ºtask_name
            task_id=task.task_id,
            task_description=task.description,
            runtime_id=self.runtime_id,
            steps=steps,
            success=success,
            final_result=final_result,
            total_duration=total_duration,
            error_type=final_trajectory_error_type,
            error_message=final_trajectory_error_message,
            metadata={
                'runtime_id': self.runtime_id,
                'original_task_id': task.task_id
            }
        )
        
        # ä¿å­˜è½¨è¿¹
        await self._save_trajectory(trajectory)
        
        # === å°†è¿è¡ŒæœŸé—´æ•è·çš„æ–°å·¥å…·äº‹ä»¶è¿½åŠ åˆ°è½¨è¿¹ ===
        if self._tool_event_buffer:
            for ev in self._tool_event_buffer:
                steps.append(ExecutionStep(
                    step_id=len(steps)+1,
                    action_type=ActionType.TOOL_CALL,
                    action_params=ev,
                    observation=f"New tool available during execution: {ev.get('name')}",
                    success=True
                ))
            self._tool_event_buffer.clear()
        
        return trajectory
    
    def _create_tool_available_callback(self, trajectory_id: str, step_id: int):
        """åˆ›å»ºå·¥å…·å¯ç”¨æ—¶çš„å›è°ƒå‡½æ•°"""
        async def callback(tool_event: Dict[str, Any]):
            tool_name = tool_event.get("name", tool_event.get("tool_id", "unknown"))
            logger.info(f"ğŸ‰ ä»»åŠ¡ {trajectory_id} æ­¥éª¤ {step_id}: æ–°å·¥å…· {tool_name} ç°å·²å¯ç”¨")
        return callback
    
    def _map_tool_id_to_server(self, tool_id: str) -> str:
        """æ˜ å°„å·¥å…·IDåˆ°å®é™…çš„MCPæœåŠ¡å™¨ID"""
        # ç®€å•çš„æ˜ å°„é€»è¾‘ï¼Œå¯ä»¥æ ¹æ®éœ€è¦æ‰©å±•
        mapping = {
            'python': 'python-executor-mcp-server',
            'python-executor': 'python-executor-mcp-server',
            'browser': 'browser-navigator-mcp-server',
            'browser-navigator': 'browser-navigator-mcp-server',
        }
        
        # ç²¾ç¡®åŒ¹é…
        if tool_id in mapping:
            return mapping[tool_id]
        
        # éƒ¨åˆ†åŒ¹é…
        for key, value in mapping.items():
            if key in tool_id.lower():
                return value
        
        # é»˜è®¤è¿”å›åŸå§‹ID
        return tool_id
    
    async def _save_trajectory(self, trajectory: TrajectoryResult):
        """ä¿å­˜è½¨è¿¹åˆ°æ–‡ä»¶"""
        out_dir = os.getenv('OUTPUT_DIR', '/app/output/trajectories')
        os.makedirs(out_dir, exist_ok=True)
        
        collection_file = os.path.join(out_dir, "trajectories_collection.json")
        
        trajectories = []
        if os.path.exists(collection_file):
            try:
                with open(collection_file, 'r', encoding='utf-8') as f:
                    trajectories = json.load(f)
                    if not isinstance(trajectories, list):
                        trajectories = []
            except (json.JSONDecodeError, Exception) as e:
                logging.error(f"Error reading trajectories collection: {e}")
                trajectories = []
        
        trajectories.append(trajectory.__dict__)
        
        with open(collection_file, 'w', encoding='utf-8') as f:
            json.dump(trajectories, f, ensure_ascii=False, indent=2, default=str)
        
        logger.info(f"Saved trajectory {trajectory.task_id} to collection")

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        logger.info("ğŸ§¹ æ¸…ç†Enhanced Reasoning Runtimeèµ„æº")
        
        # å…³é—­ToolScoreå®¢æˆ·ç«¯
        if self.toolscore_client:
            await self.toolscore_client.close()
        
        # å…³é—­å®æ—¶å®¢æˆ·ç«¯
        if self.real_time_client:
            await self.real_time_client.close()
        
        # æ¸…ç†MCPå®¢æˆ·ç«¯
        if self.mcp_client:
            await self.mcp_client.cleanup()

# è¿è¡ŒæœåŠ¡
if __name__ == '__main__':
    import logging
    logging.basicConfig(level=logging.INFO)
    
    async def main():
        runtime = EnhancedReasoningRuntime()
        await runtime.initialize()
        
        from core.task_manager import start_runtime_service
        # å¯åŠ¨æœåŠ¡
        await start_runtime_service(runtime)
    
    asyncio.run(main())