# Agent数据平台 - 用户使用指南

## 📖 什么是Agent数据平台？

Agent数据平台是一个专门用于**批量生成AI智能体训练数据**的自动化系统。简单来说，它就像一个"数据工厂"，能够自动执行各种任务并记录完整的操作过程，为训练更智能的AI助手提供高质量的学习材料。

### 🎯 核心价值

- **自动化数据生成**：无需人工标注，系统自动执行任务并生成轨迹数据
- **大规模并行处理**：支持同时处理成千上万个任务
- **高质量输出**：生成的数据包含完整的思考过程和执行步骤
- **即插即用**：3条命令即可启动完整系统

## 🏗️ 系统架构简介

想象这个系统就像一个智能工厂：

```
任务输入 → 智能调度中心 → 专业工作站 → 结果输出
   ↓           ↓            ↓         ↓
任务文件    Redis队列    运行时环境   轨迹数据
```

### 核心组件

1. **任务调度中心（Dispatcher）**
   - 负责读取任务列表
   - 智能分配任务到不同的工作站
   - 监控整个执行过程

2. **专业工作站（Runtimes）**
   - **智能推理工作站**：LLM驱动的多工具组合推理任务 ⭐ NEW
   - **代码执行工作站**：专门处理编程任务
   - **网页操作工作站**：专门处理网页浏览和交互任务

3. **数据存储系统**
   - **Redis**：临时存储任务队列
   - **文件系统**：永久保存执行轨迹

## 🚀 快速开始

### 系统要求

- **硬件要求**：
  - 内存：8GB以上（推荐16GB）
  - 硬盘：20GB以上可用空间
  - CPU：4核以上
  - GPU：可选（用于本地LLM推理）

- **软件要求**：
  - Docker Desktop
  - Windows 10/11 或 Linux 或 macOS

### 一键启动

1. **下载项目**
   ```bash
   git clone <项目地址>
   cd agent-data-platform
   ```

2. **构建系统**
   ```bash
   docker-compose build --parallel
   ```

3. **启动服务**
   ```bash
   docker-compose up -d
   ```

4. **检查状态**
   ```bash
   docker-compose ps
   ```

看到所有服务都显示"Up"状态，说明系统启动成功！

## 📋 如何使用

### 1. 准备任务文件

系统通过读取`tasks.jsonl`文件来获取要执行的任务。每一行代表一个任务：

```json
{"task_id": "研究框架对比", "task_type": "reasoning", "description": "研究PyTorch和TensorFlow的主要差异和优劣势", "expected_tools": ["browser", "python_executor"], "max_steps": 12}
{"task_id": "计算阶乘", "task_type": "code", "description": "计算5的阶乘", "expected_tools": ["python_executor"], "max_steps": 4}
{"task_id": "搜索文档", "task_type": "web", "description": "在Python官网搜索文档", "expected_tools": ["browser"], "max_steps": 8}
```

**任务类型说明**：
- `reasoning`：智能推理任务（如研究分析、数据收集与处理、复杂问题解决）⭐ NEW
- `code`：编程任务（如数据处理、算法实现、API调用）
- `web`：网页操作任务（如信息搜索、表单填写、页面交互）

### 2. 监控执行进度

**查看完成的任务数量**：
```bash
ls output/trajectories | wc -l
```

**查看实时日志**：
```bash
docker-compose logs -f dispatcher
```

**查看系统状态**：
访问 http://localhost:8001/metrics 查看详细指标

### 3. 获取结果

执行完成的任务会在`output/trajectories/`目录下生成对应的轨迹文件，包含：
- 完整的执行步骤
- 每一步的输入输出
- 成功/失败状态
- 执行时间等元数据

## ⚙️ 配置选项

### LLM配置

系统支持两种LLM配置方式：

#### 方式1：使用本地LLM（推荐）

系统内置vLLM服务，可以运行本地模型：

```yaml
# 在docker-compose.yml中配置
vllm:
  environment:
    - MODEL=你的模型名称  # 如：Salesforce/codegen-350M-mono
    - TENSOR_PARALLEL_SIZE=1
    - GPU_MEMORY_UTILIZATION=0.8
```

#### 方式2：使用外部API服务

系统支持多种外部API提供商，包括Google Gemini、DeepSeek、OpenAI等。

**快速配置**：
1. 复制环境变量模板：`cp .env.example .env`
2. 编辑`.env`文件，填入API密钥
3. 重启服务：`docker-compose restart`

**支持的API提供商**：

```bash
# Google Gemini API (推荐，性价比高)
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_API_URL=https://generativelanguage.googleapis.com/v1beta

# DeepSeek API (代码生成专用)
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_API_URL=https://api.deepseek.com/v1

# OpenAI API
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_API_BASE=https://api.openai.com/v1
```

**或者在docker-compose.yml中直接配置**：

```yaml
sandbox-runtime:
  environment:
    - GEMINI_API_KEY=your_gemini_api_key_here
    - DEEPSEEK_API_KEY=your_deepseek_api_key_here
    - OPENAI_API_KEY=your_openai_api_key_here
```

**API优先级**：系统会按 Gemini > DeepSeek > OpenAI > 本地vLLM 的顺序自动选择可用的API。

详细配置说明请参考：[外部API配置指南.md](./外部API配置指南.md)

### 性能调优

**并发控制**：
```yaml
sandbox-runtime:
  environment:
    - MAX_CONCURRENT=4  # 同时执行的任务数
  deploy:
    replicas: 2  # 运行时实例数量
```

**资源限制**：
```yaml
sandbox-runtime:
  deploy:
    resources:
      limits:
        memory: 2G
        cpus: '1.0'
```

## 🔄 大规模并行化

### 水平扩展

1. **增加运行时实例**：
   ```bash
   docker-compose up -d --scale sandbox-runtime=4 --scale web-runtime=2 --scale reasoning-runtime=3
   ```

2. **分布式部署**：
   - 在多台机器上部署运行时
   - 共享同一个Redis队列
   - 自动负载均衡

### 批量任务处理

1. **准备大量任务**：
   ```python
   # 生成1000个任务的示例
   import json
   
   tasks = []
   for i in range(1000):
       if i % 3 == 0:
           task = {
               "task_id": f"reasoning_task_{i}",
               "task_type": "reasoning",
               "description": f"分析和处理数据集第{i}部分",
               "expected_tools": ["browser", "python_executor"],
               "max_steps": 10
           }
       else:
           task = {
               "task_id": f"code_task_{i}",
               "task_type": "code",
               "description": f"处理数据集第{i}部分",
               "expected_tools": ["python_executor"],
               "max_steps": 5
           }
       tasks.append(json.dumps(task))
   
   with open('tasks.jsonl', 'w') as f:
       f.write('\n'.join(tasks))
   ```

2. **监控处理进度**：
   ```bash
   # 实时监控
   watch -n5 'echo "代码队列: $(docker exec redis redis-cli llen tasks:code)"'
   watch -n5 'echo "推理队列: $(docker exec redis redis-cli llen tasks:reasoning)"'
   watch -n5 'echo "已完成: $(ls output/trajectories | wc -l)"'
   ```

## 🖥️ 交互界面

### Web监控界面

系统提供多个监控端点：

- **健康检查**：http://localhost:8001/health
- **系统指标**：http://localhost:8001/metrics
- **Redis管理**：可以安装RedisInsight进行可视化管理

### 命令行工具

```bash
# 查看系统状态
./scripts/smoke_test.sh

# 执行负载测试
./load_test.sh

# 查看详细日志
docker-compose logs --tail=100 -f
```

### 自定义监控

可以集成Grafana进行可视化监控：

```bash
# 启动监控栈
docker-compose -f docker-compose.yml -f config/monitoring.yml up -d
```

访问 http://localhost:3000 查看Grafana仪表板

## 📊 输入输出说明

### 输入格式

**任务文件（tasks.jsonl）**：
```json
{
  "task_id": "唯一标识符",
  "task_type": "reasoning|code|web",
  "description": "任务描述",
  "expected_tools": ["工具列表"],
  "max_steps": 最大步骤数,
  "timeout": 超时时间（秒）,
  "priority": 优先级（1-10）
}
```

### 输出格式

**轨迹文件（output/trajectories/task_id.json）**：
```json
{
  "task_id": "任务ID",
  "success": true,
  "steps": [
    {
      "step_id": 1,
      "action_type": "code_execution",
      "action_params": {"code": "print('Hello')"},
      "observation": "Hello",
      "success": true,
      "timestamp": 1234567890.123,
      "duration": 0.5
    }
  ],
  "final_result": "任务执行结果",
  "total_duration": 2.3,
  "metadata": {"runtime_id": "sandbox-1"}
}
```

## 🔧 故障排除

### 常见问题

1. **服务启动失败**
   ```bash
   # 检查端口占用
   netstat -tulpn | grep :6379
   
   # 重新构建镜像
   docker-compose build --no-cache
   ```

2. **任务执行缓慢**
   ```bash
   # 增加并发数
   docker-compose up -d --scale sandbox-runtime=4
   
   # 检查资源使用
   docker stats
   ```

3. **内存不足**
   ```bash
   # 清理Docker缓存
   docker system prune -a
   
   # 调整内存限制
   # 修改docker-compose.yml中的memory限制
   ```

### 日志分析

```bash
# 查看错误日志
docker-compose logs | grep ERROR

# 查看特定服务日志
docker-compose logs sandbox-runtime

# 实时跟踪日志
docker-compose logs -f --tail=50
```

## 🎯 最佳实践

### 任务设计

1. **合理设置步骤数**：简单任务3-5步，复杂任务10-15步
2. **明确任务描述**：描述要具体，避免歧义
3. **设置合理超时**：代码任务30-60秒，网页任务60-300秒

### 性能优化

1. **批量处理**：一次提交大量任务比逐个提交效率更高
2. **资源监控**：定期检查CPU、内存使用情况
3. **缓存利用**：相似任务会自动使用缓存结果

### 数据管理

1. **定期备份**：重要的轨迹数据要及时备份
2. **清理策略**：设置自动清理过期数据的策略
3. **版本控制**：对任务文件进行版本管理

## 📈 扩展功能

### 自定义运行时

可以开发自定义的运行时来支持特定类型的任务：

```python
class CustomRuntime(RuntimeInterface):
    async def execute(self, task: TaskSpec) -> TrajectoryResult:
        # 实现自定义执行逻辑
        pass
```

### 集成外部服务

系统支持集成各种外部服务：
- 数据库连接
- API服务调用
- 文件处理服务
- 机器学习模型

## 🤝 技术支持

如果在使用过程中遇到问题：

1. 查看本文档的故障排除部分
2. 检查系统日志获取详细错误信息
3. 参考项目README.md中的技术文档
4. 提交Issue到项目仓库

---

**总结**：Agent数据平台是一个强大而易用的AI训练数据生成工具。通过简单的配置和操作，您就可以大规模生成高质量的智能体训练数据，为AI系统的改进提供宝贵的学习材料。