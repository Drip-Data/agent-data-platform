# 🎯 核心模块1：任务合成器系统 (简化版)

## 📋 项目概述

任务合成器系统专注于任务合成的核心流程：从执行轨迹中提取任务本质，存储到种子任务库，然后通过任务变异和编排生成新的TaskSpec。该系统与核心模块2(沙盒执行环境)形成数据闭环，持续积累和优化任务数据资产。

## 🏗️ 简化系统架构

```
📥 数据输入层
├── 用户种子任务
├── 用户种子轨迹  
└── 高质量轨迹回流 (数据闭环)

🎯 核心模块1：任务合成系统 (简化)
├── 轨迹总结器 (核心组件)
│   ├── LLM Prompt调用
│   └── 轨迹本质提取
├── 种子任务库
│   ├── 种子数据存储
│   └── 数据格式管理
├── 任务变异器
│   ├── 参数变异
│   ├── 复杂度变异
│   └── 领域迁移
└── 任务编排器
    ├── 工具列表管理 (预定义)
    ├── 任务编排逻辑
    └── TaskSpec输出

🏃 核心模块2：沙盒执行环境 (已实现)
├── 行为执行器 (基座模型)
└── 输出执行轨迹
```

## 📊 数据结构设计

### 轨迹总结器输入格式 (TrajectoryResult)

基于现有的`TrajectoryResult`格式：

```json
{
  "task_id": "fibonacci_10",
  "runtime_id": "sandbox-1", 
  "success": true,
  "steps": [
    {
      "step_id": 1,
      "action_type": "code_generation",
      "action_params": {"description": "Calculate the 10th Fibonacci number"},
      "observation": "def fibonacci(n):\n    if n <= 1:\n        return n\n    return fibonacci(n-1) + fibonacci(n-2)\n\nresult = fibonacci(10)\nprint(f\"The 10th Fibonacci number is: {result}\")",
      "success": true,
      "timestamp": 1748844062.5536706
    },
    {
      "step_id": 2,
      "action_type": "code_execution", 
      "action_params": {"code": "..."},
      "observation": "The 10th Fibonacci number is: 55",
      "success": true,
      "timestamp": 1748844064.7515452
    }
  ],
  "final_result": "The 10th Fibonacci number is: 55",
  "total_duration": 2.1978795528411865,
  "metadata": {"cached": false, "exit_code": 0}
}
```

### 种子任务库数据格式 (TaskEssence)

```json
{
  "essence_id": "essence_001",
  "task_type": "code",
  "domain": "math_algorithms", 
  "query": "计算第N个斐波那契数",
  "original_tools": ["python_executor"],
  "complexity_level": "medium",
  "success_pattern": {
    "code_pattern": "递归实现",
    "execution_time": 2.19,
    "steps_count": 2
  },
  "extracted_at": "2024-01-15T10:30:00Z",
  "source_trajectory_id": "fibonacci_10"
}
```

### 任务编排器输出格式 (TaskSpec)

```json
{
  "task_id": "synthesized_fibonacci_15",
  "task_type": "code",
  "description": "计算第15个斐波那契数并优化算法效率", 
  "expected_tools": ["python_executor"],
  "constraints": {
    "max_execution_time": 30,
    "complexity_requirement": "optimized"
  },
  "max_steps": 5,
  "timeout": 300,
  "priority": 1,
  "synthesis_metadata": {
    "mutation_type": "parameter_variation",
    "source_essence_id": "essence_001",
    "generated_at": "2024-01-15T10:35:00Z"
  }
}
```

## 🔧 核心组件设计

### 1. 轨迹总结器 (TrajectoryEssenceExtractor)

**功能**：接收执行轨迹，通过LLM Prompt提取任务本质

```python
import openai
from typing import Dict, List
from dataclasses import dataclass
from core.interfaces import TrajectoryResult

@dataclass
class TaskEssence:
    """任务本质数据结构"""
    essence_id: str
    task_type: str
    domain: str
    query: str
    original_tools: List[str]
    complexity_level: str
    success_pattern: Dict
    extracted_at: str
    source_trajectory_id: str

class TrajectoryEssenceExtractor:
    """轨迹总结器 - 使用LLM提取轨迹本质"""
    
    def __init__(self, llm_client):
        self.llm_client = llm_client
        self.extraction_prompt = self._build_extraction_prompt()
    
    async def extract_essence(self, trajectory: TrajectoryResult) -> TaskEssence:
        """从轨迹中提取任务本质"""
        
        # 1. 构建prompt输入
        trajectory_context = self._format_trajectory_for_llm(trajectory)
        
        # 2. 调用LLM进行总结
        extraction_result = await self._call_llm_for_extraction(trajectory_context)
        
        # 3. 解析LLM输出并构造TaskEssence
        essence = self._parse_llm_response(extraction_result, trajectory)
        
        return essence
    
    def _build_extraction_prompt(self) -> str:
        """构建轨迹提取prompt"""
        return """
你是一个任务分析专家，需要从Agent执行轨迹中提取任务的本质信息。

请分析以下执行轨迹，提取出：
1. task_type: 任务类型 (code/web/reasoning)
2. domain: 领域分类 (math_algorithms/data_processing/web_automation/etc)
3. query: 核心任务意图的简洁描述
4. complexity_level: 复杂度等级 (simple/medium/complex)
5. success_pattern: 成功执行的关键模式

执行轨迹：
{trajectory_context}

请按照以下JSON格式返回分析结果：
{
  "task_type": "...",
  "domain": "...", 
  "query": "...",
  "complexity_level": "...",
  "success_pattern": {
    "code_pattern": "...",
    "key_steps": "...",
    "execution_efficiency": "..."
  }
}
"""
    
    def _format_trajectory_for_llm(self, trajectory: TrajectoryResult) -> str:
        """格式化轨迹数据供LLM分析"""
        context = f"""
任务ID: {trajectory.task_id}
执行成功: {trajectory.success}
总耗时: {trajectory.total_duration:.2f}秒
最终结果: {trajectory.final_result}

执行步骤:
"""
        for step in trajectory.steps:
            context += f"""
步骤 {step.step_id}: {step.action_type}
- 参数: {step.action_params}
- 观察: {step.observation[:200]}...
- 成功: {step.success}
"""
        return context
    
    async def _call_llm_for_extraction(self, trajectory_context: str) -> str:
        """调用LLM进行轨迹分析"""
        prompt = self.extraction_prompt.format(trajectory_context=trajectory_context)
        
        response = await self.llm_client.generate(
            prompt=prompt,
            model="gpt-4o-mini",
            temperature=0.3,
            max_tokens=500
        )
        
        return response
    
    def _parse_llm_response(self, llm_response: str, trajectory: TrajectoryResult) -> TaskEssence:
        """解析LLM响应并构造TaskEssence"""
        import json
        import uuid
        from datetime import datetime
        
        try:
            parsed = json.loads(llm_response)
            
            return TaskEssence(
                essence_id=str(uuid.uuid4()),
                task_type=parsed["task_type"],
                domain=parsed["domain"],
                query=parsed["query"],
                original_tools=trajectory.steps[0].action_params.get("tools", ["python_executor"]),
                complexity_level=parsed["complexity_level"],
                success_pattern=parsed["success_pattern"],
                extracted_at=datetime.now().isoformat(),
                source_trajectory_id=trajectory.task_id
            )
        except Exception as e:
            # 如果LLM解析失败，使用默认值
            return self._create_fallback_essence(trajectory)
    
    def _create_fallback_essence(self, trajectory: TrajectoryResult) -> TaskEssence:
        """创建备用的任务本质"""
        import uuid
        from datetime import datetime
        
        return TaskEssence(
            essence_id=str(uuid.uuid4()),
            task_type="code",  # 默认类型
            domain="general",
            query=f"基于轨迹 {trajectory.task_id} 的任务",
            original_tools=["python_executor"],
            complexity_level="medium",
            success_pattern={"execution_time": trajectory.total_duration},
            extracted_at=datetime.now().isoformat(),
            source_trajectory_id=trajectory.task_id
        )
```

### 2. 种子任务库 (SeedTaskDatabase)

**功能**：存储和管理提取的任务本质数据

```python
import json
import sqlite3
from typing import List, Optional
from datetime import datetime

class SeedTaskDatabase:
    """种子任务数据库"""
    
    def __init__(self, db_path: str = "seed_tasks.db"):
        self.db_path = db_path
        self._init_database()
    
    def _init_database(self):
        """初始化数据库表"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS task_essences (
            essence_id TEXT PRIMARY KEY,
            task_type TEXT NOT NULL,
            domain TEXT NOT NULL,
            query TEXT NOT NULL,
            original_tools TEXT NOT NULL,  -- JSON格式
            complexity_level TEXT NOT NULL,
            success_pattern TEXT NOT NULL,  -- JSON格式
            extracted_at TEXT NOT NULL,
            source_trajectory_id TEXT NOT NULL,
            usage_count INTEGER DEFAULT 0,
            last_used TEXT,
            quality_score REAL DEFAULT 0.5
        )
        """)
        
        # 创建索引
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_task_type ON task_essences(task_type)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_domain ON task_essences(domain)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_complexity ON task_essences(complexity_level)")
        
        conn.commit()
        conn.close()
    
    async def store_essence(self, essence: TaskEssence) -> bool:
        """存储任务本质到数据库"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
            INSERT OR REPLACE INTO task_essences 
            (essence_id, task_type, domain, query, original_tools, 
             complexity_level, success_pattern, extracted_at, source_trajectory_id)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                essence.essence_id,
                essence.task_type,
                essence.domain,
                essence.query,
                json.dumps(essence.original_tools),
                essence.complexity_level,
                json.dumps(essence.success_pattern),
                essence.extracted_at,
                essence.source_trajectory_id
            ))
            
            conn.commit()
            conn.close()
            return True
            
        except Exception as e:
            print(f"Error storing essence: {e}")
            return False
    
    async def get_essence_by_id(self, essence_id: str) -> Optional[TaskEssence]:
        """根据ID获取任务本质"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("SELECT * FROM task_essences WHERE essence_id = ?", (essence_id,))
        row = cursor.fetchone()
        conn.close()
        
        if row:
            return self._row_to_essence(row)
        return None
    
    async def get_essences_by_domain(self, domain: str, limit: int = 10) -> List[TaskEssence]:
        """根据领域获取任务本质列表"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
        SELECT * FROM task_essences 
        WHERE domain = ? 
        ORDER BY quality_score DESC, usage_count ASC 
        LIMIT ?
        """, (domain, limit))
        
        rows = cursor.fetchall()
        conn.close()
        
        return [self._row_to_essence(row) for row in rows]
    
    async def get_random_essences(self, count: int = 5) -> List[TaskEssence]:
        """随机获取种子任务用于变异"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
        SELECT * FROM task_essences 
        ORDER BY RANDOM() 
        LIMIT ?
        """, (count,))
        
        rows = cursor.fetchall()
        conn.close()
        
        return [self._row_to_essence(row) for row in rows]
    
    def _row_to_essence(self, row) -> TaskEssence:
        """将数据库行转换为TaskEssence对象"""
        return TaskEssence(
            essence_id=row[0],
            task_type=row[1],
            domain=row[2],
            query=row[3],
            original_tools=json.loads(row[4]),
            complexity_level=row[5],
            success_pattern=json.loads(row[6]),
            extracted_at=row[7],
            source_trajectory_id=row[8]
        )
    
    async def update_usage(self, essence_id: str):
        """更新使用统计"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
        UPDATE task_essences 
        SET usage_count = usage_count + 1, last_used = ?
        WHERE essence_id = ?
        """, (datetime.now().isoformat(), essence_id))
        
        conn.commit()
        conn.close()
```

### 3. 任务变异器 (TaskMutator)

**功能**：基于种子任务生成变异任务

```python
import random
import re
from typing import Dict, List

class TaskMutator:
    """任务变异器 - 基于种子数据生成变异任务"""
    
    def __init__(self, llm_client):
        self.llm_client = llm_client
        self.mutation_prompts = self._build_mutation_prompts()
    
    async def parameter_mutation(self, seed_essence: TaskEssence) -> Dict:
        """参数变异：改变数值、字符串等参数"""
        
        mutation_prompt = self.mutation_prompts["parameter"].format(
            original_query=seed_essence.query,
            domain=seed_essence.domain,
            complexity=seed_essence.complexity_level
        )
        
        mutated_description = await self.llm_client.generate(
            prompt=mutation_prompt,
            model="gpt-4o-mini",
            temperature=0.7,
            max_tokens=200
        )
        
        return {
            "description": mutated_description.strip(),
            "mutation_type": "parameter_variation",
            "source_essence_id": seed_essence.essence_id
        }
    
    async def complexity_mutation(self, seed_essence: TaskEssence) -> Dict:
        """复杂度变异：增加或减少任务复杂度"""
        
        # 随机选择增加或减少复杂度
        direction = random.choice(["increase", "decrease"])
        
        mutation_prompt = self.mutation_prompts["complexity"].format(
            original_query=seed_essence.query,
            direction=direction,
            current_complexity=seed_essence.complexity_level
        )
        
        mutated_description = await self.llm_client.generate(
            prompt=mutation_prompt,
            model="gpt-4o-mini", 
            temperature=0.6,
            max_tokens=200
        )
        
        return {
            "description": mutated_description.strip(),
            "mutation_type": f"complexity_{direction}",
            "source_essence_id": seed_essence.essence_id
        }
    
    async def domain_transfer(self, seed_essence: TaskEssence, target_domain: str) -> Dict:
        """领域迁移：将任务迁移到相似领域"""
        
        mutation_prompt = self.mutation_prompts["domain_transfer"].format(
            original_query=seed_essence.query,
            source_domain=seed_essence.domain,
            target_domain=target_domain
        )
        
        mutated_description = await self.llm_client.generate(
            prompt=mutation_prompt,
            model="gpt-4o-mini",
            temperature=0.6,
            max_tokens=200
        )
        
        return {
            "description": mutated_description.strip(),
            "mutation_type": "domain_transfer",
            "source_essence_id": seed_essence.essence_id,
            "target_domain": target_domain
        }
    
    def _build_mutation_prompts(self) -> Dict[str, str]:
        """构建各种变异类型的prompt"""
        return {
            "parameter": """
基于以下原始任务，生成一个参数变异的新任务。保持核心逻辑不变，但改变具体的数值、数据或参数。

原始任务: {original_query}
领域: {domain}
复杂度: {complexity}

请生成一个新的任务描述，改变其中的参数但保持相同的解决思路：
""",
            
            "complexity": """
基于以下原始任务，{direction}任务的复杂度。

原始任务: {original_query}
当前复杂度: {current_complexity}

请生成一个复杂度{direction}的新任务描述：
""",
            
            "domain_transfer": """
将以下任务从 {source_domain} 领域迁移到 {target_domain} 领域，保持相似的解决方法和思路。

原始任务: {original_query}

请生成迁移到新领域的任务描述：
"""
        }
```

### 4. 任务编排器 (TaskOrchestrator)

**功能**：使用预定义工具列表进行任务编排，输出TaskSpec

```python
from core.interfaces import TaskSpec, TaskType
from typing import List, Dict
import uuid

class TaskOrchestrator:
    """任务编排器 - 组装最终的TaskSpec"""
    
    def __init__(self):
        # 预定义的工具分类列表
        self.tool_categories = {
            "code": ["python_executor", "code_analyzer", "debugger"],
            "web": ["browser", "web_scraper", "form_filler"],
            "math": ["calculator", "math_solver", "plotter"],
            "data": ["data_processor", "csv_reader", "json_parser"],
            "file": ["file_reader", "file_writer", "zip_handler"]
        }
        
        # 复杂度到步骤数和超时的映射
        self.complexity_mapping = {
            "simple": {"max_steps": 3, "timeout": 60},
            "medium": {"max_steps": 6, "timeout": 180}, 
            "complex": {"max_steps": 10, "timeout": 300}
        }
    
    async def orchestrate_task(self, mutated_task: Dict, source_essence: TaskEssence) -> TaskSpec:
        """编排任务，生成最终的TaskSpec"""
        
        # 1. 确定任务类型
        task_type = TaskType(source_essence.task_type)
        
        # 2. 选择合适的工具
        expected_tools = self._select_tools(
            task_type=source_essence.task_type,
            description=mutated_task["description"],
            original_tools=source_essence.original_tools
        )
        
        # 3. 估算执行参数
        execution_params = self._estimate_execution_params(
            complexity=source_essence.complexity_level,
            description=mutated_task["description"]
        )
        
        # 4. 构造TaskSpec
        task_spec = TaskSpec(
            task_id=f"synthesized_{str(uuid.uuid4())[:8]}",
            task_type=task_type,
            description=mutated_task["description"],
            expected_tools=expected_tools,
            constraints=self._build_constraints(source_essence),
            max_steps=execution_params["max_steps"],
            timeout=execution_params["timeout"],
            priority=self._calculate_priority(source_essence)
        )
        
        # 5. 添加合成元数据
        if hasattr(task_spec, 'synthesis_metadata'):
            task_spec.synthesis_metadata = {
                "mutation_type": mutated_task["mutation_type"],
                "source_essence_id": mutated_task["source_essence_id"],
                "generated_at": datetime.now().isoformat()
            }
        
        return task_spec
    
    def _select_tools(self, task_type: str, description: str, original_tools: List[str]) -> List[str]:
        """根据任务类型和描述选择工具"""
        
        # 基础工具 (来自原始工具)
        selected_tools = list(original_tools)
        
        # 根据任务类型添加相关工具
        if task_type in self.tool_categories:
            base_tools = self.tool_categories[task_type]
            selected_tools.extend([tool for tool in base_tools if tool not in selected_tools])
        
        # 根据描述关键词添加特定工具
        description_lower = description.lower()
        if "文件" in description_lower or "file" in description_lower:
            selected_tools.extend([tool for tool in self.tool_categories["file"] if tool not in selected_tools])
        
        if "数据" in description_lower or "data" in description_lower:
            selected_tools.extend([tool for tool in self.tool_categories["data"] if tool not in selected_tools])
        
        if "计算" in description_lower or "math" in description_lower:
            selected_tools.extend([tool for tool in self.tool_categories["math"] if tool not in selected_tools])
        
        # 去重并返回
        return list(set(selected_tools))
    
    def _estimate_execution_params(self, complexity: str, description: str) -> Dict:
        """估算执行参数"""
        base_params = self.complexity_mapping.get(complexity, self.complexity_mapping["medium"])
        
        # 根据描述调整参数
        description_lower = description.lower()
        
        # 如果描述中包含"优化"、"复杂"等关键词，增加步骤和时间
        if any(keyword in description_lower for keyword in ["优化", "复杂", "advanced", "optimize"]):
            base_params = {
                "max_steps": base_params["max_steps"] + 2,
                "timeout": base_params["timeout"] + 60
            }
        
        return base_params
    
    def _build_constraints(self, essence: TaskEssence) -> Dict:
        """构建任务约束"""
        constraints = {}
        
        # 基于成功模式添加约束
        if "execution_time" in essence.success_pattern:
            execution_time = essence.success_pattern["execution_time"]
            constraints["max_execution_time"] = min(execution_time * 2, 60)  # 最多是原来的2倍，但不超过60秒
        
        # 基于任务类型添加约束
        if essence.task_type == "code":
            constraints.update({
                "memory_limit": "512MB",
                "allowed_imports": ["math", "random", "time", "json", "re"]
            })
        
        return constraints
    
    def _calculate_priority(self, essence: TaskEssence) -> int:
        """计算任务优先级"""
        # 简单的优先级计算逻辑
        priority = 1
        
        if essence.complexity_level == "simple":
            priority = 1
        elif essence.complexity_level == "medium":
            priority = 2
        else:  # complex
            priority = 3
        
        return priority
```

### 5. 任务合成引擎 (TaskSynthesisEngine)

**功能**：协调所有组件完成任务合成

```python
import asyncio
import random
from typing import List
from datetime import datetime

class TaskSynthesisEngine:
    """任务合成引擎 - 协调所有组件"""
    
    def __init__(self, llm_client):
        self.essence_extractor = TrajectoryEssenceExtractor(llm_client)
        self.seed_database = SeedTaskDatabase()
        self.task_mutator = TaskMutator(llm_client)
        self.task_orchestrator = TaskOrchestrator()
    
    async def process_trajectory(self, trajectory: TrajectoryResult) -> TaskSpec:
        """处理单个轨迹，生成新任务"""
        
        # 1. 提取轨迹本质
        print(f"正在提取轨迹 {trajectory.task_id} 的本质...")
        essence = await self.essence_extractor.extract_essence(trajectory)
        
        # 2. 存储到种子库
        print(f"存储任务本质到种子库...")
        await self.seed_database.store_essence(essence)
        
        # 3. 生成变异任务
        print(f"生成变异任务...")
        mutated_task = await self._generate_mutation(essence)
        
        # 4. 任务编排
        print(f"进行任务编排...")
        task_spec = await self.task_orchestrator.orchestrate_task(mutated_task, essence)
        
        # 5. 更新使用统计
        await self.seed_database.update_usage(essence.essence_id)
        
        print(f"成功生成新任务: {task_spec.task_id}")
        return task_spec
    
    async def synthesize_from_seed_library(self, count: int = 5) -> List[TaskSpec]:
        """从种子库批量合成任务"""
        
        # 1. 获取随机种子任务
        seed_essences = await self.seed_database.get_random_essences(count)
        
        if not seed_essences:
            print("种子库为空，无法合成任务")
            return []
        
        # 2. 并行生成任务
        tasks = []
        for essence in seed_essences:
            task = self._synthesize_from_essence(essence)
            tasks.append(task)
        
        synthesized_tasks = await asyncio.gather(*tasks)
        
        print(f"从种子库成功合成 {len(synthesized_tasks)} 个任务")
        return synthesized_tasks
    
    async def _synthesize_from_essence(self, essence: TaskEssence) -> TaskSpec:
        """从单个本质合成任务"""
        
        # 生成变异任务
        mutated_task = await self._generate_mutation(essence)
        
        # 任务编排
        task_spec = await self.task_orchestrator.orchestrate_task(mutated_task, essence)
        
        # 更新使用统计
        await self.seed_database.update_usage(essence.essence_id)
        
        return task_spec
    
    async def _generate_mutation(self, essence: TaskEssence) -> Dict:
        """生成变异任务"""
        
        # 随机选择变异类型
        mutation_types = ["parameter", "complexity", "domain_transfer"]
        mutation_type = random.choice(mutation_types)
        
        if mutation_type == "parameter":
            return await self.task_mutator.parameter_mutation(essence)
        elif mutation_type == "complexity":
            return await self.task_mutator.complexity_mutation(essence)
        else:  # domain_transfer
            # 随机选择目标领域
            target_domains = ["math_algorithms", "data_processing", "text_analysis", "web_automation"]
            target_domain = random.choice([d for d in target_domains if d != essence.domain])
            return await self.task_mutator.domain_transfer(essence, target_domain)
    
    async def get_synthesis_stats(self) -> Dict:
        """获取合成统计信息"""
        conn = sqlite3.connect(self.seed_database.db_path)
        cursor = conn.cursor()
        
        # 统计种子库信息
        cursor.execute("SELECT COUNT(*) FROM task_essences")
        total_essences = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(DISTINCT domain) FROM task_essences")
        unique_domains = cursor.fetchone()[0]
        
        cursor.execute("SELECT AVG(usage_count) FROM task_essences")
        avg_usage = cursor.fetchone()[0] or 0
        
        conn.close()
        
        return {
            "total_seed_essences": total_essences,
            "unique_domains": unique_domains,
            "average_usage": round(avg_usage, 2),
            "last_updated": datetime.now().isoformat()
        }
```

## 🔄 数据闭环处理

```python
class TrajectoryFeedbackProcessor:
    """轨迹反馈处理器 - 简化版数据闭环"""
    
    def __init__(self, synthesis_engine: TaskSynthesisEngine):
        self.synthesis_engine = synthesis_engine
        
    async def process_trajectory_feedback(self, trajectory: TrajectoryResult):
        """处理轨迹反馈"""
        
        # 只处理成功的轨迹
        if not trajectory.success:
            print(f"轨迹 {trajectory.task_id} 执行失败，跳过处理")
            return
        
        # 检查轨迹质量
        if not self._is_quality_trajectory(trajectory):
            print(f"轨迹 {trajectory.task_id} 质量不达标，跳过处理") 
            return
        
        try:
            # 处理轨迹并生成新任务
            new_task = await self.synthesis_engine.process_trajectory(trajectory)
            
            print(f"基于轨迹 {trajectory.task_id} 生成新任务 {new_task.task_id}")
            
            # 这里可以将新任务直接投入执行队列
            # await self._dispatch_to_queue(new_task)
            
            return new_task
            
        except Exception as e:
            print(f"处理轨迹反馈时发生错误: {e}")
            return None
    
    def _is_quality_trajectory(self, trajectory: TrajectoryResult) -> bool:
        """判断轨迹质量"""
        return (
            trajectory.success and 
            trajectory.total_duration < 120 and  # 执行时间合理
            len(trajectory.steps) >= 2 and      # 至少有2个步骤
            len(trajectory.steps) <= 15 and     # 步骤数不过多
            trajectory.metadata.get("exit_code") == 0  # 成功执行
        )
```

## 📁 简化项目结构

```
synthesis/
├── __init__.py
├── core/
│   ├── essence_extractor.py     # 轨迹总结器
│   ├── seed_database.py         # 种子任务库
│   ├── task_mutator.py          # 任务变异器  
│   ├── task_orchestrator.py     # 任务编排器
│   ├── synthesis_engine.py      # 任务合成引擎
│   └── feedback_processor.py    # 轨迹反馈处理
├── config/
│   └── synthesis_config.py      # 合成器配置
├── tests/
│   ├── test_extraction.py       # 提取功能测试
│   ├── test_mutation.py         # 变异功能测试
│   └── test_integration.py      # 集成测试
└── main.py                      # 主程序入口
```

## 🚀 使用示例

```python
# main.py
import asyncio
from core.llm_client import LLMClient
from synthesis.core.synthesis_engine import TaskSynthesisEngine
from synthesis.core.feedback_processor import TrajectoryFeedbackProcessor

async def main():
    # 初始化LLM客户端
    llm_client = LLMClient({
        "api_key": "your_openai_api_key",
        "model": "gpt-4o-mini"
    })
    
    # 初始化合成引擎
    synthesis_engine = TaskSynthesisEngine(llm_client)
    
    # 初始化反馈处理器
    feedback_processor = TrajectoryFeedbackProcessor(synthesis_engine)
    
    # 示例：处理一个轨迹反馈
    # trajectory = load_trajectory_from_file("output/trajectories/fibonacci_10.json")
    # new_task = await feedback_processor.process_trajectory_feedback(trajectory)
    
    # 示例：从种子库批量合成任务
    tasks = await synthesis_engine.synthesize_from_seed_library(count=10)
    
    for task in tasks:
        print(f"Generated task: {task.task_id} - {task.description[:50]}...")
    
    # 获取统计信息
    stats = await synthesis_engine.get_synthesis_stats()
    print(f"Synthesis stats: {stats}")

if __name__ == "__main__":
    asyncio.run(main())
```

## 🎯 发展路线图 (简化版)

### 第一阶段 (MVP) - 2周
- [x] 实现轨迹总结器基础功能 (LLM调用)
- [x] 构建种子任务数据库 (SQLite)
- [x] 实现基础任务变异 (参数、复杂度、领域)
- [x] 任务编排器 (预定义工具列表)
- [ ] 集成测试

### 第二阶段 (优化) - 1周  
- [ ] LLM prompt优化
- [ ] 数据库性能优化
- [ ] 变异算法改进
- [ ] 错误处理完善

### 第三阶段 (扩展) - 后续
- [ ] 支持更多变异类型
- [ ] 动态工具管理
- [ ] 质量评估机制
- [ ] 与沙盒环境完整集成
