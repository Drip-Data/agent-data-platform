# 🎯 任务合成器系统开发方案

## 📋 项目概述

基于现有的Agent数据平台架构，将**核心模块1：任务合成系统**作为独立的Docker服务集成到现有的容器化架构中，与**核心模块2：沙盒执行环境**形成完整的数据闭环。

## 🏗️ 系统架构分析

### 现有架构（核心模块2）
```
├── redis (队列服务)
├── dispatcher (任务分发器)  
├── sandbox-runtime (沙盒执行环境) × 2副本
├── web-runtime (Web导航运行时)
├── vllm (推理服务，可选)
├── prometheus (监控)
└── grafana (仪表板)
```

### 目标架构（集成任务合成器）
```
├── redis (队列服务)
├── synthesis-engine (新增：任务合成器) 
├── dispatcher (任务分发器)  
├── sandbox-runtime (沙盒执行环境) × 2副本
├── web-runtime (Web导航运行时)
├── vllm (推理服务，可选)
├── prometheus (监控)
└── grafana (仪表板)
```

## 🔄 数据流设计

### 当前数据流
```
tasks.jsonl → dispatcher → redis队列 → runtime → 轨迹输出
```

### 目标数据流
```
初始种子任务 → synthesis-engine → redis队列 → runtime → 轨迹输出
                    ↑                                      ↓
                    └──────── 轨迹反馈 ←─────────────────────┘
```

## 📁 项目文件结构设计

```
agent-data-platform/
├── synthesis/                           # 新增：任务合成器模块
│   ├── __init__.py
│   ├── Dockerfile                       # 合成器Docker配置
│   ├── requirements.txt                 # 合成器依赖
│   ├── main.py                         # 合成器主程序
│   ├── core/
│   │   ├── __init__.py
│   │   ├── essence_extractor.py        # 轨迹总结器
│   │   ├── seed_database.py            # 种子任务库
│   │   ├── task_mutator.py             # 任务变异器
│   │   ├── task_orchestrator.py        # 任务编排器
│   │   ├── synthesis_engine.py         # 合成引擎
│   │   └── feedback_processor.py       # 轨迹反馈处理器
│   ├── config/
│   │   ├── __init__.py
│   │   └── settings.py                 # 配置管理
│   ├── data/
│   │   └── seed_tasks.db              # SQLite种子库（持久化）
│   └── tests/
│       ├── test_extraction.py
│       ├── test_mutation.py
│       └── test_integration.py
├── core/                               # 现有共享接口
│   ├── interfaces.py                  # TaskSpec等定义
│   ├── llm_client.py                  # 现有LLM统一客户端 ✅
│   └── dispatcher.py                  # 任务分发器
├── runtimes/                          # 现有运行时
│   ├── sandbox/
│   └── web_navigator/
├── docker-compose.yml                 # 更新：添加synthesis服务
├── docker-compose.dev.yml            # 新增：开发环境配置
└── README.md                          # 更新：项目文档
```

## 🔧 核心组件实现计划

### 阶段1：基础框架搭建 (2-3天)

#### 1.1 创建项目结构
- [ ] 创建`synthesis/`目录和基础文件
- [ ] 配置`synthesis/requirements.txt`
- [ ] 编写`synthesis/Dockerfile`
- [ ] 更新`docker-compose.yml`

#### 1.2 复用现有LLM客户端
**重要更新**：直接使用现有的 `core/llm_client.py`，支持vLLM、OpenAI、Gemini、DeepSeek等多种API

```python
# synthesis/core/synthesis_llm.py
from core.llm_client import LLMClient
import json
import logging

logger = logging.getLogger(__name__)

class SynthesisLLMClient:
    """基于现有LLMClient的任务合成专用客户端"""
    
    def __init__(self, config: Dict):
        # 直接使用现有的LLM客户端
        self.llm_client = LLMClient(config)
        
    async def extract_task_essence(self, trajectory_context: str) -> str:
        """调用LLM提取任务本质"""
        prompt = self._build_extraction_prompt(trajectory_context)
        # 使用现有的通用API调用方法
        return await self.llm_client._call_api(prompt)
    
    async def mutate_task(self, essence_data: str, mutation_type: str) -> str:
        """调用LLM进行任务变异"""
        prompt = self._build_mutation_prompt(essence_data, mutation_type)
        return await self.llm_client._call_api(prompt)
    
    async def orchestrate_task(self, mutated_task: str, tools_list: List[str]) -> str:
        """调用LLM进行任务编排"""
        prompt = self._build_orchestration_prompt(mutated_task, tools_list)
        return await self.llm_client._call_api(prompt)
```

#### 1.3 基础配置管理
```python
# synthesis/config/settings.py
from pydantic import BaseSettings

class SynthesisSettings(BaseSettings):
    redis_url: str = "redis://redis:6379"
    database_path: str = "/app/data/seed_tasks.db"
    synthesis_batch_size: int = 10
    vllm_url: str = "http://vllm:8000"  # 复用现有vLLM服务
    
    class Config:
        env_prefix = ""
```

### 阶段2：轨迹总结器实现 (3-4天)

#### 2.1 轨迹总结器
```python
# synthesis/core/essence_extractor.py
from core.interfaces import TrajectoryResult
from synthesis.core.synthesis_llm import SynthesisLLMClient

class TrajectoryEssenceExtractor:
    """基于现有LLM客户端的轨迹本质提取器"""
    
    def __init__(self, config: Dict):
        # 使用现有LLM客户端的配置和接口
        self.llm_client = SynthesisLLMClient(config)
        
    async def extract_essence(self, trajectory: TrajectoryResult) -> TaskEssence:
        """从轨迹中提取任务本质"""
        trajectory_context = self._format_trajectory_for_llm(trajectory)
        
        # 调用LLM进行轨迹分析
        llm_response = await self.llm_client.extract_task_essence(trajectory_context)
        
        # 解析并构造TaskEssence
        essence = self._parse_llm_response(llm_response, trajectory)
        return essence
    
    def _build_extraction_prompt(self, trajectory_context: str) -> str:
        """构建任务本质提取的专用prompt"""
        return f"""你是任务分析专家，需要从Agent执行轨迹中提取任务本质。

请分析以下执行轨迹，提取出：
1. task_type: 任务类型 (code/web/reasoning)
2. domain: 领域分类 (math_algorithms/data_processing/web_automation等)
3. query: 核心任务意图的简洁描述
4. complexity_level: 复杂度等级 (simple/medium/complex)
5. success_pattern: 成功执行的关键模式

执行轨迹：
{trajectory_context}

请按照JSON格式返回分析结果：
{{
  "task_type": "...",
  "domain": "...", 
  "query": "...",
  "complexity_level": "...",
  "success_pattern": {{
    "key_steps": "...",
    "execution_pattern": "...",
    "success_indicators": "..."
  }}
}}"""
```

### 阶段3：任务变异器实现 (2-3天)

#### 3.1 任务变异器（基于现有LLM）
```python
# synthesis/core/task_mutator.py
class TaskMutator:
    """基于现有LLM客户端的任务变异器"""
    
    def __init__(self, config: Dict):
        self.llm_client = SynthesisLLMClient(config)
    
    async def parameter_mutation(self, essence: TaskEssence) -> Dict:
        """参数变异 - 调用现有LLM接口"""
        prompt = self._build_parameter_mutation_prompt(essence)
        response = await self.llm_client.mutate_task(essence.to_dict(), "parameter")
        return self._parse_mutation_response(response)
    
    async def complexity_mutation(self, essence: TaskEssence) -> Dict:
        """复杂度变异 - 调用现有LLM接口"""  
        prompt = self._build_complexity_mutation_prompt(essence)
        response = await self.llm_client.mutate_task(essence.to_dict(), "complexity")
        return self._parse_mutation_response(response)
```

### 阶段4：任务编排器 (2-3天)

#### 4.1 任务编排器（复用现有工具列表）
```python
# synthesis/core/task_orchestrator.py
class TaskOrchestrator:
    """任务编排器，生成符合现有接口的TaskSpec"""
    
    def __init__(self, config: Dict):
        self.llm_client = SynthesisLLMClient(config)
        # 使用现有系统中已定义的工具列表
        self.available_tools = {
            "code": ["python_executor", "shell_executor", "file_operations"],
            "web": ["browser", "web_search", "form_filling"],
            "reasoning": ["llm_reasoning", "data_analysis"]
        }
    
    async def orchestrate_task(self, mutated_task: Dict, essence: TaskEssence) -> TaskSpec:
        """编排任务，生成标准TaskSpec"""
        tools_list = self.available_tools.get(essence.task_type, ["python_executor"])
        
        # 调用LLM进行任务编排
        llm_response = await self.llm_client.orchestrate_task(
            json.dumps(mutated_task), 
            tools_list
        )
        
        # 构造符合现有接口的TaskSpec
        return self._build_task_spec(llm_response, essence, tools_list)
```

## 🐳 Docker配置方案

### 1. 任务合成器Dockerfile

```dockerfile
# synthesis/Dockerfile
FROM python:3.10-slim

WORKDIR /app

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    curl \
    sqlite3 \
    && rm -rf /var/lib/apt/lists/*

# 安装Python依赖
COPY synthesis/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 复制源码（包含现有的core模块）
COPY synthesis/ ./synthesis/
COPY core/ ./core/

# 创建数据目录
RUN mkdir -p /app/data /app/logs

# 健康检查
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8003/health || exit 1

# 暴露监控端口
EXPOSE 8003

CMD ["python", "-m", "synthesis.main"]
```

### 2. Docker Compose配置更新

```yaml
# 在现有docker-compose.yml中添加
synthesis-engine:
  build:
    context: .
    dockerfile: ./synthesis/Dockerfile
  environment:
    - REDIS_URL=redis://redis:6379
    - VLLM_URL=http://vllm:8000  # 复用现有vLLM服务
    # LLM API配置（继承现有配置）
    - GEMINI_API_KEY=${GEMINI_API_KEY}
    - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}  
    - OPENAI_API_KEY=${OPENAI_API_KEY}
    - DATABASE_PATH=/app/data/seed_tasks.db
    - LOG_LEVEL=INFO
    - SYNTHESIS_BATCH_SIZE=10
    - FEEDBACK_ENABLED=true
  depends_on:
    redis:
      condition: service_healthy
    vllm:
      condition: service_healthy  # 依赖现有vLLM服务
  volumes:
    - ./synthesis/data:/app/data  # 持久化种子库
    - ./output:/app/output        # 共享轨迹输出
  ports:
    - "8003:8003"  # 监控端口
  restart: unless-stopped
  logging:
    driver: "json-file"
    options:
      max-size: "100m"
      max-file: "3"
```

## 🔌 与现有系统集成方案

### 1. 复用现有LLM配置

**优势**：
- ✅ 无需重新开发LLM客户端
- ✅ 自动继承现有的多API支持（vLLM、Gemini、DeepSeek、OpenAI）
- ✅ 复用现有的API密钥配置和优先级检测机制
- ✅ 继承现有的错误处理和重试逻辑

**集成方式**：
```python
# synthesis组件直接导入现有LLM客户端
from core.llm_client import LLMClient

# 在合成器中初始化时传入现有配置
config = {
    "vllm_url": "http://vllm:8000",  # 使用现有vLLM服务
    # 其他配置从环境变量自动读取
}
llm_client = LLMClient(config)
```

### 2. Redis队列设计

#### 现有队列
```
tasks:code      # 代码任务队列
tasks:web       # Web任务队列
```

#### 新增队列
```
tasks:synthesized    # 合成任务队列
trajectories:feedback # 轨迹反馈队列（新增）
```

### 3. 环境变量继承

任务合成器将直接继承现有的环境变量配置：

```bash
# 现有的LLM配置（无需修改）
GEMINI_API_KEY=your_gemini_api_key
DEEPSEEK_API_KEY=your_deepseek_api_key  
OPENAI_API_KEY=your_openai_api_key
VLLM_URL=http://vllm:8000

# 新增的合成器配置
SYNTHESIS_BATCH_SIZE=10
FEEDBACK_ENABLED=true
```

## 📅 开发时间计划

### 第1周：基础框架
- Day 1-2: 项目结构搭建和Docker配置
- Day 3-4: 集成现有LLM客户端，创建合成专用包装器
- Day 5: 基础测试和调试

### 第2周：核心功能
- Day 1-3: 轨迹总结器实现（基于现有LLM）
- Day 4-5: 种子任务库实现

### 第3周：任务变异
- Day 1-2: 任务变异器实现（调用现有LLM）
- Day 3-4: 任务编排器实现（复用现有工具列表）
- Day 5: 变异功能测试

### 第4周：系统集成
- Day 1-3: 合成引擎和反馈处理器
- Day 4-5: Redis队列集成和测试

### 第5周：完善和部署
- Day 1-2: 监控和日志系统
- Day 3-4: 端到端测试
- Day 5: 生产环境部署

## 🎯 成功标准

### 技术指标
- [ ] 合成器能成功启动并连接现有LLM服务
- [ ] 轨迹反馈处理成功率 > 95%
- [ ] 任务生成延迟 < 10秒/任务（利用现有LLM优化）
- [ ] 生成任务的执行成功率 > 80%
- [ ] 与现有LLM配置完全兼容

### 业务指标
- [ ] 种子库每日增长 > 100条
- [ ] 数据闭环正常运行
- [ ] 任务多样性满足要求
- [ ] 系统稳定运行7×24小时

## 🔄 用户LLM选择权

基于现有的 `LLMClient` 实现，用户拥有完全的LLM选择权：

### 1. 自动检测机制
```python
# 现有LLMClient的自动检测优先级：
# 1. Gemini (如果设置了 GEMINI_API_KEY)
# 2. DeepSeek (如果设置了 DEEPSEEK_API_KEY)  
# 3. OpenAI (如果设置了 OPENAI_API_KEY)
# 4. vLLM本地服务 (默认回退)
```

### 2. 用户配置方式
```bash
# 用户只需要设置对应的API密钥
export GEMINI_API_KEY="your_key"     # 使用Gemini
# 或
export DEEPSEEK_API_KEY="your_key"   # 使用DeepSeek  
# 或
export OPENAI_API_KEY="your_key"     # 使用OpenAI
# 或不设置任何密钥，自动使用本地vLLM
```

### 3. 成本控制建议
- **开发测试**：使用本地vLLM（免费）
- **性价比优先**：使用Gemini API（成本低）
- **质量优先**：使用GPT-4或DeepSeek-Coder
- **完全自主**：使用本地vLLM部署开源模型

## 💡 关键优势

通过复用现有LLM基础设施，我们获得：

1. **零重复开发**：直接使用经过验证的LLM客户端
2. **配置一致性**：与现有runtime保持相同的LLM配置方式  
3. **用户友好**：无需额外配置，继承现有API设置
4. **成本可控**：利用现有的本地vLLM服务作为免费选项
5. **扩展性强**：自动支持未来添加的新LLM提供商

---

这个修改后的方案是否更符合您的要求？现在任务合成器将完全复用现有的LLM基础设施，用户可以继续使用已配置的LLM服务，无需额外配置。 