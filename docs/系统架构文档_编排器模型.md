# 系统架构：编排器模型

本文档旨在概述本智能代理系统的核心架构，该架构围绕一个中心的“编排器”（Orchestrator）模型构建。此设计将代理的推理能力（“大脑”）与其执行能力（“四肢”）完全分离，从而创建了一个灵活、可扩展且功能强大的系统。

## 1. 核心设计哲学

本系统的运作基于一个简单而强大的原则：**LLM负责提议，系统负责执行。**

-   **大脑 (LLM)**: 负责所有的推理、规划和决策。它以结构化的XML格式制定计划。
-   **神经中枢 (Orchestrator)**: `EnhancedReasoningRuntime` 类扮演着协调者的角色。它负责解释LLM的计划，将任务分派给正确的工具，并格式化结果以供LLM观察。
-   **四肢 (MCP Servers)**: 每一个MCP服务器都是一个专门化的工具（例如，代码执行、网页浏览），在被调用时执行特定的功能。

## 2. 系统架构图 (Mermaid)

```mermaid
graph TD
    subgraph "用户/任务来源"
        A[任务输入 TaskSpec]
    end

    subgraph "核心控制层 (Control Plane)"
        B(TaskManager)
        C{EnhancedReasoningRuntime (Orchestrator)}
        D[ReasoningPromptBuilder]
    end

    subgraph "推理与决策 (Reasoning & Decision)"
        E[LLMClient]
        F[[Google Gemini API]]
    end

    subgraph "工具执行层 (Execution Plane)"
        G[ToolScoreClient]
        subgraph "MCP服务器 (工具集)"
            H1[Microsandbox Server]
            H2[BrowserUse Server]
            H3[DeepSearch Server]
            H4[...]
        end
    end

    subgraph "数据输出"
        I[轨迹日志 Trajectory Log]
    end

    %% 流程连接
    A -- 任务规格 --> B
    B -- 分发任务 --> C
    C -- 1. 构建初始Prompt --> D
    D -- Prompt模板 --> C
    C -- 2. 调用LLM (携带Prompt) --> E
    E -- API请求 --> F
    F -- XML计划 --> E
    E -- XML计划 --> C
    C -- 3. 解析XML并决定执行 --> G
    G -- 统一接口调用 --> H1
    G -- 统一接口调用 --> H2
    G -- 统一接口调用 --> H3
    H1 -- 结果 --> G
    H2 -- 结果 --> G
    H3 -- 结果 --> G
    G -- 4. 返回工具结果 --> C
    C -- 5. 将结果注入历史 --> E
    C -- 6. 记录完整轨迹 --> I

    %% 样式
    style C fill:#f9f,stroke:#333,stroke-width:2px
    style G fill:#bbf,stroke:#333,stroke-width:2px
```

## 3. 逐步工作流程

1.  **任务入口**: 一个`TaskSpec`���任务规格）被提交给`TaskManager`，它作为系统的入口点，并将任务路由到`EnhancedReasoningRuntime`。

2.  **提示词构建**: `EnhancedReasoningRuntime`（我们的编排器）开始其主循环。它首先调用`ReasoningPromptBuilder`来动态地组装一个详细的系统提示。该提示包含了用户的任务、XML规则，以及一个从正在运行的MCP服务器上动态获取的所有可用工具及其能力的列表。

3.  **LLM提议计划**: 编排器通过`LLMClient`将完整的提示发送给Gemini API。至关重要的一步是，它在API调用中包含了`stop_sequences`（如`<execute_tools />`）。这会强制LLM在为当前步骤制定完行动计划后立即停止生成文本。LLM返回一个响应，其中包含其在`<think>`块中的思考过程和一个在`<sequential>`或`<parallel>`块中的行动计划。

4.  **编排器解析与分派**: 编排器接收到XML计划。它解析XML以理解LLM的意图。
    -   如果计划是`<sequential>`，它会提取序列中的**第一个动作**。
    -   如果计划是`<parallel>`，它会提取**所有动作**以供并发执行。

5.  **统一工具执行**: 编排器**不会直接调用工具**。相反，它将标准化的动作指令发送给`ToolScoreClient`。该客户端充当所有工具的统一网关，负责根据服务名称（如`microsandbox`）将请求路由到正确的MCP服务器。

6.  **MCP服务执行**: 目标MCP服务器（例如`microsandbox_server`）接收请求，执行具体动作（例如`microsandbox_execute`），并将结果返回给`ToolScoreClient`。

7.  **结果观察与循环**: `ToolScoreClient`将结果传回给编排器。然后，编排器会：
    a. 将结果包装在`<result>`标签中。
    b. 将其作为一个新的`assistant`消息追加到对话历史中。
    c. 将整个回合（思考、行动、结果）记录到轨迹日志文件中，以供未来训练使用。
    d. **循环**，回到第3步，将更新后的历史记录再次发送给LLM，供其进行下一步决策。

这个循环会一直持续，直到LLM确定任务完成并输出`Final Answer:`标签。

## 4. 关键架构原则

-   **关注点分离 (Separation of Concerns)**: “思考者”（LLM）与“执行者”（MCP服务器）被完全解耦。编排器作为中间桥梁，使两者可以独立演进。
-   **动态发现 (Dynamic Discovery)**: 编排器没有硬编码任何关于特定工具的知识。它在运行时通过`toolscore_client`查询MCP服务器来了解哪些工具是可用的。
-   **可扩展性 (Extensibility)**: 要添加一个新工具，只需创建一个新的MCP服务器，并让它实现`get_capabilities`方法即可。核心的编排器代码完全不需要改动。
-   **数据驱动设计 (Data-Driven by Design)**: 整个架构的设计天然地就会产生高质量的、用于现代强化学习（RL）智能体训练的`(State, Action, Observation)`数据。
